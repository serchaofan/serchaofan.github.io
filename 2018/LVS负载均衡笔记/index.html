<!DOCTYPE html>
<html lang="zh-CN">
  <head hexo-theme='https://github.com/volantis-x/hexo-theme-volantis/tree/4.3.1'>
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
  
  <!-- 渲染优化 -->
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://cdn.jsdelivr.net'>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <link rel="preload" href="/css/first.css" as="style">
  

  <!-- 页面元数据 -->
  
  <title>LVS负载均衡学习笔记 - TianyiGu&#39;s Blog</title>
  
    <meta name="keywords" content="server,负载均衡,LVS,keepalived">
  

  

  <!-- feed -->
  

  <!-- import meta -->
  

  <!-- link -->
  
    <link rel="shortcut icon" type='image/x-icon' href="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202202240150263.jpg">
  

  <!-- import link -->
  

  
    
<link rel="stylesheet" href="/css/first.css">

  

  
  <link rel="stylesheet" href="/css/style.css" media="print" onload="this.media='all';this.onload=null">
  <noscript><link rel="stylesheet" href="/css/style.css"></noscript>
  

  <script id="loadcss"></script>

  
<script>
if (/*@cc_on!@*/false || (!!window.MSInputMethodContext && !!document.documentMode))
    document.write(
	'<style>'+
		'html{'+
			'overflow-x: hidden !important;'+
			'overflow-y: hidden !important;'+
		'}'+
		'.kill-ie{'+
			'text-align:center;'+
			'height: 100%;'+
			'margin-top: 15%;'+
			'margin-bottom: 5500%;'+
		'}'+
	'</style>'+
    '<div class="kill-ie">'+
        '<h1><b>抱歉，您的浏览器无法访问本站</b></h1>'+
        '<h3>微软已经于2016年终止了对 Internet Explorer (IE) 10 及更早版本的支持，<br/>'+
        '继续使用存在极大的安全隐患，请使用当代主流的浏览器进行访问。</h3><br/>'+
        '<a target="_blank" rel="noopener" href="https://www.microsoft.com/zh-cn/WindowsForBusiness/End-of-IE-support"><strong>了解详情 ></strong></a>'+
    '</div>');
</script>


<noscript>
	<style>
		html{
			overflow-x: hidden !important;
			overflow-y: hidden !important;
		}
		.kill-noscript{
			text-align:center;
			height: 100%;
			margin-top: 15%;
			margin-bottom: 5500%;
		}
	</style>
    <div class="kill-noscript">
        <h1><b>抱歉，您的浏览器无法访问本站</b></h1>
        <h3>本页面需要浏览器支持（启用）JavaScript</h3><br/>
        <a target="_blank" rel="noopener" href="https://www.baidu.com/s?wd=启用JavaScript"><strong>了解详情 ></strong></a>
    </div>
</noscript>

</head>

  <body>
    

<header id="l_header" class="l_header auto shadow blur show" style='opacity: 0' >
  <div class='container'>
  <div id='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h m-phone' id="pjax-header-nav-list">
        <li><a id="s-comment" class="fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li><a id="s-toc" class="s-toc fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
            <img no-lazy class='logo' src='https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202202240150263.jpg'/>
          
          
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h m-pc'>
          
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>

			<ul class='switcher nav-list-h m-phone'>
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

    <div id="l_body">
      <div id="l_cover">
  
    
        <div id="full" class='cover-wrapper post dock' style="display: none;">
          
            <div class='cover-bg lazyload placeholder' data-bg="https://uploadbeta.com/api/pictures/random/?key=BingEverydayWallpaperPicture"></div>
          
          <div class='cover-body'>
  <div class='top'>
    
    
      <p class="title">Volantis</p>
    
    
  </div>
  <div class='bottom'>
    <div class='menu navigation'>
      <div class='list-h'>
        
          
            <a href="/v4/getting-started/"
              
              
              id="v4getting-started">
              <img src='https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f5c3.svg'><p>文档</p>
            </a>
          
            <a href="/faqs/"
              
              
              id="faqs">
              <img src='https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f516.svg'><p>帮助</p>
            </a>
          
            <a href="/examples/"
              
              
              id="examples">
              <img src='https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f396.svg'><p>示例</p>
            </a>
          
            <a href="/contributors/"
              
              
              id="contributors">
              <img src='https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f389.svg'><p>社区</p>
            </a>
          
            <a href="/archives/"
              
              
              id="archives">
              <img src='https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f4f0.svg'><p>博客</p>
            </a>
          
            <a target="_blank" rel="noopener" href="https://github.com/volantis-x/hexo-theme-volantis/"
              
              
              id="https:githubcomvolantis-xhexo-theme-volantis">
              <img src='https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f9ec.svg'><p>源码</p>
            </a>
          
        
      </div>
    </div>
  </div>
</div>

          <div id="scroll-down" style="display: none;"><i class="fa fa-chevron-down scroll-down-effects"></i></div>
        </div>
    
  
  </div>

      <div id="safearea">
        <div class="body-wrapper" id="pjax-container">
          

<div class='l_main'>
  <article class="article post white-box reveal md shadow article-type-post" id="post" itemscope itemprop="blogPost">
  


  
  <div class="article-meta" id="top">
    
    
    
      <h1 class="title">
        LVS负载均衡学习笔记
      </h1>
      <div class='new-meta-box'>
        
          
            
  <div class='new-meta-item category'>
    <a class='notlink'>
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <a class="category-link" href="/categories/%E5%BA%94%E7%94%A8%E8%BF%90%E7%BB%B4/">应用运维</a>
    </a>
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2018年5月27日</p>
  </a>
</div>

          
        
      </div>
    
  </div>


  
  
  <span id="more"></span>
<h1 id="LVS-原理"><a href="#LVS-原理" class="headerlink" title="LVS 原理"></a>LVS 原理</h1><p>LVS（Linux Virtual Server）Linux 虚拟服务器是由章文嵩于 1998 年开发的负载均衡软件，提供<strong>传输层</strong>和<strong>应用层</strong>的负载均衡，传输层的负载均衡工具为 IPVS，应用层的负载均衡工具为 KTCPVS。</p>
<h2 id="LVS-集群的通用体系结构"><a href="#LVS-集群的通用体系结构" class="headerlink" title="LVS 集群的通用体系结构"></a>LVS 集群的通用体系结构</h2><p>LVS 集群采用三层结构：</p>
<ul>
<li><p>负载调度器（load balancer）：整个集群的前端机，将网络请求无缝调度到真实服务器上，使服务器集群的结构对客户透明。因为所有的操作都是在 Linux 内核完成的，调度开销很小，所以具有很高的吞吐率。</p>
</li>
<li><p>服务器池（server pool）：是一组真正执行客户请求的服务器。服务器池的结点数目是可变的，可以在服务器池中增加服务器来满足不断增长的请求负载。对大多数网络服务来说，请求间不存在很强的相关性，请求可以在不同的结点上并行执行。</p>
</li>
<li><p>共享存储（shared storage）：为服务器池提供一个共享的存储区，通常是数据库、网络文件系统或者分布式文件系统，这样很容易使得服务器池拥有相同的内容，提供相同的服务。需要一个分布式锁管理器（Distributed Lock Manager）来保证应用程序在不同结点上并发访问的一致性。</p>
<p><img src="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220101395.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220101395.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p>
</li>
</ul>
<p>前端负载均衡器称为 Director Server（DR），后端的实际服务器称为 Real Server(RS)，IP 虚拟服务器软件称为 IP Virtual Server（IPVS），IPVS 工作在 Linux 内核中。在调度器的实现技术中，IP 负载均衡技术的效率是最高的。</p>
<p><strong>LVS 的几种 IP 地址</strong></p>
<ul>
<li>VIP：virtual IP，DR 上接收外网数据包的网卡 IP 地址</li>
<li>DIP：director IP，DR 上转发数据包到 RS 的网卡 IP 地址</li>
<li>RIP：real IP，RS 的 IP 地址</li>
<li>CIP：client IP，客户端 IP 地址</li>
</ul>
<p><strong>为什么要用共享存储？</strong><br>共享存储是可选的，但若网络服务需要相同的内容，应该使用共享存储，否则无共享结构的代价会很大，每台服务器需要一样大的存储空间，任何更新需要涉及每一台服务器，系统的维护代价会非常高。分布式文件系统提供良好的<strong>伸缩性和可用性</strong>，分布式文件系统<strong>在每台服务器使用本地硬盘作 Cache</strong>，可以使得访问分布式文件系统的速度接近于访问本地硬盘。</p>
<p><strong>如何实现高可用性？</strong><br>调度器上有资源监测进程时刻监视各个服务器结点的健康状况，当服务器对<strong>ICMP ping 不可达</strong>时或者网络服务在<strong>指定的时间内没有响应</strong>时，资源监测进程会通知内核将该服务器<strong>从调度列表中删除</strong>。一旦监测到服务器恢复工作，通知调度器将其加入调度列表，管理员也可通过命令随时向调度列表添加或移除服务器。<br>调度器存在单点故障问题，因此需要对调度器进行主从备份，并用 HeartBeat 机制进行主从故障监测。当从调度器不能听得主调度器的心跳时，从调度器通过 ARP 欺骗 （Gratuitous ARP）来接管集群对外的 VIP，同时接管主调度器的工作来提供负载调度服务。当主调度器恢复后，有两种<strong>恢复机制</strong>。第一种为<strong>主调度器自动变成从调度器（类似抢占）</strong>，另一种为<strong>从调度器释放 VIP，主调度器收回 VIP 继续提供负载调度服务</strong>。<br>当主调度器失效时，<strong>主调度器上所有已建立连接的状态信息将丢失，已有连接会中断。</strong> 客户需要重新连接从调度器，从调度器才会将新连接调度到各个服务器上。因此，调度器在内核中实现了一种高效同步机制，将主调度器的状态信息及时同步到从调度器。当从调度器接管时，绝大部分已建立的连接会持续下去。</p>
<h2 id="三种-IP-负载均衡技术"><a href="#三种-IP-负载均衡技术" class="headerlink" title="三种 IP 负载均衡技术"></a>三种 IP 负载均衡技术</h2><ul>
<li><p><strong>VS/NAT</strong>：调度器重写请求报文的目标地址，根据预设算法，将请求分派给实际服务器，实际服务器在响应报文通过调度器时，报文的源地址被重写，再返回给客户。<br><strong>优点：</strong> 节约 IP 地址，能对内部进行伪装<br><strong>缺点：</strong> 效率低，返回给请求方的流量需经过 DR 且请求和响应报文都要 DR 进行地址的重写，当客户端请求增多时，DR 的处理能力会成为瓶颈<br>完整过程：</p>
<ol>
<li>PC 向调度器发送请求报文，调度器收到后根据调度算法选择后端的实际服务器，将报文中目的 IP 与目的端口改写为实际服务器的 IP 地址与端口，并进行转发。</li>
<li>实际服务器收到后，进行处理，将结果返回给调度器</li>
<li>调度器再将源 IP 地址与源端口改回为调度器的 IP 和端口，回复给 PC。</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220101833.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220101833.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="><br><img src="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220101451.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220101451.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="><br><strong>数据包流向：客户端–&gt;调度器–&gt;实际服务器–&gt;调度器–&gt;客户端</strong></p>
</li>
<li><p><strong>VS/TUN</strong>（IP Tunneling）：调度器将请求报文通过 IP 隧道转发到实际服务器，实际服务器将响应报文直接回复给客户，调度器仅需处理请求报文，将请求报文的地址重写，无需重写响应报文的地址，极大解放了调度器，集群系统的最大吞吐量能提高 10 倍。</p>
<p><strong>IP 隧道技术：</strong>又称为 IP 封装技术，可以将带有源和目标 IP 地址的数据报文使用新的源和目标 IP 进行<strong>第二次封装</strong>，这样这个报文就可以发送到一个指定的目标主机上</p>
<p>由于多个 RS 都共享一个隧道 IP（为 VIP），所以需要通过 ARP 进行 IP 地址解析出 MAC，而为了不让 RS 响应 ARP 请求导致出现错误，必须对 RS 进行抑制操作，这样只有 DR 进行 ARP 响应，也就让 PC 认为 DR 就是实际服务器。</p>
<p><strong>注：</strong> 由于调度器不会对 IP 报文进行修改，所以 TCP 报文中的目的端口也不会修改，因此要求 RS 与 DR 的端口号必须一致</p>
<p>完整过程：</p>
<ol>
<li>PC 发送请求给调度器，调度器进行调度算法选择后端的实际服务器，将原报文进行第二次封装，源地址变为 DIP，目的地址变为 RIP，然后通过 IP 隧道发给指定实际服务器。</li>
<li>实际服务器处理完数据后直接回复给 PC</li>
</ol>
<p>实际服务器的 RIP 和 DR 的 DIP 可以不处于同一物理网络中，且 RIP 必须可以和公网通信，即集群节点可以跨互联网实现。<br>实际服务器的隧道接口上需要配置 VIP 地址，以便接收 DR 转发的数据包，以及作为响应报文的源 IP。<br>DR 给 RS 时需要借助隧道，隧道外层的 IP 头部的源 IP 是 DIP，目标 IP 是 RIP。而 RS 响应给客户端的 IP 头部是根据隧道内层的 IP 头分析得到的，源 IP 是 VIP，目标 IP 是 CIP。这样客户端就无法区分这个 VIP 到底是 DR 的还是服务器组中的。</p>
<p>VS/TUN 模式一般会用来负载调度缓存服务器组，这些缓存服务器一般放置在不同网络环境，可以就近返回数据给客户端。在请求对象不能在缓存服务器本地找到的情况下，缓存服务器要向源服务器发请求，将结果取回，最后将结果返回给客户。</p>
<p><img src="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220101770.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220101770.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="><br><img src="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220102531.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220102531.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="><br><strong>数据包流向：客户端–&gt;调度器–&gt;实际服务器–&gt;客户端</strong></p>
</li>
<li><p><strong>VS/DR</strong>（Direct Routing）：与 VS/TUN 类似，但调度器改写的是数据包的目的 MAC 地址，通过链路层进行负载分担。此法没有 IP 隧道的开销，但要求调度器与实际服务器<strong>必须在同一网段</strong>，也就是说 RIP 可用公网地址。</p>
<p>完整过程：</p>
<ol>
<li>PC 向调度器发送请求，调度器根据调度算法选择后端实际服务器，将数据帧的目的 MAC 改写为该实际服务器的 MAC 地址，并转发。</li>
<li>实际服务器收到后处理完数据后直接将结果回复给 PC</li>
</ol>
<p><strong>注：</strong>因为与 VS/TUN 类似，直接修改以太网帧，所以对于 IP 报文不会做修改，因此<strong>RS 的端口号必须与 DR 一致</strong>。且<strong>RS 上必须配置 VIP（通过配置环回口 IP 地址），VIP 为网卡别名的 IP 地址，仅用于回复数据包时使用作为源地址，不能用于通信</strong>。由于流出接口为 RIP 所在网卡接口，因此源 MAC 地址为 RIP 所在接口的 MAC 地址。且<strong>并不支持端口映射。</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220102386.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220102386.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="><br><strong>数据包流向：客户端–&gt;调度器–&gt;实际服务器–&gt;客户端</strong></p>
</li>
</ul>
<p><strong>三种模式的比较</strong><br>DR 和 TUN 模式的性能高于 NAT，因为不需要 DR 对响应报文的操作<br>DR 性能高于 TUN，因为不需要维护 IP 隧道<br>DR 中调度器和实际服务器必须在同一个网段中，TUN 可实现跨网段负载均衡。</p>
<p>只有 NAT 支持端口映射，DR 与 TUN 都不支持。</p>
<p><strong>为什么 VS/TUN 与 VS/DR 要在环回口 L0 上配置 VIP，能不能在出口网卡上配置 VIP？</strong><br>在环回口上配置 VIP 使得 RS 能通过路由收到请求数据包，并将结果返回给客户。不可以将 VIP 配置在出口网卡上，否则真实服务器会响应客户端的 ARP 请求，客户端上的 ARP 表就会记录真实服务器的 MAC，造成混乱，LB 就失效了。必须保证路由器只保存 DR 上的 VIP 对应的 MAC，即只允许 DR 进行 ARP 响应。<br>在环回口配置 VIP 后，还需要设置<code>arp_ignore=1</code>和<code>arp_announce=2</code>来隐藏 RS 上的 VIP。<strong>应该在配置 VIP 之前就设置 arp 参数，防止配置 VIP 后、设置 arp 抑制之前被外界主机发现。</strong></p>
<blockquote>
<p><code>arp_ignore</code>：接收到 ARP 请求时的响应级别。默认为 0。</p>
<ul>
<li>0：响应目的地址是本地任意网卡上的所有 IP 地址的包</li>
<li>1：只响应目的地址恰好是入网卡的 IP 地址的包</li>
</ul>
<p><code>arp_announce</code>：将自己的地址向外通告时的通告级别。默认为 0。</p>
<ul>
<li>0：使用本地任意接口上的任意地址向外通告</li>
<li>1：尽量避免使用本地属于对方子网的 IP 地址向外通告</li>
<li>2：总是使用最佳本地地址向外通告</li>
</ul>
<p><strong>arp_announce 为 2 的含义</strong>：在此模式下将<strong>忽略这个 IP 数据包的源地址</strong>并尝试选择<strong>能与该地址通信的本地地址</strong>。<strong>首要</strong>是选择所有网络接口的子网中包含该数据包目标 IP 地址的本地地址，如果没有发现合适的地址，将选择当前的发送网络接口或其他有可能接收到该 ARP 回应的网络接口来进行发送。</p>
<p>且这两项<strong>对所有参与集群调度的网卡都要设置</strong></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sysctl -w net.ipv4.conf.all.arp_ignore=1</span><br><span class="line">sysctl -w net.ipv4.conf.ens33.arp_ignore=1</span><br><span class="line">sysctl -w net.ipv4.conf.lo.arp_ignore=1</span><br><span class="line">sysctl -w net.ipv4.conf.all.arp_announce=2</span><br><span class="line">sysctl -w net.ipv4.conf.ens33.arp_announce=2</span><br><span class="line">sysctl -w net.ipv4.conf.lo.arp_announce=2</span><br></pre></td></tr></table></figure>

<p><strong>IPVS 如何解决 HTTPS 连接问题？</strong><br>当客户访问 HTTPS 服务时，会先建立一个 SSL 连接，来交换对称公钥加密的证书并协商一个 SSL Key，来加密以后的会话。<strong>在 SSL Key 的生命周期内，后续的所有 HTTPS 连接都使用这个 SSL Key，所以同一客户的不同 HTTPS 连接也存在相关性</strong>。IPVS 调度器提供了持久服务的功能，使得在设定的时间内，来自同一 IP 地址的不同连接会被发送到集群中同一个服务器结点，可以很好地解决客户连接的相关性问题。</p>
<p><strong>可伸缩的缓存服务</strong><br>调度器一般使用 IP 隧道方法（VS/TUN）来架构缓存集群，因为缓存服务器可能在不同地方，而调度器与缓存服务器池可能不在同一个物理网段。若请求对象不能在本地找到，缓存服务器会向源服务器发请求，将结果取回并返回给客户。<br>使用此方法，调度器只调度网页缓存服务器，而缓存服务器将响应数据直接返回给客户，调度器只需要调度一次请求，其余三次都由缓存服务器直接访问 Web 服务器完成。<br>缓存服务器间有专用的组播通道，通过 ICP（Internet Cache Protocol）协议交互信息。当一台 Cache 服务器在本地硬盘中未命中当前请求时，它可以通过 ICP 查询其他 Cache 服务器是否有请求对象的副本，若存在，则从邻近的 Cache 服务器取该对象的副本，这样可以进一步提高 Cache 服务的命中率。</p>
<p><strong>可伸缩邮件服务</strong><br>服务器池有 LDAP 服务器和一组邮件服务器，调度器将 SMTP、POP3、IMAP4 和 HTTP/HTTPS 请求流负载较均衡地分发到各邮件服务器上。系统中可能的瓶颈是 LDAP 服务器，可对 LDAP 服务中 B+树的参数进行优化。<br>若分布式文件系统没有多个存储结点间的负载均衡机制，则需要相应的邮件迁移机制来避免邮件访问的倾斜。</p>
<h2 id="LVS-两种调度方式与八种算法"><a href="#LVS-两种调度方式与八种算法" class="headerlink" title="LVS 两种调度方式与八种算法"></a>LVS 两种调度方式与八种算法</h2><p><strong>两种调度方式</strong></p>
<ul>
<li>静态调度：仅根据调度算法进行调度，不管实际服务器的系统负载</li>
<li>动态反馈调度：会根据实际服务器的系统负载及性能，计算出可以调度的服务器对象</li>
</ul>
<p><strong>八种算法</strong></p>
<ul>
<li>静态调度<ul>
<li><strong>轮询</strong>（Round Robin）：调度器将请求根据调度算法按顺序轮流分配到实际服务器。调度器均等地对待每一台服务器，不管服务器上实际的连接数和系统负载。</li>
<li><strong>加权轮询</strong>（Weighted Round Robin）：根据实际服务器的不同处理能力调度访问请求。使处理能力强的服务器处理更多访问流量，调度器自动询问实际服务器负载情况，并动态调整权值。</li>
<li><strong>目标地址散列</strong>（Destination Hashing）：将请求的目标地址作为散列键，从静态分配的散列表中找出对应的服务器。</li>
<li><strong>源地址散列</strong>（Source Hashing）：将请求的源地址作为散列键，从静态分配的散列表中找出对应服务器。</li>
</ul>
</li>
<li>动态反馈调度<ul>
<li><strong>最少连接</strong>（Least Connections）：动态将网络请求调度到已建立的连接数最少的服务器上。计算方法：活跃连接数 active*256+非活跃连接数 inactive</li>
<li><strong>加权最少连接</strong>（Weighted Least Connections）：当集群中服务器性能差异较大的情况下使用。具有较高权值的服务器将承受较大比例的活动连接负载。调度器可以自动问询真实服务器的负载情况并动态调整权值。<strong>此算法为默认调度算法。</strong> 计算方法：(active*256+inactive)/weight</li>
<li><strong>基于局部性最少连接</strong>（Locality-Based Least Connections）：针对 IP 地址的负载均衡，用于缓存集群系统。根据请求的 IP 地址找出该目标 IP 地址最近使用的服务器，若该服务器不可用，则用最少连接原则选出一个可用的服务器。该算法维护的是从一个目标 IP 地址到<strong>一台</strong>服务器的映射。</li>
<li><strong>带复制的基于局部性最少连接</strong>（Locality-Based Least Connections with Replication）：针对 IP 地址的负载均衡，根据请求的目标 IP 地址找出与之对应的服务器组，按最小连接原则选出一台服务器。若该服务器超载，就在集群中按最小连接原则选出一台服务器，添加到服务器组中。该算法维护的是从一个目标 IP 地址到<strong>一组</strong>服务器的映射。</li>
</ul>
</li>
</ul>
<h2 id="LVS-持久连接"><a href="#LVS-持久连接" class="headerlink" title="LVS 持久连接"></a>LVS 持久连接</h2><p>无论使用哪种算法，LVS 持久化都能实现在一定时间内，将来自 统一客户端请求派发到此前访问过的 RS。</p>
<p>需要持久连接的原因：若连接是基于 SSL 的，则在建立连接时需要交换密钥，认证 CA 等操作，若每次刷新就又分配别的 RS，则会造成资源浪费，速度变慢，因此需要持久连接。</p>
<p>每一次建立连接后，DR 会在内存缓冲区中为每一个客户端与 RS 建立映射关系（该记录也称 <strong>“持久连接模板”</strong> ），并且能做到对同一客户端的所有请求（不局限于一个服务）都定位到一台 RS。</p>
<p>持久连接分类：</p>
<ul>
<li><p><strong>PPC（Persistent Port Connections）持久端口连接</strong>：将来自同一客户端对同一个集群的请求（同一端口）都定向到先前访问的 RS 上。</p>
</li>
<li><p><strong>PCC（Persistent Client Connections）持久客户端连接</strong>：将来自同一客户端对同一个集群所有端口（即所有服务）的请求都定向到先前访问的 RS 上。</p>
</li>
<li><p><strong>PNMPP（Persitent Netfilter Marked Packet Persistence）持久防火墙标记连接</strong>：通过防火墙策略，将对<strong>某类服务几个不同端口的访问</strong>定义成一类。</p>
<p>先对某一特定类型的数据包打上标记，然后再将基于某一类标记的服务送到后台的 RS 上去，后台的 RS 并不识别这些标记。<strong>将持久和防火墙标记结合起来就能够实现端口姻亲功能</strong>，只要是来自某一客户端的对某一特定服务（可以是不同端口）的访问都定向到同一台 RS 上。</p>
</li>
</ul>
<h1 id="KeepAlived-原理"><a href="#KeepAlived-原理" class="headerlink" title="KeepAlived 原理"></a>KeepAlived 原理</h1><p>KeepAlived 用于 RS 的健康状态检查与 LB 主从之间的故障转移（Failover）实现。 Keepalived 实现了一组健康检查器，<strong>根据其健康状况动态自适应地维护和管理负载平衡的服务器池</strong>，支持<strong>4、5、7 层协议</strong>的健康检查。使用<strong>VRRP 实现高可用性</strong>，VRRP 是路由器故障转移的基础实现方法。此外，keepalived 实现了一组到 VRRP 有限状态机的挂钩，提供低级别的高速协议交互。每个 Keepalived 框架可以独立使用或一起使用，以提供弹性基础设施。</p>
<p>Keepalived 采用纯 ANSI/ISO C 编写，围绕一个中央 I/O 多路复用器提供实时网络设计（Realtime Networking Design）。设计重点是在<strong>所有元素之间提供均匀的模块化功能</strong>。</p>
<p>为了确保鲁棒性和稳定性，守护进程 keepalived 分为 3 个不同的进程：</p>
<ul>
<li>一个精简的<strong>父进程负责分支子进程的监控</strong></li>
<li>两个子进程，一个负责<strong>VRRP 框架</strong>，另一个负责<strong>健康检查</strong></li>
</ul>
<p>每个子进程都有自己的调度 I/O 多路复用器，这样 VRRP 调度抖动得到了优化，因为 VRRP 调度比健康检查更关键。这种拆分设计可最小化健康检查外部库的使用情况，并将其自身行为降至最低，使主机闲置，从而避免由其本身造成的故障。</p>
<p>父进程监视框架称为<strong>Watchdog</strong>，每个子进程打开一个套接字，当守护进程引导时，父进程连接到套接字并向子进程周期（5s）发送 hello 包。若父进程无法向子进程套接字发送 hello，则只要重启子进程即可。</p>
<p>Watchdog 设计的优点：<br>从父进程发送到子进程的 hello 数据包通过 I/O 多路复用器调度程序完成，这样可以检测到子进程调度框架中的死循环并能通过使用 sysV 信号来检测死亡的子进程。</p>
<p>Keepalived 使用四个 Linux 内核组件：</p>
<ul>
<li>LVS 框架：使用 getsockopt 和 setsockopt 调用来获取和设置套接字上的选项。</li>
<li>Netfilter 框架：支持 NAT 和伪装（Masquerading）的 IPVS 代码。</li>
<li>Netlink 接口：设置和删除网络接口上的 VRRP 虚拟 IP。</li>
<li>组播：通过组播地址<strong>224.0.0.18</strong>发送 VRRP 通告。</li>
</ul>
<h1 id="LVS-与-KeepAlived-搭建"><a href="#LVS-与-KeepAlived-搭建" class="headerlink" title="LVS 与 KeepAlived 搭建"></a>LVS 与 KeepAlived 搭建</h1><p>首先在 DR 上安装依赖工具包<code>libnl3-devel</code>、<code>popt-static</code>，然后安装<code>ipvsadm</code>。<br><code>ipvsadm</code>是 ipvs 的命令行管理工具，可以定义、删除、查看 virtual service 和 Real Server 的属性。</p>
<p>可通过<code>grep -i &#39;ip_vs&#39; /boot/config-内核版本号</code>查看是否内核中编译了 IPVS 功能</p>
<p><a target="_blank" rel="noopener" href="http://www.linuxvirtualserver.org/software/index.html">ipvsadm 的下载地址</a><br>也可以通过 yum 安装，安装完成后启动并设置开机自启<br><code>systemctl enable ipvsadm</code>,<code>systemctl start ipvsadm</code></p>
<p>ipvsadm 命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ipvsadm选项中，大写选项管理虚拟服务virtual service，小写选项管理关联了虚拟服务的真实服务器RealServer</span><br><span class="line">1. 管理virtual service</span><br><span class="line">    -A --add-service    # 添加virtual service</span><br><span class="line">        -t --tcp-service 服务器IP[:端口]    # TCP服务</span><br><span class="line">        -u --udp-service 服务器IP[:端口]    # UDP服务</span><br><span class="line">        -f --fwmark-service 防火墙标记      # 防火墙标记</span><br><span class="line">        -s --scheduler 算法                # 指定算法</span><br><span class="line">    -E   # 修改，参数与-A一致</span><br><span class="line">    -D   # 删除，参数与-A一致</span><br><span class="line">        -t|-u|-f</span><br><span class="line">    -C   # 清空所有虚拟服务（IPVS规则）</span><br><span class="line">    -L   # 查看所有虚拟服务</span><br><span class="line">        -n 数字格式显示主机地址和端口</span><br><span class="line">        --stats 显示更详细的统计信息（连接数、入站包、出站包量等）</span><br><span class="line">        --rate  显示速率（每秒连接数CPS、每秒入站包个数InPPS、出站包个数OutPPS等）且是实时的</span><br><span class="line">        --timeout 显示会话超时时间（tcp、tcpfin、udp）</span><br><span class="line">        -p    设置持久化连接时长</span><br><span class="line">        --persistent-conn  查看持久化连接情况</span><br><span class="line">        -c    显示当前IPVS的连接状况，实时的</span><br><span class="line">        --sort   排序，是实时的</span><br><span class="line">    -S   # 保存IPVS规则，并输出到屏幕。可通过 &gt;文件，导入到文件</span><br><span class="line">    -R   #载入之前的规则（要指定规则文件）。一般通过 &lt;文件，导入规则</span><br><span class="line"></span><br><span class="line">2. 管理RealServer</span><br><span class="line">    -a   # 添加real server</span><br><span class="line">        -r 指定RS的IP地址和端口</span><br><span class="line">        -g DR模式</span><br><span class="line">        -i TUN模式</span><br><span class="line">        -m NAT模式</span><br><span class="line">        -t|-u|-f</span><br><span class="line">        -w 权重</span><br><span class="line">    -e   # 编辑real server</span><br><span class="line">    -d   # 删除real server</span><br></pre></td></tr></table></figure>

<h2 id="NAT-模式搭建"><a href="#NAT-模式搭建" class="headerlink" title="NAT 模式搭建"></a>NAT 模式搭建</h2><p>实验环境：</p>
<ul>
<li>Client：192.168.205.151</li>
<li>VIP：192.168.205.152</li>
<li>DIP：172.16.184.130</li>
<li>RIP1：172.16.184.131</li>
<li>RIP2：172.16.184.132</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220102332.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220102332.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p>
<p>Client 和 RS 都采用单网卡，但非同一网段。DR 采用双网卡，一张连接 Client，一张连接 RS。且此实验 RS 要用 host-only 网卡，需要设置网关</p>
<p><code>route add default gw 172.16.184.130</code></p>
<p>确保 Server3 和 Server4 的网关配置生效，否则无法给 Client 连接。</p>
<p><strong>注：一定要将网卡配置为静态 IP 地址，不能使用 DHCP 获取，否则配置的网关会自动消失。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># route -n</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         172.16.184.130  0.0.0.0         UG    0      0        0 ens36</span><br><span class="line">172.16.184.0    0.0.0.0         255.255.255.0   U     100    0        0 ens36</span><br><span class="line"># ip route</span><br><span class="line">default via 172.16.184.130 dev ens36</span><br><span class="line">172.16.184.0/24 dev ens36  proto kernel  scope link  src 172.16.184.131  metric 100</span><br></pre></td></tr></table></figure>

<p>Client 请求过程：Client 向 DR 发请求包，VIP 接收，经过 ip_forward 转发到 DIP，然后根据算法选择 RS，将数据包发往 RS。<br>RS 响应过程：RS 向 DR 发响应包，DR 的 DIP 接收响应包，经过 ip_forward 转发到 VIP，最后将包回复给 Client。<br><strong>因为 VIP 与 DIP 不是一个网段，所以 DR 上要开启 ip_forward</strong>，并且要注意 iptables 与 ipvs 不可同时配置。</p>
<p><code>echo &quot;net.ipv4.ip_forward=1&quot; &gt;&gt; /etc/sysctl.conf &amp;&amp; sysctl -p</code></p>
<p>在 Server2 上配置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ipvsadm -A -t 192.168.205.152:80 -s rr</span><br><span class="line">ipvsadm -a -t 192.168.205.152:80 -r 172.16.184.131 -m</span><br><span class="line">ipvsadm -a -t 192.168.205.152:80 -r 172.16.184.131 -m</span><br></pre></td></tr></table></figure>

<p>通过<code>ipvsadm -nL</code>查看 LVS 服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ipvsadm -Ln</span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  192.168.205.152:80 rr</span><br><span class="line">  -&gt; 172.16.184.131:80            Masq    1      0          0</span><br><span class="line">  -&gt; 172.16.184.132:80            Masq    1      0          0</span><br></pre></td></tr></table></figure>

<p>LVS 需要服务器间的时间同步，因此需要在 Server2 上配置 chronyd 服务。修改<code>/etc/chronyd.conf</code>，添加更新源。然后<code>chronyc sources -v</code>自动同步。</p>
<p>然后在 Server3 和 Server4 的 chronyd 配置文件中修改更新源<code>server 192.168.205.152 iburst</code>并自动更新。</p>
<p>在 Client 上多次访问<code>192.168.205.152</code>，因为选择的算法是轮询，所以会有以下现象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># curl 192.168.205.152</span><br><span class="line">Server 3</span><br><span class="line"># curl 192.168.205.152</span><br><span class="line">Server 4</span><br><span class="line"># curl 192.168.205.152</span><br><span class="line">Server 3</span><br><span class="line"># curl 192.168.205.152</span><br><span class="line">Server 4</span><br></pre></td></tr></table></figure>

<p>在 Server2 上查看<code>ipvsadm -L --stats</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ipvsadm -L --stats</span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port               Conns   InPkts  OutPkts  InBytes OutBytes</span><br><span class="line">  -&gt; RemoteAddress:Port</span><br><span class="line">TCP  server2:http                        7       34       20     2235     2240</span><br><span class="line">  -&gt; server3:http                        3       14        8      918      896</span><br><span class="line">  -&gt; server4:http                        4       20       12     1317     1344</span><br></pre></td></tr></table></figure>

<p>修改为 wrr 算法。在 Server2 上修改 IPVS 规则：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ipvsadm -E -t 192.168.205.152:80 -s wrr</span><br><span class="line">ipvsadm -e -t 192.168.205.152:80 -r 172.16.184.131:80 -m -w 5</span><br><span class="line">ipvsadm -e -t 192.168.205.152:80 -r 172.16.184.132:80 -m -w 3</span><br></pre></td></tr></table></figure>

<p>Client 上访问几次，再在 Server2 上查看，可发现访问 Server3 和 Server4 的包数量比例大约为 5:3</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ipvsadm -L -n</span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  192.168.205.152:80 wrr</span><br><span class="line">  -&gt; 172.16.184.131:80            Masq    5      0          22</span><br><span class="line">  -&gt; 172.16.184.132:80            Masq    3      0          13</span><br></pre></td></tr></table></figure>

<h2 id="DR-模式搭建"><a href="#DR-模式搭建" class="headerlink" title="DR 模式搭建"></a>DR 模式搭建</h2><p>环境：</p>
<ul>
<li>DR 的 VIP：172.16.246.140</li>
<li>DIP：172.16.246.134</li>
<li>RIP1：172.16.246.135</li>
<li>RS1 的 VIP：172.16.246.140</li>
<li>RIP2：172.16.246.136</li>
<li>RS2 的 VIP：172.16.246.140</li>
</ul>
<p>一定要确保 DR 和 RS 在同一个交换机上，即都在同一个网段，以及 VIP 都要在同一个网段。</p>
<p><img src="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220102731.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220102731.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p>
<p>首先在 DR 上配置，创建网卡别名<code>ens33:0</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ifconfig ens33:0 172.16.246.140 netmask 255.255.255.0 broadcast 172.16.246.255 up  # 这是临时的，切要确保地址都是静态的，否则过一段时间配的地址会自动删除</span><br><span class="line"></span><br><span class="line"># ifconfig</span><br><span class="line">ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.16.246.134  netmask 255.255.255.0  broadcast 172.16.246.255</span><br><span class="line">......</span><br><span class="line">ens33:0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.16.246.140  netmask 255.255.255.0  broadcast 172.16.246.255</span><br><span class="line">        ether 00:0c:29:bf:f9:0c  txqueuelen 1000  (Ethernet)</span><br></pre></td></tr></table></figure>

<p>在两个后端 RS 服务器上<code>ping</code>DR 上的这两个地址，测试能够联通</p>
<p>然后在 RS 上配置 IP 地址，也确保为静态 IP。并且需要将 RS 的内核参数<code>arp_ignore</code>和<code>arp_announce</code>分别调整。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sysctl -w net.ipv4.conf.all.arp_ignore=1</span><br><span class="line">sysctl -w net.ipv4.conf.ens33.arp_ignore=1</span><br><span class="line">sysctl -w net.ipv4.conf.lo.arp_ignore=1</span><br><span class="line">sysctl -w net.ipv4.conf.all.arp_announce=2</span><br><span class="line">sysctl -w net.ipv4.conf.ens33.arp_announce=2</span><br><span class="line">sysctl -w net.ipv4.conf.lo.arp_announce=2</span><br></pre></td></tr></table></figure>

<p>然后在环回口上配置 VIP，保证 DR、RS 的 VIP 相同。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ifconfig lo:0 172.16.246.140 netmask 255.255.255.255 boardcast 172.16.246.140 up</span><br><span class="line"># 一定要设置netmask为255.255.255.255，否则连接可能出问题</span><br></pre></td></tr></table></figure>

<p>并且配置路由</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">route add -host 172.16.246.140 dev lo:0</span><br><span class="line"></span><br><span class="line"># route</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">172.16.246.0    0.0.0.0         255.255.255.0   U     100    0        0 ens33</span><br><span class="line">s3              0.0.0.0         255.255.255.255 UH    0      0        0 lo</span><br></pre></td></tr></table></figure>

<p>在 DR 上篇配置路由<code>route add -host 172.16.246.140 dev ens33:0</code></p>
<p>确保 RS 与 DR 的防火墙都放行了 http 以及对应端口。</p>
<p>在 DR 上配置 LVS</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ipvsadm -A -t 172.16.246.140:80 -s wlc</span><br><span class="line">ipvsadm -a -t 172.16.246.140:80 -r 172.16.246.135 -g -w 3</span><br><span class="line">ipvsadm -a -t 172.16.246.140:80 -r 172.16.246.136 -g -w 4</span><br></pre></td></tr></table></figure>

<p>在宿主机上测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># curl 172.16.246.140</span><br><span class="line"></span><br><span class="line"># ipvsadm -L</span><br><span class="line">....</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  s1:http wlc</span><br><span class="line">  -&gt; rs1:http                     Route   3      0          13</span><br><span class="line">  -&gt; rs2:http                     Route   4      0          17</span><br></pre></td></tr></table></figure>

<h2 id="持久化配置"><a href="#持久化配置" class="headerlink" title="持久化配置"></a>持久化配置</h2><p><em>仍使用 DR 配置的实验环境</em></p>
<p>只需要配置一条<code>ipvsadm -E -t 172.16.246.140:80 -p 600</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ipvsadm -L -n</span><br><span class="line">.....</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  172.16.246.140:80 wlc persistent 600</span><br><span class="line">  -&gt; 172.16.246.135:80            Route   3      0          0</span><br><span class="line">  -&gt; 172.16.246.136:80            Route   4      0          0</span><br></pre></td></tr></table></figure>

<p>在宿主机上访问<code>172.16.246.140</code>，访问到的是 RS2（即<code>172.16.246.136</code>），在查看 DR 上信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ipvsadm -L -n --persistent-conn</span><br><span class="line">Prot LocalAddress:Port            Weight    PersistConn ActiveConn InActConn</span><br><span class="line">  -&gt; RemoteAddress:Port</span><br><span class="line">TCP  172.16.246.140:80 wlc persistent 600</span><br><span class="line">  -&gt; 172.16.246.135:80            3         0           0          0</span><br><span class="line">  -&gt; 172.16.246.136:80            4         1           0          4</span><br><span class="line">  # 可知RS2已有一个持久化连接</span><br></pre></td></tr></table></figure>

<h2 id="Keepalived-配置"><a href="#Keepalived-配置" class="headerlink" title="Keepalived 配置"></a>Keepalived 配置</h2><p>实验环境：</p>
<ul>
<li>DR：<code>172.16.246.134</code></li>
<li>DR-Backup：<code>172.16.246.133</code></li>
<li>RS1：<code>172.16.246.135</code></li>
<li>RS2：<code>172.16.246.136</code></li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220103723.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220103723.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p>
<p>需要在 DR 和 DR-backup 上安装 keepalived，可直接通过 yum 安装。</p>
<p>设置独立的 keepalived 日志，因为默认 keepalived 日志是记录在<code>/var/log/messages</code>中的。修改<code>/etc/sysconfig/keepalived</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 有以下配置项</span><br><span class="line"># --vrrp               -P    只运行vrrp子进程</span><br><span class="line"># --check              -C    只运行健康检查子进程</span><br><span class="line"># --dont-release-vrrp  -V    不会在守护进程停止时删除VIP和路由</span><br><span class="line"># --dont-release-ipvs  -I    不会在守护进程停止时删除IPVS拓扑</span><br><span class="line"># --dump-conf          -d    备份日志配置文件</span><br><span class="line"># --log-detail         -D    记录详细日志信息</span><br><span class="line"># --log-facility       -S    syslog的号码0-7</span><br><span class="line"></span><br><span class="line"># 默认配置是只有-D</span><br><span class="line">KEEPALIVED_OPTIONS=&quot;-D&quot;</span><br><span class="line"># 添加-S 0</span><br><span class="line">KEEPALIVED_OPTIONS=&quot;-D -S 0&quot;</span><br></pre></td></tr></table></figure>

<p>然后在<code>/etc/rsyslog.conf</code>中添加<code>local0</code>的配置<code>local0.* /var/log/keepalived.log</code>，重启 rsyslog 服务即可。</p>
<p>keepalived 的配置文件<code>/etc/keepalived/keepalived.conf</code>，修改前最好备份。配置文件分为是三个部分：全局配置、VRRPd 配置、LVS 配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 此配置截取自默认配置，仅用于说明参数</span><br><span class="line"># 全局配置</span><br><span class="line">global_defs &#123;</span><br><span class="line">   # 邮件报警功能，可以不要</span><br><span class="line">   notification_email &#123;</span><br><span class="line">     acassen@firewall.loc</span><br><span class="line">   &#125;</span><br><span class="line">   notification_email_from Alexandre.Cassen@firewall.loc  # 告警邮箱地址</span><br><span class="line">   smtp_server 127.0.0.1</span><br><span class="line">   smtp_connect_timeout 30</span><br><span class="line">   router_id LVS_DEVEL       # 标识keepalived服务器的字符串</span><br><span class="line">   vrrp_skip_check_adv_addr</span><br><span class="line">   vrrp_strict</span><br><span class="line">   vrrp_garp_interval 0</span><br><span class="line">   vrrp_gna_interval 0</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># VRRP实例配置</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER       # 角色状态，master或backup</span><br><span class="line">    interface eth0     # 定义vrrp绑定的接口，此网卡是面向集群的网卡</span><br><span class="line">    virtual_router_id 51   # VRID，同实例的该值必须相同</span><br><span class="line">    priority 100           # 优先级，值越大越高</span><br><span class="line">    advert_int 1           # 心跳信息发送间隔，单位秒</span><br><span class="line">    authentication &#123;       # 认证方式</span><br><span class="line">        auth_type PASS     # 密码认证</span><br><span class="line">        auth_pass 1111     # 密码，最多8个字符</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;    # VIP地址设置，只要master节点设置</span><br><span class="line">        192.168.200.16</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># LVS虚拟服务配置</span><br><span class="line">virtual_server 10.10.10.2 1358 &#123;  # VIP与端口</span><br><span class="line">    delay_loop 6              # 健康检查时间间隔</span><br><span class="line">    lb_algo rr                # LB算法</span><br><span class="line">    lb_kind NAT               # LB类型</span><br><span class="line">    persistence_timeout 50    # 持久化时长</span><br><span class="line">    protocol TCP</span><br><span class="line"></span><br><span class="line">    sorry_server 192.168.200.200 1358  # 当所有RS都宕机时，请求发送到的服务器，一般就设为DR或本节点</span><br><span class="line"></span><br><span class="line">    real_server 192.168.200.2 1358 &#123;  # RS的配置</span><br><span class="line">        weight 1           # 权重</span><br><span class="line">        HTTP_GET &#123;         # 健康状况检查的检查方式</span><br><span class="line">        # 常见的有HTTP_GET|SSL_GET|TCP_CHECK|DNS_CHECK|MISC_CHECK</span><br><span class="line">            url &#123;</span><br><span class="line">              path /testurl/test.jsp   # 状态检查url路径的是否健康</span><br><span class="line">              digest 640205b7b0fc66c1ea91c463fac6334d</span><br><span class="line">              #健康状况需要状态码，可以是status_code、digest或digest+status_code</span><br><span class="line">              #digest值用keepalived的genhash命令生成，一般使用status_code即可</span><br><span class="line">              status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3    # 连接超时时间，若超时则认为RS可能宕机</span><br><span class="line">            nb_get_retry 3       # 重试次数，防止误判</span><br><span class="line">            delay_before_retry 3 # 重试时间间隔</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>在 DR 上的配置</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">global_defs &#123;</span><br><span class="line">   notification_email &#123;</span><br><span class="line">     sysadmin@firewall.loc</span><br><span class="line">   &#125;</span><br><span class="line">   notification_email_from Alexandre.Cassen@firewall.loc</span><br><span class="line">   smtp_server 127.0.0.1</span><br><span class="line">   smtp_connect_timeout 30</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">   vrrp_skip_check_adv_addr</span><br><span class="line">   vrrp_strict</span><br><span class="line">   vrrp_garp_interval 0</span><br><span class="line">   vrrp_gna_interval 0</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens33</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 120</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;         # 不同实例的认证密码最好不同，以确保接管正常</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        172.16.246.141       # 虚拟IP，不能和真实IP一致，随便写就行</span><br><span class="line">        172.16.246.142</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">virtual_server 172.16.246.140 80 &#123;       # 虚拟主机</span><br><span class="line">    delay_loop 6</span><br><span class="line">    lb_algo wlc</span><br><span class="line">    lb_kind DR           # LVS类型为DR</span><br><span class="line">    persistence_timeout 50</span><br><span class="line">    protocol TCP</span><br><span class="line">    sorry_server 172.16.246.134 80    # 配置RS全部挂掉后访问的服务器</span><br><span class="line">    real_server 172.16.246.135 80 &#123;       # 后端RS</span><br><span class="line">        weight 1</span><br><span class="line">        HTTP_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">              path /</span><br><span class="line">              status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    real_server 172.16.246.136 80 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        HTTP_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">              path /</span><br><span class="line">              status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以将 DR 上的该配置文件传到 Backup 上，修改配置。还要修改<code>router_id</code>的配置，因为<code>router_id</code>用于标识不同服务器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 只要修改以下配置</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">  state BACKUP</span><br><span class="line">  priority 100</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>都启动 keepalived，使用命令<code>keepalived</code>或者<code>systemctl start keepalived</code>即可</p>
<p>可查看日志文件<code>/var/log/keepalived.log</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">s1 Keepalived[42451]: Starting Healthcheck child process, pid=42452</span><br><span class="line">s1 Keepalived[42451]: Starting VRRP child process, pid=42453</span><br><span class="line">s1 Keepalived_healthcheckers[42452]: Initializing ipvs</span><br><span class="line">s1 Keepalived_healthcheckers[42452]: Opening file &#x27;/etc/keepalived/keepalived.conf&#x27;.</span><br><span class="line">s1 Keepalived_vrrp[42453]: Registering Kernel netlink reflector</span><br><span class="line">s1 Keepalived_vrrp[42453]: Registering Kernel netlink command channel</span><br><span class="line">s1 Keepalived_vrrp[42453]: Registering gratuitous ARP shared channel</span><br><span class="line">s1 Keepalived_vrrp[42453]: Opening file &#x27;/etc/keepalived/keepalived.conf&#x27;.</span><br><span class="line">s1 Keepalived_healthcheckers[42452]: Activating healthchecker for service [172.16.246.140]:80</span><br><span class="line">s1 Keepalived_healthcheckers[42452]: Activating healthchecker for service [172.16.246.140]:80</span><br></pre></td></tr></table></figure>

<p>Keepalived 配置会自动创建 ipvs 策略，此时看<code>ipvsadm -L</code>已是 keepalived 的配置了</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ipvsadm -L -n</span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  172.16.246.140:80 wlc persistent 50</span><br><span class="line">  -&gt; 172.16.246.135:80            Route   1      0          0</span><br><span class="line">  -&gt; 172.16.246.136:80            Route   1      0          0</span><br></pre></td></tr></table></figure>

<p>宿主机上访问服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; curl 172.16.246.140</span><br><span class="line">RS2</span><br><span class="line">&gt; curl 172.16.246.140</span><br><span class="line">RS2</span><br><span class="line">&gt; curl 172.16.246.140</span><br><span class="line">RS2</span><br><span class="line"># 因为设置了持久化，一直访问RS2</span><br></pre></td></tr></table></figure>

<p>此时停止 RS2 的 httpd 服务，再访问服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; curl 172.16.246.140</span><br><span class="line">RS1</span><br><span class="line">&gt; curl 172.16.246.140</span><br><span class="line">RS1</span><br><span class="line"># 成功切换到RS1</span><br></pre></td></tr></table></figure>

<p>恢复 RS2 服务，在 DR 上停止 keepalived。再访问服务，仍能访问，keepalived 配置成功。</p>
<p>将后端 RS 的 httpd 全部关闭，然后再次访问，就会访问到 DR 的页面。</p>
<p><strong>几种时间间隔：</strong></p>
<ul>
<li><code>advert_int</code>：vrrp 主备间发送和接收心跳信息的时间间隔</li>
<li><code>delay_loop</code>：健康状态检查的时间间隔</li>
<li><code>connect_timeout</code>：连接 RS 的超时时间</li>
<li><code>nb_get_retry</code>：一个节点不健康的判定重试次数</li>
<li><code>delay_before_retry</code>：判定某节点可能宕机后等待的时间，之后重试连接</li>
</ul>
<p><strong>几种健康检查：</strong></p>
<ul>
<li><code>TCP_CHECK</code>：TCP 连接来检查后端 RS 是否健康</li>
<li><code>HTTP_GET</code>：获取指定页面检查 RS 是否健康（通过匹配 digest、status_code）</li>
<li><code>SSL_GET</code>：类似 HTTP_GET，但使用的 HTTPS</li>
<li><code>MISC_CHECK</code>：加载自定义健康状态检查脚本来检查对象是否健康（脚本的返回值需要是 0 或 1）</li>
<li><code>DNS_CHECK</code>：通过 DNS 检查 RS 是否健康</li>
</ul>
<p><strong>若出现两台服务器争抢同一 IP 资源时，要先排查两个地方：</strong></p>
<ul>
<li>主备两台服务器之间是否正常通信，如果不正常是否有 iptables 防火墙阻挡</li>
<li>主备两台服务器对应的 keepalived.conf 配置是否出错</li>
</ul>
<p><strong>解决裂脑的常见方案：</strong></p>
<ul>
<li>如果开启防火墙，一定要放行心跳信息，一般通过允许 IP 段解决</li>
<li>拉一条以太网网线作心跳线冗余</li>
<li>通过监控软件监测裂脑</li>
<li>若备节点出现 VIP，且主节点完好正常，则说明发生裂脑了。</li>
</ul>
<h2 id="Keepalived-双实例双主模式配置"><a href="#Keepalived-双实例双主模式配置" class="headerlink" title="Keepalived 双实例双主模式配置"></a>Keepalived 双实例双主模式配置</h2><p>多实例，即业务 A 在 hostA 上是主模式，在 hostB 上是备模式，而业务 B 在 hostA 上是备模式，在 hostB 上是主模式。</p>
<p>实验环境：</p>
<ul>
<li><code>172.17.1.128</code>：业务 A 的 master，业务 B 的 backup</li>
<li><code>172.17.1.129</code>：业务 A 的 backup，业务 B 的 master</li>
<li>业务 A 的 VIP：<code>172.17.1.100</code></li>
<li>业务 B 的 VIP：<code>172.17.1.200</code></li>
</ul>
<p>172,17.1.128 的配置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vrrp_instance BusinessA &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens32</span><br><span class="line">    virtual_router_id 100</span><br><span class="line">    priority 120</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        172.16.1.100/24 dev ens32 label ens32:1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance BusinessB &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens32</span><br><span class="line">    virtual_router_id 200</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        172.16.1.200/24 dev ens32 label ens32:2</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>172.17.1.129 的配置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vrrp_instance BusinessA &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens32</span><br><span class="line">    virtual_router_id 100</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        172.16.1.100/24 dev ens32 label ens32:1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance BusinessB &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens32</span><br><span class="line">    virtual_router_id 200</span><br><span class="line">    priority 120</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        172.16.1.200/24 dev ens32 label ens32:2</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>重新启动 keepalived，查看<code>ip addr</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ens32: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    link/ether 00:0c:29:05:bd:c3 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.16.1.128/24 brd 172.16.1.255 scope global dynamic noprefixroute ens32</span><br><span class="line">       valid_lft 1800sec preferred_lft 1800sec</span><br><span class="line">    inet 172.16.1.100/24 scope global secondary ens32:1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 172.16.1.200/24 scope global secondary ens32:2</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">ens32: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    link/ether 00:0c:29:74:d9:f9 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.16.1.129/24 brd 172.16.1.255 scope global dynamic noprefixroute ens32</span><br><span class="line">       valid_lft 1722sec preferred_lft 1722sec</span><br><span class="line">    inet 172.16.1.200/24 scope global secondary ens32:2</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 172.16.1.100/24 scope global secondary ens32:1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<h2 id="Nginx-负载均衡配合-Keepalived"><a href="#Nginx-负载均衡配合-Keepalived" class="headerlink" title="Nginx 负载均衡配合 Keepalived"></a>Nginx 负载均衡配合 Keepalived</h2><p>实验环境：</p>
<ul>
<li>LB 1: <code>172.16.1.128</code></li>
<li>LB 2: <code>172.16.1.129</code></li>
<li>业务 A VIP：172.16.1.100</li>
<li>业务 B VIP：172.16.1.200</li>
<li>web RS1：172.17.0.2<ul>
<li>业务 A：80 端口</li>
<li>业务 B：81 端口</li>
</ul>
</li>
<li>web RS2：172.17.0.3<ul>
<li>业务 A：80 端口</li>
<li>业务 B：81 端口<br><img src="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220103444.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/serchaofan/picBed/blog/202206220103444.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></li>
</ul>
</li>
</ul>
<p>RS1 上的 nginx 配置 server 块：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  business-a-2;</span><br><span class="line">    root         /usr/share/nginx/html;</span><br><span class="line">    include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">      index index.html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    listen       81;</span><br><span class="line">    server_name  business-b-2;</span><br><span class="line">    root         /usr/share/nginx/html-1;</span><br><span class="line">    include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">      index index.html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>RS2 上的 nginx 配置 server 块：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  business-a-3;</span><br><span class="line">    root         /usr/share/nginx/html;</span><br><span class="line">    include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">       index index.html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen     81;</span><br><span class="line">    server_name  business-b-3;</span><br><span class="line">    root       /usr/share/nginx/html-1;</span><br><span class="line">    include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        index index.html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>LB1 和 LB2 的 nginx 上配置负载均衡：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">upstream business-a-pool &#123;</span><br><span class="line">    server 172.17.0.2:80 weight=1;</span><br><span class="line">    server 172.17.0.3:80 weight=1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">upstream business-b-pool &#123;</span><br><span class="line">    server 172.17.0.2:81 weight=1;</span><br><span class="line">    server 172.17.0.3:81 weight=1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>LB 上的 keepalived 配置沿用上面双实例的配置。</p>
<p>LB1 和 LB2 的 nginx 的 server 块一致，配置如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       172.16.1.100:80;</span><br><span class="line">    server_name  business-a;</span><br><span class="line">    include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://business-a-pool;</span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        proxy_set_header X-Forwarded-For $remote_addr;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    listen       172.16.1.200:80;</span><br><span class="line">    server_name  business-b;</span><br><span class="line">    include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://business-b-pool;</span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        proxy_set_header X-Forwarded-For $remote_addr;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>依次访问两个业务，实现了多实例的负载均衡与高可用：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ curl 172.16.1.100</span><br><span class="line">business-a 172.17.0.2:80</span><br><span class="line"></span><br><span class="line">$ curl 172.16.1.100</span><br><span class="line">business-a 172.17.0.3:80</span><br><span class="line"></span><br><span class="line">$ curl 172.16.1.200</span><br><span class="line">business-b 172.17.0.3:81</span><br><span class="line"></span><br><span class="line">$ curl 172.16.1.200</span><br><span class="line">business-b 172.17.0.2:81</span><br></pre></td></tr></table></figure>

<h2 id="解决服务监听网卡上不存在-IP-地址的问题"><a href="#解决服务监听网卡上不存在-IP-地址的问题" class="headerlink" title="解决服务监听网卡上不存在 IP 地址的问题"></a>解决服务监听网卡上不存在 IP 地址的问题</h2><p>若在 nginx 配置中 server 块的 listen 配置一个本机没有的 ip 地址，则会报错<br>解决方法：在<code>/etc/sysctl.conf</code>添加配置<code>net.ipv4.ip_nonlocal_bind = 1</code>或通过命令<code>sysctl -w net.ipv4.ip_nonlocal_bind=1</code><br>然后<code>sysctl -p</code>使配置生效。</p>
<h2 id="解决高可用服务只针对物理服务器的问题"><a href="#解决高可用服务只针对物理服务器的问题" class="headerlink" title="解决高可用服务只针对物理服务器的问题"></a>解决高可用服务只针对物理服务器的问题</h2><p>若出现机器未宕机且 keepalived 正常工作，然而是服务挂了，keepalived 则无法进行切换。有两种方法解决当服务挂掉的时候也能实现 keepalived 的 IP 漂移切换。</p>
<ul>
<li>写守护进程脚本处理。当本地 nginx 业务出现问题，就强制停掉 keepalived 以实现 IP 漂移。<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">while true</span><br><span class="line">do</span><br><span class="line">  if [ `netstat -lntup | grep nginx | wc -l` ne 1 ]; then</span><br><span class="line">    systemctl stop keepalived</span><br><span class="line">  fi</span><br><span class="line">  sleep 5</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li>
<li>使用监测脚本，然后配置在 keepalived 的配置文件中。脚本与上面类似，但是去掉<code>sleep 5</code>，然后在配置文件中添加：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vrrp_script chk_nginx_proxy &#123;</span><br><span class="line">  script &quot;脚本路径&quot;</span><br><span class="line">  interval 2   //当nginx挂掉时，keepalived在2秒内就会按照脚本停止</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
并在 vrrp 实例中添加<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">track_script &#123;</span><br><span class="line">  chk_nginx_proxy</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="解决多组-keepalived-服务器在一个局域网的冲突问题"><a href="#解决多组-keepalived-服务器在一个局域网的冲突问题" class="headerlink" title="解决多组 keepalived 服务器在一个局域网的冲突问题"></a>解决多组 keepalived 服务器在一个局域网的冲突问题</h2><p>若同一个局域网内存在多组 keepalived 服务器对，就会造成 IP 多播地址冲突问题，导致接管错乱，不同组 keepalived 都会默认使用<code>224.0.0.18</code>作为多播地址。<br>解决方法：每个 keepalived 对指定唯一多播地址。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">global_defs &#123;</span><br><span class="line">  ......</span><br><span class="line">  vrrp_mcast_group4  224.0.0.19    //指定多播地址</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="配置指定文件接受-Keepalived-日志"><a href="#配置指定文件接受-Keepalived-日志" class="headerlink" title="配置指定文件接受 Keepalived 日志"></a>配置指定文件接受 Keepalived 日志</h2><p>keepalived 默认日志输出到<code>/var/log/messages</code>，所以最好单独记录该日志。<br>修改<code>/etc/sysconfig/keepalived</code>，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">KEEPALIVED_OPTIONS=&quot;-D -d -S 0&quot;</span><br></pre></td></tr></table></figure>

<p>选项含义：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># --vrrp               -P    只与vrrp子系统运行</span><br><span class="line"># --check              -C    只与健康检查子系统运行</span><br><span class="line"># --dont-release-vrrp  -V    在keepalived进程停止时不移除VIP和VIP的路由</span><br><span class="line"># --dont-release-ipvs  -I    在keepalived进程停止时不移除ipvs策略</span><br><span class="line"># --dump-conf          -d    导出配置数据</span><br><span class="line"># --log-detail         -D    输出详细日志</span><br><span class="line"># --log-facility       -S    本地syslog设备（0-7，默认为LOG_DAEMON）</span><br></pre></td></tr></table></figure>

<p>然后在<code>/etc/rsyslog.conf</code>中添加 keepalived 配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">local0.*        /var/log/keepalived.log</span><br></pre></td></tr></table></figure>

<p>并在<code>*.info;mail.none;authpriv.none;cron.none</code>后添加<code>local0.none</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*.info;mail.none;authpriv.none;cron.none;local0.none     /var/log/messages</span><br></pre></td></tr></table></figure>

<p>重启 rsyslog 服务 <code>systemctl restart rsyslog.service</code></p>
<h2 id="开发监测-Keepalived-裂脑脚本"><a href="#开发监测-Keepalived-裂脑脚本" class="headerlink" title="开发监测 Keepalived 裂脑脚本"></a>开发监测 Keepalived 裂脑脚本</h2><p>在备服务器上执行脚本，若能 ping 通主节点且备节点有 VIP，就报警。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">VIP=172.16.1.100</span><br><span class="line">LB1_IP=172.16.1.128</span><br><span class="line">while true</span><br><span class="line">do</span><br><span class="line">  ping -c 2 -W 3 $LB1_IP &amp;&gt;/dev/null</span><br><span class="line">  if [ $? -eq 0 -a `ip addr | grep &quot;$LB1_IP&quot;|wc -l` -eq 1 ];then</span><br><span class="line">    echo &quot;split brain ....&quot;</span><br><span class="line">  sleep 5</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><blockquote>
<p><a target="_blank" rel="noopener" href="http://www.linuxvirtualserver.org/zh/index.html">LVS 中文官方文档</a> &gt; <a target="_blank" rel="noopener" href="http://www.cnblogs.com/f-ck-need-u/p/8451982.html#1-lvs-">骏马金龙 LVS 系列文章</a> &gt; <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzIxMjE5MTE1Nw==&mid=2653193749&idx=1&sn=9321bf2c628b8d60913336ff6592f823&chksm=8c99f4cfbbee7dd9e580eac24a5d481993a09bc93720dddc70d602e38e923012e1d7b245a76e&mpshare=1&scene=23&srcid=0528GJKDr5wutmhQnNTVwG1H#rd">负载均衡的原理</a><br>高性能网站构建实战<br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA4NzQzMzU4Mg==&mid=2652921952&idx=1&sn=c9e4cee313f9052095d499d5be41c2dd&chksm=8bed4861bc9ac1778610eace025dfa685e661f04b53b539666b597d649e3429be01048242010&mpshare=1&scene=23&srcid=0710bpqIBIAZyCVTrxFmag58#rd">Linux 之虚拟服务器 LVS 搭建</a></p>
<p><a target="_blank" rel="noopener" href="http://blog.51cto.com/manito/590937">lvs arp 问题配置误区</a></p>
<p><a target="_blank" rel="noopener" href="https://www.linuxidc.com/Linux/2013-08/88524.htm">LVS 集群中持久连接详解（PPC+PCC+PNMPP）</a></p>
</blockquote>

  
  
    
    <div class='footer'>
      
      
      
      
    </div>
  
  
    


  <div class='article-meta' id="bottom">
    <div class='new-meta-box'>
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/server/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>server</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>负载均衡</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/LVS/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>LVS</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/keepalived/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>keepalived</p></a></div>


        
      
    </div>
  </div>


  
  

  
    <div class="prev-next">
      
        <a class='prev' href='/2018/Ansible%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/'>
          <p class='title'><i class="fas fa-chevron-left" aria-hidden="true"></i>Ansible基础学习笔记</p>
          <p class='content'>Ansible 是一个部署一群远程主机的工具，使用 SSH 实现管理节点和远程节点间的通信，实现批量自动化操作。




Ansible 结构
Ansible 安装
Inventory
Play...</p>
        </a>
      
      
        <a class='next' href='/2018/wireshark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/'>
          <p class='title'>Wireshark学习笔记<i class="fas fa-chevron-right" aria-hidden="true"></i></p>
          <p class='content'>基于 wireshark v2.4.5本篇包含以下内容

基本操作
捕获过滤器


tshark 命令使用
常用操作


参考文章



基本操作两种过滤器：

捕获过滤器 Capture Fi...</p>
        </a>
      
    </div>
  
</article>


  

  <article class="post white-box reveal shadow" id="comments">
    <p ct><i class='fas fa-comments'></i> 评论</p>
    
    <div id="valine_container" class="valine_thread">
  <i class="fas fa-cog fa-spin fa-fw fa-2x"></i>
</div>

  </article>






</div>
<aside class='l_side'>
  
  
    
    



  <section class="widget toc-wrapper shadow desktop mobile" id="toc-div" >
    
  <header>
    
      <i class="fas fa-list fa-fw" aria-hidden="true"></i><span class='name'>本文目录</span>
    
  </header>


    <div class='content'>
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#LVS-%E5%8E%9F%E7%90%86"><span class="toc-text">LVS 原理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#LVS-%E9%9B%86%E7%BE%A4%E7%9A%84%E9%80%9A%E7%94%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84"><span class="toc-text">LVS 集群的通用体系结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E7%A7%8D-IP-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%8A%80%E6%9C%AF"><span class="toc-text">三种 IP 负载均衡技术</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LVS-%E4%B8%A4%E7%A7%8D%E8%B0%83%E5%BA%A6%E6%96%B9%E5%BC%8F%E4%B8%8E%E5%85%AB%E7%A7%8D%E7%AE%97%E6%B3%95"><span class="toc-text">LVS 两种调度方式与八种算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LVS-%E6%8C%81%E4%B9%85%E8%BF%9E%E6%8E%A5"><span class="toc-text">LVS 持久连接</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#KeepAlived-%E5%8E%9F%E7%90%86"><span class="toc-text">KeepAlived 原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#LVS-%E4%B8%8E-KeepAlived-%E6%90%AD%E5%BB%BA"><span class="toc-text">LVS 与 KeepAlived 搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#NAT-%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA"><span class="toc-text">NAT 模式搭建</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DR-%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA"><span class="toc-text">DR 模式搭建</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE"><span class="toc-text">持久化配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Keepalived-%E9%85%8D%E7%BD%AE"><span class="toc-text">Keepalived 配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Keepalived-%E5%8F%8C%E5%AE%9E%E4%BE%8B%E5%8F%8C%E4%B8%BB%E6%A8%A1%E5%BC%8F%E9%85%8D%E7%BD%AE"><span class="toc-text">Keepalived 双实例双主模式配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Nginx-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%85%8D%E5%90%88-Keepalived"><span class="toc-text">Nginx 负载均衡配合 Keepalived</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%9C%8D%E5%8A%A1%E7%9B%91%E5%90%AC%E7%BD%91%E5%8D%A1%E4%B8%8A%E4%B8%8D%E5%AD%98%E5%9C%A8-IP-%E5%9C%B0%E5%9D%80%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">解决服务监听网卡上不存在 IP 地址的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9C%8D%E5%8A%A1%E5%8F%AA%E9%92%88%E5%AF%B9%E7%89%A9%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">解决高可用服务只针对物理服务器的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E5%A4%9A%E7%BB%84-keepalived-%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9C%A8%E4%B8%80%E4%B8%AA%E5%B1%80%E5%9F%9F%E7%BD%91%E7%9A%84%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98"><span class="toc-text">解决多组 keepalived 服务器在一个局域网的冲突问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E6%8E%A5%E5%8F%97-Keepalived-%E6%97%A5%E5%BF%97"><span class="toc-text">配置指定文件接受 Keepalived 日志</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%80%E5%8F%91%E7%9B%91%E6%B5%8B-Keepalived-%E8%A3%82%E8%84%91%E8%84%9A%E6%9C%AC"><span class="toc-text">开发监测 Keepalived 裂脑脚本</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E6%A1%A3"><span class="toc-text">参考文档</span></a></li></ol>
    </div>
  </section>


  


</aside>



		  
		  <!--此文件用来存放一些不方便取值的变量-->
<!--思路大概是将值藏到重加载的区域内-->

<script>
  window.pdata={}
  pdata.ispage=true;
  pdata.postTitle="LVS负载均衡学习笔记";
  pdata.commentPath="";
  pdata.commentPlaceholder="";
  // header 这里无论是否开启pjax都需要
  var l_header=document.getElementById("l_header");
  
  l_header.classList.add("show");
  
  
    // cover
    var cover_wrapper=document.querySelector('.cover-wrapper');
    
    cover_wrapper.id="none";
    cover_wrapper.style.display="none";
    
  
</script>

        </div>
        
  
  <footer class="footer clearfix">
    <br><br>
    
      
        <div class="aplayer-container">
          


        </div>
      
    
      
        <br>
        <div class="social-wrapper">
          
            
              <a href="https://github.com/serchaofan"
                class="social fab fa-github flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
                
              </a>
            
          
        </div>
      
    
      
        <div><p>博客内容遵循 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
      
    
      
        本站使用
        <a href="https://github.com/volantis-x/hexo-theme-volantis/tree/4.3.1" target="_blank" class="codename">Volantis</a>
        作为主题
      
    
      
        <div class='copyright'>
        <p>苏ICP备19069282号</p>

        </div>
      
    
  </footer>


        <a id="s-top" class="fas fa-arrow-up fa-fw" href="javascript:void(0)"></a>
      </div>
    </div>
    <div>
      <script>
/************这个文件存放不需要重载的全局变量和全局函数*********/
window.volantis={};
window.volantis.loadcss=document.getElementById("loadcss");
/******************** Pjax ********************************/
function VPjax(){
	this.list=[] // 存放回调函数
	this.start=()=>{
	  for(var i=0;i<this.list.length;i++){
		this.list[i].run();
	  }
	}
	this.push=(fn,name)=>{
		var f=new PjaxItem(fn,name);
		this.list.push(f);
	}
	// 构造一个可以run的对象
	function PjaxItem(fn,name){
		// 函数名称
		this.name = name || fn.name
		// run方法
		this.run=()=>{
			fn()
		}
	}
}
volantis.pjax={}
volantis.pjax.method={
	complete: new VPjax(),
	error: new VPjax(),
	send: new VPjax()
}
volantis.pjax={
	...volantis.pjax,
	push: volantis.pjax.method.complete.push,
	error: volantis.pjax.method.error.push,
	send: volantis.pjax.method.send.push
}
/********************脚本懒加载函数********************************/
// 已经加入了setTimeout
function loadScript(src, cb) {
	setTimeout(function() {
		var HEAD = document.getElementsByTagName('head')[0] || document.documentElement;
		var script = document.createElement('script');
		script.setAttribute('type','text/javascript');
		if (cb) script.onload = cb;
		script.setAttribute('src', src);
		HEAD.appendChild(script);
	});
}
//https://github.com/filamentgroup/loadCSS
var loadCSS = function( href, before, media, attributes ){
	var doc = window.document;
	var ss = doc.createElement( "link" );
	var ref;
	if( before ){
		ref = before;
	}
	else {
		var refs = ( doc.body || doc.getElementsByTagName( "head" )[ 0 ] ).childNodes;
		ref = refs[ refs.length - 1];
	}
	var sheets = doc.styleSheets;
	if( attributes ){
		for( var attributeName in attributes ){
			if( attributes.hasOwnProperty( attributeName ) ){
				ss.setAttribute( attributeName, attributes[attributeName] );
			}
		}
	}
	ss.rel = "stylesheet";
	ss.href = href;
	ss.media = "only x";
	function ready( cb ){
		if( doc.body ){
			return cb();
		}
		setTimeout(function(){
			ready( cb );
		});
	}
	ready( function(){
		ref.parentNode.insertBefore( ss, ( before ? ref : ref.nextSibling ) );
	});
	var onloadcssdefined = function( cb ){
		var resolvedHref = ss.href;
		var i = sheets.length;
		while( i-- ){
			if( sheets[ i ].href === resolvedHref ){
				return cb();
			}
		}
		setTimeout(function() {
			onloadcssdefined( cb );
		});
	};
	function loadCB(){
		if( ss.addEventListener ){
			ss.removeEventListener( "load", loadCB );
		}
		ss.media = media || "all";
	}
	if( ss.addEventListener ){
		ss.addEventListener( "load", loadCB);
	}
	ss.onloadcssdefined = onloadcssdefined;
	onloadcssdefined( loadCB );
	return ss;
};
</script>
<script>
  
  loadCSS("https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14/css/all.min.css", window.volantis.loadcss);
  
  
  
  
</script>
<!-- required -->

<script src="https://cdn.jsdelivr.net/npm/jquery@3.5/dist/jquery.min.js"></script>

<script>
  function pjax_fancybox() {
    $(".md .gallery").find("img").each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("class", "fancybox");
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 判断当前页面是否存在描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".md .gallery").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  function SCload_fancybox() {
    if ($(".md .gallery").find("img").length == 0) return;
    loadCSS("https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css", document.getElementById("loadcss"));
    loadScript('https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js', pjax_fancybox)
  };
  $(function () {
    SCload_fancybox();
  });
  function Pjax_SCload_fancybox(){
	if (typeof $.fancybox == "undefined") {
	 SCload_fancybox();
    } else {
	 pjax_fancybox();
    }
  }
  volantis.pjax.push(Pjax_SCload_fancybox)
  volantis.pjax.send(()=>{
      if (typeof $.fancybox != "undefined") {
        $.fancybox.close();    // 关闭弹窗
      }
  },'fancybox')
</script>


<!-- internal -->




<script>
  function loadIssuesJS() {
    if ($(".md").find(".issues-api").length == 0) return;
	
	  loadScript('/js/issues.js');
	
  };
  $(function () {
    loadIssuesJS();
  });
  volantis.pjax.push(()=>{
	if (typeof IssuesAPI == "undefined") {
	  loadIssuesJS();
	}
  },"IssuesJS")
</script>



  <script defer src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.1.0/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script>




  

<script>
  window.FPConfig = {
	delay: 0,
	ignoreKeywords: [],
	maxRPS: 5,
	hoverDelay: 25
  };
</script>
<script defer src="https://cdn.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"></script>











  
  
<script src="/js/valine.js"></script>


<script>
  function emoji(path, idx, ext) {
    return path + "/" + path + "-" + idx + "." + ext;
  }
  var emojiMaps = {};
  for (var i = 1; i <= 54; i++) {
    emojiMaps['tieba-' + i] = emoji('tieba', i, 'png');
  }
  for (var i = 1; i <= 101; i++) {
    emojiMaps['qq-' + i] = emoji('qq', i, 'gif');
  }
  for (var i = 1; i <= 116; i++) {
    emojiMaps['aru-' + i] = emoji('aru', i, 'gif');
  }
  for (var i = 1; i <= 125; i++) {
    emojiMaps['twemoji-' + i] = emoji('twemoji', i, 'png');
  }
  for (var i = 1; i <= 4; i++) {
    emojiMaps['weibo-' + i] = emoji('weibo', i, 'png');
  }
  function pjax_valine() {
    if(!document.querySelectorAll("#valine_container")[0])return;
    let pagePlaceholder = pdata.commentPlaceholder || "快来评论吧~";
    let path = pdata.commentPath;
    if (path.length == 0) {
      let defaultPath = '';
      path = defaultPath || decodeURI(window.location.pathname);
    }
    var valine = new Valine();
    valine.init(Object.assign({"path":null,"placeholder":"快来评论吧~","appId":null,"appKey":null,"meta":["nick","mail","link"],"requiredFields":["nick","mail"],"enableQQ":true,"recordIP":false,"avatar":"robohash","pageSize":10,"lang":"zh-cn","highlight":true,"mathJax":false}, {
      el: '#valine_container',
      path: path,
      placeholder: pagePlaceholder,
      emojiCDN: 'https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji/valine/',
      emojiMaps: emojiMaps,
    }))
  }
  $(function () {
    pjax_valine();
  });
  volantis.pjax.push(pjax_valine);
</script>






  
<script src="/js/app.js"></script>



<!-- optional -->

  <script>
const SearchServiceimagePath="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/img/";
const ROOT =  ("/" || "/").endsWith('/') ? ("/" || "/") : ("//" || "/" );

$('.input.u-search-input').one('focus',function(){
	
		loadScript('/js/search/hexo.js',setSearchService);
	
})

function listenSearch(){
  
    customSearch = new HexoSearch({
      imagePath: SearchServiceimagePath
    });
  
}
function setSearchService() {
	listenSearch();
	
}
</script>











  <script defer>

  const LCCounter = {
    app_id: 'u9j57bwJod4EDmXWdxrwuqQT-MdYXbMMI',
    app_key: 'jfHtEKVE24j0IVCGHbvuFClp',
    custom_api_server: '',

    // 查询存储的记录
    getRecord(Counter, url, title) {
      return new Promise(function (resolve, reject) {
        Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({url})))
          .then(resp => resp.json())
          .then(({results, code, error}) => {
            if (code === 401) {
              throw error;
            }
            if (results && results.length > 0) {
              var record = results[0];
              resolve(record);
            } else {
              Counter('post', '/classes/Counter', {url, title: title, times: 0})
                .then(resp => resp.json())
                .then((record, error) => {
                  if (error) {
                    throw error;
                  }
                  resolve(record);
                }).catch(error => {
                console.error('Failed to create', error);
                reject(error);
              });
            }
          }).catch((error) => {
          console.error('LeanCloud Counter Error:', error);
          reject(error);
        });
      })
    },

    // 发起自增请求
    increment(Counter, incrArr) {
      return new Promise(function (resolve, reject) {
        Counter('post', '/batch', {
          "requests": incrArr
        }).then((res) => {
          res = res.json();
          if (res.error) {
            throw res.error;
          }
          resolve(res);
        }).catch((error) => {
          console.error('Failed to save visitor count', error);
          reject(error);
        });
      });
    },

    // 构建自增请求体
    buildIncrement(objectId) {
      return {
        "method": "PUT",
        "path": `/1.1/classes/Counter/${ objectId }`,
        "body": {
          "times": {
            '__op': 'Increment',
            'amount': 1
          }
        }
      }
    },

    // 校验是否为有效的 UV
    validUV() {
      var key = 'LeanCloudUVTimestamp';
      var flag = localStorage.getItem(key);
      if (flag) {
        // 距离标记小于 24 小时则不计为 UV
        if (new Date().getTime() - parseInt(flag) <= 86400000) {
          return false;
        }
      }
      localStorage.setItem(key, new Date().getTime().toString());
      return true;
    },

    addCount(Counter) {
      var enableIncr = '' === 'true' && window.location.hostname !== 'localhost';
      enableIncr = true;
      var getterArr = [];
      var incrArr = [];
      // 请求 PV 并自增
      var pvCtn = document.querySelector('#lc-sv');
      if (pvCtn || enableIncr) {
        var pvGetter = this.getRecord(Counter, 'https://coconutmilktaro.top' + '/#lc-sv', 'Visits').then((record) => {
          incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-sv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + 1;
              if (pvCtn) {
                pvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(pvGetter);
      }

      // 请求 UV 并自增
      var uvCtn = document.querySelector('#lc-uv');
      if (uvCtn || enableIncr) {
        var uvGetter = this.getRecord(Counter, 'https://coconutmilktaro.top' + '/#lc-uv', 'Visitors').then((record) => {
          var vuv = this.validUV();
          vuv && incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-uv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + (vuv ? 1 : 0);
              if (uvCtn) {
                uvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(uvGetter);
      }

      // 请求文章的浏览数，如果是当前页面就自增
      var allPV = document.querySelectorAll('#lc-pv');
      if (allPV.length > 0 || enableIncr) {
        for (i = 0; i < allPV.length; i++) {
          let pv = allPV[i];
          let title = pv.getAttribute('data-title');
          var url = 'https://coconutmilktaro.top' + pv.getAttribute('data-path');
          if (url) {
            var viewGetter = this.getRecord(Counter, url, title).then((record) => {
              // 是当前页面就自增
              let curPath = window.location.pathname;
              if (curPath.includes('index.html')) {
                curPath = curPath.substring(0, curPath.lastIndexOf('index.html'));
              }
              if (pv.getAttribute('data-path') == curPath) {
                incrArr.push(this.buildIncrement(record.objectId));
              }
              if (pv) {
                var ele = pv.querySelector('#lc-pv #number');
                if (ele) {
                  if (pv.getAttribute('data-path') == curPath) {
                    ele.innerText = (record.times || 0) + 1;
                  } else {
                    ele.innerText = record.times || 0;
                  }
                  pv.style.display = 'inline';
                }
              }
            });
            getterArr.push(viewGetter);
          }
        }
      }

      // 如果启动计数自增，批量发起自增请求
      if (enableIncr) {
        Promise.all(getterArr).then(() => {
          incrArr.length > 0 && this.increment(Counter, incrArr);
        })
      }

    },


    fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${ api_server }/1.1${ url }`, {
          method,
          headers: {
            'X-LC-Id': this.app_id,
            'X-LC-Key': this.app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      this.addCount(Counter);
    },

    refreshCounter() {
      var api_server = this.app_id.slice(-9) !== '-MdYXbMMI' ? this.custom_api_server : `https://${ this.app_id.slice(0, 8).toLowerCase() }.api.lncldglobal.com`;
      if (api_server) {
        this.fetchData(api_server);
      } else {
        fetch('https://app-router.leancloud.cn/2/route?appId=' + this.app_id)
          .then(resp => resp.json())
          .then(({api_server}) => {
            this.fetchData('https://' + api_server);
          });
      }
    }

  };

  LCCounter.refreshCounter();

  document.addEventListener('pjax:complete', function () {
    LCCounter.refreshCounter();
  });
</script>




  <script>
const rootElement = document.documentElement;
const darkModeStorageKey = "user-color-scheme";
const rootElementDarkModeAttributeName = "data-user-color-scheme";

const setLS = (k, v) => {
    localStorage.setItem(k, v);
};

const removeLS = (k) => {
    localStorage.removeItem(k);
};

const getLS = (k) => {
    return localStorage.getItem(k);
};

const getModeFromCSSMediaQuery = () => {
  return window.matchMedia("(prefers-color-scheme: dark)").matches
    ? "dark"
    : "light";
};

const resetRootDarkModeAttributeAndLS = () => {
  rootElement.removeAttribute(rootElementDarkModeAttributeName);
  removeLS(darkModeStorageKey);
};

const validColorModeKeys = {
  dark: true,
  light: true,
};

const applyCustomDarkModeSettings = (mode) => {
  const currentSetting = mode || getLS(darkModeStorageKey);

  if (currentSetting === getModeFromCSSMediaQuery()) {
    resetRootDarkModeAttributeAndLS();
  } else if (validColorModeKeys[currentSetting]) {
    rootElement.setAttribute(rootElementDarkModeAttributeName, currentSetting);
  } else {
    resetRootDarkModeAttributeAndLS();
  }
};

const invertDarkModeObj = {
  dark: "light",
  light: "dark",
};

/**
 * get target mode
 */
const toggleCustomDarkMode = () => {
  let currentSetting = getLS(darkModeStorageKey);

  if (validColorModeKeys[currentSetting]) {
    currentSetting = invertDarkModeObj[currentSetting];
  } else if (currentSetting === null) {
    currentSetting = invertDarkModeObj[getModeFromCSSMediaQuery()];
  } else {
    return;
  }
  setLS(darkModeStorageKey, currentSetting);
  return currentSetting;
};

/**
 * bind click event for toggle button
 */
var btn=$("#wrapper .toggle-mode-btn,#rightmenu-wrapper .toggle-mode-btn");
function bindToggleButton() {
    btn.on('click',(e) => {
      const mode = toggleCustomDarkMode();
      applyCustomDarkModeSettings(mode);
    });
}

applyCustomDarkModeSettings();
document.addEventListener("DOMContentLoaded", bindToggleButton);
volantis.pjax.push(bindToggleButton);
volantis.pjax.send(()=>{
	btn.unbind('click');
},'toggle-mode-btn-unbind');
</script>








<script>
function listennSidebarTOC() {
  const navItems = document.querySelectorAll(".toc li");
  if (!navItems.length) return;
  const sections = [...navItems].map((element) => {
    const link = element.querySelector(".toc-link");
    const target = document.getElementById(
      decodeURI(link.getAttribute("href")).replace("#", "")
    );
    link.addEventListener("click", (event) => {
      event.preventDefault();
      window.scrollTo({
		top: target.offsetTop + 100,
		
		behavior: "smooth"
		
	  });
    });
    return target;
  });

  function activateNavByIndex(target) {
    if (target.classList.contains("active-current")) return;

    document.querySelectorAll(".toc .active").forEach((element) => {
      element.classList.remove("active", "active-current");
    });
    target.classList.add("active", "active-current");
    let parent = target.parentNode;
    while (!parent.matches(".toc")) {
      if (parent.matches("li")) parent.classList.add("active");
      parent = parent.parentNode;
    }
  }

  function findIndex(entries) {
    let index = 0;
    let entry = entries[index];
    if (entry.boundingClientRect.top > 0) {
      index = sections.indexOf(entry.target);
      return index === 0 ? 0 : index - 1;
    }
    for (; index < entries.length; index++) {
      if (entries[index].boundingClientRect.top <= 0) {
        entry = entries[index];
      } else {
        return sections.indexOf(entry.target);
      }
    }
    return sections.indexOf(entry.target);
  }

  function createIntersectionObserver(marginTop) {
    marginTop = Math.floor(marginTop + 10000);
    let intersectionObserver = new IntersectionObserver(
      (entries, observe) => {
        let scrollHeight = document.documentElement.scrollHeight + 100;
        if (scrollHeight > marginTop) {
          observe.disconnect();
          createIntersectionObserver(scrollHeight);
          return;
        }
        let index = findIndex(entries);
        activateNavByIndex(navItems[index]);
      },
      {
        rootMargin: marginTop + "px 0px -100% 0px",
        threshold: 0,
      }
    );
    sections.forEach((element) => {
      element && intersectionObserver.observe(element);
    });
  }
  createIntersectionObserver(document.documentElement.scrollHeight);
}

document.addEventListener("DOMContentLoaded", listennSidebarTOC);
document.addEventListener("pjax:success", listennSidebarTOC);
</script>

<!-- more -->

 
	   
	    


<script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script>


<script>
    var pjax;
    document.addEventListener('DOMContentLoaded', function () {
      pjax = new Pjax({
        elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox])',
        selectors: [
          "title",
          
          "#pjax-container",
          "#pjax-header-nav-list"
        ],
        cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
        timeout: 5000
      });
    });

    document.addEventListener('pjax:send', function (e) {
      //window.stop(); // 相当于点击了浏览器的停止按钮

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      window.subData = null; // 移除标题（用于一二级导航栏切换处）

      volantis.$switcher.removeClass('active'); // 关闭移动端激活的搜索框
      volantis.$header.removeClass('z_search-open'); // 关闭移动端激活的搜索框
      volantis.$wrapper.removeClass('sub'); // 跳转页面时关闭二级导航

      // 解绑事件 避免重复监听
      volantis.$topBtn.unbind('click');
      $('.menu a').unbind('click');
      $(window).unbind('resize');
      $(window).unbind('scroll');
      $(document).unbind('scroll');
      $(document).unbind('click');
      $('body').unbind('click');
	  // 使用 volantis.pjax.send 方法传入pjax:send回调函数 参见layout/_partial/scripts/global.ejs
	  volantis.pjax.method.send.start();
    });

    document.addEventListener('pjax:complete', function () {
      $('.nav-main').find('.list-v').not('.menu-phone').removeAttr("style",""); // 移除小尾巴的移除
      $('.menu-phone.list-v').removeAttr("style",""); // 移除小尾巴的移除
      $('script[data-pjax], .pjax-reload script').each(function () {
        $(this).parent().append($(this).remove());
      });
      try{
		// 使用 volantis.pjax.push 方法传入重载函数 参见layout/_partial/scripts/global.ejs
		volantis.pjax.method.complete.start();
      } catch (e) {
        console.log(e);
      }
    });

    document.addEventListener('pjax:error', function (e) {
	  // 使用 volantis.pjax.error 方法传入pjax:error回调函数 参见layout/_partial/scripts/global.ejs
	  volantis.pjax.method.error.start();
      window.location.href = e.triggerElement.href;
    });
</script>
 
	  
    </div>
  </body>
</html>
