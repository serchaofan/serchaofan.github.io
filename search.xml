<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[信息安全学习笔记（软考）]]></title>
    <url>%2F2018%2F10%2F03%2F%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E8%BD%AF%E8%80%83%EF%BC%89%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[KVM学习笔记]]></title>
    <url>%2F2018%2F10%2F03%2FKVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[OpenVPN学习笔记]]></title>
    <url>%2F2018%2F10%2F03%2FOpenVPN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <tags>
        <tag>网络</tag>
        <tag>VPN</tag>
        <tag>OpenVPN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集群概念及应用笔记]]></title>
    <url>%2F2018%2F10%2F01%2F%E9%9B%86%E7%BE%A4%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%BA%94%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[集群概念 集群概念几种服务器性能增强方式： Scale on：向上扩展。也称垂直扩展，在服务器硬件上扩展 Scale out：向外扩展。也称水平扩展，在服务器数量上扩展 LB集群与HA集群的着眼点： LB集群是为了增加请求的并发处理能力，而HA集群是为了增加服务的可用性 RAID阵列与NFS的区别： NFS是文件系统服务器，前端web对数据的请求是文件级别的。属于NAS NAS具有锁机制，因为NAS是服务器，是有操作系统的，这样就不会造成数据的不一致了。 RAID阵列是磁盘，前端web对数据的请求是块级别的。属于DAS DAS就是磁盘，无法设置磁盘锁，因为读写操作是在内存中执行的，读取的数据都是在web服务器中执行操作，不同的web服务器读取同一段数据会造成数据的不一致 但是DAS的速度远高于NAS 一个文件包含多个数据块]]></content>
      <tags>
        <tag>server</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Puppet自动化工具笔记]]></title>
    <url>%2F2018%2F10%2F01%2FPuppet%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <tags>
        <tag>运维</tag>
        <tag>Puppet</tag>
        <tag>自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL高可用笔记]]></title>
    <url>%2F2018%2F10%2F01%2FMySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[drbd数据同步笔记]]></title>
    <url>%2F2018%2F09%2F30%2Fdrbd%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Heartbeat笔记]]></title>
    <url>%2F2018%2F09%2F30%2FHeartbeat%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Heartbeat概念 Heartbeat概念Heartbeat 项目是 Linux-HA 工程的一个组成部分，它实现了一个高可用集群系统。可以将资源（IP及程序服务等资源）从一台故障计算机快速转移到另一台运转正常的机器继续提供服务。 通过修改heartbeat的配置文件，可以指定一台heartbeat服务器作为主服务器，另一台自动成为热备服务器。在热备服务器上面配置heartbeat守护程序来监听来自主服务器的心跳信息。如果在规定时间内，无法监听到心跳信息，那么就启动故障转移，取得主服务器上的相关资源的所有权，接替主服务器继续不间断的提供服务，从而达到资源以及服务高可用的目的。而heartbeat还支持主主模式，即两台服务器互为主备，互相监听，发送心跳报文。 注：heartbeat的业务切换时间大概在5到20秒，所谓的业务不间断其实是保障业务一致，不会造成数据错误。heartbeat的高可用是服务器级别的，而不是服务级别的。 业务切换的常见条件为： 服务器宕机 心跳线故障 heartheat服务本身故障 heartbeat服务器间通信的方法： 串口线缆。线缆专门进行心跳通信，稳定，且不用配IP地址。缺点：服务器距离不能远。 两台服务器网卡通过以太网线直连。推荐使用 两台服务器网卡通过以太网设备连接。不稳定 脑裂两台正常运行的高可用服务器在心跳超时内无法监听到对方心跳报文，于是各自启动了故障转移，获取了资源的所有权，两台服务器都拥有同一个VIP地址，数据会出现不一致或丢失，这种情况称为脑裂（split brain）。 发生脑裂的原因： 高可用服务器对之间的心跳链路故障，导致无法正常通信 心跳线故障 网卡或相关驱动故障 IP配置冲突 心跳线间连接的设备故障，如交换机 仲裁机器故障 高可用服务器上开启了防火墙，过滤掉了心跳报文 心跳配置不一致，如心跳方式、心跳广播冲突，以及软件BUG等 防止脑裂的方法： 同时使用串口线缆和一台线缆，组成两条心跳线 检测到脑裂时强行关闭一个节点，若备节点认为主节点故障，则会自动向主节点发送关机命令（此功能需要特殊设备支持，如STONITH、fencing） 对脑裂的告警，及时采取措施 启用磁盘锁，正在提供服务的一方锁住共享磁盘，即使发生脑裂也不会出现数据不一致或丢失情况。 增加仲裁机制。例如设置参考IP地址，若能ping通的服务器则接管服务，ping不通的服务器主动放弃竞争。 STONITH：Shoot-The-Other-Node-In-The-Head，是heartbeat的一个组件，能够保护数据使其不会因为节点异常或者同时访问而遭到损坏。用于集群服务无法停下的情况，在这种情况下，集群可以使用STONITH来强制整个节点离线，并让服务在其它节点上安全启用。 heartbeat消息类型三种heartbeat消息类型： 心跳消息：控制心跳频率和出现故障后进行故障转换的等待时间。可以单播广播和组播，约150字节。 集群转换消息：ip-request和ip-request-resp 当主服务器恢复后，使用ip-request消息要求备机将服务的提供权交还给主服务器。备服务器将服务提供权释放后，通过ip-request-resp通知主服务器，主节点收到后开始正常提供服务 重传消息：rexmit-request控制重传心跳请求 heartbeat IP地址接管及故障转移heartbeat通过IP地址接管和ARP广播进行故障转移。为防止ARP老化时间内，客户端仍请求已故障的服务器，备服务器会进行强制所有客户端进行ARP表项刷新。 VIP为对外提供服务的IP地址，因此需要在DNS上配置将网站的域名解析到这个VIP。有两种手工配置VIP的方法： ifconfig eth0:1 [IP地址] netmask [掩码] up ip addr add [IP地址/掩码] broadcast [该网段广播地址] dev eth1 注：ip addr能看到网卡别名和VIP，而ifconfig无法看到。 参考文章 Heartbeat介绍 Heartbeat高可用解决方案 heartbeat单独提供高可用服务]]></content>
      <tags>
        <tag>server</tag>
        <tag>heartbeat</tag>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sed与Awk笔记]]></title>
    <url>%2F2018%2F09%2F29%2FSed%E4%B8%8EAwk%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Sed Awk Sedsed是一个面向字符流的编辑器，对文本进行过滤和替换操作，sed一次仅读取一行进行操作，适合处理大数据文件。可在一个或多个文件上自动实现编辑，简化对多个文件执行相同的编辑处理工作。 sed默认不修改源文件，仅仅修改输出信息，sed先将从文件读入的内容放入缓冲区，称为模式空间，在模式空间中对文件的副本操作，再输出到屏幕。 12345678910sed [选项]... [输入文件]... -n, --quiet, --silent 静默模式，结果不显示到屏幕 -e 脚本 添加脚本指令，可添加多个 -f 脚本文件 添加脚本文件 --follow-symlinks 直接修改文件时跟随软链接 -i[SUFFIX] 直接修改源文件，若指定SUFFIX前缀，则进行对源文件的备份 -l N 指定l命令（输出非打印字符）可输出的行长度 --posix 关闭所有 GNU 扩展 -s, --separate 默认sed将输入的多个文件名当做一个长的输入流，而GNU sed允许看做单独的文件 -u, --unbuffered 从输入文件读取最少的数据，即最低限度的缓存输入和输出 sed的指令：[地址]指令 内容，在sed中/称为定界符，也可用其他的符号作为定界符，如:或|等。 a：append追加，若不指定行数，则会在每一行后都添加一行内容 1234例：sed &apos;2a XXXXX&apos; 文件 在文件的第二行后添加一行内容XXXXX sed &apos;/XXX/a XXXXX&apos; 文件 在所有包含XXX的行后添加一行XXXXX sed &apos;1,4a XXXXX&apos; 在第1到4行后添加一行XXXXX sed &apos;$a XXXXX&apos; 在最后一行后添加一行，$表示最后一行 i：insert插入，是在行前添加一行内容，若不指定行数，则在每一行前添加 12例：sed &apos;2i XXXXX&apos; 文件 在第二行前添加一行XXXXX sed &apos;/XXX/i XXXXX&apos; 在包含XXX的行前添加一行XXXXX d：delete删除 1234例：sed &apos;2d&apos; 删除第二行 sed &apos;/^$/d&apos; 删除空白行 sed &apos;1~2d&apos; ~用于指定从第几行开始的指定步长行的内容 1~2用于指定第1行开始的两行，即第1,2行 s：substitution替换 123例：sed &apos;s/XXX/XXXX/&apos; 将XXX替换为XXXX，会替换第一个匹配的 sed &apos;s/XXX/XXXX/n&apos; 只替换第n个匹配的XXX，n的范围是1-512 sed &apos;s/XXX/XXXX/g&apos; 对模式空间的所有匹配都更改 c：替换 1例：sed &apos;/XXX/c XXXXX&apos; 将包含XXX的一行替换为XXXXX p：打印 12例：sed &apos;s/XXX/XXXX/p&apos; 替换后，打印替换后的句子（会重复打印）以及其他未替换的内容 若和-n一起使用，则只打印进行处理的行 n：一遇到匹配的行就立刻移动到下一行 若要执行多个指令，则指令间用逗号分隔，或通过-e 指令1 -e 指令2...指定，最好通过文件添加指令，然后通过-f指定指令文件。 还可使用/XXX/ {指令/内容}替换：匹配的语句支持正则表达式 123456例：&lt;body&gt;hello&lt;body&gt; sed &apos;s/body/\/body/2&apos; 将第二个body换为/body，还可用&#123;&#125;实现 sed &apos;/body/ &#123;s//\/body/2&#125;&apos; 就是s/后的要替换的内容提前到前面 还可以用&amp;替换要替换的部分 sed &apos;/body/ &#123;s//\/&amp;/2&#125;&apos; 正则表达式\w\+匹配每一个单词，例：将每个单词都添加一个[] sed &#39;s/\w\+/[&amp;]&#39; \n匹配子串，n表示第n个子串，用\(XXX\) 匹配子串，会将XXX作为主串，将XXX后的字符串作为子串，例：将abcdefg中的efg替换为fff：sed &#39;s/\(abcd\)efg/\1fff&#39; 可通过在匹配的行间添加逗号选定行范围：sed &#39;/efg/,/abc/&#39; 将指定的内容添加到匹配的行下面：使用a\指令，sed &#39;/abc/a\test&#39;，将test字符串插入到匹配包含abc的行的下面。同理，i\将指定内容添加到匹配的行上面 打印奇数行：sed -n &#39;p;n&#39;或sed -n &#39;1~2p&#39;打印偶数行：sed -n &#39;n;p&#39;或sed -n &#39;2~2p&#39; AwkAwk是一种模式匹配的程序设计语言，用于对文本和数据进行扫描和处理，常用操作是将数据转换为格式化的报表。常见的awk编译器版本有awk，gawk，gawk与awk一致。 awk先逐行扫描文件，寻找匹配特定模式的行，并进行操作。因此，awk基本结构就是由模式匹配和处理动作组成。]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>sed</tag>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix搭建笔记]]></title>
    <url>%2F2018%2F09%2F28%2Fzabbix%E6%90%AD%E5%BB%BA%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[zabbix介绍 zabbix搭建 zabbix常用操作 zabbix介绍Zabbix是一个企业级开源的分布式监控套件，可以监控网络和服务的监控状况。 zabbix组成：zabbix server和zabbix agent Zabbix Server可通过SNMP、Zabbix_agent、ping、端口扫描等方法提供对远程服务器的监视 Zabbix Agent安装在需要被监控的目录服务器上收集信息。 zabbix核心组件： zabbix server：收集agent的监控信息，对数据统计操作，设置配置。zabbix server可单独监控，也可与agent结合。可轮询agent主动接收监控数据，也可被动接收。 zabbix databases：存储所有配置信息，以及监控数据 zabbix web GUI：通常与server运行在同一主机上，用于可视化操作 zabbix可选组件： proxy：代理服务器，用于分布式监控环境，代理server接收agent的监控数据 agent：被监控主机，收集本地数据 zabbix也可用于监控java应用，可基于JMX组件监控JVM 常用术语： 监控项item：一个特定的监控指标的数据，监控项是zabbix数据收集的核心 触发器trigger：一个表达式，用于评估某监控对象的某特定item内所接收的数据是否在合理范围内，即阈值。当数据量大于阈值时，触发器状态从ok变为problem 事件event：发生的事情，如触发器状态的变化，新的agent或agent重新注册 动作action：指对特定事件事先定义的处理方法，包含操作与条件 报警升级escalation：发送警报或执行远程命令的自定义方案 媒介media：发送通知的手段或通道，如Email，jabber，SMS 通知notification：通过选定的媒介向用户发送的有关某事件的信息 远程命令：预定义的命令，可在被监控主机处于某特定条件下自动执行 模板template：用于快速定义被监控主机的预设条目集合，包含item，trigger，graph，screen（多个graph），application，low-level discovery rule。模板可以直接链接到单个主机 应用程序application：一组item的集合 web场景web scennaria：用于检测web站点可用性的一个或多个http请求 Zabbix特点： 配置简单：可使用模板，直接添加监控设备、可配置组监控、可对模板继承，进行精细设定 实时绘图，自定义监控图表（面板），支持网络拓扑图 灵活的告警机制：可自定义告警升级（escalation）、接受者和告警方式，还可通过远程命令实现自动化动作action 可进行不同类型数据的收集：性能、SNMP、IPMI、JMX，可自定义收集数据的间隔 数据存储：可将数据存放在数据库中，并内置数据清理机制 网络自动发现机制：自动发现网络设备、文件系统、网卡等，agent自动注册 zabbix由C开发，高性能，内存消耗低。web前段由php编写 提供丰富的API 可进行权限认证，并进行访问控制 zabbix搭建搭建zabbix监控服务器端 zabbix需要LAMP或LNMP的环境，先安装以下环境gcc gcc-c++ autoconf automake zlib zlib-devel openssl openssl-devel pcre-devel 安装php环境：yum install php 安装mysql/mariadb环境：yum install mariadb* LNMP环境搭建Zabbix可通过yum安装nginx，但版本不是最新的。通过源码安装nginx版本为1.14。 首先创建nginx用户及用户组。然后下载源码包并解压，进入目录 1234567891011121314151617181920./configure --prefix=/usr/local/nginx \ --sbin-path=/usr/sbin/nginx \ --conf-path=/etc/nginx/nginx.conf \ --error-log-path=/var/log/nginx/error.log \ --pid-path=/var/run/nginx/nginx.pid \ --lock-path=/var/lock/nginx.lock \ --user=nginx \ --group=nginx \ --http-log-path=/var/log/nginx/access.log \ --http-client-body-temp-path=/var/tmp/nginx/client \ --with-http_ssl_module \ --with-http_stub_status_module \ --with-http_gzip_static_module \ --with-http_dav_module \ --with-http_stub_status_module \ --with-http_addition_module \ --with-http_flv_module \ --with-http_mp4_module \ --with-http_sub_module \ --with-debug 进入/etc/nginx/nginx.conf添加一行user nginx nginx 安装zabbix，首先去官网选择主机环境版本下载页，安装zabbix的repo源。 然后安装zabbix-server-mysql zabbix-web-mysql zabbix-agent zabbix-web 若是客户端，不需要搭建LAMP或LNMP环境，只需要安装repo源和zabbix-agent和zabbix-sender，并且zabbix-sender也不是必须安装，若要主动向zabbix服务器发送监控数据时才需要安装。 zabbix的几个目录： /etc/zabbix：zabbix配置目录 /var/log/zabbix：zabbix日志目录 /var/run/zabbix：zabbix运行目录 /usr/lib/zabbix：zabbix库文件目录 /usr/share/zabbix：zabbix的web文件目录 修改nginx配置文件，找到下面配置，修改fastcgi_param后的路径为/usr/share/zabbix 1234567location ~ \.php$ &#123; root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/share/zabbix$fastcgi_script_name; include fastcgi_params;&#125; 在mysql创建zabbix库，和管理数据库的用户zabbix 123create database zabbixdb;grant all on zabbix.* to zabbix@127.0.0.1 identified by &apos;zabbix&apos;;flush privileges; 导入zabbix的sql文件，sql文件存放在/usr/share/doc/zabbix-server-mysql-3.4.14/create.sql.gz中，用gunzip create.sql.gz解压，然后导入mysql -u root -p zabbixdb &lt; create.sql 修改/etc/zabbix/zabbix_server.conf 1234DBHost=localhostDBName=zabbixdbDBUser=zabbixDBPassword=zabbix 安装zabbix后，会自动创建系统用户zabbix，但这个用户是设置了无法登录，而zabbix不允许。需要重新创建 zabbix命令 1234567891011121314zabbix_server -c 指定配置文件，默认/etc/zabbix/zabbix_server.conf -f 在前台运行zabbix_server -R 执行运行时管理功能，功能如下 config_cache_reload 重新读取配置缓存 housekeeper_execute 执行housekeeper log_level_increase=target 提升日志等级，若不指定target则影响zabbix所有进程 log_level_decrease=target 降低日志等级，同上 #target可以是PID，进程类型zabbix_agentd 与zabbix_server参数一致，并多了下面的配置 -p 显示已知的items -t 测试指定的item 启动zabbix_server服务systemctl start zabbix-server.service或zabbix_server启动 参考文章 zabbix官方中文手册]]></content>
      <tags>
        <tag>运维</tag>
        <tag>监控</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lucene与Solr笔记]]></title>
    <url>%2F2018%2F09%2F26%2FLucene%E4%B8%8ESolr%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[ELK与EFK详细笔记]]></title>
    <url>%2F2018%2F09%2F24%2FELK%E4%B8%8EEFK%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容： ELK Elasticsearch Logstash Kibana Beats ELK架构 EFK Fluentd EFK架构 Elasticsearch Elasticsearch是基于Lucene的搜索框架，使用Java编写，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口，上手容易，拓展节点方便，可用于存储和检索海量数据，接近实时搜索，海量数据量增加，搜索响应性能几乎不受影响。 Apache Lucene：目前存在的拥有最先进，高性能和全功能搜索引擎功能的库。但仅仅是一个库，Elasticsearch则是提供了Lucene库的RESTful API接口，将所有的功能打包成一个单独的服务，做到”开箱即用“。 Elasticsearch主要特点： 全文检索，结构化检索 数据统计、分析，接近实时处理 分布式搜索（可部署数百台服务器） 自动发现节点 副本机制 处理PB级别的结构化或者非结构化数据 保障可用性 搜索纠错，自动完成 与各种语言基础，与Hadoop、Spark等大数据分析平台集成 使用场景：日志搜索，数据聚合，数据监控，报表统计分析 使用Elasticsearch的大企业：维基百科、卫报、StackOverflow、Github、ebay Elasticsearch安装 因为Lucene和Elasticsearch都是Java写的，所以首先搭建JDK环境，下载JDK1.8，设置环境变量，并source /etc/profile应用 123echo &quot;export JAVA_HOME=/usr/local/jdk1.8&quot;&gt;&gt;/etc/profileecho &quot;export CLASSPATH=$JAVA_HOME/lib&quot;&gt;&gt;/etc/profileecho &quot;export PATH=$JAVA_HOME/bin:$PATH&quot;&gt;&gt;/etc/profile 下载Elasticsearch，目前版本为6.4.1，解压到/usr/local/elasticsearch-6.4 不能使用root运行elasticsearch，需要创建一个用户 12useradd elasticchown -R elastic:elastic /usr/local/elasticsearch-6.4 切换到该用户，并执行elasticsearch。等待一段时间启动，然后执行curl localhost:9200查看。若看到json对象信息则说明成功。 12345678910111213curl localhost:9200&#123; &quot;name&quot; : &quot;3dcAoxl&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;GNdmHFuXTsK-6B-swVNQag&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.4.1&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;,...... &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 运行报错 12bootstrap checks failed #bootstrap检查失败max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] #最大虚拟内存太低 解决： 临时解决： sysctl -w vm.max_map_count=262144 永久解决：修改/etc/sysctl.conf文件，添加 vm.max_map_count设置，并执行sysctl -p 1max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 解决：修改unix最大同时打开文件数，ulimit -n 65536 1234567elasticsearch -E &lt;键值对&gt; 设置参数 -d, --daemonize 后台启动 -p, --pidfile &lt;Path&gt; 设置PID文件 -q, --quiet 静默启动 -s, --silent 显示最少的输出 -v, --verbose 显示详细输出 Elasticsearch配置文件ES核心配置文件config/elasticsearch.yml 12345cluster.name: my-application #集群名称，若相同，且是同一网段会自动加入node.name: node-1 #当前节点名称node.attr.rack: r1 #network.host: 127.0.0.1 #默认情况下，Elastic只允许本机访问 #若要远程访问，取消注释并修改值为0.0.0.0 JVM配置文件jvm.option，最好不要调。 12345678-Xms1g #最小堆内存-Xmx1g #最大堆内存#两个值最好一致，且为机器物理内存的一半到2/3，也不能太小-XX:+UseConcMarkSweepGC-XX:CMSInitiatingOccupancyFraction=75-XX:+UseCMSInitiatingOccupancyOnly#垃圾回收算法，官方已经优化过了，不用调整 Elasticsearch概念Elasticsearch 是 面向文档 的，意味着它存储整个对象或文档。且Elasticsearch不仅存储文档，而且索引每个文档的内容使之可以被检索。在Elasticsearch 中，是对文档进行索引、检索、排序和过滤，而不是对行列数据。这就是ES能支持复杂的全文搜索的原因。 Elasticsearch使用JSON作为文档的序列化格式。存储数据到 Elasticsearch 的行为叫做索引（动词，索引一个文档就是存储一个文档到索引），一个 Elasticsearch 集群可以包含多个索引 ，相应的每个索引可以包含多个类型 。这些不同的类型存储着多个文档 ，每个文档又有多个字段 。Elasticsearch和Lucene使用倒排索引（也称反向索引）结构达到较高的检索速度。倒排索引就是关系型数据库通过增加一个索引到指定列上以提高搜索速度。 RESTRepresentational State Transfer表述性状态传递，是一种软件架构风格，提供的是一组设计原则和约束条件，主要用于客户端与服务器交互的软件，使得软件更简洁、有层次，更利于实现缓存等机制。 REST提供的与资源交互的方法：类似于HTTP，但REST的方法仅仅面向资源，无法对web应用操作。 GET：列出URI以及资源中详细信息 PUT：将给定的一组资源替换当前资源 POST：在指定资源中创建、追加一个新资源 DELETE：删除资源 HEAD：获取头信息 12345678PUT /megacorp/employee/1&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125; megacorp为索引名，employee为类型名，1为雇员ID。Elasticsearch仅需要找到雇员ID文件，就能知道该雇员的所有信息。 若要与关系型数据库对照，索引（indice或index）对应库，类型（type）对应表，文档（document）对应行，字段（field）对应列 Elasticsearch通过将数据分片（shards）存储以解决数据量大时不能直接存储在一块硬盘中，且无法一次性搜索超大的数据量的情况。创建索引时，只需定义所需的分片数即可。每个分片本身都是一个功能齐全且独立的“索引”，可以托管在集群中的任何节点上。 每个Elasticsearch分片都是Lucene索引。每个Lucene可包含的最大文件数量为Integer.MAX_VALUE - 128个文件可以使用/_cat/shards监视分片大小。 并通过创建分片的副本（replicas），当主分片不可用时，副本就充当主分片使用。Elasticsearch为每个索引分配5个主分片和1个副本，若集群中有两个节点，该索引的分片数会翻倍，即10个分片。 集群原理一个运行的Elasticsearch实例为一个节点，集群是由一个或多个拥有相同cluster.name的节点构成的，当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。 cluster.name默认为elasticsearch 主节点：负责管理集群范围内的所有变更（增删索引和节点等），任何节点都可以成为主节点。主节点并不需要涉及到文档级别的变更和搜索等操作，因此流量的增加它也不会成为瓶颈。 每个节点都知道任意文档所处的位置，并且能够将请求直接转发到存储客户所需文档的节点。 集群健康可通过curl localhost:9200/_cluster/health或使用telnet 127.0.0.1 9200并输入GET /_cluster/health HTTP/1.1获取集群的健康状况，或通过curl 127.0.0.1 9200/_cat/health?v查看。 123456&#123; &quot;cluster_name&quot;: &quot;elasticsearch&quot;, &quot;status&quot;: &quot;green&quot;, &quot;timed_out&quot;: false,......&#125; 其中健康状况就是字段status，有三个可能值： green：所有的主分片和副本分片都正常运行 yellow：所有的主分片都正常运行，但不是所有的副本分片都正常运行 red：有主分片没能正常运行，数据可能丢失，需要紧急修复 水平扩容读操作、搜索和返回数据都可以同时被主分片或副本分片所处理，所以拥有越多的副本分片时，也将拥有越高的吞吐量。在运行中的集群上是可以动态调整副本分片数目的 ，可以按需伸缩集群。 1234curl -H &quot;Content-Type: application/json&quot; -X PUT localhost:9200/blogs/_settings -d &apos;&#123; &quot;number_of_replicas&quot;: 2&#125;&apos; 如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少，需要增加更多的硬件资源来提升吞吐量，但是更多的副本分片数提高了数据冗余量。 添加索引可通过curl添加索引 12345678curl -H &quot;Content-Type: application/json&quot; -X PUT localhost:9200/blogs/article/1 -d &apos;&#123; &quot;title&quot;: &quot;article1&quot;, &quot;content&quot;: &quot;article1&quot;&#125;&apos;# -H设置内容类型，要设为JSON格式# -X设置请求类型，设为PUT# -d设置请求数据 若添加成功就会返回以下信息： 1234567891011121314&#123; &quot;_index&quot;: &quot;blogs&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;:&#123; &quot;total&quot;: 2, #目前总共的分片数 &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;_seq_no&quot;: 0, &quot;_primary_term&quot;: 1&#125; 对已存在的记录再进行PUT操作就会更新该记录，同时，该字段的_version和_result都会改变，_version会+1，_result会变为updated。 再通过curl localhost:9200/blogs/article/1，获取该文章的元数据，以及_source属性，存储的就是文章中定义的内容。 1234567891011&#123; &quot;_index&quot;: &quot;blogs&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;article1&quot;, &quot;content&quot;: &quot;article1&quot; &#125;&#125; 可通过curl localhost:9200/_cat/indices?v获取当前节点的索引信息 若要删除某个索引或类型或文档，都可通过curl -X DELETE localhost:9200/要删的资源删除。 简单搜索curl localhost:9200/_search?pretty获取本节点的所有文档信息，并且返回结果不仅告知匹配了哪些文档，还包含了整个文档本身：显示搜索结果给最终用户所需的全部信息。?pretty会将json重新排版显示。 1234567891011121314151617181920&#123; ...... &quot;hits&quot; : &#123; &quot;total&quot; : 2, &quot;max_score&quot; : 1.0, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;blogs&quot;, &quot;_type&quot; : &quot;article&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;article2&quot;, &quot;content&quot; : &quot;article2&quot; &#125; &#125;, ...... ] &#125;&#125; 可通过_all字段进行指定文档或类型中的搜索，例如/_all/employee/_search?进行指定类型中搜索（所有索引的中的employee（如果存在）） ?q=字段:值进行查询字符串（Query-string）搜索 1234567curl localhost:9200/_search?q=title:article2&#123; ...... &quot;hits&quot;:&#123;&quot;total&quot;:1,&quot;max_score&quot;:0.2876821,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;blogs&quot;,&quot;_type&quot;:&quot;article&quot;,&quot;_id&quot;:&quot;2&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123; &quot;title&quot;: &quot;article2&quot;, &quot;content&quot;: &quot;article2&quot; &#125;&#125;]&#125;&#125; 查询表达式搜索使用的是Elasticsearch开发的DSL（领域特定语言），基于JSON定义查询，能够构造复杂的查询语句。 不使用Query-string查询，而是通过请求体查询，请求会通过Json构造。 12345678curl localhost:9200/_search -X GET -H &quot;Content-Type: application/json&quot; -d &apos;&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; #使用了match类型查询 &quot;title&quot;: &quot;article1&quot; &#125; &#125;&#125;&apos; 常用请求体搜索规则： &quot;query&quot;:{}表示开始查询，其中定义许多查询规则，会计算评分数量（相关度）_score &quot;bool&quot;：进行布尔匹配 &quot;must&quot;：包含 &quot;must_not&quot;：不包含 &quot;match&quot;：普通匹配，若用空格隔开多个关键字，则es认为是或的关系，如果要同时满足多个关键词，即与关系，必须用bool查询 &quot;match_phrase&quot;：短语精确匹配 &quot;filter&quot;：过滤器，不会计算评分数量 &quot;range&quot;：匹配范围，例如：&quot;range&quot;:{age&quot;:{&quot;gt&quot;:30}}匹配age大于30 &quot;size&quot;：设置一次返回的结果数量，默认为10条。 &quot;from&quot;：设置移位，默认从位置0开始 12345678910111213141516171819202122# 已经alias curl_lo_g=&apos;curl -X GET -H &apos;Content-Type:application/json&apos;&apos;# export LO_ES=&apos;localhost:9200&apos;curl_lo_g $&#123;LO_ES&#125;/_all/employee/_search -d &apos;&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;age&quot;: &#123; &quot;gt&quot;: &quot;30&quot; #要加上双引号 &#125; &#125; &#125;, #这里有逗号 &quot;must&quot;: &#123; &quot;match&quot;: &#123; &quot;hobby&quot;: &quot;swimming&quot; &#125; &#125; &#125; &#125; &#125;&apos; 对于filter和query的区别： 大部分filter的速度快于query的速度 filter不会计算相关度得分，且结果会有缓存，效率高 全文搜索、评分排序，使用query 是非过滤，精确匹配，使用filter 高亮搜索能将搜索结果的要搜索的字符串高亮显示， 12345678910111213141516171819202122232425262728curl_lo_g $&#123;LO_ES&#125;/_all/employee/_search -d &apos;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;hobby&quot;: &quot;climbing&quot; &#125; &#125;, &quot;highlight&quot;: &#123; #只需要添加highlight搜索即可 &quot;fields&quot;: &#123; #fields指定高亮的字段 &quot;hobby&quot;: &#123;&#125; #需要高亮搜索的字段 &#125; &#125;&#125;&apos;......&#123;&quot;_index&quot;:&quot;tech&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;3&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123; &quot;name&quot;: &quot;wangwu&quot;, &quot;age&quot;: &quot;26&quot;, &quot;address&quot;: &quot;yangzhou&quot;, &quot;hobby&quot;: [&quot;swimming&quot;, &quot;climbing&quot;]&#125;,&quot;highlight&quot;:&#123; #标出高亮部分 &quot;hobby&quot;:[ &quot;&lt;em&gt;climbing&lt;/em&gt;&quot; #高亮部分由HTML标签&lt;em&gt;封装 #告诉浏览器把其中的文本表示为强调的内容 #通常为斜体 ]&#125;&#125;]&#125;&#125; 聚合聚合aggregations用于生成基于数据的精细分析结果，类似SQL的group by。 LogstashLogstash是一个开源的服务器端数据处理管道（Pipeline），它可以同时从多个源中提取数据，对其进行转换，然后将其发送到数据存储（如Elasticsearch）。支持丰富的 Input 和 Output 类型，能够处理各种应用的日志。 Logstash对于每一行数据（称为event）按流水线三个部分进行操作： input：负责产生事件（即数据），即数据源，如syslog、数据库日志、web日志、文件系统日志、java的log4j、网络日志、防火墙等各类日志，kafka、RabbitMQ等消息队列，移动设备、智能家居、传感器、联网汽车等IoT数据，以及Beats能获取的数据。是必须配置 filter：负责数据处理与转换，包括过滤，分类等操作。不是必须配置。 output：负责数据的输出，可输出到数据分析或存储的软件，如Elasticsearch，nagios，kibana等数据处理软件。是必须配置 Logstash开箱即用，包含许多聚合（aggregation）和突变（mutation），以及模式匹配（pattern matching），地理映射（geo mapping）和动态查找（dynamic lookup）功能。 Logstash安装 下载Logstash包，版本为6.4.1，解压到/usr/local/logstash6.4 进入logstash的bin目录执行./logstash -e &#39;input{stdin{}} output{stdout{codec=&gt;rubydebug}}&#39;，需要等待一段时间，期间会有信息，直到出现Successfully started Logstash API endpoint {:port=&gt;9600}，然后输入hello world即可看到以下信息。若要退出，按Ctrl+D。 1234567hello world&#123; &quot;message&quot; =&gt; &quot;hello world&quot;, &quot;host&quot; =&gt; &quot;VM_0_7_centos&quot;, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;@timestamp&quot; =&gt; 2018-09-26T11:09:10.781Z&#125; docker下载Logstash：直接docker pull logstash即可。 docker下启动Logstash：首先要确保本地存放pipeline配置文件的目录存在。通过在该目录添加配置文件。或者直接-v ~/config:/usr/share/logstash/config可直接修改所有配置 docker run -it -v ~/pipeline:/usr/share/logstash/pipeline logstash Logstash配置文件： logstash.yml：主配置文件 pipelines.yml：管道的配置，包括input，filter，output jvm.options：JVM配置文件 log4j2.properties：log4j2的配置 startup.options：启动脚本选项文件，包含Logstash的变量。若要让Logstash按修改后的配置运行，需要重新用root运行bin/system-install导入参数。 自定义的Logstash配置文件，一般以.conf结尾，同样存放在配置文件目录中。 logstash命令 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081logstash -n NAME 指定logstash的node.name，若不指定默认是当前的主机名 -f CONFIG_PATH 从特定文件或目录加载logstash配置 -e CONFIG_STRING 使用给定的字符串作为配置数据（与配置文件的语法相同） 默认输入：“input &#123;stdin &#123;type =&gt; stdin&#125;&#125;” 默认输出：“output &#123;stdout &#123;codec =&gt; rubydebug&#125;&#125;“ 若直接使用默认，则-e &quot;&quot; 即可（不能什么都不加） --field-reference-parser MODE 在解析字段引用时使用的模式 字段引用解析器用于扩展管道配置中的字段引用，能更好地处理非法和模糊输入 可用的MODE值：1. LEGACY：LEGACY解析器，不发出警告 2. COMPAT：COMPAT解析器，对每个不同的模糊或非法语法输入警告一次（默认使用） 3.STRICT：STRICT解析器，模糊或非法语法输入会引发插件运行时异常 --modules MODULES 加载logstash模块，不能与&apos;-e&apos;或&apos;-f&apos;一起使用 因为会覆盖在logstash.yml中加载的模块 两种写法：--modules module1 --modules module2 ... --modules=module1,module2 -M MODULES_VARIABLE Load variables for module template. Multiple instances of &apos;-M&apos; or &apos;--modules.variable&apos; are supported. Ignored if &apos;--modules&apos; flag is not used. Should be in the format of &apos;-M &quot;MODULE_NAME.var.PLUGIN_TYPE.PLUGIN_NAME.VARIABLE_NAME=VALUE&quot;&apos; as in &apos;-M &quot;example.var.filter.mutate.fieldname=fieldvalue&quot;&apos; --setup Load index template into Elasticsearch, and saved searches, index-pattern, visualizations, and dashboards into Kibana when running modules. (default: false) --cloud.id CLOUD_ID Sets the elasticsearch and kibana host settings for module connections in Elastic Cloud. Your Elastic Cloud User interface or the Cloud support team should provide this. Add an optional label prefix &apos;&lt;label&gt;:&apos; to help you identify multiple cloud.ids. e.g. &apos;staging:dXMtZWFzdC0xLmF3cy5mb3VuZC5pbyRub3RhcmVhbCRpZGVudGlmaWVy&apos; --cloud.auth CLOUD_AUTH Sets the elasticsearch and kibana username and password for module connections in Elastic Cloud e.g. &apos;username:&lt;password&gt;&apos; --pipeline.id ID Sets the ID of the pipeline. (default: &quot;main&quot;) -w COUNT 指定pipeline worker数量（即线程数），默认1 --experimental-java-execution (Experimental) Use new Java execution engine. (default: false) -b, --pipeline.batch.size SIZE Size of batches the pipeline is to work in. (default: 125) -u, --pipeline.batch.delay DELAY_IN_MS When creating pipeline batches, how long to wait while polling for the next event. (default: 50) --pipeline.unsafe_shutdown Force logstash to exit during shutdown even if there are still inflight events in memory. By default, logstash will refuse to quit until all received events have been pushed to the outputs. (default: false) --path.data PATH 数据存储目录。插件需要能访问该目录，默认安装目录下的data/ -p, --path.plugins PATH 插件目录，可指定多个Plugins are expected to be in a specific directory hierarchy: &apos;PATH/logstash/TYPE/NAME.rb&apos; where TYPE is &apos;inputs&apos; &apos;filters&apos;, &apos;outputs&apos; or &apos;codecs&apos; and NAME is the name of the plugin. (default: []) -l PATH 指定Logstash的日志目录，默认安装目录下的logs/ --log.level LEVEL 设置日志等级（fatal/error/warn/info/debug/trace），默认info --config.debug Print the compiled config ruby code out as a debug log (you must also have --log.level=debug enabled). WARNING: This will include any &apos;password&apos; options passed to plugin configs as plaintext, and may result in plaintext passwords appearing in your logs! (default: false) -i, --interactive SHELL Drop to shell instead of running as normal. Valid shells are &quot;irb&quot; and &quot;pry&quot; -t 检查logstash配置文件语法是否正常 -r 自动检测配置文件是否变动，若变动自动重载 --config.reload.interval RELOAD_INTERVAL How frequently to poll the configuration location for changes, in seconds. (default: 3000000000) --http.host HTTP_HOST Web API binding host (default: &quot;127.0.0.1&quot;) --http.port HTTP_PORT Web API http port (default: 9600..9700) --log.format FORMAT Specify if Logstash should write its own logs in JSON form (one event per line) or in plain text (using Ruby&apos;s Object#inspect) (default: &quot;plain&quot;) --path.settings SETTINGS_DIR 包含logstash.yml的目录，可通过LS_SETTINGS_DIR环境变量配置 默认&quot;/usr/local/logstash6.4/config&quot; --verbose 相当于设置日志等级为info --debug 相当于设置日志等级为debug --quiet 相当于设置日志等级为info Logstash如何工作关闭Logstash可通过systemctl stop logstash或直接kill关闭。Logstash有自己关闭过程，以达到安全地关闭： 首先停止所有的input、filter、output插件 处理完所有管道中的事件 最后关闭Logstash进程 在处理过程中，以下的状况会影响关闭过程： input插件以很慢的速度接收数据 速度慢的filter，如执行sleep(10000)的Ruby filter或执行非常繁重的查询的Elasticsearch过滤器。 一个断开连接的output插件，等待重新连接以刷新正在进行的事件。 Logstash有一个停顿检测机制（stall detection），可以在关闭过程中分析管道和插件的行为。此机制会对内部队列中的飞行事件（in-flight events）数量和繁忙的worker线程列表定期生成信息报告。 若要在Logstash关闭阶段直接强行关闭，可在主配置文件中设置pipeline.unsafe_shutdown值为true，但这样可能造成数据丢失，不安全。 Logstash配置文件logstash.yml因为配置文件的语法是YAML，所以有两种写法： 1234567pipeline: batch: size: 125 delay: 50#等同于pipeline.batch.size: 125pipeline.batch.delay: 50 配置文件也支持${}引用变量 如果使用命令的--modules指定模块，则配置文件中所有配置的模块都会被忽略。 模块的配置： 123modules: - name: 模块名 var.插件类型.插件名.键: 值 所有配置参数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253node.name #节点名，默认为主机名#path参数path.data #数据存放目录，默认为安装目录的data/path.config #logstash.yml路径path.plugins #插件的路径#插件应该位于特定的目录层次结构中：PATH/logstash/TYPE/NAME.rb#其中TYPE的值可以是inputs，filters，outputs或codecs，NAME是插件的名称#http参数http.port #监听的http主机端口，默认为9600http.host #监听的http主机IP，默认为127.0.0.1#日志log参数log.level #日志等级（fatal/error/warn/info/debug/trace），默认infolog.format #日志格式，默认为plain格式path.logs #日志的路径，默认安装目录的logs/#pipeline参数（关于pipeline的配置可专门存放在一个配置文件中，如pipeline.yml）pipeline.id #pipeline的ID，默认为mainpipeline.workers #管道的worker数量，默认为CPU的核数pipeline.batch.size #单个工作线程将从输入收集的最大事件数，默认125。增大此值会加大内存开销，还需调整JVM堆内存参数pipeline.batch.delay #event被调度到worker前等待的时间，单位毫秒，默认50pipeline.unsafe_shutdown #在关闭时立刻退出，会导致数据丢失。 #默认为false，完全退出前会将数据处理好并输出到屏幕再退出#config参数config.string #pipeline配置config.test_and_exit #检查配置是否有效，然后退出。默认为false不检查config.reload.automatic #定期检查配置是否已更改，并在配置发生更改时重新加载配置。默认false不检查config.reload.interval #检查配置是否变动的时间间隔，需要上一条开启。默认3sconfig.debug #是否开启调试日志消息。若开启还需要将log.level的值设为debug。默认false #注：日志消息可能会包含明文密码config.support_escapes #是否开启转义字符，即启用\转义。默认falsemodules #设置模块#queue参数queue.type #用于事件缓冲的队列模型（model to use for event buffering），有以下两种，默认memory。 memory：传统基于内存的队列 persisted：基于磁盘的响应队列（disk-based ACKed queueing）path.queue #启用持久队列（即上一项值为persisted）时存储数据文件的目录。默认data/queuequeue.pagt_capacity #启用持久队列时使用的页面数据文件的大小。默认64MBqueue.max_events #启用持久队列时队列中未读事件的最大数量。默认0，不限制queue.max_bytes #队列的总容量，以字节数表示。确保磁盘容量大于此值。默认1G#若与上一项同时配置，则Logstash会加载先配置的一项queue.checkpoint.acks #启用持久队列时强制检查点之前的最大ACK响应事件数。默认1024，若设为0则不限制queue.checkpoint.writes #在启用持久队列时强制检查点之前写入事件的最大数量。默认1024，若设为0则不限制queue.drain #启用后，Logstash将等待直到持久队列耗尽，然后才能关闭。默认false#dead_letter_queue参数dead_letter_queue.enable #是否启用dead_letter_queue，简称DLQ功能。默认false不启用dead_letter_queue.max_bytes #每个DLQ的最大大小。超出就会删除条目，默认1Gpath.dead_letter_queue #DLQ目录的位置，默认为安装目录的data/dead_letter_queue 自定义Logstash配置文件自定义的配置文件主要用于指定input、filter、output插件等管道参数。 配置文件支持的值类型： 列表Lists：[ ]中包含多个值。如path =&gt; [&#39;XXX&#39;,&#39;XXX&#39;] 布尔值Boolean：指定true或false 字节Bytes：是字符串字段，表示有效的字节单位。支持SI（k M G T P E Z Y）和二进制（binary）（Ki Mi Gi Ti Pi Ei Zi Yi）单位。二进制单位基数为1024，SI单位基数为1000。此字段不区分大小写，并接受值和单位之间的空格。 编解码器codec：表示数据的Logstash编解码器的名称。编解码器可用于输入和输出。例：codec =&gt; json 输入编解码器提供了一种在数据进入输入之前对其进行解码的便捷方式。 输出编解码器提供了一种在数据离开输出之前对数据进行编码的便捷方式。 使用输入或输出编解码器无需在Logstash管道中使用单独的过滤器。 哈希Hash：键值对集合，多条键值对间使用空格间隔，而不是逗号 数字Number：数字必须为浮点型或整型 密码Password：密码必须是一个字符串，且该字符串应未被记录或打印 URI：可以是完整的URL，也可以是类似邮件地址，如user:pass@XXX.net，如果URI包含密码，则不会记录或打印URI的密码部分 路径Path：表示有效操作系统路径的字符串 字符串String：必须用引号括住，可以是单引号或双引号 转义序列Escape Sequences：默认不启用转义序列。如果要在字符串中使用转义字符，需要在logstash.yml中设置config.support_escapes：true。 Logstash日志Logstash的日志存放在LS_HOME/logs中，默认日志等级为INFO， Logstash的日志框架基于Log4j 2框架，其大部分功能直接暴露给用户。 在调试问题时，尤其是插件问题时，一般将日志记录级别增加到DEBUG以获取更详细的消息。从5.0版本开始，可以在Logstash中配置特定日志子系统的日志记录。 Logstash提供一个带有开箱即用设置的log4j2.properties文件，可以更改轮换策略，类型和其他log4j2配置。需要重启Logstash以应用该配置。 慢日志（Slowlog）用于报告在通过管道（pipeline）时花费不正常时间的事件的日志消息。慢日志同样存放在LS_HOME/logs中。可在主配置文件中添加slowlog的配置，如下： 1234slowlog.threshold.warn: 2sslowlog.threshold.info: 1sslowlog.threshold.debug: 500msslowlog.threshold.trace: 100ms 以上配置指定了触发慢日志的条件。在过滤器中处理超过100ms的事件会在慢日志中记录为trace等级的事件，超过2秒的事件会记录为等级为warn的事件 可通过curl -X GET localhost:9600/_node/logging?pretty获取关于日志的信息 12345678910111213curl localhost:9600/_node/logging?pretty&#123; "host" : "VM_0_7_centos", "version" : "6.4.1", "http_address" : "127.0.0.1:9600", "id" : "07b4b966-d732-4263-bc16-1efc6e927e1c", "name" : "VM_0_7_centos", "loggers" : &#123; #显示的是日志子系统以及日志等级 "logstash.agent" : "INFO", "logstash.api.service" : "INFO", "logstash.codecs.line" : "INFO", "logstash.codecs.rubydebug" : "INFO",...... 可通过curl -X PUT localhost:9600/_node/logging?pretty -H &#39;Content-Type: application/json&#39; -d &#39;{...}&#39;动态设置指定日志子系统的日志等级。例如： 1234curl -XPUT &apos;localhost:9600/_node/logging?pretty&apos; -H &apos;Content-Type: application/json&apos; -d &apos;&#123; &quot;logger.logstash.outputs.elasticsearch&quot; : &quot;DEBUG&quot;&#125;&apos; 则会在log4j2.properties配置中自动添加上该指定配置。若要重置已通过日志记录API动态更改的任何日志记录级别，需要通过将PUT请求发送到_node/logging/reset将所有日志记录级别都恢复为log4j2.properties文件中指定的值 curl -X PUT localhost:9600/_node/logging/reset?pretty 将其他任意日志导入Logstash的操作：编写一个pipeline配置文件test.conf，或直接在pipeline.yml添加 123456789input &#123; #设置input参数 file &#123; #通过列表添加两个日志 path =&gt; [&apos;/var/log/httpd/access_log&apos;,&apos;/var/log/squid/access.log&apos;] &#125;&#125;output &#123; #标准输出，一定要加，否则无法输出到屏幕 stdout &#123;&#125;&#125; 启动Logstash，bin/logstash -f config/test.conf。会不断获取httpd和squid的日志消息 1234567891011121314&#123; &quot;path&quot; =&gt; &quot;/var/log/httpd/access_log&quot;, &quot;message&quot; =&gt; &quot;127.0.0.1 - - [02/Oct/2018:16:11:16 +0800] \&quot;GET / HTTP/1.0\&quot; 200 10 \&quot;-\&quot; \&quot;ApacheBench/2.3\&quot;&quot;, &quot;@timestamp&quot; =&gt; 2018-10-02T08:11:20.344Z, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;VM_0_7_centos&quot;&#125;&#123; &quot;path&quot; =&gt; &quot;/var/log/squid/access.log&quot;, &quot;message&quot; =&gt; &quot;1538467887.306 656 180.126.242.119 TCP_TUNNEL/200 33103 CONNECT xui.ptlogin2.qq.com:443 - HIER_DIRECT/xui.ptlogin2.qq.com -&quot;, &quot;@timestamp&quot; =&gt; 2018-10-02T08:11:27.355Z, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;VM_0_7_centos&quot;&#125; 若要将elasticsearch的日志都再导入elasticsearch，可进行以下配置： 12345678910111213141516input &#123; file &#123; path =&gt; &apos;/usr/local/es-6.4/logs/elasticsearch.log&apos; type =&gt; &apos;elasticsearch&apos; start_position =&gt; &apos;beginning&apos; #从日志的头开始读 &#125;&#125;output &#123; elasticsearch &#123; #使用elasticsearch插件 hosts =&gt; &apos;127.0.0.1:9200&apos; #指定elasticsearch源 index =&gt; &apos;es_message-%&#123;+YYYY.MM.dd&#125;&apos; #指定index &#125; stdout&#123; codec =&gt; rubydebug &#125;&#125; 启动Logstash就会显示已导入elasticsearch的日志 12345678&#123; &quot;type&quot; =&gt; &quot;elasticsearch&quot;, &quot;message&quot; =&gt; &quot;[2018-10-03T16:06:50,392][INFO ][o.e.c.m.MetaDataMappingService] [system135] [.kibana/PnIK501cQUydUEIVp0icjw] update_mapping [doc]&quot;, &quot;@timestamp&quot; =&gt; 2018-10-03T08:06:50.560Z, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;system5.example.com&quot;, &quot;path&quot; =&gt; &quot;/usr/local/es-6.4/logs/elasticsearch.log&quot;&#125; Logstash常用插件默认的Logstash安装包括Beats输入插件。 Beats输入插件使Logstash能够从Elastic Beats框架接收事件，任何与Beats框架一起使用的Beat（如Packetbeat和Metricbeat），也可以将事件数据发送到Logstash。 Grok：是Logstash过滤器的基础，用于从非结构化数据中获取结构，具有丰富的集成模式，能快速处理Web，系统，网络和其他类型的事件格式。 Codecs：通常用于简化对JSON和多行事件等常见事件结构的处理。 KibanaKibana是一个开源分析和可视化平台，旨在与Elasticsearch协同工作。可使用Kibana搜索，查看以及与存储在Elasticsearch索引中的数据进行交互，可以轻松地执行高级数据分析，并在各种图表（charts），表格（tables）和地图（maps）中可视化数据。 Kibana是基于JS的WEB界面，在Node.js上运行，而官方在Kibana包中包含了必要的Node.js二进制文件，并且不支持针对单独维护的Node.js版本运行Kibana，因此不需要单独搭建Nodejs环境。 应将Kibana配置为针对相同版本的Elasticsearch节点运行，即版本要一致。 注：从V6.0.0开始，Kibana仅支持64位操作系统。 Kibana安装下载Kibana包，版本为6.4.1，解压到/usr/local/kibana6.4 kibana需要elasticsearch的开启才能正常使用，否则启动kibana会不断报错，进入Kibana后也会提示status为red，无法正常使用，因此需要先启动elasticsearch。开启后，进入kibana目录下bin执行kibana命令。需要等待一段时间直到出现信息[info][listening][server][http] Server running at http://localhost:5601。通过浏览器localhost:5601访问kibana。 注：内存或CPU不足会将Elasticsearch杀死，Kibana也就无法启动 Kibana的文件结构：除了bin、config、data、plugins，kibana还有以下目录： node： node_modules optimize：存放透明的源代码。某些管理操作（例如，插件安装）导致源代码在运行中被重新传输。 src webpackShims 可在浏览器访问localhost:5601/status查看kibana是否启动正常，插件是否加载正常，以及kibana的当前信息。 启动时Kibana信息处理warning消息 123[warning][security] Generating a random key for xpack.security.encryptionKey. To prevent sessions from being invalidated on restart, please set xpack.security.encryptionKey in kibana.yml 1[warning][security] Session cookies will be transmitted over insecure connections. This is not recommended. Kibana配置Kibana只有一个配置文件KIBANA_HOME/config/kibana.yml。默认运行在localhost的5601端口。 常见配置： 123456789101112131415161718server.port: 5601 #Kibana服务端口server.host: &quot;localhost&quot; #向哪些主机开放端口，若要所有主机都能访问，即客户端能远程访问，需要设为0.0.0.0server.name: &quot;your-hostname&quot; #Kibana实例名，一般为主机名server.basePath: &quot;&quot; #server.maxPayloadBytes: 1048576server.rewriteBasePath: falseelasticsearch.url: &quot;http://localhost:9200&quot; #Elasticsearch的地址，需要设置正确elasticsearch.preserveHost: truekibana.index: &quot;.kibana&quot;kibana.defaultAppId: &quot;home&quot;#elasticsearch.username: &quot;user&quot; #设置es授权用户名#elasticsearch.password: &quot;pass&quot; #设置es授权用户密码#server.ssl.enabled: false #是否开启ssl#server.ssl.certificate: /path/to/your/server.crt#server.ssl.key: /path/to/your/server.key#elasticsearch.ssl.certificate: /path/to/your/client.crt#elasticsearch.ssl.key: /path/to/your/client.key Kibana基本功能添加index的管理首先要在elasticsearch添加index数据 1234567curl -X PUT -H &quot;Content-Type: application/json&quot; localhost:9200/tech/employee/1 -d &apos;&#123; &quot;name&quot;: &quot;zhangsan&quot;, &quot;age&quot;: &quot;25&quot;, &quot;address&quot;: &quot;nanjing&quot;, &quot;hobby&quot;: [ &quot;football&quot;, &quot;tennis&quot;, &quot;game&quot; ]&#125;&apos; 然后刷新kibana，进入Management中的Kibana，选Index pattern，并创建。 创建完成后，进入Discover菜单，可查看插入的数据 使用kibana提供的数据进行分析从kibana文档中下载数据，可选择银行账户数据account.json，下载以后使用curl -H &#39;Content-Type: application/x-ndjson&#39; -XPOST &#39;localhost:9200/bank/account/_bulk?pretty&#39; --data-binary @accounts.json导入elasticsearch。开启kibana，进入Management添加index pattern，然后进入Discover菜单，选择bank，添加要看的字段。 为数据创建报表，进入Visualize菜单，可根据需要选择报表形式，此处选Pie饼图，然后再选择bank即可进入定制界面。 选择split slices，然后在聚合（aggregation）中选择range，然后进行自定义数据范围 ELK架构若环境的内存少，就在es配置文件添加以下配置 bootstrap.memory_lock: false 为避免内存与磁盘间的swap，会损耗大量性能 bootstrap.system_call_filter: false 参考文章 全文搜索引擎 Elasticsearch 入门教程 每天5分中玩转docker容器技术 Elasticsearch: 权威指南 Elasticsearch官方文档 Logstash简单介绍 ELK 之 Logstash Logstash官方文档 ES之五：ElasticSearch聚合]]></content>
      <tags>
        <tag>运维</tag>
        <tag>监控</tag>
        <tag>Elasticsearch</tag>
        <tag>ELK</tag>
        <tag>EFK</tag>
        <tag>Kibana</tag>
        <tag>Logstash</tag>
        <tag>搜索</tag>
        <tag>日志</tag>
        <tag>Fluentd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重学数据结构与算法笔记]]></title>
    <url>%2F2018%2F09%2F15%2F%E9%87%8D%E5%AD%A6%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neural-style试玩环境搭建]]></title>
    <url>%2F2018%2F09%2F15%2FNeural-style%E8%AF%95%E7%8E%A9%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Cacti监控学习]]></title>
    <url>%2F2018%2F09%2F15%2FCacti%E7%9B%91%E6%8E%A7%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[本篇笔记包含以下内容： Cacti原理与安装 Cacti常用操作 Cacti原理与安装Cacti是一套基于PHP，MySQL，SNMP及RRDTool开发的网络流量监测图形分析工具。使用SNMP服务获取数据，用rrdtool存储和更新数据，并可以使用rrdtool生成图表。因此SNMP和RRDtool是Cacti的关键。注意，Cacti仅仅是一个展示工具，是一个PHP网页，真正实现数据收集以及绘图的是SNMP和RRDtool。 MySQL与PHP用来存储一些变量数据并对变量进行调用，如主机名、主机IP、Snmp团体名、端口号、模板信息等，Snmp抓取的数据并不存放在MySQL中，而是存放在rrdtool生成的RRD文件中，rrdtool对数据的更新和存储就是对RRD文件的处理，RRD文件是大小固定的档案文件，能存储的数据量在创建时就被定义好了。 Cacti特点： 提供图形化页面操作实现rrdtool create命令 周期性执行能取得数据的命令，并将取回的数据存储在rrd文件中 通过rrdtool绘图并展示 强大的用户管理机制 丰富的插件库，如thold，并提供插件框架允许自定义模板 Cacti模板分为三类： 图形模板：定义图形的绘制 数据模板：定义如何获得数据，如何保存数据 主机模板：就是分好类的图形模板和数据模板，可直接应用于一个或一类主机 SNMP简介 Simple Network Management Protocol简单网络管理协议，由一组网络管理的标准组成，包含一个应用层协议、数据库模型（database schema）和一组资源对象。该协议能够支持网络管理系统，用以监测连接到网络上的设备是否有任何引起管理上关注的情况。 SNMP管理的网络主要由三部分组成： 被管理的设备 SNMP代理（Agent） 网络管理系统（NMS） 三部分之间的关系： 网络中被管理的每一个设备都存在一个管理信息库（MIB）用于收集并储存管理信息。通过SNMP协议，NMS能获取这些信息。被管理设备，又称为网络单元或网络节点，可以是支持SNMP协议的路由器、交换机、服务器或者主机等等。 SNMP代理是被管理设备上的一个网络管理软件模块，拥有本地设备的相关管理信息，并用于将它们转换成与SNMP兼容的格式，传递给NMS。 NMS运行应用程序来实现监控被管理设备的功能。另外，NMS还为网络管理提供大量的处理程序及必须的储存资源。 上述资料引用自百度百科snmp RRDtool简介 Round Robin Database Tool轮询式数据库工具，是一个强大的绘图的引擎。其中，Round Robin是一种存储数据的方式，使用固定大小的空间来存储数据，并有一个指针指向最新的数据的位置。RRDtool针对处理的是时序型数据(time-series data)，比如网络带宽，温度，CPU负载等等这些和时间相关联的数据或者说指标。 上述资料引用自百度百科rrdtool和RRDtool入门详解 Cacti安装首先需要搭建LAMP环境yum install httpd php php-devel php-gd gd gd-devel gcc glibc openssl* mariadb* zlib* php-xml libxml libjpeg libpng freetype cairo-devel pango-devel cairo是一个2D图形库 Pango是一个用于布局和呈现文本的库 gd也是一个图形库，用于动态生成图片 12345yum install net-snmp \ net-snmp-devel \ net-snmp-utils \ lm_sensors \ rrdtool* 安装snmp主程序及相关监控工具。net-snmp会提供两个命令snmpwalk和snmpget lm_sensors：是一款基于linux系统的硬件监控的软件。可以监控主板，CPU的工作电压，温度等数据。 开启snmpd和snmptrapd服务systemctl start snmpd snmptrapd 修改snmp配置文件/etc/snmp/snmpd.conf，找到com2sec notConfigUser default public一行，复制到下一行并修改 12com2sec myuser 127.0.0.1 mycommunity# 127.0.0.1可配置为要监控的主机或网段 找到下面的group配置，同样复制一行并修改 1group mygroup v2c myuser 再下面，找到view配置，添加一行 1view all included .1 保存并重启snmpd服务。执行snmpwalk -c mycommunity 127.0.0.1 -v2c可看到大量信息。 注：如果是被监控主机，只需要安装net-snmp和lm_sensors即可。 cacti安装完成后，会在/etc/httpd/conf.d/中生成一个cacti.conf配置文件，可以不用改动，文件中指定的网页存储位置为/usr/share/cacti/，该目录中存放着所有php网页。 cacti的sql数据存放在/usr/share/doc/cacti/cacti.sql需要导入数据库。首先要进入mariadb，创建数据库cactidb，退出后，mysql -u root -p cactidb &lt; /usr/share/doc/cacti/cacti.sql导入数据库。 在数据库中创建用户管理cactidb，进入数据库grant all on cactidb.* to cactiadmin@localhost identified by &quot;cactiadmin&quot;;并flush privileges; 设置httpd虚拟主机，使用户通过cacti.example.com直接访问 1234567891011&lt;VirtualHost *:80&gt; ServerName cacti.example.com DocumentRoot &quot;/usr/share/cacti&quot; ErrorLog &quot;log/cacti-access.log&quot; CustomLog &quot;log/cacti-error.log&quot; common&lt;/VirtualHost&gt;&lt;Directory &quot;/usr/share/cacti&quot;&gt; Require all granted Options Indexes AllowOverride None&lt;/Directory&gt; 修改管理Cacti的配置文件/usr/share/cacti/include/config.php，修改以下内容： 1234$database_default = &apos;cactidb&apos;; 设置数据库名$database_username = &apos;cactiadmin&apos;; 设置数据库中cacti用户名$database_password = &apos;cactiadmin&apos;; 设置数据库中cacti用户密码$url_path = &apos;/&apos;; 网页访问的路径，可改可不改，若不改就是通过http://localhost/cacti访问 创建普通用户用于周期性执行获取数据的php脚本，因为为了安全性，不能让管理员执行。useradd cactiuser，并且将cacti目录中log和rra目录的所属人和所属组都改为cactiuser，chown -R cactiuser:cactiuser /usr/share/cacti/log /usr/share/cacti/rra 至此，安装配置完毕，重启Apache，浏览器输入cacti.example.com访问，开始网页配置。 若遇到以下报错： 说明cacti数据库管理员cactiadmin没有对mysql.time_zone_name表的select权限，需要授权。 12grant select on mysql.time_zone_name to cactiadmin@localhost;flush privileges; 并且要修改/etc/my.cnf配置，在[mysqld]下添加： 1default-time-zone = &apos;+8:00&apos; 重启并进入mysql，使用命令验证 1234567show variables like &apos;%time_zone%&apos;; +------------------+--------+| Variable_name | Value |+------------------+--------+| system_time_zone | CST || time_zone | +08:00 |+------------------+--------+ 退出MySQL，使用命令mysql_tzinfo_to_sql tz_file tz_name | mysql -u root -p mysql tz_file指timezone文件，存放在/usr/share/zoneinfo中 执行mysql_tzinfo_to_sql /usr/share/zoneinfo/Asia/Shanghai Shanghai | mysql -u root -p mysql 说明php的timezone没设置，修改/etc/php.ini，把;date.timezone =注释去除，设置为date.timezone = Asia/Shanghai。支持的时区表 网页下拉还有类似的问题，需要修改mysql表中相应参数。修改/etc/my.cnf文件，在[mysqld]下添加报错项，只要满足即可。 12345678max_heap_table_size=2048Mtmp_table_size=2048Mjoin_buffer_size=2048Minnodb_buffer_pool_size=2048Minnodb_doublewrite=offinnodb_flush_log_at_timeout=10innodb_read_io_threads=32innodb_write_io_threads=16 修改完后重启php和mysql 12systemctl restart mariadb.service systemctl restart php-fpm.service 重新访问cacti.example.com。进入安装选项页面： 有两种选项： 12New Primary Server：若是主节点就选这项New Remote Poller：若是用于收集主节点无法访问的服务器的信息，就选这项 Cacti的各个路径已自动设置好。由于Spine还没有安装，所以会提示错误，但不影响安装。 安装模板，若为Linux或unix主机，必选Local Linux Machine，若为Windows主机，必选Windows Device。 用户登录界面，初始的管理员用户名和密码都是admin，登陆后会强制要求更改。 密码设置有几个条件必须满足： 大于8位 含有字母大小写 至少包含一个数字 至少包含一个特殊字符 若想绕过这些规则，可直接进入mysql的cactidb库，执行update user_auth set password = md5(&quot;密码&quot;) where username=&quot;admin&quot;; 然后就进入了cacti主界面。 查看Graph页面，出现以下报错： 是因为没有运行/usr/share/cacti/poller.php，这个是cacti自带的脚本，用于收集数据，并生成图表。默认cacti每5分钟收集一次信息，所以要设置定时，每五分钟运行该脚本。而cacti安装后已生成一个文件/etc/cron.d/cacti，内容如下：若带有注释，就将注释去除，并要修改用户名。需要确定crond服务是否启动。 1*/5 * * * * cactiuser /usr/bin/php /usr/share/cacti/poller.php &gt; /dev/null 2&gt;&amp;1 最好通过crontab -e -u cactiuser输入*/5 * * * * /usr/bin/php /usr/share/cacti/poller.php &gt; /dev/null 2&gt;&amp;1设置cron。 先手动执行一次php /usr/share/cacti/poller.php &gt; /dev/null 2&gt;&amp;1，可通过查看/var/log/cacti/cacti.log确认是否能获取数据。然后查看/usr/share/cacti/rra/是否有rrd文件。然后重启httpd，访问cacti的Graph。 有可能没有启动的原因是系统时间和BIOS时间不符，通过hwclock -s同步。 参考文章 Cacti实战 Linux运维之道（第二版） 高性能网站构建实战 Cacti完全使用手册 ( 让你快速个性化使用Cacti ) 服务器监控系统cacti cacti安装与配置 使用 SNMP 和 Cacti 监控 Linux 服务器]]></content>
      <tags>
        <tag>运维</tag>
        <tag>监控</tag>
        <tag>server</tag>
        <tag>Cacti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLite学习笔记]]></title>
    <url>%2F2018%2F09%2F07%2FSQLite%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容： SQLite介绍与安装 []]]></content>
      <tags>
        <tag>数据库</tag>
        <tag>SQLite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cuda环境搭建]]></title>
    <url>%2F2018%2F08%2F16%2FCuda%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[CUDA为 CUDA搭建CUDA环境搭建大致需要以下步骤： Nvidia显卡驱动安装 CUDA安装 cuDNN安装 Nvidia驱动安装首先卸载现有的驱动（如果不是最新的话） sudo apt-get remove nvidia* 自动安装Nvidia最新驱动 sudo apt-get install bumblebee-nvidia nvidia-driver nvidia-settings 其中：nvidia-driver对应了最新的Nvidia驱动，bumblebee-nvidia为Nvidia的大黄蜂模式驱动，用于双显卡智能切换。 安装Nvidia的系统管理界面Nvidia-smi sudo apt-get install nvidia-smi 使用nvidia-smi查看显卡详细信息 12]]></content>
      <tags>
        <tag>CUDA</tag>
        <tag>Nvidia</tag>
        <tag>人工智能</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IS-IS学习笔记]]></title>
    <url>%2F2018%2F08%2F05%2FIS-IS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于华三网络学习笔记 本篇主要包含以下内容： OSI地址 IS-IS概述 IS-IS实现 OSI地址在OSI协议体系中，OSI地址标识了一台支持OSI协议的设备。IS-IS的报文封装在数据链路层，采用OSI报文格式，包含OSI地址。IS-IS协议将ISO网络层地址称NSAP。IS-IS用OSI地址标识不同IS，并构建网络拓扑数据库，计算到达各节点的最短路径树。 OSI地址使用的是NASP（Network Service Access Point网络服务接入点）地址格式，是IP地址和上层协议号的组合，用于标识设备和设备启用的服务。 NASP由IDP（Initial Domian Part初始域部分）和DSP（Domain Specific Part域指定部分），IDP表示IP地址的主网络号，DSP表示IP地址的子网号和主机地址。IDP和DSP长度是可变的，但NASP的总长最多为20字节，最少8字节。 在IS-IS中，NASP地址被分为3部分：可变长区域地址，System ID，NSEL。 System ID用于在区域中唯一表示主机或服务器，一般会由Router ID转换得出。 转换方法：Router ID的每部分都扩展为3位数字，不足则在前补零，将扩展后的地址重新划分为3部分，每部分4个数字，得到System ID NSEL类似于协议标识符，当协议为IP时，NSEL均为00。 路由器只需配置一个区域地址，但最多可以配置3个，同一区域中所有节点的区域地址都相同。 NET（Network Entity Title网络实体名称）指示的是IS本身的网络层信息，不包括传输层信息，可看做NSEL为0的特殊的NASP。一台路由器只需配置一个NET，最多3个，若配置多个NET，则必须保证System ID相同。NET除了可以通过Router ID转换变得，也可通过MAC地址转换变得，但MAC地址由于具有全局性，一个区域内的路由器的MAC没有规律，管理不方便，所以一般还是用Router ID映射。 IS-IS概述IS-IS（Intermediate System-to-Intermediate System，中间系统到中间系统）是ISO为CLNP（Connection Less Network Protocol，无连接网络协议）设计的一种动态路由协议。IS-IS能够同时应用在TCP/IP和OSI环境中，形成了集成化IS-IS。采用TLV架构，易于扩展。 IS-IS属于内部网关路由协议，用于自治系统内部。IS-IS是一种链路状态协议，与TCP/IP网络中的OSPF协议非常相似，使用最短路径优先算法SPF进行路由计算。 IS-IS常见术语：区域（Area）：路由域的细分单元，IS-IS允许将整个路由域分为多个区域 路由域（Routing Domain）：较大的区域，可包含多个区域 中间系统Intermediate System（IS）：即路由器 终端系统End System（ES）：即主机 ES-IS：主机和路由器之间运行的协议 IS-IS：路由器与路由器之间运行的协议，就是用来提供路由域内或一个区域内的路由 IS-IS路由器有三种角色： Level-1：负责区域内的路由，只与属于同一区域的Level-1和Level-1-2路由器形成邻居关系，维护一个Level-1的链路状态数据库，该链路状态数据库包含本区域的路由信息，到区域外的报文转发给最近的Level-1-2路由器。 Level-2：负责区域间的路由，可以与同一区域或者其它区域的Level-2和Level-1-2路由器形成邻居关系，维护一个Level-2的链路状态数据库，该链路状态数据库包含区域间的路由信息。所有Level-2路由器和Level-1-2路由器组成路由域的骨干网，负责在不同区域间通信，路由域中的Level-2路由器必须是物理连续的，以保证骨干网的连续性。 Level-1-2：同时属于Level-1和Level-2的路由器，可以与同一区域的Level-1和Level-1-2路由器形成Level-1邻居关系，也可以与同一区域或者其他区域的Level-2和Level-1-2路由器形成Level-2的邻居关系。Level-1路由器必须通过Level-1-2路由器才能连接至其他区域。Level-1-2路由器维护两个链路状态数据库，Level-1的链路状态数据库用于区域内路由，Level-2的链路状态数据库用于区域间路由。 每台路由器只能属于一个区域，区域边界在链路上。 IS-IS协议报文IS-IS使用协议数据单元PDU进行通讯。PDU有以下类型： IS-IS Hello PDU：简称IIH，负责路由间的邻居关系建立和维护 链路状态PDU：简称LSP，描述路由器中的所有链路状态信息 时序报文SNP：用于确认邻居间最新接收的LSP，类似于确认报文。包括两种报文：CSNP和PSNP 全时序报文CSNP：包含网络中每个LSP的摘要信息。当路由器收到一个CSNP时，它会将该CSNP与其链路状态数据库LSDB进行比较，如果该路由器丢失了一个在CSNP中存在的LSP时， 它会发送一个组播PSNP，向网络中其它路由器索要其需要的LSP。 部分时序报文PSNP：在点对点链路中用于确认接收的LSP和请求最新或者丢失的LSP；在广播链路中仅用于请求最新或者丢失的LSP。 IS-IS报文直接封装在链路层数据中。报头包含通用报头Common Header和专用报头Specific Header。 IS-IS网络类型点对点：主要用于PPP、HDLC 广播：主要用于以太网 IS-IS实现邻接关系 邻居关系建立 若在点对点网络，只要IS能接收到对端的P2P IIH报文，则邻居能建立，状态变为UP 若在广播网络，邻居建立需要三次握手。 邻接关系建立 若在点对点网络： 若在同一区域Area，L1间只建立L1邻接关系，L1和L1/2只建立L1邻接关系，L1/2间建立L1和L2邻接关系。 若在不同区域，L1间不建立邻接关系（邻居关系都不是），L2间建立L2邻接关系，L1/2间建立L2邻接关系。 若在广播网络：会选举DIS（Desginated IS，指定IS），类似DR，相同角色的IS间会选举一个，例如L1的路由器间选出一个，与L2间选出的并不冲突。 DIS的作用： 一旦一个设备选举为DIS以后，DIS发送HELLO数据包的时间间隔是普通路由器的1/3，这样可以保证DIS失效的时候可以被快速检测到。 DIS的选举是抢占的, 不能不参加选举，IS-IS中不存在备份DIS,当一个DIS不能工作的时候，直接选举另外一个。 在广播子网中创建并向所有的路由器通告伪节点LSP(Link State Protocol Data unit 链路状态数据单元). 在LAN中通过每10s周期性发送CSNP（完全数据库描述）来泛洪LSP(Link State Protocol Data unit 链路状态数据单元). DIS的选举过程： 比较接口优先级，高的优 具有最大的(SNPA子网接入点)的路由器将当选DIS。广播网络中SNPA是指MAC地址 点到点 广播 Hello报文 P2P IIH Level-1/2 LAN IIH Hello报文形式 单播 组播 Hello定时器 10s 10s，DIS为3.3s 邻接关系数量 1 多个 LSDB同步同步相关报文： LSP报文：用于描述链路状态信息 Level-1 LSP仅在区域内传播，Level-2 LSP在骨干网传播 SNP报文：用于描述LSDB中LSP摘要，并对邻居之间最新接收的LSP进行确认 CSNP报文：包含所有LSP的摘要信息，在广播网络中周期发送，在点对点网络中只在第一次发送 PSNP报文：列举最近收到的一个或多个LSP序号，用于LSP确认 在广播网络中： 所有同类路由器向DIS发送自己的所有LSP DIS周期发送LSP摘要信息 IS向DIS发送PSNP响应 DIS回复LSP_K 参考资料 百度百科IS-IS]]></content>
      <tags>
        <tag>网络</tag>
        <tag>IS-IS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件系统学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2F%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Postfix邮件服务器学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2FPostfix%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Tomcat学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2FTomcat%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[SSH与SSL协议学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2FSSH%E4%B8%8ESSL%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[SSL/TLS概念 OpenSSL简介 SSH协议 SSL/TLS概念SSL（Secure Socket Layer，安全套接字层）是一种标准安全协议，由美国网景（Netscape）开发，用于在在线通信中建立Web服务器和浏览器之间的加密链接。SSL技术的使用确保了Web服务器和浏览器之间传输的所有数据都保持加密状态。TLS（transport Layer Security，安全传输层协议）是SSL标准化后的版本，与SSL基本没有区别。 SSL/TLS的主要功能： 认证用户与服务器，确保数据发送到正确的客户端和服务器，即可靠性 加密数据，即机密性 维护数据的完整性 SSL协议架构SSL基于TCP，且分为两个子层：握手层和记录层，其中握手层负责建立SSL连接，记录层负责对报文的加解密。 握手层： 协商加密能力 协商密钥参数 验证对方身份 建立并维护SSL会话 握手层协议报文格式： 消息类型Type 消息长度Length 消息相关参数Content SSL提供三种握手过程，分别为： 无客户端身份认证的全握手 客户端向服务器发送以下信息：支持的SSL最高版本、加密套件列表、压缩算法列表、客户端随机数（32位）、会话ID 服务器端回应客户端以下信息：服务器同意的SSL版本、加密套件、压缩算法、会话ID、服务器端随机数。并且还会发送服务器的证书、服务器端密钥交换的信息，最后通知对端握手信息已发完 客户端再向服务器端发送密钥参数和握手过程的验证报文，并通知对端开始启用加密参数 服务器再向客户端发送自己的握手过程验证报文，并通知对端开始启用加密参数 有客户端身份认证的全握手 与上面类似，但在第2步后，服务器端还会向客户端请求客户端的证书，然后客户端回应自己的证书，并会附加上数字签名 会话恢复 当SSL连接因某些原因不正常断开后，可在超时时间内进行会话恢复。 客户端向服务器发送的消息与第1条一致，其中会话ID为上一次SSL连接的会话ID。其余过程也基本一致。 记录层： 保护传输数据的机密性，对数据进行加密和解密 验证传输数据的完整性，计算报文摘要 对报文压缩 保证数据传输的可靠有序 记录层对数据包的三个操作：分片、压缩、加密 记录层协议报文格式： 报文类型：1个字节，密钥改变协议（20）、告警协议（21）、握手协议（22）、应用层数据（23） 版本：2字节，TLS1.0（3,1）、SSL3.0（3,0） 长度：2字节记录层报文的长度，包括加密数据和MAC值 MAC：消息验证码 SSL会话与连接 SSL会话是指客户端与服务器间的关联关系，通过握手协议创建。而SSL连接是用于点对点数据的传输，连接的维持时间比较短暂，且一定与一个会话关联。 一次会话过程通常会发起多个SSL连接来完成任务，这些连接共享会话定义的安全参数，这样可以避免为每个SSL连接单独进行安全参数的协商，而只需在会话建立时进行一次协商，提高了效率。 HTTPS与HTTP连接的建立耗时也因为SSL层而出现3倍的差距。可通过curl -w &quot;TCP handshake: %{time_connect}, SSL handshake: %{time_appconnect}&quot; -so /dev/null 网址测试。 OpenSSL概念OpenSSL是一个SSL的密码库，是对SSL协议的实现，包含了主要的密码算法，常用的密钥和证书封装管理功能。 OpenSSL提供八种对称加密算法（DES、AES、Blowfish、CAST、IDEA、RC2、RC5），支持四种非对称加密算法（DH、RSA、DSA、椭圆曲线EC），实现五种信息摘要算法（MD2、MD5、MDC2、SHA（SHA+SHA1）、RIPEMD） Heartblood漏洞简介 心脏出血漏洞，于2014年被公开。受害者的内存内容就会以每次64KB的速度进行泄露，通过读取网络服务器内存，攻击者可以访问敏感数据，从而危及服务器及用户的安全。 SSH协议Secure Shell安全壳协议，是建立在TCP上的安全协议，端口号22。可以防止中间人攻击、DNS和IP欺骗，并可加快数据的传输速度，且通过ssh传输的数据都是经过压缩的。 目前SSH有两个版本SSH1和SSH2，这两个版本互不兼容。SSH有以下特点： 支持DES、3DES加密 支持公钥（密钥）验证方式、密码（口令）验证方式、不验证 支持RSA认证 SSH连接建立过程： 版本号协商：客户端与服务器协商出双方使用的SSH版本 密钥与算法协商：客户端与服务器交换算法协商报文，协商出使用的算法，并且生成会话密钥和ID 认证：客户端向服务器发送认证请求，服务器端对客户端认证 会话请求：客户端向服务器发送会话请求，服务器等待并处理客户端请求 交互会话：数据加密传输 sshd服务通过openssh软件实现sshd服务，sshd正是使用ssh协议进行远程访问或传输文件的服务。 sshd主要要有三个软件： openssh：包含openssh服务器与客户端需要的核心文件 openssh-clients：openssh客户端软件 openssh-server：openssh服务器软件 Openssh的配置文件 /etc/ssh/ssh_config：客户端配置文件 /etc/ssh/sshd_config：服务器端配置文件 ssh命令常见选项： 123456ssh [username@]host [options] [command] -p 指定连接的远程主机端口，默认22 -v 显示详细信息，一般用于拍错 -C 压缩所有数据 可直接通过ssh在远端执行命令 -l 指定登录用户名 sshd_config配置1234567891011121314151617181920212223242526272829Port 22 #端口号#为安全起见，在实际生产环境中，最好将端口改为非22，减小ssh暴露的危险Protocol 2 #SSH版本，默认2，SSH1已淘汰AddressFamily #ListenAddress 0.0.0.0 #设置sshd服务器监听的本地IP地址。0.0.0.0表示监听本地所有IP地址（如果有多个）HostKey /etc/ssh/ssh_host_rsa_key #服务器秘钥文件的路径（还有dsa等密钥）Compression yes #是否可使用压缩指令KeyRegenerationInterval 1h #服务器重新生成密钥的周期ServerKeyBits 1024 #服务器密钥的长度LogLevel INFO #日志等级LoginGraceTime 2m #输入密码后，若2分钟内未连接成功，则断开PermitRootLogin yes #是否允许使用root登录远程主机，若为生产环境需要设为noStrictModes yes #ssh在接收登录请求之前是否检查用户根目录和rhosts文件的权限和所有权，默认开启SyslogFacility AUTHPRIV #日志类型PubkeyAuthentication yes #是否开启公钥验证，如果使用公钥验证的方式登录时，则设置为yesAuthorizedKeysFile .ssh/authorized_keys #公钥验证文件的路径PasswordAuthentication yes #是否开启密码验证PermitEmptyPasswords no #是否允许空密码登录PrintMotd yes #登录后是否打印信息（上次登录时间和地点等），信息内容可在/etc/motd中编辑PrintLastLog yes #显示上次登录的信息，默认允许UsePrivilegeSeparation sandbox #是否允许权限较低的程序一共用户操作，会让sshd在远程用户登入后产生一个属于该用户的sshd程序，使系统较安全UseDNS yes #为了判断客户端是否合法，会使用DNS反查客户端主机名。 #若是内网，则no可以让连接更快。MaxAuthTries 6 #最多密码尝试次数MaxSessions 10 #最多终端数ClientAliveInterval 0 #向客户端发送keepalive报文的间隔ClientAliveCountMax 3 #若三次收不到keepalive消息，则认为连接断开TCPKeepAlive #是否持续连接，设置yes可以防止死连接#SSH Server会传送KeepAlive的讯息给Client端，以确保两者的联机正常 最好将ssh的日志文件/var/log/secure的路径改掉，减小入侵后ssh日志文件被删除的风险。可修改/etc/rsyslog.conf的authpriv参数，包括特权信息如用户名在内的认证活动。 默认：authpriv.* /var/log/secure ，修改此项即可改变ssh日志路径 密钥分发命令ssh-keygen用于生成密钥对。 参考文章 百度百科-ssl 百度百科-ssh]]></content>
      <tags>
        <tag>server</tag>
        <tag>OpenSSL</tag>
        <tag>SSL</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Xinted学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2FXinted%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[无人值守学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2F%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇主要包含以下内容： PXE概述 Kickstart 网络安装试验 Kickstart配置 Cobbler PXE概述Preboot Execution Environment远程预启动执行环境，就是使计算机通过网络启动。 要达成PXE必须要有两个环节： 客户端的网卡必须要支持PXE用户端功能，并且开机时选择从网卡启动，这样系统才会以网卡进入PXE客户端的程序 PXE服务器必须要提供至少含有DHCP以及TFTP的服务 DHCP服务必须要能够提供客户端的网络参数，还要告知客户端TFTP所在的位置； TFTP则提供客户端的boot loader及kernel file下载路径。 可选的其他服务：NFS、FTP、HTTP等 完整的PXE交互过程： Client向DHCP发送IP地址请求消息，DHCP检测Client是否合法（主要是检测Client的网卡MAC地址），如果合法则返回Client的IP地址，同时将启动文件pxelinux.0的位置信息一并传送给Client Client向TFTP发送获取pxelinux.0请求消息，TFTP接收到消息之后再向Client发送pxelinux.0大小信息，试探Client是否满意，当TFTP收到Client发回的同意大小信息之后，正式向Client发送pxelinux.0，Client接收并执行pxelinux.0文件 Client向TFTP Server发送获取针对本机的配置信息文件的请求（在TFTP服务的pxelinux.cfg目录下，这是系统菜单文件，格式和isolinux.cfg格式一样，功能也是类似），TFTP将配置文件发回Client，继而Client根据配置文件执行后续操作。 Client向TFTP发送Linux内核请求信息，TFTP接收到消息之后将内核文件发送给Client Client向TFTP发送根文件请求信息，TFTP接收到消息之后返回Linux根文件系统Client启动Linux内核 Client从FTP或HTTP下载安装源文件，读取自动化安装脚本 引用自Cobbler原理解析 KickstartKickstart概述Kickstart是通过自动应答文件，将安装系统过程中手动设置的语言、密码、网络等参数自动设置。 Kickstart文件有三种生成方式： 手动书写 system-config-kickstart图形化配置 红帽系系统自带的Anaconda生成 Kickstart准备服务分工介绍： DHCP：为安装的新主机分配IP地址 TFTP：仅仅提供引导文件 VSFTP|HTTP|NFS：提供系统镜像中所有文件，然后会根据Kickstart文件自动选择要安装的软件，并配置 防止访问出现错误，先将selinux设为Permissive。setenforce 0 DHCP配置首先配置DHCP服务。yum install dhcp修改配置文件/etc/dhcp/dhcpd.conf12345678910111213141516171819# 日志级别log-facility local7;# DNS服务器域名option domain-name-servers system1.example.com;# 网关option routers 192.168.10.2;# 默认分配时间default-lease-time 600;# 最大分配时间max-lease-time 7200;subnet 192.168.10.0 netmask 255.255.255.0 &#123; # 地址分配范围 range 192.168.10.101 192.168.10.110; # TFTP服务器（重要） next-server 192.168.10.100; # TFTP服务器上的共享启动文件名（重要） filename &quot;pxelinux.0&quot;;&#125; 重新加载并设置开机自启systemctl restart dhcpdsystemctl enable dhcpd若开启了防火墙应该放行服务123firewall-cmd --permanent --add-service=dhcpfirewall-cmd --permanent --add-port=67/tcp --add-port=67/udpfirewall-cmd --reload TFTP配置配置TFTP服务，首先需要安装xinetd服务，因为TFTP是被Xinetd动态管理的服务。yum install xinetd tftp-server修改配置文件/etc/xinetd.d/tftp123456789101112131415service tftp&#123; socket_type = dgram protocol = udp wait = yes user = root server = /usr/sbin/in.tftpd # server_args指定共享目录路径 server_args = -s /tftpboot disable = no per_source = 11 cps = 100 2 flags = IPv4&#125;disable的值默认为yes，表示禁用tftp，因此要改为no，开启tftp 重启Xinted服务systemctl restart xinetd.service123通过查看服务是否开启# ss -aupt | grep xinetdudp UNCONN 0 0 *:tftp *:* users:((&quot;xinetd&quot;,pid=3490,fd=5)) 若开启了防火墙，需要放行服务和端口123firewall-cmd --permanent --add-service=tftpfirewall-cmd --permanent --add-port=69/udpfirewall-cmd --reload 使用VSFTP搭建镜像源安装VSFTPD服务yum install vsftpdsystemctl start vsftpdsystemctl enable vsftpd 将光盘镜像挂载在/var/ftp/pub中。mount /dev/cdrom /var/ftp/pub 若开启了防火墙，应该放行端口和服务123firewall-cmd --permanent --add-port=20/tcp --add-port=21/tcpfirewall-cmd --permanent --add-service=ftpfirewall-cmd --reload 在浏览器中输入ftp://192.168.10.100访问成功。 使用HTTP搭建镜像源安装HTTPD服务yum install httpdsystemctl start httpdsystemctl enable httpd 将光盘镜像挂载在/var/www/html/centos7上。mount /dev/cdrom /var/www/html/centos7 若开启了防火墙，应该放行端口和服务123firewall-cmd --permanent --add-port=80/tcpfirewall-cmd --permanent --add-service=httpfirewall-cmd --reload 在浏览器中输入192.168.10.100/centos7访问成功。 Syslinux配置安装syslinux服务syslinux是一个功能强大的引导加载程序，用于获取引导文件。yum install syslinux将引导文件复制到TFTP主目录cp /usr/share/syslinux/pxelinux.0 /tftpboot若要图形化菜单功能（仅仅是可以上下键切换，最好一起复制了），可将/usr/share/syslinux中的menu.32或vesamenu.c32复制到/tftpboot。这里就复制vesamenu.c32，比menu.32更好。并在/tftpboot中创建目录pxelinux.cfg用于存放默认开机选项，并在该目录中创建default文件 创建存放CentOS7内核文件的目录mkdir /tftpboot/centos7，并将挂载镜像目录/var/ftp/pub/isolinux/中vmlinuz和initrd.img两个内核文件复制到该目录中。cp /var/ftp/pub/isolinux/{vmlinuz,initrd.img} /tftpboot/centos7/最好将isolinux目录下的isolinux.cfg也复制过去，该文件提供了开机选项，可以以它作为修改开机选项和菜单的模板。可以直接将内容拷贝过去，cat /var/ftp/pub/isolinux/isolinux.cfg &gt; /tftpboot/pxelinux.cfg/default。 default即isolinux.cfg简单解析123456789101112131415161718192021222324252627282930default vesamenu.c32 # 必须指定，填/tftpboot中复制的图形化文件timeout 10 # 在选择界面停留的时间（若未操作）display boot.msg # 选项的说明文件菜单的一些显示设置，不用改menu clearmenu background splash.pngmenu title CentOS 7 # 引导是显示的标题menu vshift 8menu rows 18menu margin 8#menu hiddenmenu helpmsgrow 15menu tabmsgrow 13.....在引导界面上显示的选项label linux menu label ^Install CentOS 7 kernel ./centos7/vmlinuz # vmlinuz是可引导的、压缩的内核，路径要设为相对路径（相对于tftp根目录） append initrd=./centos7/initrd.img ks=ftp://192.168.10.100/ks_config/ks.cfg quiet # 设置内核文件，要设置initrd.img的相对路径 # initrd.img全称boot loader initialized RAM disk， boot loader初始化的内存盘。在linux内核启动前，boot loader会将存储介质中的initrd文件加载到内存，内核启动时会在访问真正的根文件系统前先访问该内存中的initrd文件系统 # 后面跟着ks=ks.cfg文件的路径，http或ftp都行 # 后面还可以跟上ksdevice=eth0，当客户端有多块网卡时，此项就会让系统不提示要选择哪块网卡label check menu label Test this ^media &amp; install CentOS 7 menu default # 默认光标停留在此标签（选项）上 kernel ./centos7/vmlinuz append initrd=./centos7/initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 rd.live.check quiet 整个/tftpboot的目录结构如下12345678/tftpboot/├── centos7│ ├── initrd.img│ └── vmlinuz├── pxelinux.0├── pxelinux.cfg│ └── default└── vesamenu.c32 网络安装试验做这个实验时，要先修改/tftpboot/pxelinux.cfg/default1234567891011找到以下内容label linux menu label ^Install CentOS 7 menu default kernel ./centos7/vmlinuz append initrd=./centos7/initrd.img inst.stage2=ftp://192.168.10.100/pub quietnet.ifnames=0 biosdevname=0inst.stage2设置FTP镜像源在quiet后再加上net.ifnames=0 biosdevname=0让网卡名称为ethN，而不是默认的eno16777728这样的随机名称 创建一个新的虚拟机，不指定镜像。进入虚拟机的BIOS设置进入Boot菜单，通过-或+改变启动顺序，将Network boot from Intel E1000移到最上面。保存退出，会自动启动主机，通过网络读取FTP镜像源。最后进入图形化安装界面 Kickstart配置手动配置首先创建ks.cfg，存放在/var/ftp/ks_config（FTP源）或/var/www/html/centos/ks_config（HTTP源）。修改/tftpboot/pxelinux.cfg/default12345678仍然找到这段内容，修改initrid后的内容删除原来的inst.stage2，改为ks=fs.cfg路径，HTTP同理label linux menu label ^Install CentOS 7 menu default kernel ./centos7/vmlinuz append initrd=./centos7/initrd.img ks=ftp://192.168.10.100/ks_config/ks.cfg quietnet.ifnames=0 biosdevname=0 在主目录中有系统自动创建的anaconda-ks.cfg，可以此为模板。在图像化配置安装时就是向该文件中添加配置，直到点击安装时，安装程序就会根据该配置文件安装。 anaconda-ks.cfg简单解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142分为三个部分：1. 选项指令段，用于图形化安装时除包选择外的所有手动操作2. %packages段，用于选择软件包3. 脚本段，可选。分为两种： %pre：预安装脚本段，在安装系统之前就执行的脚本。很少使用 %post：后安装脚本段，在系统安装完成后执行的脚本。必选选项：# auth验证选项auth --enableshadow --passalgo=sha512 --enableshadow|--useshadow 开启shadow文件验证 --passalgo 指定密码加密算法# bootloader指定如何安装引导程序bootloader --append=&quot;crashkernel=auto&quot; --location=mbr --boot-drive=sda --append 指定内核参数 --location 指定引导程序的位置，默认为MBR --boot-drive 指定grub安装的分区# keyboard键盘类型keyboard --vckeymap=us --xlayouts=&apos;us&apos; --vckeymap指定键盘分布，默认为us美式# lang指定语言lang en_US.UTF-8# rootpw指定root密码rootpw --iscrypted $6$D2fmDfXJI30ZbG0x$lenXfD98spplf7jHTmfiJ0m7CgQqJM.ddQ5hu07qiU3A5fJcRhSQA5KZolrWoSfGm2oIwJUglnRwoXth9rDGc0 --iscrypted 使用加密密码可选选项：install 表示是安装系统，若为install还需指定安装方式： cdrom 表示从光盘安装 harddrive 硬盘安装，硬盘必须是VFAT或EXT文件系统 --dir 指定从包含安装树（install-tree）的目录安装 --partition 指定从哪个分区安装 nfs --server 指定NFS服务器主机名或IP地址 --dir 指定安装树目录 --opts 指定NFS的挂载选项 url --url 后面跟上地址update 表示是升级系统graphical 表示图形模式下执行kickstart安装，默认text 文本模式下根据kickstart执行安装（手动创建一定是text）firstboot 安装后第一次启动默认会有需要手动配置的界面，应该禁用 --enable|--disable 启用|禁用ignoredisk 指定忽略的磁盘 --only-use=sdanetwork 配置网络 --bootproto 地址协议，dhcp或static。若为static需要配置IP、掩码、网关、DNS --device=ens33 设置网卡名 --onboot=off 是否在引导系统时启用设备 --ipv6=auto 开启IPv6 --no-activate --hostname=localhost.localdomain 主机名若协议为static，则需要以下选项： --ip= --netmask= --gateway= --nameserver=repo 设置repo源 --name= --baseurl=services 设置服务是否启用 --disabled= --enabled=timezone Asia/Shanghai --isUtc --nontp 指定时区selinux 设置selinux --enforcing --permissive --disabledfirewall 是否开启防火墙 --disable|--enablexconfig --startxonbootautostep 交互式，和interactive类似interactive 使用kickstart文件指定的参数交互式安装，但仍会给出每一步的选择项，如果直接下一步就使用kickstart参数cmdline 在完全非交互的命令行模式下进行安装driverdisk 指定驱动程序所在位置 --source=autopart 自动分区 --type=lvmzerombr 清除磁盘的MBRclearpart 在安装系统前清除分区 --all 清除所有分区 --initlabel 创建标签，对于没有MBR或者GPT的新硬盘，该选项是必须的 --drives=sda 清除指定的分区 --Linux 清除Linux分区 --none 不清除分区 常用cleanpart --all --initlabelpart [分区] 创建分区 --fstype 文件系统类型 --asprimary 强制为主分区 --size 设置大小（单位Mb） --grow 使用所有可用空间，即为其分配所有剩余空间。 对于根分区至少需要3G空间（即使是--grow，也还是需要指定--size）user 在系统中生成一个新用户 --name 指定用户名 --groups 指定辅助组，非默认组 --homedir 用户家目录，如果不指定则默认为/home/&lt;username&gt; --password 该用户的密码，如果不指定或省略则创建后该用户处于锁定状态 --shell 用户的shell，不指定则默认 --uid 用户UID，不指定则自动分配一个非系统用户的UIDloggin 指定安装过程中的错误日志位置 --host 指定日志将发送到那台主机上 --port 如果远程主机的rsyslog使用非默认端口，则应该指定该端口选项 --level 指定日志级别halt|reboot 安装完成后操作，halt为关机，reboot为重启，默认是halt# 软件包或软件包组# @表示包组，@base和@core默认包含%packages@^graphical-server-environment@base@core@desktop-debugging@dial-up@fonts@gnome-desktop@guest-agents@guest-desktop-agents@hardware-monitoring@input-methods@internet-browser@multimedia@print-client@x11kexec-tools%end%addon com_redhat_kdump --enable --reserve-mb=&apos;auto&apos;%end%anacondapwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notemptypwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyokpwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty%end 注：%addon、%anaconda、%packages、%onerror、%pre、%post必须以%end结尾 官方并不建议手工创建kickstart文件，因为太过复杂，且容易出错。因此，可通过system-config-kickstart图形化工具快速生成kickstart文件。 system-config-kickstart配置需要安装该工具yum install system-config-kickstart打开工具后，按照以下界面配置即可。 若需要修改，则直接打开修改即可。若图形化无法添加安装软件包，就在生成的ks.cfg中添加。最终修改后的ks.cfg文件如下12345678910111213141516171819202122232425262728293031installkeyboard &apos;us&apos;rootpw --iscrypted $1$8.DdzSgf$UIjrFmFh/4Mavb/4q7z8U.url --url=&quot;ftp://192.168.10.100/pub&quot;lang en_USfirewall --disabledauth --useshadow --passalgo=sha512graphicalselinux --disabledskipxnetwork --bootproto=dhcp --device=eth0network --hostname=system10.example.comreboottimezone Asia/Shanghaibootloader --location=mbrzerombrclearpart --all --initlabelpart /boot --fstype=&quot;xfs&quot; --size=200part / --fstype=&quot;xfs&quot; --size=5part /var --fstype=&quot;xfs&quot; --size=10services --enabled=httpd%packages@base@coretreenmapwgethttpd%end 再次进行安装，进入下面画面时，发现配置已根据kickstart文件填写完成。 CobblerCobbler与Kickstart类似，是一个Linux服务器快速网络安装的服务，可以通过PXE快速安装、重装物理服务器和虚拟机。基于Python开发，支持命令行管理、web界面管理、提供API接口。可以管理DHCP，DNS，TFTP、RSYNC以及yum仓库、构造系统ISO镜像。 Cobbler会在请求内核文件后，再请求Kickstart文件（即ks.cfg）和OS镜像。然后Cobbler加载Kickstart文件并接收安装OS镜像。 Cobbler常见术语： distro：发行版，相当于一个操作系统镜像，包含内核和initrd信息以及软件包等 repository：保存一个yum或rsync存储库的镜像信息 profile：配置文件，包含distro、kickstart文件和repository等信息，作用为了修改/tftpboot/pxelinux.cfg/default文件，每生成或修改一次profile，都会在default文件中修改或追加对应的label system：目标系统，即要安装的主机，包含配置文件或镜像，IP地址等信息 image：系统镜像 system、image、repository用的很少，主要用distro和profile。 Cobbler安装仍然使用之前Kickstart的环境。必须关闭selinux。首先安装epel-release，因为Cobbler位于epel源中。然后安装Cobbler及其他工具程序yum install cobbler cobbler-web pykickstart其中cobbler-web是cobbler的网页端配置工具，可不用安装。pykickstart是用于检查kickstart文件语法的工具cobbler的运行依赖于dhcp、tftp、rsync及dns服务，因此在现有环境下还要安装rsync。yum install rsyncsystemctl enable rsyncdsystemctl start rsyncdsystemctl enable cobblerd.servicesystemctl start cobblerd.service 使用命令cobbler check进行检查，对查出的错误一一解决。12345671 : The &apos;server&apos; field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it.2 : For PXE to be functional, the &apos;next_server&apos; field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network. 这两个问题需要设置/etc/cobbler/settings，修改以下内容：123# 将127.0.0.1修改为本机的IP地址next_server: 192.168.10.100server: 192.168.10.100 13 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run &apos;cobbler get-loaders&apos; to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The &apos;cobbler get-loaders&apos; command is the easiest way to resolve these requirements. 问题是需要获取bootloaders文件，执行cobbler get-loaders自动下载，但要求联网。也可复制，但需要的文件很多，有的不好找，最好直接执行命令。 14 : debmirror package is not installed, it will be required to manage debian deployments and repositories 安装debmirror软件包并将/etc/debmirror.conf中的dists和arches注释。12#@dists=&quot;sid&quot;;#@arches=&quot;i386&quot;; 15 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to &apos;cobbler&apos; and should be changed, try: &quot;openssl passwd -1 -salt &apos;random-phrase-here&apos; &apos;your-password-here&apos;&quot; to generate new one 需要使用openssl生成加密密码来取代默认的密码。123456openssl passwd -1 -salt &apos;cobbler&apos; &apos;123456&apos; passwd 表示生成密码 -1 表示使用MD5加密 -salt 表示使用后面提供的参数生成，后面跟上用户名和密码会生成一个加密密码，将这串字符替换掉原来的默认密码default_password_crypted: &quot;$1$cobbler$52QDrGSqGlT9d5qbjg7QY/&quot; 16 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them 安装cman和fence-agents，cman可能会找不到这个包，但只安装fence-agents就够了。 最后使用命令cobbler sync应用调整的参数或重启cobblerd服务，再执行一次cobbler check检查，若还有错就继续排错，若没有错误就会显示No configuration problems found. All systems go. Cobbler默认管理tftp服务，默认不管理dhcp，因此tftp的根目录变为/var/lib/tftpboot。如果让Cobbler管理DHCP，则Cobbler管理DHCP的模板文件/etc/cobbler/dhcp.template会覆盖/etc/dhcp/dhcpd.conf。 将光盘挂载到本地，mount /dev/cdrom /mnt/mirror，然后执行cobbler import --name=CentOS7 --path=/mnt/mirror生成distro，从本地导入的过程实际上是将系统镜像中的文件复制到/var/www/cobbler/ks_mirror/CentOS7中。在/var/www/cobbler/images中也会生成一个CentOS7-x86_64的目录，其中存放了initrd.img和vmlinuz文件。 然后，需要提供kickstart文件，这里继续使用Kickstart实验用的ks.cfg文件，将文件移动到/var/lib/cobbler/kickstarts中，并改名为CentOS7.ks，需要修改以下内容。 123#如果存在ignoredisk设置，一定要注释掉，cobbler编译时不支持此语法修改镜像安装源url --url=&quot;http://http://192.168.10.100/cobbler/ks_mirror/CentOS7/&quot; 在导入镜像生成distro的过程中，会自动生成一个profile。使用cobbler profile list查看。使用cobbler profile report --name=CentOS7-x86_64查看profile信息。 123# cobbler profile report --name=CentOS7-x86_64其中profile默认使用的kickstart文件有误Kickstart : /var/lib/cobbler/kickstarts/sample_end.ks 需要通过cobbler profile edit --name=CentOS7-x86_64 --kickstart=/var/lib/cobbler/kickstarts/CentOS7.ks修改。 最好再修改内核启动参数net.ifnames和biosdevname使网卡名为ethN系列而不是用enoXXXXXX随机名。cobbler profile edit --name=CentOS7-x86_64 --kopts=&quot;net.ifnames=0 biosdevname=0&quot; 若要手动添加一个profile，可使用cobbler profile add --name=XXX --distro=distro名 --kickstart=ks文件路径。每添加一个profile，就是在/var/lib/tftpboot/pxelinux.cfg/default中添加一个label，一个label就是开机启动时的引导选项。 12345LABEL CentOS7-x86_64 kernel /images/CentOS7-x86_64/vmlinuz MENU LABEL CentOS7-x86_64 append initrd=/images/CentOS7-x86_64/initrd.img ksdevice=bootif lang= text net.ifnames=0 biosdevname=0 kssendmac ks=http://192.168.10.100/cblr/svc/op/ks/profile/CentOS7-x86_64 ipappend 2 在配置完成后，执行cobbler sync同步设置。 通过浏览器访问default文件中ks参数指定的ks文件路径，看是否能访问，若能显示文件内容，则配置没有问题。 重启xinetd、cobblerd、dhcpd服务，以防配置未刷新。 仍然使用一台裸机进行安装，会自动进入安装界面。 使用cobbler-web图形化配置如果开启了防火墙，需要放行443端口和https服务，因为Cobbler在CentOS7只支持https。 在浏览器访问https://IP地址/cobbler_web即可，输入账号密码，均为cobbler。 首先进行镜像的导入，左侧菜单的Import DVD选项配置。 菜单的Events查看事件日志。 进入distros配置，添加内核选项。也可以通过profiles配置。 设置网卡名为ethN系列 修改或编写ks文件 也可进入菜单system进行system配置。 参考文章 骏马金龙–无人值守CentOS7kickstart文件详解KICKSTART无人值守安装Cobbler-自动化部署神器cobbler无人值守批量安装Linux系统Cobbler原理解析Linux就该这么学Linux运维之道（第二版）]]></content>
      <tags>
        <tag>无人值守</tag>
        <tag>PXE</tag>
        <tag>Kickstart</tag>
        <tag>Cobbler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rsync文件同步服务器学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2FRsync%E6%96%87%E4%BB%B6%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容 Rsync介绍与搭建 quick check算法介绍 rsync的工作方式 rsync命令使用 规则解析 Rsync服务器搭建 Rsync部分报错解决 Rsync+Inotify文件自动同步 Mutt+Msmtp实现邮件监控 Rsync介绍与搭建Rsync（Remote Synchronize）是一个远程数据同步工具，可使本地主机不同分区或目录之间及本地和远程两台主机之间的数据快速同步镜像，远程备份等功能。 Rsync特点： 使用TCP 873端口 可根据数据变化进行差异备份或增量备份，减少数据流量 传输可以通过ssh协议加密数据 支持拷贝特殊文件如链接，设备等 可以镜像保存整个目录树和文件系统 可以保持原来文件或目录的所有属性均不改变 可使用rsh、ssh，或直接通过socket连接 支持匿名的或认证的进程模式传输 使用Rsync自己的quick check算法 rsync传输大文件时速度大概是scp的20倍以上 rsync同步过程由两部分模式组成：决定哪些文件需要同步的检查模式，文件同步时的同步模式。 检查模式是指按照指定规则来检查哪些文件需要被同步。 默认情况下，rsync使用quick check算法。可以通过rsync命令选项设置指定的检查模式。 同步模式是指在文件确定要被同步后，在同步过程发生之前要做哪些额外工作。 quick check算法介绍比较源文件和目标文件的文件大小和修改时间mtime（修改时间），只要存在不同，就发送端会传输该文件，如果目标路径下没有文件，则rsync会直接传输文件。若存在差异，并不会传送整个文件，而是只传源文件和目标文件所不同的部分，实现真正的增量同步。 rsync的增量传输体现在两个方面：文件级别的增量传输和数据块级别的增量传输。 文件级别的增量传输是指源主机上有，但目标主机上没有将直接传输该文件 数据块级别的增量传输是指只传输两文件所不同的那一部分数据。 两台计算机Host-A与Host-B，其中Host-A是源主机，即数据的发送端Sender，Host-B是目标主机，即数据的接收端Receiver。Host-A上存在文件file-A，Host-B上存在file-B。注：file-A与file-B是同名文件。rsync的实现有以下过程： Host-A告诉Host-B有文件file-A要传输。 Host-B收到信息后，将文件file-B划分为一系列大小固定的数据块(大小在500-1000字节之间)，并以chunk号码对数据块进行编号，同时还会记录数据块的起始偏移地址以及数据块长度。 Host-B对每一个分割好的数据块执行两种校验：一种是 32 位的滚动弱校验（rolling checksum），另一种是 128 位的 MD5 强校验。将file-B计算出的所有滚动弱校验和强校验码跟随在对应数据块chunk[N]后形成校验码集合，然后发送给主机Host-A 不同数据块的滚动弱校验值有可能相同，但几率非常小。 Host-A通过搜索file-A 的所有该固定大小的数据块（偏移量可以任选），并计算它的校验码和校验码集合中的校验码进行匹配。 如果能匹配上校验码集合中的某个数据块条目，则表示该数据块和file-B中数据块相同，不需要传输。 如果不能匹配校验码集合中的数据块条目，则表示该数据块是非匹配数据块，它需要传输给Host-B，于是Host-A将跳转到下一个字节，从此字节处继续取数据块进行匹配。 数据匹配过程有三个层次：首先比较hash值，然后比较弱滚动校验，最后比较强校验。 当Host-A发现是匹配数据块时，将只发送这个匹配块的附加信息给Host-B。同时，如果两个匹配数据块之间有非匹配数据，则还会发送这些非匹配数据。 当Host-B陆陆续续收到这些数据后，会创建一个临时文件，并通过这些数据重组这个临时文件，使其内容和file-A 相同。临时文件重组完成后，修改该临时文件的属性信息(如权限、所有者、mtime等)，然后重命名该临时文件替换掉file-B。 rsync的工作方式 本地传输方式：首先rsync命令执行时，会有一个rsync进程，然后根据此进程fork另一个rsync进程作为连接的对端，连接建立之后，后续所有的通信将采用管道的方式。 远程shell连接方式：本地敲下rsync命令后，将请求和远程主机建立远程shell连接（如ssh连接），连接建立成功后，在远程主机上将fork远程shell进程调用远程rsync程序，并将rsync所需的选项通过远程shell命令（如ssh）传递给远程rsync。这样两端就都启动了rsync，之后它们将通过管道的方式进行通信。 网络套接字连接远程主机上的rsync daemon：当通过网络套接字和远程已运行好的rsync建立连接时，rsync daemon进程会创建一个子进程来响应该连接并负责后续该连接的所有通信。这样两端也都启动了连接所需的rsync，此后通信方式是通过网络套接字来完成的。 远程shell临时启动一个rsync daemon：不要求远程主机上事先启动rsync服务，而是临时派生出rsync daemon，它是单用途的一次性daemon，仅用于临时读取daemon的配置文件，当此次rsync同步完成，远程shell启动的rsync daemon进程也会自动停止。 发起连接的一端称为Client端，就是执行rsync命令的一端，连接的另一端称为Server端。 注：当Client端和Server端都启动好rsync进程并建立好了rsync连接(管道、网络套接字)后，将使用Sender端和Receiver端来代替Client端和Server端的概念。 当两端的rsync连接建立后，Sender端的rsync进程称为Sender进程，该进程负责Sender端所有的工作。Receiver端的rsync进程称为Receiver进程，负责接收sender端发送的数据，以及完成文件重组的工作。Receiver端还有一个核心进程Generator进程，该进程负责在Receiver端执行--delete动作、比较文件大小和mtime以决定文件是否跳过、对每个文件划分数据块、计算校验码以及生成校验码集合，然后将校验码集合发送给Sender端。 三个进程的作业流程：Generator进程的输出结果作为Sender端的输入，Sender端的输出结果作为Recevier端的输入。并且，这三个进程是完全独立、并行工作的。 数据同步方式 推 push：一台主机负责把数据传送给其他主机，服务器开销很大，比较适合后端服务器少的情况 拉 pull：所有主机定时去找一主机拉数据，可能就会导致数据缓慢 rsync命令使用1234567891011本地传输方式: rsync [OPTION...] SRC... [DEST]远程shell连接方式: Pull: rsync [OPTION...] [USER@]HOST:SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST:DEST连接远程主机上的rsync daemon: Pull: rsync [OPTION...] [USER@]HOST::SRC... [DEST] rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST::DEST rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST 若主机与路径用:分隔，则为shell连接，若为::，则为daemon连接。 注：源路径如果是一个目录的话，带上尾随斜线和不带尾随斜线是不一样的，不带尾随斜线表示的是整个目录包括目录本身，带上尾随斜线表示的是目录中的文件，不包括目录本身。 若只有源路径或只有目的路径，则相当于ls -l查看指定文件或目录属性。 常用选项： 12345678910111213141516171819202122232425262728293031-a 归档模式，表示递归传输并保持文件属性。等同于&quot;-rtopgDl&quot;。-P 显示文件传输的进度信息-v 显示rsync过程中详细信息(最多支持-vvvv)-r 递归-t 保持mtime属性(最好加上，否则时间会设置为当前系统时间，在增量备份时会因为时间出错)-o 保持owner属性-g 保持group属性(属组)。-p 保持perms属性(权限，不包括特殊权限)。-D 拷贝设备文件和特殊文件。-l 如果文件是软链接文件，则拷贝软链接本身而非软链接所指向的对象。-z 传输时进行压缩提高效率。-R 使用相对路径。意味着将命令行中指定的全路径而非路径最尾部的文件名发送给服务端，包括它们的属性-u 仅在源mtime比目标已存在文件的mtime新时才拷贝。接收端判断，不会影响删除行为。--size-only 只检查文件大小（默认算法是检查文件大小和mtime不同的文件）--max-size 限制rsync传输的最大文件大小。可以使用单位后缀，还可以是一个小数值(例如：&quot;--max-size=1.5m&quot;)--min-size 限制rsync传输的最小文件大小。这可以用于禁止传输小文件或那些垃圾文件。--exclude 指定排除规则来排除不需要传输的文件。一个exclude只能指定一条规则，若有多条规则，就要写多个exclude--exclude-from 若规则有多条，可以写在文件中，并使用此选项加载规则文件--include 指定传输规则，只传输符合该规则的文件，与exclude相反--delete 接收端的rsync会先删除目标目录下已经存在，但发送端目录不存在的文件，以SRC为主，对DEST进行同步。多则删之，少则补之。注意&quot;--delete&quot;是在接收端执行的，所以它是在exclude/include规则生效之后才执行的。-b --backup 对目标上已存在的文件做一个备份，备份的文件名后默认使用&quot;~&quot;做后缀。--backup-dir 指定备份文件的保存路径，若指定，保存路径必须存在。 不指定时默认和待备份文件保存在同一目录下。 默认没有后缀，可通过&quot;--suffix=&quot;指定-e 指定所要使用的远程shell程序，默认为ssh。--port 连接daemon时使用的端口号，默认为873端口。--password-file daemon模式时的密码文件，是rsync模块认证的密码。-W --whole-file rsync将不再使用增量传输，而是全量传输。在网络带宽高于磁盘带宽时，该选项比增量传输更高效。--existing 要求只更新目标端已存在的文件，目标端还不存在的文件不传输。注意，使用相对路径时如果上层目录不存在也不会传输。--ignore-existing 要求只更新目标端不存在的文件。和&quot;--existing&quot;结合使用有特殊功能。--remove-source-files 要求删除源端已经成功传输的文件。 最常用组合-avz。 命令示例： 1234567891011rsync -r -R /etc/dir-1 /tmp 将/etc/dir-1目录复制到/tmp目录下，tmp目录下将会有etc/dir-1子目录rsync -r -R /etc/./dir-1 /tmp 将/etc/dir-1目录复制到/tmp目录下，但在/etc/和dir-1目录间加上了“.” 因此仅仅将dir-1目录复制过去作为子目录，tmp目录下将有dir-1子目录rsync -r -b --backup-dir --suffix=&apos;.bak&apos; /etc/dir-1 /tmp 备份文件，若不存在就直接复制，若已存在就添加后缀以区分rsync -r --exclude=&quot;*.txt&quot; /etc/dir-1 /tmp 将/etc/dir-1目录下的以&quot;.txt&quot;结尾的文件排除rsync -r -v --delete --exclude=&quot;*.txt&quot; /etc/dir-1 /tmp 将/tmp/dir-1中存在而/etc/dir-1不存在的文件删除，并且不删除&quot;.txt&quot;结尾的文件（即使源中不存在）sending incremental file listdeleting dir-1/a3.logdeleting dir-1/a2.logdeleting dir-1/a1.log 规则解析规则作用时间：当发送端敲出rsync命令后，rsync将立即扫描命令行中给定的文件和目录(扫描过程中还会按照目录进行排序，将同一个目录的文件放在相邻的位置)，这称为拷贝树(copy tree)，扫描完成后将待传输的文件或目录记录到文件列表中，然后将文件列表传输给接收端。筛选规则的作用时刻是在扫描拷贝树时，所以会根据规则来匹配并决定文件是否记录到文件列表中(严格地说是会记录到文件列表中的，只不过排除的文件会被标记为hide隐藏起来)，只有记录到了文件列表中的文件或目录才是真正需要传输的内容。筛选规则的生效时间在rsync整个同步过程中是非常靠前的，它会影响很多选项的操作对象，最典型的如--delete，--delete是在generator进程处理每个文件列表时、生成校验码之前进行的，这样就无需为多余的文件生成校验码。 rsync规则：通过选项--filter指定规则 exclude规则：即排除规则，只作用于发送端，被排除的文件不会进入文件列表(实际上是加上隐藏规则进行隐藏)。 include规则：即包含规则，也称为传输规则，只作用于发送端，被包含的文件将明确记录到文件列表中。 hide规则：即隐藏规则，只作用于发送端，隐藏后的文件对于接收端来说是看不见的，也就是说接收端会认为它不存在于源端。 show规则：即显示规则，只作用于发送端，是隐藏规则的反向规则。 protect规则：即保护规则，该规则只作用于接收端，被保护的文件不会被删除掉。 risk规则：即取消保护规则。是protect的反向规则。 clear规则：删除include/exclude规则列表。 上述内容都引用自骏马金龙－rsync介绍与用法 Rsync服务器搭建实验环境： Rsync服务器：192.168.205.135 Rsync客户端：192.168.205.134 首先，两台主机都需要安装rsync，yum/dnf install rsync，fedora已默认安装。 由于rsync的配置文件默认不存在，所以需要手动创建。Rsync有三个配置文件： rsyncd.conf：主配置文件 rsyncd.secrets：密码文件 rsyncd.motd：服务器信息文件 创建/etc/rsyncd.conf文件，具体参数可通过man rsyncd.conf查看 配置文件分为两部分：全局参数，模块参数全局参数：对 rsync 服务器生效，如果模块参数和全局参数冲突，冲突的地方模块参数生效模块参数：定义需要通过 rsync 输出的目录定义的参数 12345678910111213141516171819202122232425262728293031# 常见全局参数：port = 873 监听端口address = 192.168.205.135 监听服务器地址uid = nobody 数据传输时使用的用户ID，默认nobodygid = nobody 数据传输时使用的组ID，默认nobodyread only = yes 是否只读max connections = 10 并发连接数，0表示无限制。超出并发连接数时若再访问，会收到稍后重试的消息use chroot = no 是否开启chroot，若设为yes，rsync会首先进行chroot设置，将根映射到模块中path指定目录 需要root权限，在同步符号连接资料时仅同步文件名，不同步文件内容transfer logging = yes 开启Rsync数据传输日志功能#log format = 设置日志格式，默认log格式为：&quot;%o %h [%a] %m (%u) %f %l&quot;# 默认log格式表达的是：&quot;操作类型 远程主机名[远程IP地址] 模块名 (认证的用户名) 文件名 文件长度字符数&quot;#syslog facility = 指定rsync发送日志消息给syslog时的消息级别，默认值是daemonlock file = /var/run/rsync.lock 设置锁文件log file = /var/log/rsyncd.log 设置日志文件pid file = /var/run/rsyncd.pid 设置进程号文件motd file = /etc/rsyncd.motd 设置服务器信息提示文件hosts allow = 192.168.205.134 设置允许访问服务器的主机# 模块配置[rsync_test]comment = rsync test 添加注释path = /root/rsync_test 同步文件或目录路径ignore errors 忽略一些IO错误# exclude = 可以指定不同步的目录或文件，使用相对路径auth users = tom,jack 允许连接的用户，可以是系统中不存在的secrets file = /etc/rsyncd.secrets 设置密码验证文件，该文件的权限要求为只读（600），该文件仅在设置了auth users才有效list = false 是否允许查看模块信息timeout = 600 可以覆盖客户指定的 IP 超时时间。确保rsync服务器不会永远等待一个崩溃的客户端。 超时单位为秒钟，0表示没有超时定义，这也是默认值。 对于匿名rsync服务器来说，一个理想的数字是600 相关系统操作： 1234567useradd tom &amp;&amp; echo &quot;redhat&quot; | passwd tom --stdinecho &quot;tom:redhat&quot; &gt;&gt; /etc/rsyncd.secretsecho &quot;jack:redhat&quot; &gt;&gt; /etc/rsyncd.secrets 添加用户到密码文件chmod 600 /etc/rsyncd.secrets 修改密码文件权限echo &quot;Welcome to Rsync&quot; &gt;&gt; /etc/rsyncd.motd# firewall-cmd --permanent --add-port=873/tcp 若开启了防火墙，就放行端口rsync --daemon --config=/etc/rsyncd.conf 启动rsyncd服务 客户端同步文件：rsync -r tom@192.168.205.135::rsync_test /root/rsync_test 自动备份脚本，可配合crond使用 123456789101112#!/bin/bash# 本脚本是将服务器端的文件定期同步到本端# 设置服务器端模块和本端目录SRC=rsync_testDEST=/root/rsync_testServer=192.168.205.135# 设置验证用户名和密码User=tomPassword=redhat# 若本地同步目录不存在，就创建目录。同步时会删除目录中本端存在，但服务器端不存在的文件[ ! -d $DEST ] &amp;&amp; mkdir $DESTrsync -az --delete $&#123;User&#125;@$&#123;Server&#125;::$SRC $DEST/$(date +%Y%m%d) 若使用Xinetd服务管理Rsync，需要先安装xinetd。创建文件/etc/xinetd.d/rsync，添加以下内容。 123456789service rsync &#123; disable = no socket_type = stream wait = no user = root server = /usr/bin/rsync server_args = --daemon --config=/etc/rsyncd.conf log_on_failure += USERID&#125; 然后重启xinetd服务即可。 Rsync部分报错解决12rsync: failed to connect to 192.168.205.135 (192.168.205.135): No route to host (113)rsync error: error in socket IO (code 10) at clientserver.c(125) [Receiver=3.1.2] 解决：防火墙问题，放行端口或直接关闭 12@ERROR: auth failed on module rsync_testrsync error: error starting client-server protocol (code 5) at main.c(1648) [Receiver=3.1.2] 解决：用户名与密码问题或模块问题，检查用户名与密码是否匹配，服务器端模块是否存在 12rsync: read error: Connection reset by peer (104)rsync error: error in rsync protocol data stream (code 12) at io.c(759) [Receiver=3.1.2] 解决：服务器端配置文件/etc/rsyncd.conf问题，检查配置文件参数是否出错 Rsync+Inotify文件自动同步Inotify介绍Inotify是一个 Linux特性，是inode notify的简写，能监控文件系统操作，反应灵敏，异步传输信息，比cron高效，通过Inotify能试试了解文件系统发生的所有变化。 注：Linux内核需要大于2.6才集成了Inotify，先要通过uname -r查看内核版本 Inotify一些特点： 允许程序员使用标准 select 或者 poll 函数来监视事件 使用一个独立的文件描述符，可以通过系统调用获得 使用rsync工具与inotify机制相结合，可以实现触发式备份（实时同步）。 在系统/proc/sys/fs/inotify/目录中有三个文件： max_queued_events：inotify实例事件队列可容纳的事件个数，默认16384 max_user_instances：每个用户可以运行的inotifywait或inotifywatch命令的进程数，默认128 max_user_watches：每个进程最多监控文件数，默认8192 若要监控的文件量较大时，需要适当增大这三个值 可以在/etc/sysctl.conf中添加以下内容修改这三个值，或通过sysctl -w直接设置。 123fs.inotify.max_queued_events =fs.inotify.max_user_instances =fs.inotify.max_user_watches = Inotify常用的文件系统事件： 事件名 描述 IN_ACCESS 文件访问事件 IN_MODIFY 文件修改事件 IN_ATTRIB 文件属性修改事件 IN_OPEN 文件打开事件 IN_CLOSE_WRITE 可写文件被关闭事件 IN_CLOSE_NOWRITE 不可写文件被关闭事件 IN_MOVED_FROM IN_MOVED_TO 文件移动或重命名事件 IN_DELETE 文件或目录删除事件 IN_CREATE 文件或目录创建事件 IN_DELETE_SELF 自删除事件 若系统为fedora，可直接安装dnf install inotify-tools，若系统为CentOS，则需要先安装epel-release再安装yum install inotify-tools inotify-tools提供两个应用程序：inotifywait和inotifywatch inotifywait命令用法： 1234567891011121314151617inotifywait [options] file... @&lt;file&gt; 排除监控指定文件 --exclude &lt;pattern&gt; 使用正则表达式匹配例外文件，区分大小写 --excludei &lt;pattern&gt; 使用正则表达式匹配例外文件，不区分大小写 -m|--monitor 一直监听，不退出。若不加此项，监听到一个事件后就退出 -d|--daemon 相当于-m，但是是在后台运行，需要-o或--outfile指定输出文件，或者通过再指定--syslog将错误信息输出至syslog系统日志 -r|--recursive 递归监控目录 --fromfile &lt;file&gt; 从文件中读取需要监控与例外的文件名，每行一个文件，若文件名以@开头，表示例外文件 -o|--outfile &lt;file&gt; 将事件信息输出到文件，默认输出到标准输出 -s|--syslog 将错误事件日志发送到syslog，而不是stderr -q|--quiet 静默模式，只输出事件 -qq 静默模式，什么都不输出（包括事件） --format &lt;fmt&gt; 指定输出信息格式 --timefmt &lt;fmt&gt; 设置时间格式 -c|--csv 使用CSV格式输出 -t|--timeout &lt;seconds&gt; 在指定时间内若监听到事件，就退出 -e|--event &lt;event1&gt; [ -e|--event &lt;event2&gt; ... ] 只监控指定事件 实例：inotifywait -m -d -r -o /var/log/html_monitor /var/www/html 然后进入/var/www/html进行以下操作 123456touch a.htmlvim a.html cp a.html b.htmlrm a.html chmod -r b.html mv b.html a.html 在/var/log/html_monitor中就有以下信息 123456789/var/www/html/ CREATE a.html/var/www/html/ OPEN a.html/var/www/html/ ATTRIB a.html/var/www/html/ CLOSE_WRITE,CLOSE a.html/var/www/html/ OPEN,ISDIR /var/www/html/ ACCESS,ISDIR ...../var/www/html/ MOVED_FROM b.html/var/www/html/ MOVED_TO a.html 仅仅几步操作，就生成了170多行事件信息。 ## Inotify与Rsync实时同步数据 要求分析：数据发布服务器既是Rsync服务器同时也是Inotify监控服务器，该服务器是用于发布数据的，将数据同步到Web服务器，实现Web服务器与此数据发布服务器的同步。 实验环境： 数据发布服务器：192.168.205.135 Web服务器：192.168.205.134 首先需要在Web服务器上编写rsyncd.conf，添加模块 123456[www]comment = web file dictionarypath = /var/www/htmlauth users = wwwsecrets file = /etc/rsyncd.secretshosts allow = 192.168.205.135 进行系统准备： 1234567891011# 在Web服务器上创建用户wwwuseradd www &amp;&amp; echo &quot;redhat&quot; | passwd www --stdinecho &quot;www:redhat&quot; &gt;&gt; /etc/rsyncd.secretschmod 600 /etc/rsyncd.secrets查看/var/www是否所属于www，若不是就chown -R www:www /var/www# 在数据发布服务器上ssh-keygenssh-copy-id -i ~/.ssh/id_rsa.pub www@192.168.205.134# 在Web服务器上，同理，双向交换ssh公钥ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.205.135 数据发布服务器上触发同步脚本示例： 1234567#!/bin/bashSRC=/var/www/web_html/DST=www@192.168.205.134::www/usr/bin/inotifywait -d -r -o var/log/inotify_web -e modify,delete,create,attrib $&#123;SRC&#125; | while read linedo /usr/bin/rsync -az --delete $&#123;SRC&#125; $&#123;DST&#125; 2&gt;&amp;1done &amp; 加上执行权限chmod a+x并写入/etc/rc.local，echo &quot;脚本名&quot; &gt;&gt; /etc/rc.local 参考文章 rsync Rsync原理详解及部署 Rsync完全手册 inotify+rsync+mutt+msmtp 实现linux文件或者目录自动更新并且实现发邮件给管理员 Linux运维之道（第二版） 真正的inotify+rsync实时同步 彻底告别同步慢]]></content>
      <tags>
        <tag>server</tag>
        <tag>Rsync</tag>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux性能监控常用命令]]></title>
    <url>%2F2018%2F08%2F01%2FLinux%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[top与htop uptime,free和vmstat mpstat与iostat ps和pstree top与htoptop查看动态进程状态，默认每5秒刷新一次。 123456top-d：指定top刷新的时间间隔，默认是5 秒-b：批处理模式，每次刷新分批显示-n：指定top刷新几次就退出，可以配合-b使用-p：指定监控的pid，指定方式为-pN1 -pN2 ...或-pN1, N2 [,...]-u：指定要监控的用户的进程，可指定UID或用户名 1234567891011121314151617181920212223top - 02:20:36 up 6:48, 1 user, load average: 0.00, 0.00, 0.00Tasks: 145 total, 2 running, 143 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 2029396 total, 1600964 free, 161512 used, 266920 buff/cacheKiB Swap: 2097148 total, 2097148 free, 0 used. 1670652 avail Mem # Tasks为进程数# us：用户占用cpu百分比 sy：系统占用cpu百分比 ni：进程空间内改变过优先级的进程占cpu百分比 id：空闲cpu百分比 wa：I/O等待时间比率 hi：不可中断睡眠时间比率 si：可中断睡眠时间比率 st：被偷走时间比率，一般为虚拟机占用 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND # PR：优先级# NI：nice值，负数为高优先级，正数为低优先级# VIRT：虚拟内存总量 # RES：进程实际使用内存 # SHR：共享内存 # S：进程状态。有五种状态：D-不可中断的睡眠态 R-运行态 S-睡眠态 T-停止 Z-僵尸态# TIME+：进程使用CPU的时间总计（单位1/100秒） 进入top视图后的操作 12345678910111213141516171819201：查看每个逻辑CPU的状况P：按cpu使用率排序（默认） M：按内存使用率排序 N：按PID排序 T：根据TIME+进行排序H：切换为线程l：切换负载信息m：切换显示内存信息（只是将数字改为类似进度条）t：切换显示进程和CPU状态信息（只是将数字改为类似进度条）k：指定要杀死的进程号A：切换显示模式。有四个窗口，在左上角显示，按a（后一个）或w（前一个）进行窗口切换 Def：默认字段组 Job：任务字段组 Mem：内存字段组 Usr：用户字段组d或s：修改刷新间隔f：选择要添加显示的字段，标上*为已选的R：反向排序c：显示进程的完整命令路径名V：树视图，命令会按进程的父子关系显示u：显示指定用户的进程n或#：设置最多显示的进程量r：设置指定进程的nice优先级 htop默认没有安装，需要dnf install htop 可通过鼠标点击操作，h查看帮助 uptime,free和vmstatuptime获取主机运行时间，查询系统负载 1234509:05:53 up 12 days,13:33,2 users,load average: 0.01,0.02,0.0509:05:53--当前时间up 12 days, 13:33--系统启动时长2 users--当前登录系统的用户数load average: 0.01,0.02,0.05--系统在最近的1,5,15分钟的平均负载 负载率(load)，即特定时间长度内，cpu运行队列中的平均进程数(包括线程)，一般平均每分钟每核的进程数小于3都认为正常，大于5时负载已经非常高。Linux运行队列包括正在运行的、在等待的、处于可中断睡眠态（IO等待）的进程。若为多核CPU，还需要除以核数。 平均负载最佳值为1，意味着每个进程都能立刻访问CPU，并且没有丢失CPU周期 free查看内存与swap分区使用状况，实际是从/proc/meminfo中读取数据的 123456789101112131415free -b 单位b -k 单位kb（默认） -m 单位mb -g 单位gb -h 自动选择单位 -l 显示高内存、低内存详细统计数据 -t 显示内存与swap的总和 -s N 设置刷新周期（单位秒），ctrl+C退出 -c N 设置刷新次数 -w 分开显示buffers和cachetotal used free shared buff/cache available# cache为缓存：把读取的数据放在内存中，再次读的话就直接从内存中读了，加快读取# buffer为缓冲：写入数据时，把分散的写入操作保存到内存中，然后集中写入硬盘，减少磁盘碎片与硬盘反复寻道，加快写入 vmstat报告进程、内存、分页、块IO、中断、CPU活动信息，能够显示平均数据和实时样本。 123456789101112vmstat [options] [delay [count]] -a 显示内存信息 -f 显示自从系统启动以来产生的子进程数量 -m 显示slab信息 -n 与-a类似 -s 事件计数器和内存状态 -d 磁盘状态 -D 磁盘状态概述 -p 分区 磁盘分区统计信息 -S 单位 输出与-n一致，但可指定单位 -t 显示时间戳，输出比-n增加了一项CST时间戳 刷新间隔 [次数] 设置持续刷新间隔及刷新次数 虚拟内存模式 1234567891011121314151617181920212223242526vmstat procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa stProc： r：可运行进程的数量（正在运行+等待运行） b：不可中断睡眠进程的数量memory： swpd：虚拟内存使用量 free：空闲内存 buff：缓冲区内存 cache：用作缓存的内存swap： si：swap in,从磁盘换入的内存数量/s so：swap out,交换到磁盘的内存数量/sio： bi：block in,从块设备收到的块数/s bo：block out,发送到块设备的块数/ssystem： in：interrupt,每秒中断数量 cs：context switch,每秒上下文切换数量cpu： us：非内核代码运行时间 sy：内核代码运行时间 id：idle,空闲花费时间，包含IOwait时间 wa：wait,IO等待花费时间 st：steal,虚拟软件花费时间 磁盘模式 1234567891011121314151617vmstat -ddisk- ------------reads------------ ------------writes----------- -----IO------ total merged sectors ms total merged sectors ms cur secdisk：磁盘名reads： total：成功读取的总量 merged：合并后分组的读 sectors：成功读取的扇区 ms：读取花费时间（单位毫秒）writes： total：成功写入的总量 merged：合并后分组的写 sectors：成功写入的扇区 ms：写入花费时间（单位毫秒）IO： cur：正在进行的IO sec：IO花费时间（单位秒） mpstat与iostatmpstat与iostat都在sysstat包中，若没有这两个命令，则需要安装dnf install sysstat mpstat用于报告在多处理器服务器上每个可用CPU的统计数据。 12345678910111213mpstat [ 选项 ] [ &lt;时间间隔&gt; [ &lt;次数&gt; ] ] -A 相当于-u -I ALL -P ALL -I &#123;SUM|CPU|SCPU|ALL&#125; 报告中断统计数据 SUM 报告每个处理器中断的总数量，显示CPU编号和intr/s一个或多个CPU每秒接收每个独特中断的个数 CPU 显示intr/s，但排列难以阅读 SCPU 显示intr/s，排版容易阅读 ALL 显示所有中断统计信息 -P &#123;cpu编号|ON|ALL&#125; cpu 指明统计的cpu编号（0开始） ON 每个在线CPU的统计数据 ALL 所有CPU的统计数据 -u 统计CPU使用率，输出与-P一致 时间间隔interval [次数times] 指定报告时间间隔及次数，最后会生成平均值 123456789101112mpstat -uCPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idleCPU：CPU编号%usr：用户级别（应用）执行时CPU使用率%nice：用户级别使用nice优先级执行时CPU使用率%sys：系统级别（内核）执行时CPU使用率（不包括硬件软件中断服务的时间）%iowait：系统未完成磁盘I/O请求期间，CPU空闲时间百分比%irq：CPU硬件中断时间百分比%soft：CPU软件中断时间百分比%steal：虚拟化软件为其他虚拟CPU服务时，虚拟CPU非主动等待时间百分比%guest：CPU运行虚拟处理器花费时间百分比%idle：CPU空闲时间百分比 iostatps和pstreepsps命令有两种风格：BSD和Unix。BSD格式的参数前不加-，Unix格式会在参数前加- 查看所有进程 123456789101112131415161718192021222324252627ps ax # a表示此tty下的所有程序（不区分用户），x表示所有程序（不区分tty终端机），若增加u参数，可以用户为主的格式来显示程序状况ps -ef # -e显示所有程序，只显示PID、TTY、TIME、CMD，-f增加显示UID、PPID、C、STIMEps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDUSER：进程发起用户 PID：进程号 %CPU，%MEM：CPU，内存占用率VSZ：虚拟内存（单位kb） RSS：常驻内存（实际物理内存）（单位kb） TTY：该进程在哪个终端运行STAT：进程状态 S：可中断睡眠 &lt;：高优先级 s：子进程 +：位于后台 R：运行（Running） T：停止状态（Terminate） Z：僵尸进程（Zombie）START————进程开启时间TIME：进程已启动时间COMMAND：产生进程的命令名ps -ef中不同的几个PPID：父进程IDC：CPU占用率STIME：进程启动时间 显示用户进程 12ps -f -u [用户名1,用户名2...] #-u指定用户，可指定多个，不能加-e，不然等于没指定例：ps -f -u apache 显示指定进程 123ps -f -C [进程] # -C指定进程名，进程名必须是精确的，不能用通配符。同样不能指定-e例：ps -f -C httpdps -f -p [进程号] # -p指定进程号 通过cpu或内存占用对进程排序 123ps -ef --sort=[+|-]pcpu,[+|-]pmem--sort用于指定多个字段，pcpu为按CPU排序，pmem为按内存排序，+为升序，-为降序例：ps -ef --sort=-pcpu | head -6 显示CPU占用排名前五的进程 以树显示进程层级关系 12ps -f --forest例：ps -f --forest -C httpd 查看指定父进程下的所有子进程 1ps --ppid [PPID] 显示进程的线程 12ps -f -L -C [进程]或-p [进程号] #显示指定进程的线程例：ps -f -L -C httpd 指定要显示的列 12ps -o pid,uname,pcpu,pmem,comm,etime其中：uname为用户名，etime为进程已运行时间 通过watch命令将ps变为实时查看器 1234watch -n 指定指令执行间隔 -d 高亮显示指令输出信息不同之处例：watch -n 1 &apos;ps -e -o pid,uname,cmd,pmem,pcpu --sort=-pcpu,-pmem | head -11&apos; pstree查看进程树，常用选项 12345678910-p 显示进程PID-g 显示进程组ID，即PGID-u 显示进程所属用户-a 显示进程的命令及参数-H PID 高亮显示指定进程及它的所有父进程-T 只显示进程，不显示线程-t 显示完整的线程名-s 显示进程的父进程-n 按PID排序输出-Z 显示selinux上下文（需要开启selinux） 参考文章 10 basic examples of Linux ps command ps命令的10个例子 Linux性能优化大师]]></content>
      <tags>
        <tag>运维</tag>
        <tag>监控</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVM逻辑卷与RAID磁盘阵列学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2FLVM%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8ERAID%E7%A3%81%E7%9B%98%E9%98%B5%E5%88%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容 LVM逻辑卷 LVM概述 LVM创建与调整 LVM快照 RAID磁盘阵列 RAID概述 RAID基础搭建 LVM逻辑卷LVM概述LVM(Logical Volume Manager)逻辑卷管理器，可以灵活调整存储空间大小，并不会对现有数据造成任何损坏。红帽系的系统全部默认开启了LVM。 几个关键术语： PV(Physical Volume，物理卷)：最低层的存储设备（硬盘，分区） VG(Volume Group，卷组)：单个或多个PV构成的存储资源池，不能直接存放数据 LV(Logical Volume，逻辑卷)：从VG中划分出的存储空间，可直接存放数据 PE(Physical Extend，物理扩展单元)：逻辑层面上最小的存储单元（类似block），一个PE大小4MB，是告诉PV，表明存储单元位于PV的哪个位置。PE大小必须满足2的指数幂 LE(Logical Extend，逻辑扩展单元)：与PE类似，默认情况下，PE与LE一样大。LE告诉LV，表明存储单元处于VG的哪个位置 LVM创建流程： 使用几块硬盘或分区（未创建文件系统）创建物理卷，并将分区的识别号设置为LVM，即8e 将多个物理卷组合成一个卷组，卷组会根据指定的PE大小将空间划分为多个PE，在LVM中存储以PE为单元 在卷组中分出逻辑卷，这些逻辑卷在外界看来就是多个独立的硬盘分区 对逻辑卷制作文件系统，并挂载 LVM写入机制：LV是从VG中划分出来的，LV中的PE很可能来自于多个PV。在向LV存储数据时，有多种存储机制，其中两种是： 线性模式(linear)：先写完来自于同一个PV的PE，再写来自于下一个PV的PE。 条带模式(striped)：一份数据拆分成多份，分别写入该LV对应的每个PV中，所以读写性能较好，类似于RAID 0。 尽管striped读写性能较好也不建议使用该模式，因为lvm的着重点在于弹性容量扩展而非性能，要实现性能应该使用RAID来实现，而且使用striped模式时要进行容量的扩展和收缩将比较麻烦。默认的是使用线性模式。 引用自骏马金龙的LVM详解 LVM创建与调整实验环境： CentOS7 /dev/sdb 大小20G 将/dev/sdb分为4个分区，每个分区5G，并将磁盘标识号设为8e，表示LVM 1234567891011121314# fdisk -l /dev/sdbDisk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0xde948938 Device Boot Start End Blocks Id System/dev/sdb1 2048 10487807 5242880 8e Linux LVM/dev/sdb2 10487808 20973567 5242880 8e Linux LVM/dev/sdb3 20973568 31459327 5242880 8e Linux LVM/dev/sdb4 31459328 41943039 5241856 8e Linux LVM 准备裸磁盘与裸分区，制作PV使用pvcreate [裸磁盘/裸分区]创建PV 12345# pvcreate /dev/sdb1 /dev/sdb2 /dev/sdb3 /dev/sdb4 Physical volume &quot;/dev/sdb1&quot; successfully created. Physical volume &quot;/dev/sdb2&quot; successfully created. Physical volume &quot;/dev/sdb3&quot; successfully created. Physical volume &quot;/dev/sdb4&quot; successfully created. 可使用pvdisplay [磁盘/分区]查看pv信息1234pvdisplay选项列表 若不指定磁盘或分区，就是查看所有PV -m # 查看该设备中PE的使用分布图 -s # 查看pv简短信息 pvs或pvscan也可查看所有PV信息12345678# pvscan PV /dev/sda2 VG centos lvm2 [&lt;19.00 GiB / 0 free] PV /dev/sdb4 lvm2 [&lt;5.00 GiB] PV /dev/sdb2 lvm2 [5.00 GiB] PV /dev/sdb1 lvm2 [5.00 GiB] PV /dev/sdb3 lvm2 [5.00 GiB] Total: 5 [&lt;39.00 GiB] / in use: 1 [&lt;19.00 GiB] / in no VG: 4 [&lt;20.00 GiB] 最后一行显示的是&quot;pv的总容量/已使用的pv容量/空闲的pv容量&quot; pvremove [分区]删除PVpvmove [分区]删除PV中的所有数据 制作VGvgcreate [VG名][多个裸磁盘]制作卷组12345vgcreate选项列表 -s # 指定PE大小。不指定默认大小4M -l # 卷组上允许创建的最大逻辑卷数 -p # 卷组中允许添加的最大物理卷数 在创建VG后，只有VG没有数据时才能修改属性，如PE大小 1234# vgcreate -s 8M my_vg1 /dev/sdb1 /dev/sdb2 Volume group &quot;my_vg1&quot; successfully created# vgcreate -s 8M my_vg2 /dev/sdb3 /dev/sdb4 Volume group &quot;my_vg2&quot; successfully created vgdisplay [VG名]查看VG信息vgs和vgscan也可显示所有VG信息 vgreduce [VG名] [PV名]从VG中删除指定PVvgextend [VG名] [PV名]添加PV到VG中1234# vgreduce my_vg1 /dev/sdb2 Removed &quot;/dev/sdb2&quot; from volume group &quot;my_vg1&quot;# vgextend my_vg1 /dev/sdb2 Volume group &quot;my_vg1&quot; successfully extended 1234vgchange [选项] [VG名] 修改卷组的属性经常被用来设置卷组是处于活动状态或非活动状态。处于活动状态的卷组无法被删除，必须使用vgchange命令将卷组设置为非活动状态后才能删除。 -a y|n 设置卷组的活跃|非活跃状态 vgremove [VG名]删除VG 创建逻辑卷LVlvcreate -L N -n [LV名][VG名]创建逻辑卷1234lvcreate选项列表 -L N # 指定逻辑卷大小N，若N不是PE的整数倍，系统会自动将LV大小变大为PE整数倍 -n # 指定LV名 -l n # 指定PE个数，即通过PE个数指定逻辑卷大小 12345678910# lvcreate -L 6G -n my_lv1 my_vg1 Logical volume &quot;my_lv1&quot; created.# lvcreate -l 1000 -n my_lv2 my_vg2 Logical volume &quot;my_lv2&quot; created.# lvscan ACTIVE &apos;/dev/centos/swap&apos; [2.00 GiB] inherit ACTIVE &apos;/dev/centos/root&apos; [&lt;17.00 GiB] inherit ACTIVE &apos;/dev/my_vg2/my_lv2&apos; [7.81 GiB] inherit ACTIVE &apos;/dev/my_vg1/my_lv1&apos; [6.00 GiB] inherit lvdisplay [LV名]查看指定或所有LV详细信息lvs和lvscan可查看全部LV信息 lvextend [选项] +[扩容大小] [LV]用于扩展逻辑卷的空间大小，而不中断应用程序对逻辑卷的访问12345lvextend选项 -L 指定逻辑卷的大小 -l 指定逻辑卷的大小（LE数） 若不添加加号，则要指定扩容后的大小（一定要比增容前大） 若添加加号，则要指定要扩容的大小 12345678# lvextend -L +100M /dev/my_vg1/my_lv1 Rounding size to boundary between physical extents: 104.00 MiB. Size of logical volume my_vg1/my_lv1 changed from 6.00 GiB (768 extents) to 6.10 GiB (781 extents). Logical volume my_vg1/my_lv1 successfully resized.# lvextend -l +10 /dev/my_vg2/my_lv2 Size of logical volume my_vg2/my_lv2 changed from 7.81 GiB (1000 extents) to 7.89 GiB (1010 extents). Logical volume my_vg2/my_lv2 successfully resized. lvreduce [选项] -[缩小大小] [LV]减少LVM逻辑卷占用的空间大小。有可能会删除逻辑卷上已有的数据参数与用法与lvextend一致lvresize [选项] [+|-][扩大或缩小大小] [LV]调整LVM逻辑卷的空间大小，可以增大空间和缩小空间，可能会使逻辑卷上已有的数据丢失参数与用法与lvextend与lvreduce一致。 若该LV已制作完文件系统并挂载完成，而要对该LV进行容量的改变操作，首先需要umount将挂载取消，然后使用上述命令进行容量改变操作，然后再制作文件系统并挂载。然而，通过任何查看命令都会发现LV大小并没有改变。因此，在改变大小后，还要继续以下操作。 若文件系统为ext4，则需要执行resize2fs [LV路径] 若文件系统为xfs，则需要执行xfs_growfs [LV路径]xfs文件系统只支持增大分区空间的情况，不支持减小的情况。硬要减小的话，只能在减小后将逻辑分区重新通过mkfs.xfs命令重新格式化才能挂载上，这样的话这个逻辑分区上原来的数据就丢失了。xfs是不支持裁剪的，ext是支持裁剪的，所以xfs尽量不要缩小LV 建议在修改容量后执行e2fsck -f [LV路径]检查是否修改后的大小会影响数据。12345678# e2fsck -f /dev/my_vg1/my_lv1 e2fsck 1.42.9 (28-Dec-2013)Pass 1: Checking inodes, blocks, and sizesPass 2: Checking directory structurePass 3: Checking directory connectivityPass 4: Checking reference countsPass 5: Checking group summary information/dev/my_vg1/my_lv1: 11/400624 files (0.0% non-contiguous), 64167/1599488 blocks lvremove [LV名]删除指定LV LVM快照LVM提供快照功能，可将逻辑卷的数据进行备份，并可快速恢复 实验选用/dev/my_vg1/my_lv1，并将该LV挂载在/my_lv112345678# lvdisplay /dev/my_vg1/my_lv1 --- Logical volume --- LV Path /dev/my_vg1/my_lv1 LV Name my_lv1 VG Name my_vg1...... LV Size 6.10 GiB...... lvcreate -s -n [快照名] -L [快照大小] [LV路径]创建快照123-s 创建快照-n 指定快照名-L 快照大小 1234567891011# lvcreate -s -L 1G -n my_snapshot /dev/my_vg1/my_lv1 Using default stripesize 64.00 KiB. Logical volume &quot;my_snapshot&quot; created.可通过lvscan查看，最后多了一条快照信息# lvscan ACTIVE &apos;/dev/centos/swap&apos; [2.00 GiB] inherit ACTIVE &apos;/dev/centos/root&apos; [&lt;17.00 GiB] inherit ACTIVE &apos;/dev/my_vg2/my_lv2&apos; [7.89 GiB] inherit ACTIVE Original &apos;/dev/my_vg1/my_lv1&apos; [6.10 GiB] inherit ACTIVE Snapshot &apos;/dev/my_vg1/my_snapshot&apos; [1.00 GiB] inherit 在/my_lv1中创建文件dd if=/dev/zero of=/my_lv1/files count=1 bs=100M然后将该LV卸载umount /my_lv1最后将快照恢复lvconvert --merge /dev/my_vg1/my_snapshot12345# lvconvert --merge /dev/my_vg1/my_snapshot Merging of volume my_vg1/my_snapshot started. my_lv1: Merged: 69.90% my_lv1: Merged: 100.00%快照恢复过后会自动删除 将LV重新挂载到/my_lv1，发现文件夹中已经没有任何文件了，说明快照恢复成功。 RAID磁盘阵列RAID概述Redundant Array of Independent Disks独立硬盘组，作用是防止硬盘物理损坏以及增加存储设备的吞吐量。常见的RAID形式有：RAID 0、RAID 1、RAID 3、RAID 5、RAID 6、RAID 10、RAID 01、RAID 50。 RAID 0：将多个磁盘合并为1个大磁盘，读写速度极大提高，但不具冗余，因为通过硬件或软件串联，数据是依次被写入各个硬盘，所以任何一块损坏都会导致数据丢失。 RAID 1：两组以上的N个硬盘相互做镜像，让数据被多块硬盘同时写入。一块损坏可立刻通过热交换恢复数据。由于做备份，硬盘空间只有50%。 RAID 3：将数据条块化分布于不同的硬盘上，使用简单的奇偶校验，并用单块磁盘存放奇偶校验信息。如果一块磁盘失效，奇偶盘及其他数据盘可以重新产生数据;如果奇偶盘失效则不影响数据使用。RAID 3对于大量的连续数据可提供很好的传输率，但对于随机数据来说，奇偶盘会成为写操作的瓶颈。 RAID 5：使用硬盘分割技术，至少需3块硬盘。既提高传输速度，也可实现镜像备份。但采用奇偶校验信息，写速度相当慢，读速度与RAID0相近，且镜像保障程度也不及RAID1。空间利用率高。是在所有磁盘上交叉存储数据与奇偶校验信息，并不是单独保存在某块内存中，而是分别互相保存在每一块硬盘，raid5并不是备份实际硬盘数据，而是在硬盘出现故障后通过奇偶校验信息尝试恢复数据。RAID5的利用率为总可用盘容量的(n-1)/n RAID 6：相较RAID5增加第二个独立的奇偶校验信息块，数据可靠性非常高，需要四个以上硬盘 RAID 7：全称是最优化的异步高 I/O 速率和高数据传输率，不仅仅是一种技术，它还是一个独立存储计算机，自身带的操作系统和管理工具，完全可以独立运行。采用了非同步访问，极大地减轻了数据写瓶颈，提高了 I/O 速度，存储计算机操作系统可使主机 I/O 传递性能达到最佳，能够自动执行恢复操作，并可管理备份磁盘的重建过程。该技术已被raid7公司垄断。 RAID 10（企业主要用）/01： 10为1+0 先镜射再分割数据，两个两个组成raid1，再两组两组组成raid0，拥有较高速度与较高数据保护性，但需要4块以上且数量为偶数的硬盘数，因为使用raid1，所以利用率也是50%。安全性比01强，速度也比01强，恢复速度快于5 01为0+1 先分割再镜射，两个两个组raid0，再两组两组组raid1 RAID 50：至少需要6块硬盘，将数据分为条带同时存入多个磁盘，以数据校验位保证数据安全，目的在于提高RAID5的读写性能 RAID基础搭建RAID的创建管理由mdadm命令实现123456789101112131415161718mdadm [模式] [RAID设备名] [选项] [成员设备] -a # 检测设备名 -As # 激活raid（停止的时候） -n # 指定设备数量 -c # 指定数据块大小 -l # 指定raid级别 -C # 创建 -v # 显示过程 -G # 修改raid -f # 模拟设备损坏 -r # 移除设备 [raid] -a [磁盘] 将磁盘添加到raid阵列 [raid] -r [磁盘] 将磁盘移出raid阵列 -Q # 查看摘要信息 -D # 查看详细信息（cat /proc/mdstat查看阵列状态） -S # 停止阵列 -x # 备份盘个数 --detail # 查看RAID阵列 实验目的：搭建RAID 10实验环境 CentOS7 /dev/sdb分出4分区，每个5G大小 mdadm -Cv /dev/md0 -a yes -n 4 -l 10 /dev/sdb1 /dev/sdb2 /dev/sdb3 /dev/sdb4创建RAID 可通过cat /proc/mstat查看简要RAID信息1234# cat /proc/mdstat Personalities : [raid10] md0 : active raid10 sdb4[3] sdb3[2] sdb2[1] sdb1[0] 10475520 blocks super 1.2 512K chunks 2 near-copies [4/4] [UUUU] 也可通过mdadm -D /dev/md0查看指定RAID信息12345678910111213141516171819202122232425262728293031323334353637# mdadm -D /dev/md0 /dev/md0: Version : 1.2 Creation Time : Thu Aug 2 09:56:25 2018 Raid Level : raid10 Array Size : 10475520 (9.99 GiB 10.73 GB) # Array Size总共能使用的空间，因为是raid10，所以总可用空间为400M左右，除去元数据，大于370M左右 Used Dev Size : 5237760 (5.00 GiB 5.36 GB) # Used Dev Size每颗raid组或设备上的可用空间，也即每个RAID1组可用大小为190M左右 Raid Devices : 4 # raid中设备的个数 Total Devices : 4 # 总设备个数，包括raid中设备个数，备用设备个数等 Persistence : Superblock is persistent Update Time : Thu Aug 2 09:57:17 2018 State : clean # 当前raid状态，有clean/degraded(降级)/recovering/resyncing Active Devices : 4 Working Devices : 4 Failed Devices : 0 Spare Devices : 0 Layout : near=2 # RAID10数据分布方式，有near/far/of set，默认为near，即数据的副本存储在相邻设备的相同偏移上。 # near=2表示要备份2份数据 Chunk Size : 512KConsistency Policy : resync Name : bogon:0 (local to host bogon) UUID : 1aa0ce46:4762919a:71542e42:47b8bc7b Events : 17 Number Major Minor RaidDevice State 0 8 17 0 active sync set-A /dev/sdb1 1 8 18 1 active sync set-B /dev/sdb2 2 8 19 2 active sync set-A /dev/sdb3 3 8 20 3 active sync set-B /dev/sdb4 制作文件系统并挂载该RAIDmkfs.ext4 /dev/md0 &amp;&amp; mount /dev/md0 /mnt/md0 模拟RAID损坏，这里模拟损坏/dev/sdb3mdadm /dev/md0 -f /dev/sdb3此时查看RAID信息12345678910111213141516# mdadm -D /dev/md0 ...... State : clean, degraded Active Devices : 3 # 活跃的设备仅3台 Working Devices : 3 # 工作中的设备仅3台 Failed Devices : 1 # 出现故障的设备1台 Spare Devices : 0...... Number Major Minor RaidDevice State 0 8 17 0 active sync set-A /dev/sdb1 1 8 18 1 active sync set-B /dev/sdb2 - 0 0 2 removed 3 8 20 3 active sync set-B /dev/sdb4 2 8 19 - faulty /dev/sdb3 # /dev/sdb3的状态为faulty 由于raid10允许一组raid1存在故障，不会影响使用。 进行恢复，首先要卸载文件系统umount /mnt/md0然后移除/dev/sdb3，mdadm /dev/md0 -r /dev/sdb3最后再次添加进RAID组，mdadm /dev/md0 -a /dev/sdb3立刻查看RAID状态1234567891011121314151617181920212223242526# mdadm -D /dev/md0...... Active Devices : 3 Working Devices : 4 Failed Devices : 0 Spare Devices : 1 Layout : near=2 Chunk Size : 512KConsistency Policy : resync Rebuild Status : 38% complete Name : bogon:0 (local to host bogon) UUID : 1aa0ce46:4762919a:71542e42:47b8bc7b Events : 30 Number Major Minor RaidDevice State 0 8 17 0 active sync set-A /dev/sdb1 1 8 18 1 active sync set-B /dev/sdb2 4 8 19 2 spare rebuilding /dev/sdb3 3 8 20 3 active sync set-B /dev/sdb4可以看出此时活跃设备仍为3台，但工作设备已变为4台，空闲设备为1台Rebuild Status : 38% complete 表示正在重建该设备在/dev/sdb3的状态上也可看出正在重建rebuilding 若要彻底停用该阵列，只需要先卸载文件系统，然后执行mdadm -S /dev/md0即可。 使用RAID 5进行备份mdadm -Cv /dev/md0 -n 3 -x 1 -l 5 /dev/sdb1 /dev/sdb2 /dev/sdb3 /dev/sdb4其中-n 3表示选择3块磁盘做主盘，-x 1表示选1张做备份盘，加起来一共4张磁盘。此时查看RAID信息12345678910111213141516171819202122232425262728293031323334# mdadm -D /dev/md0 /dev/md0: Version : 1.2 Creation Time : Thu Aug 2 10:35:01 2018 Raid Level : raid5 Array Size : 10475520 (9.99 GiB 10.73 GB) Used Dev Size : 5237760 (5.00 GiB 5.36 GB) Raid Devices : 3 Total Devices : 4 Persistence : Superblock is persistent Update Time : Thu Aug 2 10:35:28 2018 State : clean Active Devices : 3 Working Devices : 4 Failed Devices : 0 Spare Devices : 1 Layout : left-symmetric Chunk Size : 512KConsistency Policy : resync Name : bogon:0 (local to host bogon) UUID : 9d0e9a0d:38372c14:2ad4666f:feb13f5c Events : 18 Number Major Minor RaidDevice State 0 8 17 0 active sync /dev/sdb1 1 8 18 1 active sync /dev/sdb2 4 8 19 2 active sync /dev/sdb3 3 8 20 - spare /dev/sdb4可看出/dev/sdb4做了备份盘，状态为空闲 参考资料 百度百科–RAID磁盘阵列RAID基础，RAID10与RAID01比较，RAID10与RAID5比较骏马金龙–RAID骏马金龙–LVM图文并茂 RAID 技术全解Linux就该这么学]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>LVM</tag>
        <tag>RAID</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STP学习笔记]]></title>
    <url>%2F2018%2F07%2F31%2FSTP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[组播学习笔记]]></title>
    <url>%2F2018%2F07%2F31%2F%E7%BB%84%E6%92%AD%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于华三网络学习笔记（理论） 组播概述 组播组管理协议 组播转发机制 组播路由协议 组播概述组播用于实现点到多点的传输。 效率高，分布式应用，多点传输 数据源仅发送一份数据包，链路仅传输一份数据包，只有组播组中接受者能收到数据包 尽最大努力交付 无拥塞控制 数据报重复 数据包无序交付 组播需求问题与相关技术： 如何标识接受者—–组播地址机制 接受者动态加入或离开组播组—–组成员关系管理 组播报文如何在网络中转发—-组播报文转发过程 组播报文转发路径（组播转发树）构建—–组播路由协议 组播地址：组播地址范围：224.0.0.0---239.255.255.255 本地协议预留组播地址：224.0.0.0---224.0.0.255，属于局部范围，不会被路由器转发 用户组播地址：224.0.1.0---238.255.255.255，用户可用组播地址，全网有效232.0.0.0/8为SSM组地址，其余属于ASM组 本地管理组地址：239.0.0.0---239.255.255.255，特定本地范围有效，属于ASM组 组播MAC地址：以太网：01-00-5e-xx-xx-xx 组播地址映射：组播MAC地址中高24位固定为0x01005E，第25位为0，低23位来自组播IP地址的低23位。组播IP地址的高4位为1110，标识组播，而低28位只有23位被映射到组播MAC地址，即有5位的丢失，一共会有2^5即32个IP地址公用一个组播MAC，也就是可能会接受所在组播组外的其他组播数据。 举例：12345678组播IP地址为：224.231.123.14换成二进制：11100000 11100111 01111011 00001110组播MAC地址高24位为01005E，即0000 0001 0000 0000 0101 1110 1110|00001|11001110111101100001110 组播IP地址，共32位000000010000000001011110|0|11001110111101100001110 组播MAC地址，共48位组播IP地址中第二部分，案例中00001部分，在MAC地址中没有任何对应，一共有32种可能 组播组管理协议常用的组播组管理协议为IGMP（Internet Group Management Protocol因特网组管理协议）。主机通过IGMP通知路由器加入或离开某个组播组，路由器通过IGMP周期查询组播组成员是否处于活动状态，收集成员关系并维护 IGMP有三个版本： IGMPv1：定义了基本的组成员查询和报告过程 IGMPv2：添加了组成员快速离开机制 IGMPv3：添加了成员可指定接受或拒绝组播源的报文，支持SSM模型 IGMPv2IGMP报文： Type：IGMP报文类型，包含Membership Query、Report、Leave Group Max Reps Time：最大响应时间，只有Membership Query使用该字段 checksum：校验和 Group Address：组地址。不同报文填的不同。普遍查询填0，特定组查询填指定组播组地址，报告报文和离开报文填组播组地址 IGMPv2原理： 当同一网段中有多个IGMP路由器时，通过查询器选举机制（最小接口IP）选出唯一查询器。 查询器周期发送普遍查询消息General Query，目的地址224.0.0.1，TTL为1，进行组成员关系查询。主机收到后发送报告消息Report响应。也有称为Membership Report，但本篇统一为Report 主机若要加入组播组，可直接向查询器发送Report，离开组播组时，直接发送Leave，目的地址为224.0.0.2，通告所有组播路由器。查询器收到Leave后，会发送特定组查询消息Group-Specific Query确定该组所有成员是否都离开。 若是加入，查询器则会查看组播转发表项，若不存在就添加，表项为(组播源IP地址,组播组IP)，若为*表示任意源。组播转发表项还包含：组播指定报文的入接口、出接口等 案例完整流程： IGMP Snooping：解决二层组播。原因：组播数据在二层以广播发送主机发往IGMP查询器的报告消息经过交换机时，交换机会监听并将组播MAC和端口做映射，建立表项。当交换机收到组播数据时，就按表项转发，也就只向组成员发送了 IGMPv3概述：1.可对源过滤 2.新的报文类型与格式 3.报告报文的组播地址为224.0.0.22 4.取消成员报告抑制机制IGMPv3主机为接口上每个组播组维护一个表项（组地址，过滤模式，源列表）过滤模式：INCLUDE：只接收来自源列表的组播源的数据包 EXCLUDE：只接收不在源列表的组播源的数据包三种状态：当前状态，过滤模式改变状态，源列表改变状态。对应三种记录当主机接口维护的组状态变化时，会主动发送组记录类型为过滤模型变化或源列表变化的报告报文。当接收到查询报文时，会响应记录类型为当前状态的报告报文 组播分发树模型：是组播数据的转发数据，分为最短路径树(S,G)和共享树(*,G)组播转发机制：逆向路径转发组播路由协议：域内：DVMRP（基于路径矢量协议）、MOSPF（基于OSPF）、PIM 域间：MSDP、MBGP域内协议：基于SPT：PIM DM、DVMRP、MOSPF 基于RPT：PIM SM组播模型：ASM任意信源组播：接收端只选择加入组播组，不能选择组播源 SSM指定信源组播：接收端可以指定组播源 组播分发树：由组播路由协议建立的无环传输路径SPT最短路径树：组播源到接受者的最短路径。要为每个组播源建一棵最短路径树缺点：路由器必须为每个组播源保存路由信息RPT共享树：以某个路由器作为树根，该路由器称为汇聚点RP，以RP为树根建立到每个接收者的最短路径树。所有组播源和接收者都使用这棵树收发报文。组播源先向RP发数据，再由RP发送到所有接收者。优点：路由器保留的路由信息很少缺点：数据报文先要经过RP，再到达接收者，对RP的可靠性和性能要求高组播报文转发机制RPF逆向路径转发原因：组播报文是发送给一组接收者的，路由器收到组播报文后，必须根据报文的源地址确定正确的入接口和下游方向，然后向下游方向转发。该过程就是RPF。目的：确保组播数据沿正确路径传输，避免出现环路检查过程：在单播路由表上查找组播源（分发树为SPT）或RP（分发树为RPT）对应的RPF接口，若数据包是在RPF端口接收到的，则RPF检查成功，转发数据包。否则检查失败，直接丢弃PIM协议无关组播：与单播路由无关，但仍然依靠单播路由表进行组播路由。使用RPF转发报文。分为两种模式：PIM-DM（密集模式），PIM-SM（稀疏模式）PIM-DM：用于小型网络中接收者较多且密集的情况，采用“推”方式将流量泛洪。邻居发现：路由器周期发送PIM Hello消息，发现其他PIM路由器，建立邻居关系，判断叶子网络，选举DR（若运行的是IGMPv1，通过Hello选举，其他版本就不需要选举DR）。扩散-剪枝：将组播数据扩散到每个节点，每个节点创建(S,G)表项（包含出接口（除RPF接口外所有连接PIM-DM邻居或组播组成员的接口）与入接口列表），若节点没有该组播组成员，就向上游发送Prune剪枝消息，若共享网段有路由器上有接收者，就向上游发送Join消息，覆盖其他路由器发送的Prune。 扩散-剪枝过程周期进行。最终形成SPT。Prune消息发送情况：1.若路由器(S,G)表中出接口表为空 2.路由器从非RPF接口收到组播报文，会触发断言Assert机制，断言失败一方会向成功一方发送Prune消息。断言Assert：若同一网段有多个组播路由器，相同报文可能会被重复发送，通过断言选取网段唯一转发组播数据的路由器。过程：路由器在重复接收到报文的接口上发送Assert消息，包含S，G，单播路由的优先级，开销Metric。先比较路由优先级（高的胜），再比较开销（小的胜），再比较本地接口IP地址（大的胜）。当一台路由器上游接口故障时，该路由器将Metric值设为无穷大并广播Assert，引发新一轮断言，保证流量不会长时间中断。状态刷新机制：与组播源直连的路由器发送State Refresh，其他路由器收到后重置剪枝超时定时器，并向所有连接PIM-DM邻居的路由器发送该消息，对于处于转发的接口，消息中剪枝位为0，处于剪枝的接口，剪枝位为1。周期发送该消息可使剪枝状态的接口维持状态，减少不必要的扩散。嫁接：当被剪枝的节点上出现接收者时，节点会主动向上游发送嫁接Graft消息，上游收到后回复Graft Ack消息确认，节点从剪枝状态变为转发状态。两个消息都是单播发送。PIM-SM：用于中大型网络中，组播组成员相对分散，范围较广，采用“拉”方式。核心任务是构造维护RPT，选出RP作为共享树的根。过程：组播源侧DR向RP注册，将注册报文单播发给RP，该报文到达RP后触发建立SPT，组播源把数据沿SPT发给RP，再由RP沿RPT发给接收者 ASM模型：任意源模型。任何发送者都可作为组播源向组播组发数据，接收者无法预先知道组播源位置，但可以在任意时间加入离开组播组SSM模型：指定信源组播模型。接收端能指定组播源。SSM模型无需RP，无需构建RPT，无需组播源注册过程。]]></content>
      <tags>
        <tag>网络</tag>
        <tag>组播</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSPF学习笔记]]></title>
    <url>%2F2018%2F07%2F31%2FOSPF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于华三网络学习笔记（理论） 本篇包含以下内容 OSPF特性与基本术语 OSPF报文 OSPF邻居建立维护与状态机 OSPF特殊区域 OSPF特性与基本术语Open Shortest Path First开放最短路径优先 属于IGP，优先级AS内部10，外部150 采用链路状态算法SPF防环 封装在IP报文中，协议号89 度量值为开销cost=带宽参考值/接口带宽，参考值通常为100M，若求得的数小于1，则cost就取1 报文更新方式为触发更新+周期更新（30min。LSA老化时间60min） 增量更新（通过LSA），组播更新报文 组播地址224.0.0.5（主要，所有OSPF路由器都能收到）或224.0.0.6（DR、BDR可收到） 没有跳数限制，可用于大规模组网 路由生成过程： 生成LSA描述自身接口状态（链路开销、IP地址等） 同步OSPF区域内每台路由器的LSDB（通过交换LSA） SPF算法计算路由：每个路由器以自身为根计算最短路径树（即根到各节点的开销都是最小的），加入路由表，若两条路径开销相同，则都加入表中形成等价路由。 开启OSPF的路由器上与路由转发相关的三张表： 邻居表：记录建立了邻居关系的路由器 LSDB表：记录所有链路状态信息，需要实时同步 路由表：记录经SPF算法计算的路由 OSPF选路原则： 按路由类型优先级：区域内路由&gt;区域间路由&gt;第一类外部路由&gt;第二类外部路由 类型相同，选路由开销小的 以上都相同，形成等价路由 两类外部路由： 第一类外部路由：偏向于AS内部的选路，并不关心AS外的开销。用于控制入AS的路由选路。如图中RTA，若选择第一类外部路由，则关心AS内部的开销，会选择开销较小的RTB路线。 第二类外部路由：偏向与AS外部的选路，并不关心AS内的开销。用于控制出AS的路由选路。如图中RTA，若选择第二类外部路由，则关心AS外部的开销，会选择开销较小的RTC路线。 若同一网段的路由信息同时通过第一类外部路由和第二类外部路由学习到，在其他条件相同的情况下，会优选第一类外部路由。 骨干区域：area 0，负责转发非骨干区域之间的路由。区域间路由规则： 非骨干区域必须与骨干区域相连 非骨干区域之间不能传递路由，必须通过骨干区域 骨干区域传出的路由不能传回非骨干区域 OSPF防环：从一个区域学习到的路由不会再向该区域注入。非骨干区域间不能直接通信 当骨干区域被分割或非骨干区域不与骨干区域相连时，可通过虚连接解决。两台ABR（区域边界路由器）通过一个非骨干区域建立一条逻辑通道，对于通道上的路由器是透明的。 划分区域的好处： 减少了区域内LSDB中链路状态信息的数量 便于管理 减少路由震荡的影响范围 OSPF路由器类型： 区域内路由器Internal：所有接口都属于同一个区域 区域边界路由器Area Border：连接骨干与非骨干区域（物理上或逻辑上） 骨干路由器Backbone：至少有一个接口属于骨干区域，即所有区域内和区域边界路由器都是骨干路由器 自治系统边界路由器Autonomous System Border：与其他AS路由器交换路由信息，不一定在AS的边界，只要该路由器引入外部路由，就是ASBR。 Router ID用来在AS中唯一标识一个路由器，RouterID的选取优先级如下：局部 &gt; 全局 &gt; 自动选举局部：创建OSPF进程时同时指定router-id全局：系统视图下指定router id自动选举：环回口中最大的，若无环回口，则选取接口中IP地址最大的 网络类型： Broadcast广播：当链路层为以太网协议时，默认为Broadcast，以组播地址发报文(.5|.6)，需要DR，Hello定时器10s，邻居失效时间40s。 NBMA非广播多点可达网络：当链路层为帧中继或ATM时，默认为NBMA，以单播发报文，需要DR，Hello定时器10s，邻居失效时间40s。 P2P点到点：当链路层为PPP、HDLC时，默认P2P，以组播发报文(.5)，不需要DR，Hello定时器30s，邻居失效时间120s。 P2MP点到多点：需要手动修改，以组播发报文(.5)，不需要DR，Hello定时器30s，邻居失效时间120s。 OSPF报文OSPF五种报文： Hello报文：发现维护邻居关系，包含定时器、DR、BDR和已知邻居 DD报文：数据库描述报文，描述本地LSDB中LSA摘要，进行主从关系协商，用于路由器间LSDB同步 LSR(Request)报文：链路请求报文，向对方请求所需LSA（通过比对DD报文知道自己缺哪些LSA） LSU(Update)报文：链路状态更新报文，向对方发送所要求的LSA LSAck报文：链路状态确认报文，对收到的LSA进行确认 OSPF邻居建立维护与状态机邻居建立与维护： 组播发送Hello报文（.5），双方协商参数，若验证、区域等都相同，则表示邻居发现 邻居周期交换Hello报文，若邻居失效时间超时未收到Hello则认为邻居失效，将该邻居从邻居表中删除 DR/BDR选举：目的：减少邻接关系的数量，所有路由信息都发给DR（指定路由器），再由DR发LSA若不设置DR/BDR，则邻接关系数量R=n(n-1)/2个若设置DR/BDR，则邻接关系数量R=2(n-2)+1个 BDR是DR的备份。若DR失效，BDR立刻成为DR。DR/BDR选举原则： 首先比较Hello报文中的优先级，最高的为DR，次高的为BDR，若为0不参加选举。 优先级相同则比较RouterID，大的优 选举完毕后，即使有更优的路由器加入区域，也不会更换DR/BDR（可以在用户视图重置ospf进程，使ospf重新选举） 只有广播和NBMA网络选举DR/BDR 剩余路由器成为DRother，只与DR、BDR建立邻接关系 邻接关系建立： 初始状态，A的邻居为Down，由于邻居表为空，所以DR字段置为0.0.0.0，发送Hello报文，B收到Hello报文后，将A添加进邻居表中，邻居状态变为Init，两个路由器比较RouterID，大的（假设A）会在后面的Hello报文中将DR字段设为自己的RouterID。 B收到Hello报文，发现邻居表中有自己的RouterID，于是将邻居表中A状态变为2-way。B也收到后，同理。若当前两台路由器都是DRother，则邻接状态就会维持在2-way。只有其中一个是DR或BDR，才会继续建立关系 若进一步建立邻接关系，A会将B状态设为ExStart，并发送一个不包含LSA的DD报文，开始主从协商。其中DD报文包含MS位，最开始该MS位置1，表示路由器以自己为Master。Master路由器的作用就是在交换DD报文时，主动发送DD报文，并控制报文的序列号。Slave路由器仅能接受Master指定的序列号并被动发送DD。 B收到DD后，将发送方的状态设为ExStart。对比RouterID，若大（假设A）就在DD报文中将MS位也置为1，表明自己是Master，并回复。B收到DD报文后，同意A为Master，将MS位置0，表明自身Slave，采用A规定的序列号向A发DD报文，此时DD报文中包含LSA摘要，A收到后将B状态改为Exchange。B收到A的DD报文后也将A状态改为Exchange。 A与B都对DD报文的LSA与LSDB进行比对，若LSA信息在LSDB中都存在，就直接进入Full状态。若一方LSDB不完全包含LSA，则向另一方请求，并将对方状态置为Loading，发送LSR。另一方收到后根据LSR返回LSU。再次比对后相同就进入Full。 OSPF状态机其中有三个稳定状态：Down、2-way、Full down：未启动ospf init：收到对方hello包，但hello包中的邻居表没有自己 2-way：收到对方hello包，且在hello包中看到自己 exstart：互相发送空的DD协商主从报文，以决定谁发DD报文 exchange：交换真正的DD报文 loading：交互路由信息 full：路由学习完毕，邻接关系建立 影响OSPF建立邻接关系的因素： area是否一致 接口是否开启OSPF 接口是否开启验证 是否启用了静默接口，或开启过滤 是否处于特殊区域 Hello/Dead定时器是否一致 Router-id是否不同 链路两端接口掩码是否不同（广播类型链路hello会携带掩码信息） 两端MTU是否不同（若不同会一直在Exstart状态） 链路状态广播LSALSA老化时间3600s（1小时），每1800s（半小时）ospf就会泛洪一次全部路由信息 报文字段： LS age：LSA产生后经过的时间（单位秒） LS type：LSA类型（1-11） Link State ID：LSA链路ID，根据LSA类型而定 Advertising Router：始发LSA的路由器ID，也称LSA通告路由器LS type、Link State ID、Advertising Router三个参数唯一标识一个LSA LSA sequence number：LSA序列号，用于判断是否是最新的LSA LS checksum：LSA信息的校验和 length：LSA总长度 LSDB更新过程：收到一条LSA更新报文，在LSDB中查找该LSA，若未找到就将这条LSA加入LSDB，若找到，就对比LSA的序列号，若该条的大，就更新，否则不更新。 LSA类型： 一类：Router LSA，描述区域内部与路由器直连的链路信息，所有OSPF路由器始发，仅在区域内传播。不携带掩码信息 二类：Network LSA，记录广播或NBMA上所有路由器RouterID，DR始发，仅在区域内传播。携带网段掩码信息，和一类LSA共同计算网段一类和二类LSA解决了区域内部的通信 三类：Network Summary LSA，包含区域网段与开销，传播给相邻区域，ABR始发，区域间传播。实际就是收集一类和二类的LSA。每个三类LSA包含一个网段一、二、三类LSA解决了区域内和区域间通信 四类：ASBR Summary LSA，描述ASBR的RouterID和开销，传播给非ASBR区域，ABR始发。辅助五类LSA，实现到达ASBR。告诉OSPF内部路由器如何到达ASBR 五类：AS External LSA，描述到AS外部的路由，包含外部网段、开销等，传播给整个OSPF系统，ASBR始发。每个五类LSA包含一个网段。 七类：NSSA Exteranl LSA，只在NSSA中传播，描述到AS外部的路由，ASBR始发 路由聚合：ABR和ASBR可将具有相同前缀的路由聚合发布。 安全： 协议报文验证：通过验证的OSPF报文才能被接收（路由器+接口都要配置验证：Simple或MD5） 禁止端口发送OSPF报文：该端口成为被动端口（静默），不再发送Hello报文 过滤计算出的路由：通过过滤规则的路由才加入路由表 过滤三类LSA：设置规则过滤外部路由（本地有效） OSPF特殊区域OSPF特殊区域： Stub：不允许注入四、五类LSA。不能存在ASBR。虚连接不可穿过。若有多个ABR可能产生次优路由 Totally Stub：不允许注入三、四、五类LSA。虚连接不可穿过。ABR会产生一条0.0.0.0/0的三类LSA NSSA：不允许四、五类LSA，允许七类LSA。虚连接不可穿过。该区域存在一个ASBR，该区域不希望接收其他ASBR的外部路由。七类默认路由LSA由ASBR产生，在NSSA中传播，当到达ABR时，会转换为五类LSA传到别的区域。Totally STub和NSSA都是Stub的变形或改进 Totally NSSA：不允许注入三、四、五类LSA，而是用七类默认路由取代。虚连接不可穿过。]]></content>
      <tags>
        <tag>网络</tag>
        <tag>OSPF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BGP学习笔记]]></title>
    <url>%2F2018%2F07%2F31%2FBGP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于华三网络学习笔记（理论） 本篇包含以下内容 BGP特性与基本术语 BGP消息与状态机 BGP路由属性 BGP选路规则 BGP特性与基本术语Border Gateway Protocol边界网关协议。用于自治系统间，进行不同AS间路由传递。 路径矢量路由协议 基于TCP，端口号179 EGP协议，优先级255 支持路由聚合与CIDR 只发送增量路由 路由信息中携带经过的所有AS路径表 支持CIDR和路由聚合 丰富的路由属性、强大的路由过滤和路由策略 可传输大量路由（基于TCP的可靠传输和滑动窗口） 只能点对点连接（TCP的点对点） 基本术语 BGP发言者：发送BGP消息的路由器 Router ID：32位，在AS中唯一标识一台主机，必须配置 BGP对等体Peer：相互交换消息的BGP发言者互为对等体，也可称BGP邻居。 IBGP对等体：处于同一AS的对等体，不需要直连从IBGP获得的路由不会向其他IBGP邻居发布（为了防环）从IBGP获得的路由是否发个EBGP邻居与是否同步有关（为了防止路由黑洞）全连接：为解决部分连接导致的无法学习路由，每两个路由器都建立IBGP邻居则可以保持AS内的所有BGP路由器路由信息相同 EBGP对等体：处于不同AS的对等体，且通常要求直连从EBGP获得的路由会发布给所有IBGP邻居EBGP的TTL=1，所以只能是直连对端接口，不可跨设备（可修改TTL实现跨设备）而IBGP的TTL=255可与AS内任意BGP路由器建邻居 BGP防环： 对于EBGP：使用AS-PATH 对于IBGP：禁止将从IBGP邻居学到的路由发布出去。缺点：有路由器学不到路由。解决：全连接 BGP同步：IBGP与IGP之间同步，避免转发黑洞。收到IBGP邻居发布的路由后，会查看该路由是否在IGP表中，只有IGP表中存在，才会置为有效并发布，否则无效不发布。路由器默认关闭同步。 BGP消息与状态机BGP所有消息都是消息头+消息体，消息头长度19字节，包含以下字段： Marker：16字节，用于BGP验证的计算，不使用验证时所有位都置为1 Length：2字节，BGP消息总长度（包括报文头） Type：1字节，BGP消息的类型，取值为1到5，分别表示Open、Update、Notification、Keepalive、Route-Refresh BGP消息种类： Open：用于建立BGP邻居。TCP连接后的第一个消息，进行参数协商。包含以下字段： BGP版本 AS号 routerID Hold Time：保存时间，若超时仍未收到对端的Keepalive或Update消息，则认为BGP连接中断。建立对等体时要协商该参数并保持一致 认证信息或多协议扩展等功能 Update：在邻居间交换路由信息（发布或撤销）。可通告一类相同属性的可达路由和不可达路由。包含以下字段： 不可达路由字段长度。单位字节，若为0表示没有Withdrawn Routes Withdrawn Routes不可达路由列表，即存放被撤销的路由 路径属性字段长度。单位字节，若为0表示没有Path Attibutes Path Attibutes，存放与NLRI相关的所有路径属性列表，每个路径属性由一个TLV三元组构成。 NLRI可达路由的前缀和前缀长度二元组，存放一类相同属性的可达路由 Notification：错误通知（消息错误或断开BGP连接）。包含以下字段： 差错码，指定错误类型 差错字码，提示错误类型的详细信息 数据，出错部分的数据。用于辅助发现错误的原因，依赖于差错码和差错子码 Keepalive：维护邻居关系或对Open消息回应。只有消息头。周期发送，默认周期30s。 Route-refresh：要求对等体重新发送指定地址族的路由 BGP状态机： Idle：空闲。初始状态，等待Start事件。一旦有Start，就向邻居发起TCP建立请求 Connect：连接。等待TCP建立完成。若TCP完成，状态改为Open-sent。若失败，状态改为Active。 Active：活跃。TCP未成功建立。若超时，会返回Connect。若成功，进入Open-sent状态。 Open-sent：Open消息已发送。已发出Open消息，等待邻居的Open消息。若收到邻居的Open消息且无错误，进入OpenConfirm状态，并发送Keepalive。否则，进入Notification。 OpenConfirm：Open消息已确认。Keepalive已发送，等待邻居的Keepalive。若收到邻居的Keepalive，则进入Established状态。若收到Notification，则断开连接 Established：BGP连接建立。可发送Update交换路由，发送Keepalive维护连接，若收到Notification则断开连接 BGP路由属性 公认必遵属性：BGP路由器必须识别，必须存在于Update ORIGIN：定义路由信息来源类型：IGP–路由产生于AS内 EGP–路由通过EGP学到 Incomplete–路由来源不确定优先级：IGP&gt;EGP&gt;Incomplete AS_PATH：路由更新经过的AS路径列表，保证AS间无环。可用于路由选择和过滤当BGP将一条路由通告到其他AS时，会把本地AS号添加到AS-PATH最前优先选择AS-PATH最短的路由。若向EBGP邻居发送路由更新修改，IBGP间不修改 NEXT_HOP：路由下一跳向邻居发布路由时，会将下一跳设为自己与对端连接的端口从EBGP邻居得到的路由发给IBGP邻居时，不会修改下一跳 公认可选属性：BGP路由器必须识别，不必须存在于Update LOCAL_PREF：用于IBGP选择离开AS时的路由，表明BGP路由器的优先级仅在IBGP对等体间交换。默认值100 可选传递属性：在AS间可传递，路由器可不支持，仍可接收并通告 COMMUNITY AGGREGATOR 可选非传递属性：若BGP路由器不支持，属性会被忽略，且不通告 MED：度量值。告诉EBGP邻居进入AS的路由。仅在相邻AS间交换，收到MED的AS不会再通告给其他AS通常只比较来自同一AS的MED 私有BGP属性： Preferred-value：对从邻居学习到的路由分配优先级本地有效，不通告。初始为0 对于BGP路由处理： 接收BGP路由 路由过滤、属性设置 路由优选 发布策略 发布路由过滤、属性设置、路由聚合 BGP选路规则路由选路优先级（高到低）： 丢弃下一跳不可达的路由 Preferred-value选大 LOCAL_PREF选大 聚合路由，本地路由 AS_PATH选小 ORIGIN按优先级选 MED选小 依次选从EBGP、联盟、IBGP学到的路由 下一跳度量值最低 CLUSTER_LIST选短 ORIGINATOR_ID最小 RouterID最小路由器发布的路由 地址最小的邻居发布的路由 BGP一定能选出唯一的最优路由，且可以负载分担路由下一跳不一定是直连邻居，原因：IBGP发布路由不改变下一跳。路由器会查找直连可达地址，到达要发布路由的下一跳（去往该下一跳的路由为依赖路由，过程为路由迭代）。路由器支持基于迭代的负载分担。 BGP路由发布策略： 只发布最优路由 只发布自己使用的路由 发布所有从EBGP邻居学到的路由给所有BGP邻居（IBGP和EBGP） 不把从IBGP邻居学到的路由发布给IBGP邻居 IBGP路由发到EBGP：BGP同步关–直接发布。BGP同步开–IGP也发布时才发布 BGP连接建立后，发布所有BGP路由 BGP下一跳原则：若从EBGP邻居学到的路由传给IBGP邻居时下一跳不变，可能会导致BGP设备因为下一跳不可达而不加入路由表。解决：应在EBGP路由传给IBGP邻居时将下一跳改为自身 BGP路由不优的原因：1.同步打开，但网络不满足同步要求 2.下一跳不可达 BGP源IP地址原则：BGP设备收到一个BGP报文，会检查报文源IP地址，若与peer所指IP地址一致，则设备接收该报文，若不一致，则丢弃报文，在建环回口建立BGP关系时，要修改BGP报文源 默认情况，BGP使用到达对等体的最佳路由作为出接口作为与对等体建TCP连接的源接口将建立TCP的源接口配置为环回口，在网络中存在冗余链路时不会因为某个接口或链路故障而使BGP，提高了可靠性和稳定性 控制BGP路由常用属性：preferred-value、Local-preference、MED、next-hop-local路由首选值Preferred-value：优选大的。默认从对等体学来的路由首选值为0本地优先级Local-preference：判断离开AS的最佳路由AS路径过滤表AS_PATH list：一个基于AS表的ACL，使用正则表达式对路由携带的AS路径属性域进行匹配 正则表达式： ^ 匹配字符串的开始 $ 匹配字符串的结束 * 匹配*前的字符（串）0或多次 + 匹配+前的字符（串）1或多次 . 通配符，匹配任何一个字符 _ 下划线，匹配一个符号 - 连接符，连接两个字母或数值 ( ) 字符组，一般与-连用 [ ] 匹配[ ]中任意一个字符 常用正则组合： ^$只匹配本地路由 .*匹配所有路由 ^100匹配AS100、1001等邻居的路由 ^100_只匹配AS100邻居发的路由 _100$匹配AS100始发的路由 _100_匹配经过AS100的路由 BGP补充知识点BGP对等体组peer group：具有某些相同属性的对等体集合，可分为IBGP或EBGP对等体组 BGP团体属性：一组具有相同特征目的地址的集合，与所在AS无关，一条路由可以有多个团体属性。 公认团体属性INTERNET：有这一属性的路由可以被通告给所有对等体。路由缺省属于该团体NO_EXPORT：该团体路由不能被发布到本地AS外，若使用联盟，不能发布到联盟外NO_ADVERTISE：不能被通告任何BGP对等体NO_EXPORT_SUBCONFED：不能被发布到任何其他AS BGP聚合两种聚合：手动、自动自动：聚合为自然路由。只能引入IGP子网路由聚合，不能对BGP邻居学来的或network发布的路由进行聚合。手动：手动配置灵活的聚合，可以对从BGP邻居学习的、引入IGP的、network生成的路由聚合 BGP反射作用：可代替IBGP对等体全连接原理：允许设备从IBGP对等体接收到的路由信息发布给特定IBGP对等体，这些网络设备称为路由反射器。]]></content>
      <tags>
        <tag>BGP</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Compose学习笔记]]></title>
    <url>%2F2018%2F07%2F30%2FDocker-Compose%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[环境：docker：18.06.1，docker-compose：1.22.0 docker18.06对应的Compose文件格式版本为3.7 本篇包含以下内容： docker-compose介绍 Compose文件格式 docker-compose示例 docker-compose介绍Docker Compose是一个编排多容器分布式部署的工具，提供命令集管理容器化应用的完整开发周期，包括服务构建，启动和停止。在配置文件中，所有的容器通过services来定义，然后使用docker-compose脚本来启动，停止和重启应用，和应用中的服务以及所有依赖服务的容器。 Compose的特性 通过项目名称将单个主机隔离成多个环境，能将应用环境复制多份，还能防止使用相同名称的服务的应用间的干扰 能够保护卷中的数据，如果Compose发现存在之前运行过的容器，它会把旧容器中的数据卷拷贝到新的容器中 只会重新创建改变过的容器，Compose会缓存用于创建容器的配置信息，当你重启服务时，如果服务没有被更改，Compose就会重用已经存在的容器，加快了修改应用的速度 编排：Orchestration，根据被部署的对象间的耦合关系以及被部署对象对环境的依赖，制定部署流程中各个动作的执行顺序，部署过程中所需要的依赖文件和被部署文件的存储位置和获取方式，以及如何验证部署成功。这些信息都会在编排工具中以制定格式定义并保存。 部署：Deployment，按照编排所指定的内容和流程，在目标机器上执行编排指定环境初始化，存放指定的依赖和文件，运行指定的部署动作，按照编排中规则确认是否部署成功。 以上编排和部署定义摘选自《docker容器与容器云》 docker-compose安装 使用pip快速安装pip install docker-compose docker-compose参数选项： 12345678910111213141516docker-compose [-f &lt;arg&gt;...] [options] [COMMAND] [ARGS...] -f, --file FILE 指定compose文件，默认为docker-compose.yml -p, --project-name NAME 指定项目名，默认为所在目录名 --verbose 显示详细过程信息 --log-level LEVEL 设置日志级别(DEBUG, INFO, WARNING, ERROR, CRITICAL) --no-ansi 不打印ANSI控制字符 -H, --host HOST 指定要连接的主机 --tls 使用tls，就是指--tlsverify --tlscacert CA_PATH 指定只承认该CA颁发的证书 --tlscert CLIENT_CERT_PATH TLS证书路径 --tlskey TLS_KEY_PATH TLS密钥路径 --tlsverify 使用TLS --skip-hostname-check 不根据客户端证书中指定的名称检查守护程序的主机名 --project-directory PATH 指定工作目录，默认为compose文件所在目录 --compatibility Compose将尝试将v3文件中的部署密钥转换为其非Swarm等效项 docker-compose命令： build：构建或重构服务（services） 1234567build [options] [--build-arg key=val...] [SERVICE...] --compress 使用gzip压缩构建上下文 --force-rm 始终移除中间容器 --no-cache 构建镜像时不使用缓存 --pull 总是尝试拉取最新镜像 -m, --memory MEM 设置构建镜像的内存上限 --build-arg key=val 设置服务的构建时变量 bundle：从Compose文件生成Docker包 镜像必须存储摘要，这需要与Docker Registry进行交互。如果没有为所有镜像存储摘要，可以使用docker-compose pull或docker-compose push来获取。 123bundle [options] --push-images 在打包时自动推送已使用build指定的服务的镜像 -o, --output PATH 包文件路径，默认为&quot;项目名.dab&quot; config：校验并查看compose文件 12345config [options] --resolve-image-digests 将镜像标签写入摘要 -q, --quiet 静默模式，只校验配置，不打印信息 --services 列出所有服务 --volumes 列出所有数据卷 down：停止并删除容器、网络、镜像、数据卷 默认能删除的内容： Compose文件中定义的服务的容器 Compose文件的networks中定义的网络 默认网络（如果使用） 1234567down [options] --rmi type 删除镜像，必须指定类型： &apos;all&apos;: 删除任何服务使用的所有镜像 &apos;local&apos;: 只删除没有通过image指定自定义标签的镜像 -v, --volumes 删除在Compose文件的&quot;volumes&quot;中声明的命名卷和附加到容器的匿名卷。 --remove-orphans 为服务删除没有在compose文件中声明的容器 -t, --timeout TIMEOUT 指定几秒后关闭（默认10s） events：从容器接收实时事件 12events [options] [SERVICE...] --json 使用json格式输出事件 exec：在运行的容器中执行命令 12345678exec [options] [-e KEY=VAL...] SERVICE COMMAND [ARGS...] -d, --detach 后台运行命令 --privileged 给进程额外的权限 -u, --user USER 指定运行命令的用户 -T 禁止分配伪终端，exec默认分配一个伪终端 --index=index 设置容器的索引（如果一个服务有多个容器），默认为1 -e, --env KEY=VAL 设置环境变量 -w, --workdir DIR 设置工作目录 images：列出镜像 12images [options] [SERVICE...] -q, --quiet 静默模式，只显示镜像号 kill：杀死容器 12kill [options] [SERVICE...] -s SIGNAL 发送给容器的SIGNAL，默认为SIGKILL logs：显示容器的输出 12345logs [options] [SERVICE...] --no-color 单色输出 -f, --follow 按照日志输出 -t, --timestamps 显示时间戳 --tail=&quot;all&quot; 显示日志的末尾行数 pause：暂停服务 1pause [SERVICE...] ps：列出容器，执行此命令时必须cd到项目的根目录下 1234ps [options] [SERVICE...] -q, --quiet 静默，只显示容器号 --services 显示服务 --filter KEY=VAL 根据属性过滤服务 port：显示用于绑定的公共端口 123port [options] SERVICE PRIVATE_PORT --protocol=proto 选择协议，tcp或udp，默认tcp --index=index 设置容器的索引，默认为1 pull：拉取服务镜像 123456pull [options] [SERVICE...] --ignore-pull-failures 忽略拉取失败的镜像 --parallel 并行拉取多个镜像，默认开启，官方不推荐 --no-parallel 禁止并行拉取多个镜像 -q, --quiet 静默模式，不显示拉取信息 --include-deps 同时拉取依赖的服务 push：推送服务镜像 12push [options] [SERVICE...] --ignore-push-failures 忽略推送失败的镜像 restart：重启服务 12restart [options] [SERVICE...] -t, --timeout TIMEOUT 指定几秒后重启（默认10s） rm：删除停止的容器 1234rm [options] [SERVICE...] -f, --force 不询问确认删除 -s, --stop 在删除前自动停止容器 -v 删除任何关联的匿名数据卷，默认不会删除 run：运行一次性命令 123456789101112131415run [options] [-v VOLUME...] [-p PORT...] [-e KEY=VAL...] [-l KEY=VALUE...] SERVICE [COMMAND] [ARGS...] -d, --detach 后台运行 --name NAME 设置容器名 --entrypoint CMD 覆盖容器的ENTRYPOINT -e KEY=VAL 设置环境变量 -l, --label KEY=VAL 添加或覆盖标签 -u, --user=&quot;&quot; 以指定用户执行，可设置用户名或uid --no-deps 不启动相连的服务，默认依赖的服务也会启动 --rm 在运行后删除容器，不与-d兼容 -p, --publish=[] 发布公共端口 --service-ports 通过已启用并映射到主机的端口执行命令 --use-aliases 在容器连接的网络中使用服务的网络别名 -v, --volume=[] Bind mount挂载一个数据卷 -T 禁止分配伪终端（tty），默认run会分配一个 -w, --workdir=&quot;&quot; 容器中的工作目录 start：启动已存在的容器 1start [SERVICE...] stop：停止运行中的容器，并不会删除它们 12stop [options] [SERVICE...] -t, --timeout TIMEOUT 指定几秒后关闭（默认10s） top：显示服务的进程 1top [SERVICE...] unpause：恢复暂停的服务 1unpause [SERVICE...] up：创建并启动容器 默认会启动相连的服务。 1234567891011121314151617up [options] [--scale SERVICE=NUM...] [SERVICE...] -d, --detach 后台运行。与--abort-on-container-exit不兼容 --no-color 单色输出 --quiet-pull 静默拉取 --no-deps 不启动连接的服务 --force-recreate 强制重建服务（即使配置和镜像都没变） --always-recreate-deps 重建依赖的服务，与--no-recreate不兼容 --no-recreate 若容器存在就不会重建，与--force-recreate和-V不兼容 --no-build 即使镜像丢失也不重建镜像 --no-start 在构建服务后不启动该服务 --build 在启动容器前先构建镜像 --abort-on-container-exit 如果任何容器停止，就停止所有容器，与-d不兼容 -t, --timeout TIMEOUT 设置容器几秒后关闭（默认10s） -V, --renew-anon-volumes 重建匿名卷而不是从以前的容器中恢复数据。 --remove-orphans 删除服务的compose文件中未定义的容器 --exit-code-from SERVICE 返回指定服务的退出码 Implies --abort-on-container-exit. --scale SERVICE=NUM 将SERVICE扩展到NUM个实例。会覆盖Compose文件中的&quot;scale&quot;设置（如果存在） Compose文件格式Compose文件采用YAML语法，文件名以.yml或.yaml结尾，默认应存放在项目的根目录中，文件名应为docker-compose.yml。在Compose文件中无需再指定Dockerfile中已定义的项。 文件格式为3.7，所以compose文件最开始要写上version: &quot;3&quot; 然后定义服务services，在services:下添加服务，开始对服务的配置。 build：用于指定在构建时应用的配置选项。 context：用于指定构建上下文。 dockerfile：用于指定Dockerfile文件 args：用于给Dockerfile文件中ARG定义的参数传参 123456789101112131415161718192021version: &quot;3&quot;services: webapp: build: ./dir 可以这样直接指定上下文路径 webapp: build: 也可以作为具有在上下文中指定的路径的对象 context: ./dir 然后通过context指定上下文路径 当提供的值是相对路径时，context被解释为相对于Compose文件的位置。此目录也是发送到Docker daemon的构建上下文 build: context: . dockerfile: webapp.dockerfile 还可以指定Dockerfile文件 args: 可以为Dockerfile文件传参 args1: 123 args2: 345 也可以这样表示： args: - args1=123 - args2=345 image: webapp:tag 可以指定构建镜像，会生成一个名为webapp，并打上tag标签的镜像 在群集模式下使用Compose文件（版本3）部署堆栈时，将忽略image选项。 docker stack命令仅接受预先构建的图像。 注：YAML布尔值（true，false，yes，no，on，off）必须用引号括起来，以便解析器将它们解释为字符串。 cache_from：指定Docker引擎用于实现缓存的镜像列表 labels：使用标签将元数据添加到生成的镜像中，可使用数组或字典 shm_size：为构建的容器设置/dev/shm分区的大小，指定字节数或字节值字符串，如2mb或2000000 target：根据Dockerfile中的定义构建指定的阶段 123build: context: . target: prod cap_add和cap_drop：添加或删除容器功能 123456cap_add: - ALLcap_drop: - NET_ADMIN - SYS_ADMIN command：覆盖容器启动后默认执行的命令 123command: bundle exec thin -p 3000或使用列表表示：command: [&quot;bundle&quot;, &quot;exec&quot;, &quot;thin&quot;, &quot;-p&quot;, &quot;3000&quot;] container_name：自定义该容器名称。由于Docker容器名称必须是唯一的，因此如果指定了自定义名称，则无法将服务扩展到多个容器 volumes：卷挂载路径设置。格式：宿主机源路径:容器目的路径[:访问权限]，默认访问权限为读写。可使用相对路径，相对于compose文件所在目录。 links：链接到另一个服务中的容器，格式：服务名[:别名] external-links：链接到docker-compose.yml外部的容器，甚至并非 Compose 管理的容器。 expose：暴露端口，但不映射到宿主机，只被连接的服务访问。最好使用字符串表示数字，因为YAML会解析xx:yy这种数字格式为 60 进制，容器端口小于 60 可能出错。 ports：暴露端口信息，格式：[宿主机IP:][端口:]容器端口，可用-表示一个端口范围 docker-compose示例首先是docker-compose官方文档中的示例： 12 参考文章 Docker三剑客之Compose-一 Docker三剑客之Compose-二 Docker三剑客之Compose-三 docker-compose教程（安装，使用, 快速入门） docker-compose官方文档 Docker系列之（五）：使用Docker Compose编排容器]]></content>
      <tags>
        <tag>docker</tag>
        <tag>docker-compose</tag>
        <tag>云计算</tag>
        <tag>容器编排</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes学习笔记-1]]></title>
    <url>%2F2018%2F07%2F13%2FKubernetes%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <tags>
        <tag>云计算</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker存储学习笔记-1]]></title>
    <url>%2F2018%2F07%2F06%2FDocker%E5%AD%98%E5%82%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[主要是对docker文档(v18.03)的翻译以及自己的学习笔记本篇主要包含以下内容 Docker存储介绍 BindMount Volume数据卷 数据卷容器 Docker存储介绍Docker为容器提供了两种存放数据的资源： storage driver：管理的镜像层和容器层 特点：Copy-on-Write。新数据会存放在最上层容器层，修改现有数据会先从镜像层复制到容器层，修改后的数据直接保存在容器中，镜像层保持不变。若多层中有同名文件，用户只能看到最上层的文件。 可通过docker info查看到。Docker优先使用默认的storage driver。 data volume数据卷 特点：是目录或文件，不是磁盘，volume数据可以被永久的保存，即使使用它的容器已经销毁。 分为两种volume：bind mount 和docker managed volume 存储驱动：目前docker支持五种存储驱动。详见存储引擎 AUFS Btrfs Device Mapper Overlay ZFS 原理： Copy-On-Write写时复制 所有驱动都是用到Cow写时复制（copy-on-write），只在需要写时才复制。可以让所有容器都共享一个image文件系统，所有数据都从image读取，容器需要写操作时，才将要写的文件从image复制到自己的文件系统，即所有写操作都是对image中副本的修改。有效提高了磁盘利用率。 allocate-on-demand用时分配 在要写入一个文件时才按需分配空间 驱动： AUFS：一种Union FS联合文件系统，文件级存储。支持将不同目录挂载到同一个虚拟文件系统，下层文件系统只可读，最上层可写。若要修改，AUFS会创建一个该文件的副本，放在可写层，结果也保存在可写层。 Overlay：一种UnionFS，文件级存储。只有两层：upper层和lower层 Device Mapper：RHEL下Docker Engine的默认存储驱动，基于同名级卷管理技术框架的存储引擎。 默认情况下，在容器内创建的所有文件都存储在可写容器层中，仅存储在主机系统的内存中，即tmpfs方式，永远不会写入主机系统的文件系统，因此一旦容器停止，容器内所有文件的改动都会丢失，所以需要通过一些机制将文件保存以至于在容易停止后仍不会丢失。 docker有三种存储容器数据的方式： bind mount：可将容器数据存放在宿主机的任何位置。 volumes：通过创建数据卷将容器数据持久化到文件系统。 tmpfs：数据存放在内存中，不会写入文件系统。 BindMountbind mount可使容器中的文件存储在主机系统的任何位置。Docker主机或Docker容器上的非Docker进程可以随时修改它们。bind mount非常高效，但它们依赖于具有特定目录结构的主机文件系统。 docker提供两种选项进行bind mount。 -v或--volume：三个字段组成，冒号分隔。 第一个字段：卷名，若是匿名卷，则可省略 第二个字段：文件或目录在容器中安装的路径 第三个字段：可选项，例如ro，默认是可读可写 --mount：由多个键值对组成，用逗号分隔，键和值用=连接。以下是提供的键： type：挂载的类型，可以是bind，volume或tmpfs。 source或src：挂载源，即卷名。匿名卷可省略。 destination或dst或target：挂载到的容器中的指定目录或文件路径 readonly：以只读方式挂载，可选。 volume-opt：卷选项，可指定多次，也是键值对形式 bind-propagation：绑定传播，有以下选择：rprivate，private，rshared，shared，rslave，slave注：–mount不支持设置selinux的z或Z选项 如果使用-v或--volume绑定安装Docker主机上尚不存在的文件或目录，则-v会为您创建端点。它始终作为目录创建。而如果使用--mount，Docker不会自动为您创建它，但会生成错误。 注：bind mount允许访问敏感文件使用bind mount的一个副作用：可以通过容器中运行的进程更改主机文件系统，包括创建，修改或删除重要的系统文件或目录。这是一种强大的功能，可能会产生安全隐患，包括影响主机系统上的非Docker进程。 当挂载一个bind mount或非空数据卷到容器中的一个非空目录，则该目录中原有的文件会被掩盖（并非删除），而只显示挂载的卷内容。当挂载一个空数据卷到容器中的一个非空目录，则该目录中的文件都会复制到该卷中。若启动容器时指定了一个不存在的数据卷，则会自动创建一个卷。 123456使用-v挂载docker run -v &lt;源目录或文件&gt;:&lt;容器中目录或文件&gt;# 路径都需要绝对路径# 若添加单个文件，主机源文件必须存在，否则会当做一个新目录挂载到容器使用--mount挂载docker run --mount type=bind,src=&lt;源目录或文件&gt;,dst=&lt;容器目录或文件&gt; docker inspect 容器查看是否挂载了数据卷 bind-propagation传播挂载在指定的bind mount或数据卷上挂载是否能被复制到挂载的目录中去。用于做动态，可通过编排工具方便实现。 有以下几种选项： shared：源挂载的子挂载会暴露给副本挂载，副本挂载的子挂载也会复制到源挂载。 slave：类似于shared，但只在一个方向上。如果源挂载暴露了子挂载，则副本挂载可以看到它。但是，如果副本挂载暴露了子挂载，则源装载无法看到它。 private：此挂载是私人的。其中的子挂载不会暴露给副本挂载，副本挂载的子挂载不会暴露给源挂载。 rshared：与shared相同，但传播也扩展到嵌套在任何源或副本挂载中的挂载点。 rslave：与slave相同，但传播也扩展到嵌套在任何源或副本挂载中的挂载点。 rprivate：默认值。与private相同，源或副本挂载中任何位置的挂载点都不会沿任一方向传播。 Selinux标签如果使用selinux，则可以添加z或Z选项以修改要挂载到容器的主机文件或目录的selinux标签。这会影响主机本身上的文件或目录，并且可能会影响到Docker外部。 z选项表示绑定装载内容在多个容器之间共享。 Z选项表示绑定装载内容是私有且非共享的。使用Z选项绑定安装系统目录（例如/home或/usr）会导致主机无法运行。 当bind mount和service一起使用时，会自动忽略selinux标签（z和Z）还有ro。 Volume数据卷卷是保存Docker容器生成和使用的数据的首选机制，并且卷完全由Docker管理。写入容器的可写层需要存储驱动程序来管理文件系统，存储驱动程序使用Linux内核提供联合文件系统UFS。而数据卷是经过特殊设计的目录，可以绕过联合文件系统，为多个容器提供访问。数据卷的目的在于数据永久化，完全独立于容器的生存周期，容器删除时挂载的数据卷不会被删除。 特点： 卷比bind mount更容易备份或迁移。 卷适用于Linux和Windows容器。 可以在多个容器之间更安全地共享卷。 在容器启动时初始化，若挂载点已有数据，则会被拷贝到新初始化的数据卷中 数据卷变化不会影响镜像更新 卷驱动程序允许在远程主机或云提供程序上存储卷，加密卷的内容或添加其他功能。 可通过docker volume create 数据卷名创建数据卷。每创建一个volume，就会在/var/lib/docker/volumes中创建一个同名目录。若不指定数据卷名，就会随机生成一个volume ID作为数据卷名。 docker volume命令12345create 创建数据卷inspect 查看数据卷信息ls 查看所有数据卷prune 删除未使用的数据卷rm 删除指定数据卷 在创建volume时或启动使用为创建卷的容器时，可以指定卷的驱动。数据卷驱动可通过docker plugin install [选项] 驱动名。如果卷驱动程序要求您传递选项，则必须使用--mount标志来装入卷 docker提供-v和--mount选项进行挂载。使用与bind mount基本一致。如果需要指定卷驱动程序选项，则必须使用--mount。将卷与服务一起使用时，仅支持--mount。 注：挂载数据卷不支持单个文件，只能是目录。且不权限控制，均为可读写。因为容器配置文件里的可以指定docker inspect查看，发现Mounts中的Source字段，其中已指定了源，源为：/var/lib/docker/volumes/容器长ID/_data。 以上两种方法数据源其实还是宿主机中的，并不是真正放在volume container中，可以在通过dockerfile的ADD将数据打包进镜像并指定VOLUME，将ADD指定的目录与VOLUME设为一致，此法称为data-packed volume container。 Tmpfs使用tmpfs mount创建容器时，容器可以在容器的可写层之外创建文件。tmpfs挂载是临时的，仅保留在主机内存中。当容器停止时，将删除tmpfs挂载，该数据不可被共享，Docker默认使用tmpfs挂载。--tmpfs：安装tmpfs挂载而不允许指定任何可配置选项，并且只能与独立容器一起使用。也可以通过--mount指定type=tmpfs。 数据卷容器容器挂载数据卷，其他容器通过挂载该容器实现数据共享，挂载数据卷的容器称为数据卷容器。 创建容器时--volumes-from 数据卷容器创建数据卷容器注：由于数据卷容器仅是提供数据，所以只要create，不用rundocker rm -v 容器 在删除容器时一并删除数据卷。但是，只要有容器还在使用该数据卷，数据卷就不会删除。宿主机上的数据卷若删除，就真的没了。 123456789101112131415161718&gt; docker volume create volume_1&gt; docker volume create volume_2# 创建数据卷容器，挂载volume_1，volume_2&gt; docker create \ -v volume_1:/volume1 \ -v volume_2:/volume2 \ --name vol_container \ alpine# 创建容器挂载数据卷容器&gt; docker run -it \ --volumes-from vol_container \ --name test \ alpine/ # lsbin home mnt run sys vardev lib proc sbin tmp volume1etc media root srv usr volume2# 数据卷容器中挂载的数据卷也被挂载到新容器的根目录了，也可通过-v设置挂载点 数据卷备份、还原与迁移使用数据卷能方便地进行数据备份、迁移和还原。 备份一个容器首先创建一个数据卷，用于存放备份数据。docker volume create vol_backup然后创建一个数据卷容器，挂载该数据卷123docker create --name backup_container\ -v vol_backup:/backup \ alpine 接着运行要备份容器，挂载数据卷容器backup_container，并将要备份的数据打包放入数据卷。1234docker run --rm \ --volumes-from backup_container \ -v /backup \ alpine tar -cvf /backup/data.tar /usr /var 在主机的/var/lib/docker/volumes/vol_backup/_data/中出现了打包后的data.tar 还原一个容器12345docker run --rm \ --volumes-from backup_container \ -v /backup \ alpine \ bash -c &quot;cd /dbdata &amp;&amp; tar xvf /backup/data.tar --strip 1&quot; 删除一个数据卷删除的数据卷有两种情况： 命名卷在容器外部有指定源，删除了容器，数据卷并不会被删除 匿名卷没有指定源，在删除容器时，该匿名卷也会被删除。也可在创建容器时，加上--rm参数，关闭时自动删除容器和匿名卷。 存储引擎参考资料Docker官方文档-存储每天5分钟玩转docker容器技术]]></content>
      <tags>
        <tag>docker</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见VPN技术笔记]]></title>
    <url>%2F2018%2F06%2F18%2F%E5%B8%B8%E8%A7%81VPN%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[华三网络学习笔记（理论） 本篇包含以下知识点 VPN概述 GRE-VPN L2TP-VPN IPSEC-VPN GRE-OVER-IPSEC IPSEC-OVER-GRE MPLS BGP-MPLS-VPN SSL-VPN VPN概述Virtual Private Network虚拟私有网，利用共享公共网络仿真WAN设施，构建私有的专用网络。基于IP的VPN体系的核心是使用Tunnel隧道技术。 VPN的优势 快速构建，降低部署周期 与私有网络一样的安全性、可靠性与可管理性 提高了基础资源的利用率 简化了用户端的配置和维护工作 概念术语 承载协议：在公网传输时使用的协议 封装协议：用于标识承载协议中封装的数据包，放置在承载协议头与载荷协议头间 载荷协议：最初封装数据包的协议 隧道协议：决定如何实现隧道的协议 主要VPN技术L2 VPN技术 L2TP VPN：二层隧道协议，可实现拨号VPN与专线VPN PPTP VPN：点到点隧道协议，支持PPP在IP网络上的隧道封装，使用增强GRE技术为传输的PPP报文提供流控与拥塞控制的封装 MPLS L2 VPN：多协议标签交换L3 VPN技术 GRE VPN：通用路由封装，可在任意协议中封装任意协议的封装方法 IPSEC VPN：IP安全，并不是单个协议，而是一系列协议组成的数据安全体系，包括AH、ESP、IKE等，实现对数据私密性、完整性保护与源校验 BGP/MPLS VPN：多协议BGP，利用MPLS与MP-BGP技术 SSL VPN：安全套接字层，使用SSL协议实现远程VPN GRE-VPNGeneric Routing Encapsulation通用路由封装，是一种能在任意协议中封装任意协议的封装方法，可以直接使用GRE封装建立GRE隧道，为IP协议，协议号47。以下为GRE封装包的格式。 GRE头包含了2字节的Protocol Type，用于指示载荷协议类型，IP协议为0x0800。此外还有扩展GRE头，增加了Key和Sequence Number，具备标识数据流和分组次序的能力。IP协议使用协议号47标识GRE头，说明IP头后跟着GRE头。而GRE头中protocol type若为0x0800，说明GRE头后跟着IP头。 双方通过Tunnel接口（逻辑接口）建立隧道，再通过实际物理接口进行转发。tunnel口为载荷协议服务，物理口为承载协议服务。 GRE隧道通信过程： 隧道起点路由查找：隧道两端的路由器必须是私网边界路由器。收到数据包时查找ip路由表 加封装：查找路由表确认下一跳为tunnel口，则进行GRE封装。 承载协议路由转发：对封装后的包进行公网路由查询。 中途转发：即公网转发 解封装：到达对端私网边界路由器后，该路由器检查IP地址，若是自己则解开IP头，发现有GRE头，就交给目标Tunnel口，tunnel口解开GRE头 隧道终点路由转发：解开GRE头后，发现私网IP目的地址，然后查表转发。 每个运行GRE的路由器只有一个路由表，公网和私网之间只能通过不同的路由加以区分，因此公网私网IP地址能重复，且公网私网必须采用不同策略。 连接到私网的物理接口和Tunnel口属于私网路由AS，采用一致的私网路由策略。 连接到公网的物理接口属于公网路由AS，必须和公网采用一致的路由策略。 优点： 支持多种协议 支持IP路由协议和组播 缺点： 点对点隧道 静态配置隧道 缺乏安全性 不可分配地址空间 部署复杂 静态路由配置：配置到达目的IP的私网网段路由，下一跳为对端Tunnel口的地址。动态路由配置：将隧道和私网作为一个AS看待，动态路由需要将Tunnel口和私网都包括。 Tunnel口虚假状态：GRE本身不对隧道状态维护，系统默认根据接口状态设置Tunnel状态，即若物理链路中出现故障，物理口仍为UP，则隧道口也为UP，而此时隧道却不通。只存在于静态配置时。解决：tunnel口keepalive机制：允许路由器探测隧道口的实际状态。路由器会从tunnel口周期发keepalive消息，默认周期10s，若连续3次未收到，则认为隧道不通，会自动删除该tunnel口为出接口的静态路由。 L2TP-VPN对PPP协议链路提供隧道，允许二层链路端点和PPP会话点驻留在不同设备上，并采用分组交换技术进行信息交互。使用PSTN/ISDN拨号、xDSL直接连接到ISP位于本地的POP（存在点），或直接连接到Internet获得IP通信服务，然后ISP设备或用户设备建立L2TP通道连接对端。 L2TP特点： L2TP支持对用户和隧道的验证，和对客户端的动态地址分配。可使用PPP验证，也可使用LAC提供的AAA验证 具备点到网络特性。适合单个或少量接入 不提供加密，但可结合IPSec等加密 面向连接，为信息提供一定的可靠性 L2TP组件： LAC：L2TP访问集中器，隧道就在LAC和LNS间建立 LNS：L2TP网络服务器 NAS：网络访问服务器，抽象概念，是远程访问的接入点，可以是LAC或LNS 两种拓扑方式： 独立LAC：ISP提供LAC，不依赖IP接入点。条件：ISP支持L2TP，验证系统支持VPDN属性特点：终端用户不需要配置VPN拨号软件，只需要执行普通拨号，登录一次就可以接入企业网。 客户LAC：远程系统安装VPDN客户端，直接对LNS发起连接请求。不依赖LAC，验证只能由LNS执行条件：远程系统必须接入Internet，远程系统需要安装专用客户端软件并配置特点：只需配置VPN软件即可与企业网建立VPN连接。对用户的验证只能由LNS端执行。 L2TP封装：L2TP以UDP/IP为承载协议，UDP端口号为1701。L2TP头中Type字段标识消息类型，若为1表示控制消息，若为0表示数据消息。Tunnel ID字段标识L2TP控制连接，即隧道标识符，是在隧道建立时通过Assigned Tunnel ID AVP交换的。Session ID字段用于标识一个隧道中的各个会话，是在隧道建立时通过Assigned Session ID AVP交换的。 控制连接：在L2TP隧道内部，建立维护和释放会话与隧道控制消息：LAC与LNS间交换的隧道内消息，用于对隧道操作。包含AVP（属性值对，通过发送AVP对隧道建立维护或释放，即管理隧道和会话） L2TP协议操作： 建立控制连接：由PPP触发（1）LAC使用任意UDP端口向LNS的UDP1701端口发起连接（SCCRQ打开控制连接请求）（2）LNS将连接重定向到一个随机UDP端口并回应（SCCRP打开控制连接应答）（3）LAC收到后返回确认（SCCCN打开控制连接已确认）（4）LNS收到后再确认，隧道建立（ZLB零长度体）若要执行隧道验证，可在SCCRQ或SCCRP中加上Challenge AVP（挑战AVP）发起验证，接收方要在回应中加上Challenge Response AVP（挑战响应AVP）。 建立会话：前提为控制连接的建立。由PPP模块触发LAC发起：（1）LAC向LNS发送ICRQ（入呼叫请求）发起会话建立（2）LNS收到请求后返回ICRP（入呼叫应答）（3）LAC收到应答后返回ICCN（入连接已连接）（4）LNS再回应ZLB，会话建立LNS发起：（1）LNS发送OCRQ（出呼叫请求）发起会话建立（2）LAC收到后返回OCRP（出呼叫应答）（3）LAC执行呼叫，返回OCCN（出呼叫已连接）（4）LNS收到后回应ZLB，会话建立会使用Tunnel ID和Session ID区分不同隧道和会话 隧道状态维护LAC与LNS互发Hello消息维持会话，默认周期60s，若三次未收到对方的Hello消息，则认为隧道断开。 关闭会话与控制链接关闭会话：（1）LAC发送CDN（呼叫断开通知），通知LNS关闭会话（2）LNS收到后返回ZLB，并关闭会话关闭控制连接：（1）LAC发送StopCCN（停止控制连接通知），通知LNS关闭控制连接（2）LNS收到后回应ZLB，并关闭控制连接 L2TP验证1.对拨入的远程系统PPP验证2.LAC与LNS间隧道验证3.LNS对远程系统再次PPP验证。方式分为三种： 1）代理验证：LAC将从远程系统得到的验证信息和自身的验证信息都发给LNS 2）强制CHAP验证：LNS直接对远程系统进行CHAP验证 3）LCP重协商：LNS与远程系统重新进行LCP协商，采用相应虚拟模板接口上配置的验证方式进行验证 LAC端对远程系统用户的AAA验证包括： 本地验证：需要LAC端配置本地用户名、密码、服务类型等信息，与用户输入的通过对比进行验证。 远程验证：需要与RADIUS或TACACS服务器协同验证，需要在RADIUS或TACACS服务器上配置用户验证信息，LAC将用户输入的信息发送给验证服务器进行验证。 下图为：独立LAC隧道会话建立 下图为：客户LAC隧道会话建立 IPSEC-VPN一种网络层安全保障机制。可实现访问控制、机密性、完整性校验、数据源校验、拒绝重播报文等。IPSec是可扩展的体系，不受限于任何一种特定算法，可引入多种验证算法、加密算法、密钥管理机制。缺点：复杂，消耗大量资源、数据延迟、点对点、不支持组播 IPSec SAIPSec SA：IPSec安全联盟，安全服务通过SA实现。SA是双方的安全协定，包括协议、算法、密钥。SA是单向的，入站和出站数据流分别由入站SA和出站SA处理。 SA的三元组： SPI：安全参数索引，32位数值 IP目的地址：对方IP地址 安全协议标识符：标识AH或ESP SA建立方式： 手工配置：两端手动设置参数 自动协商：双方通过IKE生成维护 SA具有生存时间，有两种方式： 时间：每隔定时长更新SA 流量：每传输一定流量更新SA SA协商信息存放在SPD（安全策略数据库），SPD的项指向SAD（安全联盟数据库）相应项 IKEIKE：因特网密钥交换。基于UDP协议，端口号500，为IPSec提供自动协商交换密钥、建立SA服务，实际提供安全服务的是IPSec，采用DH算法交换密钥（精髓）。且可以定时更新密钥和SA，提供了完善的前向安全性。可以为IPSec自动重新建立SA，允许IPSec提供抗重播服务（通过SPI值）。 采用ISAKMP的密钥交换框架体系IKE安全机制： 身份验证：预共享密钥（默认）、RSA数字签名、DES数字签名 DH密钥交换 PFS完善前向安全性：通过在第二阶段再进行一次DH交换，使IKE SA密钥与IPSec SA密钥无派生关系 协商两个阶段： 阶段1：建立一个IKE SA，为阶段2提供保护分为主模式main和野蛮模式aggressive 主模式：强制实现的阶段1交换模式。共三步，六条消息 策略协商：A向B发送本地IKE策略，B查找匹配的策略，并确认其中协商属性包括：加密算法，散列算法（MD5、SHA等），验证方法（预共享密钥、DSS、RSA），DH组信息（默认MODP 768），DH公共值，IKE生存时间，身份信息 DH交换：A向B发起密钥生成信息，B生成密钥并回应。 ID交换验证：A向B发送身份和验证数据，B回应身份验证。 野蛮模式：远程拨号时，由于拨号用户IP无法确定，可以使用野蛮模式 A向B发送本地IKE策略，开始DH交换 B查找匹配策略，回应验证信息 A接收确认信息并验证，生成密钥，向B发送验证载荷 B验证 阶段2：在IKE SA的保护下完成IPSec SA的协商。采用快速模式 野蛮模式安全性差于主模式，但过程简单快速。在不知道对端IP且需要使用预共享密钥的情况下，必须用野蛮模式。 IPSec包处理流程出站包处理： 查找SPD，三种结果：丢弃、旁路安全服务：直接转发、提供安全服务：查找IPSec SA 若第一步结果是提供安全服务，就在SAD中找IPsec SA，若找到就根据参数提供安全服务，若找不到就查找IKE SA 若找到IKE SA，就只要创建IPSec SA，若找不到IKE SA，就要先创建IKE SA，再创建IPSec SA。 入站包处理： 检查目的地址是否本地，若是则检查数据包是否被IPSec保护 若被IPSec保护，则查找IPSec SA，若不被IPSec 保护，则交给上层 若找到IPSec SA，则解封装，若未找到则丢弃 安全协议 AH：验证头，提供完整性保护、数据源验证、抗重播服务。不支持机密性保护。IP协议，协议号51。AH头格式： Next Header：8位，指示AH头后的载荷协议类型 Payload Length：8位，指示AH的长度并减2，单位为32位 SPI：32位任意数值，用于和目的IP地址和安全协议标识结合，唯一标示一个SA Sequence Number：32位无符号整数，SA建立时为0，随着数据包发送而增大，接收方通过该值确定数据包的序列 Authentication Data：包含该数据包的完整性校验值ICV（使用HMAC算法对IP头+AH头+载荷+共享密钥加密计算），变长且必须是32位的整数倍。AH强制实现HMAC-MD5-96和HMAC-SHA-1-96两种验证算法 ESP：封装安全载荷，有AH所有功能且支持加密。包含ESP头和ESP尾。IP协议，协议号50。ESP头格式： Next Header：同上。强制包含。 SPI：同上 Sequence Number：同上 Payload Data：Next Header描述的数据，即载荷数据，长度为字节的整数倍。若加密，ESP强制实现了基础加密算法DES-CBC。强制包含。 Padding：填充，使载荷数据达到指定长度。 Pad Length：填充长度，范围为0到255。强制包含。 Authentication Data：ICV，长度由验证算法决定。可选，验证服务开启时才包含。同样强制实现HMAC-MD5-96和HMAC-SHA-1-96ESP尾格式：Padding、Pad Length、Next Header IPSec有两种工作模式： 传输模式：保护端到端安全，两个终端间直接运行IPSec，所有加解密、协商都是端系统完成，网络设备完全不参与IPSec，只进行正常路由转发。 隧道模式：保护站点到站点安全，两个安全网关间运行IPSec，整个数据包都计算AH或ESP头，AH或ESP头加上数据都被封装在一个新的IP包中。所有加解密、协商都是安全网关完成，终端主机不参与。 因此AH和ESP对两种工作模式分别有封装的方式： AH 传输模式原IP包、AH头与密钥通过散列函数（如RSA）生成校验值。将校验值封装在AH头中，再由TCP和原IP头封装。 隧道模式新IP头（根据隧道起点终点建立隧道IP头）、AH头与原IP包生成校验值。将校验值封装在AH头中，封装原IP包，再用新IP头封装。 ESP 传输模式原IP包（不包括原IP头）、ESP尾与密钥加密（通过DES等算法）生成密文。将生成的密文与ESP头和验证密钥通过数字签名算法（通过RSA）生成校验值。最后将用ESP头和原IP头封装密文和校验值。 隧道模式将整个原IP包、ESP尾、加密密钥通过加密算法（如DES）生成密文。将密文与ESP头和验证密钥通过散列函数（如RSA）生成校验值。用ESP头和新IP头封装密文和校验值。 GRE-OVER-IPSEC使用Gre Over IPsec的原因：GRE不保证数据机密性与完整性，不能数据源验证。 特性 GRE IPSec 多协议 支持 不支持 虚接口 支持 不支持 组播 支持 不支持 路由协议 支持 不支持 IP协议族 支持 支持 机密性 不支持 支持 完整性 不支持 支持 数据源验证 不支持 支持 封装：原始IP包被封装在GRE隧道包中。GRE隧道包被封装在IPSec包中。 IPSEC-OVER-GREMPLSMulti Protocol Labal Switching：多协议标签交换MPLS使用定长标签封装网络层分组。标签位于数据链路层和网络层之间，称为2.5层。多协议指：MPLS被多种二层协议封装，也可封装多种三层协议 两种工作模式： 帧模式：用于PPP、以太网、帧中继 信元模式：作用于ATM 组成： LSR：位于MPLS内部的核心交换机或路由器，提供标签交换和分发 LER：位于MPLS网络边缘，提供标签映射、移除和分发 FEC：转发等价类，转发过程中以等价方式处理的一组数据分组，可根据IP地址、隧道、COS标识创建FECLSP：标签交换通道，属于同一个FEC的数据流在每个节点赋予一个确定的标签，按照一个确定的标签转发表项进行转发，每个FEC流会有固定的转发路径，该路径就成为该FEC的LSP MPLS标签：4个字节。分为四个字段 Label：标签值，20位，标签转发表的关键索引 EXP：标识QoS优先级，3位 S：栈底标识，1位，若为1说明是最后一个标签，若为0说明后面还有MPLS标签。可实现多层MPLS标签嵌套 TTL：存活时间，8位，每经过一台LSR，TTL就减1 链路层协议为MPLS分配的标识： PPP：0x0281 以太网或HDLC：0x8847 帧中继：0x0080 标签分配协议：用于在LSR间分配标签，建立LSP。有以下四种： LDP标签分发协议：最通用 CR-LDP基于路由受限的标签分发协议：可进行路由约束、QoS，用于流量工程 RSVP-TE基于流量工程扩展的资源预留协议：用于流量工程中MPLS标签分配 MP-BGP多协议扩展BGP协议：为BGP路由分配MPLS标签 LDP消息类型： 发现Discover消息：LDP邻居的发现维护 会话Session消息：LDP邻居会话的建立维持与终止 通告Advertisement消息：向LDP邻居宣告Label、地址等信息 通知Notification消息：向LDP邻居通知事件或错误 所有LDP消息都采用TLV结构，具有扩展性（TLV：Type-Length-Value 类型-长度-值） LDP会话建立维护： 邻居发现：互发Hello消息，组播地址224.0.0.2，UDP端口646 TCP连接：LSR-ID大的，即IP地址大的一方主动发起，TCP端口646 会话建立：Master发出初始化Initialization消息，携带协商参数。协商成功Session建立 会话维持：互发Keepalive消息维持会话。LSR之间发送Label mapping消息，形成标签转发表。期间若收到任何差错消息都会关闭会话，断开TCP连接。 LDP邻居状态机：两台LDP邻居间建立LDP Session后，状态会维持在Operational 标签分配过程：上下游根据数据转发方向而定。LDP Session建立后路由器根据路由表分配标签，生成MPLS标签转发表标签转发表包含：入标签IN，出标签OUT，出接口next-hop标签为随机生成，16以下系统保留 标签分配模式： DOD下游按需标记分配：上游LSR向下游LSR发送标签请求信息。下游LSR为此FEC分配标签，通过标签映射消息反馈给上游LSR。原则：下游设备需要收到上游的标签请求才能分配标签 DU下游自主标记分配：下游LSR在LDP会话建立后主动向上游LSR发布标签映射消息，不需等待上游请求 标签控制模式： 有序：只有最下游设备能分发标签，上游设备只有收到了下游的标签映射消息，才能再向上游发送标签映射信息。使得MPLS的转发是端到端的 独立：不管是不是最下游，不管是否收到下游的标签映射信息，都向上游发送标签映射信息。任何的数据流经过MPLS网络都可进行MPLS转发 标签保持方式：收到下游的标签映射后，是否记录标签信息的原则 保守：只保留下一跳邻居的标签，丢弃所有非下一跳邻居发来的标签优点：节约空间缺点：当网络故障时，LSP收敛较慢 自由：保留来自邻居的所有标签。优点：网络故障后，路由切换时收敛快缺点：消耗空间 常用组合：DU + 有序 + 自由 MPLS转发：第一阶段：标签PUSH：报文进入MPLS网络，LER设备发现报文目的IP地址有关联的标签，对报文进行压标签。该报文就变为了MPLS报文第二阶段：标签SWAP：报文在MPLS网络内进行标签交换。第三阶段：标签POP：报文转出MPLS网络时，在最后一跳弹出标签。倒数第二跳的设备上标签表的出标签为3，说明此为倒数第二跳。一旦包查找到出标签为3，就直接弹出标签。 BGP-MPLS-VPN解决了传统VPN的问题：1.实现隧道动态建立 2.解决本地地址冲突问题 3.VPN私网路由易于控制 多VPF组网多VRF技术用于解决同一台设备（PE）上地址冲突问题。存在以下路由器角色： CE：直接与ISP相连的用户设备 PE：公网边缘路由器，与CE相连，负责VPN接入 P：公网核心路由器，负责路由与快速转发 实现：将一台路由器划分为多个VRF，每个VRF相互独立，拥有各自的路由表、端口、协议，每个VRF类似一台虚拟路由器。未划分VRF的路由在公网路由表中。各个VRF与各自的网络运行一个实例，该实例学到的路由只能加入该VPN路由表。实例与所属VPN进行绑定。并且，端口与VPN绑定，与VRF绑定的接口只会出现在该VRF对应的路由表中，当报文从该接口进入路由器后只能查询该VRF对应的路由表。确保了不同VRF数据间不会冲突。 多VRF与路由协议多实例：各VRF与各自用户网络之间运行一个路由实验，该路由实例学习到的路由只能加入该VPN的路由表。各个路由实例与所属VPN绑定，互相独立，只能学到各自的邻居信息。 MP-BGPMP-BGP（Multi Protocol BGP，多协议BGP）是对BGP根据特性（TCP连接、TLV扩展属性位）进行扩展的协议。MP-BGP相对于BGP的新增特性： 普通BGP只能传递IPv4信息，MP-BGP能承载多个协议路由信息。 新增了MP_REACH_NLRI和MP_UNREACH_NLRI两个属性，并新增了扩展团体属性（Extended_Communities）。 MP-BGP可传递BGP MPLS VPN、L2VPN、6PE等路由信息。 MP_REACH_NLRI和MP_UNREACH_NLRI两个属性都是路由更新消息属性。MP_REACH_NLRI代替了原BGP更新消息中的NLRI和Next-hop。增加了地址族的描述Address-Family、私网Label和RD，包含原有的Next-hop。若地址族描述为VPNv4，则NLRI包含两个部分，一个是私网标签（一个MPLS标签），第二部分是VPNv4地址（RD+IPv4地址）MP_UNREACH_NLRI代替了原BGP更新消息中的Withdrawn Routes。可撤销通过MP_REACH_NLRI发布的各种地址族的路由。包含Address-Family和Withdrawn Routes。 VPNv4地址族主要用于PE路由器间传递VPN路由，并只存在于MP-BGP路由信息和PE设备的私网路由表中，即只出现在路由的发布学习过程中，在穿越ISP公网时，数据包头是没有VPNv4地址的。 下图为MP_REACH_NLRI属性 下图为MP_UNREACH_NLRI属性 BGP的扩展团体属性：RT（Route Target）路由目标。本质是每个VPN实例表达自己的路由取舍方式。RT的格式有三种，都表示RT。 0x0002：2字节的AS号，加上4字节的用户自定义数字，如100:1、200:1 0x0102：4字节的IP地址，加上2字节的用户自定义数字，如192.168.1.1:1、10.1.1.1:2 0x0202：4字节的AS号，加上2字节的用户自定义数字 通常设置为冒号后的数字设置为VPN实例编号。 RT由两个部分组成：Export Target和Import Target。MP-BGP在PE间交互私网路由时，需要遵循以下规则： 在PE设备上，发送某一个VPN用户的私网路由给BGP邻居时，需要在扩展团体属性区域中增加该VPN的Export Target属性。 在PE设备上，需要将收到的MP-BGP路由的扩展团体属性中携带的RT值与本地每个VPN的Import Target对比，若存在交集，则可以将该路由添加进实例的路由表。 通过对RT的操作可实现两种模式：Hub-Spoke和Extranet。Hub-Spoke模式：用户总部可与每个分布互通，但每个VPN分布之间禁止互通。Extranet模式：使指定的节点可以与其他节点互通。 RD（Route Distinguisher）路由区分。本质就是用于私网路由的撤销，因为在撤销路由时是不能携带属性值的（包括RT），PE在删除路由时无法判断撤销哪个VPN的路由。长度6字节。RD有两种格式： 2字节的AS号，加上4字节用户自定义数，如100:1 4字节的IP地址，加上2字节用户自定义数，如192.168.1.1:1 只要保证存在相同地址的两个VPN实例的RD不同即可，但最好为每个VPN实例配置一个RD。若两个VPN实例中存在相同IP地址，则这两个实例一定不能互访，间接互访也不行。 私网标签Label，用于帮助PE判断该报文前往的VPN，是通过MPLS的多标签嵌套实现的。 BGP MPLS VPN实现分为以下步骤： 公网隧道建立：公网IGP协议开启，PE间互通。 本地VPN建立：PE上设置本地VPN并设置RD、RT属性，然后将VPN与接口绑定，即配置VRF。 私网路由的学习：PE与CE间运行路由协议多实例，各VPN实例进行路由学习。PE间建立MP-BGP邻居，下游LSR分配标签，建立标签转发表。并会生成一条MP-BGP更新消息，包含VPNv4路由前缀（即IP地址）、下一跳地址、RT属性、私网标签。PE设备会对比RT值，若通过就会记录该路由信息并发布给本地VPN。 私网数据转发：数据会根据标签转发表进行转发。]]></content>
      <tags>
        <tag>网络</tag>
        <tag>vpn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FTP笔记]]></title>
    <url>%2F2018%2F06%2F06%2FFTP%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇笔记包含以下内容 FTP原理 VSFTP搭建 服务器端 常用客户端软件 TFTP原理 服务器端 客户端 FTP原理File Transfer Protocol文件传输协议，基于TCP协议，采用C/S模式，控制连接端口21，数据连接端口20。 控制连接：负责FTP客户端与服务器交互命令与信息的传输，在整个会话过程中始终打开。 数据连接：负责客户端与服务器数据的传输，传输完毕就会关闭 文件类型：一共有４种，但目前主流仅支持以下两种。 ASCII：默认模式，发送方将文件转为ASCII码传输，适合文本文件传输 二进制：也称图像文件传输模式，按比特流传输，适合程序文件传输 格式控制：有三种选项，但目前主流配置只允许非打印。非打印：表示文件中不含有垂直格式信息。 数据结构：有四种选项，但主流配置只允许文件结构。文件结构认为数据是一个连续的字节流。 传输模式：有四种选项，但主流仅允许流方式，文件以字节流形式传输。对于文件节后，发送方在文件结束处提示关闭数据连接。 数据传输方式： 主动PORT 首先客户端（随机端口）与服务器（21端口）TCP三次握手建立连接，建立控制连接通道 客户端向服务器发送PORT命令，告知服务器使用主动模式。其中PORT命令携带参数（客户端IP地址, P1, P2），P1与P2用于标识客户端数据连接的临时端口号，具体为256*P1+P2，IP地址也是四段，每段用逗号分隔 服务器收到PORT命令后按照参数用20端口与客户端指定端口三次握手建立数据传输通道。 数据传输完毕，发送方发送FIN报文，关闭数据连接 注：若客户端在防火墙内部网络，主动方式会出现问题，因为客户端提供的端口是随机的，防火墙若未放行该端口，则无法建立FTP连接。此时需要使用被动方式建立连接 被动PASV 首先客户端（随机端口）与服务器（21端口）TCP三次握手建立连接，建立控制连接通道 客户端向服务器发送PASV命令，参数与PORT一致。但IP是服务器的，标识的是服务器端的临时端口号。 客户端用随机端口与服务器的指定临时端口TCP三次握手建立数据连接通道。 数据传输完毕，发送方发送FIN报文，关闭数据连接 FTP应答格式：服务器端处理完命令后，会将状态信息，如命令是否执行成功、出错类型、是否就绪等，通过控制连接发送给客户端，即应答。应答的目的就是对数据传输过程进行同步，也为了让客户端了解服务器目前的状态。 FTP应答由3个ASCII码数字组成，并跟随解释性文本符号。数字面向机器，文本面向用户。 第一位： 1：确定预备应答：仅仅是在发送另一个命令前期待另一个应答时启动 2：确定完成应答：要求的操作已完成，可接受新命令 3：确定中间应答：该命令已被接受，另一个命令必须被发送 4：暂时拒绝完成应答：请求的命令没有执行，但差错状态是暂时的，命令以后可以再发。 5：永久拒绝完成应答：该命令不被接受，并要求不要再重试。 第二位： 0：语法错误 1：一般性的解释信息 2：与控制和数据连接有关 3：与认证和账户登录过程有关 5：与文件系统有关 第三位：未明确规定，指示对第二位的进一步细化。 常见FTP应答： 110：重新启动标记应答 120：服务在多久时间内准备 125：数据连接打开，传输开始 150：文件状态正常，打开数据连接端口 200：命令执行成功 202：命令执行失败 211：系统状态或是系统求助响应 212：目录的状态 213：文件的状态 214：帮助信息 215：名称系统类型 220：新的联机服务准备 221：服务控制连接关闭，可注销 225：数据连接开启，但无传输动作 226：关闭数据连接端口，请求的文件操作成功 227：进入passive modes 250：请求的文件操作完成 331：用户名已接受，需要输入密码 332：登录时需账号信息 350：请求的命令需要进一步的命令 421：无法提供服务，关闭控制连接 425：无法开启数据连接 426：关闭联机，终止传输 450：请求的操作未执行 451：命令终止，有本地错误 452：未执行命令，磁盘空间不足 500：格式错误，无法识别命令 501：参数语法错误 502：命令执行失败 503：命令顺序错误 504：命令所接的参数不正确 530：未登录 532：存储文件需要账户登录 550：未执行请求的操作 551：请求的命令终止，类型未知 552：请求的文件终止，储存位溢出 553：未执行请求的命令，名称不正确 VSFTP搭建Very Secure FTP安全文件传输软件。针对系统的程序权限设计，有以下特点： 将PID的权限降低 使用chroot机制 服务的启动者就是一个一般用户 任何需要执行具有较高执行权限的VSFTP指令都由特殊的上层程序控制 VSFTPD有两种启动方式： stand alone：CentOS默认使用该方式启动VSFTPD，适合主要用于提供大量下载的任务，服务速度快。使用systemd管理就是stand alone super daemon：适合内部人员小范围使用。使用xinetd管理就是super daemon 服务器端安装vsftpd服务yum install vsftpdsystemctl enable vsftpdsystemctl start vsftpd 安装完在/etc/vsftpd中有四个默认文件： ftpusers：指定哪些用户不能访问FTP服务器，即黑名单 user_list：实行访问控制的用户列表 vsftpd.conf：VSFTP主配置文件 vsftpd_conf_migrate.sh：VSFTPD操作的一些变量和设置的脚本 配置文件/etc/vsftpd/vsftpd.conf简单解析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849listen = YES # IPv4监听，默认是以StandAlone方式启动listen_ipv6 = NO # IPv6监听 # ipv6监听若v4为yes则v6必须为no,同理v6为yes则v4为nolisten_address = # 监听的IP地址listen_port = 21 # 监听的端口port_enable = YES # 开启端口监听ftp_data_port = 20 # 数据传输端口20connect_from_port_20=YES # 数据连接的端口号pasv_enable = YES # 是否启用被动连接pasv_max_port = # 被动连接的最大端口号pasv_min_port = # 被动连接的最小端口号connect_timeout = 60 # 主动连接若60秒tcp无法建立就不建立了accept_timeout = 60 # 被动连接若60秒tcp无法建立就不建立了max_clients = 2000 # 最多允许2000用户同时登录（0为不限制）max_login_fails = 3 # 最多允许3次登录失败max_per_ip = 20 # 同一地址最多允许多少连接（0为不限制）data_connection_timeout = 300 # 数据连接超时时间（数据无响应）就断开idle_session_timeout = 300 # 用户登录上后无操作时间300s则断开user_config_dir = /etc/vsftpd/conf # dirmessage_enable=YES # 是否启用目录提示信息，默认YES。 # 当用户进入某个目录时，会先检查该目录是否存在message_file参数指定的文件 # 若有就显示文件中的内容，通常用于放置欢迎语或目录说明message_file = # 设置文件路径，该文件用于存放目录的说明或欢迎语（当dirmessage_enable为YES时生效）xferlog_enable=YES # 是否启用详细记录上传下载的日志功能，日志文件路径由xferlog_file指定xferlog_file = /var/log/xferlog # 设置文件路径，该文件用于存放目录的说明或欢迎语（当xferlog_enable为YES时生效）pam_service_name=vsftpd # PAM认证服务配置文件名，放在/etc/pam.d/目录中tcp_wrappers=YES # 开启TCP_wrappers防火墙，用于在一定程度上限制某种服务的访问权限ftpd_banner = # 登录FTP服务器时的欢迎语，默认为空download_enable = YES # 是否允许下载userlist_enable = YES # 是否启用用户名单（对名单中的用户进行访问控制）chroot_list_enable = YES # 是否启用锁定用户在自己的主目录中的功能。 # 被锁定的用户登录FTP服务器后只能进入自己的主目录，不能进入其他目录，默认为NO，应该禁用。 # 锁定的用户名单文件由chroot_list_file参数指定chroot_local_user = YES # 是否将用户限制在自己的根目录中chroot_list_file = /etc/vsftpd/chroot_list # 实行或不实行chroot的用户名单，默认就是该文件。文件中是一个用户一行记录 # 若chroot_list_enable为enable，则该文件中的用户会chroot # 若chroot_local_user为enable（chroot_list_enable为enbale仍为前提），则该文件中的用户不会chrootwrite_enable = YES # 是否允许修改，默认NOuserlist_enable=YES # 当用户登录FTP服务器时，在输入完账户名后，服务器会根据userlist_file中指定的用户列表进行控制 # 若在该文件中，则禁止该用户输入密码。默认NOuserlist_file = /etc/vsftpd/user_list # 禁止访问的，默认该文件uesrlist_deny = NO # 是否不允许该文件中的用户登录ftp，需要userlist_enable=YES # NO表示只允许该文件中的用户访问，YES表示禁止文件中的用户登录FTPuse_localtime = YES # VSFTPD默认使用GMT（格林威治）时间，为防止文档时间错误，需要改为YES，即使用本地时间banner_file = /etc/vsftpd/welcome.txt # 当用户登录时会显示的文字，文件必须存在 认证访问控制VSFTPD提供三种认证方式： 匿名访问anoymous：无需认证即可登入 本地用户local：使用ftp服务器中的用户登录 虚拟用户：创建独立ftp账户。是最安全的 匿名访问无需提供真正用户名和密码就能登录FTP服务器。最好不要开启匿名登录，若要开启就进行限制行为。 只允许匿名用户使用少量基本的操作命令 限制文件下载数量，不要允许上传 限制匿名登录的最大同时联机数 配置文件相关参数：123456789101112anonymous_enable = YES # 是否允许匿名用户登录，默认YES # 因为是匿名模式，所以要开启。否则尽量不要匿名访问anon_umask = 077 # 匿名用户创建文件的umask值，默认077，此时匿名传递的文档权限为600anon_root = /var/ftp/anon # 匿名用户的ftp根目录anon_upload_enable = NO # 允许匿名用户上传文件（这项生效的条件为write_enable为YES且ftp匿名用户对该目录有写权限），默认NOanon_mkdir_writable_enable = NO # 是否允许匿名用户创建目录（需要该目录的父目录的写权限），默认为NOanon_other_writable_enable = NO # 是否开放匿名用户其他写入权限，最好关闭anon_world_readable = YES # 仅允许匿名用户下载可读文档anon_max_rate = 0 # 匿名用户最大传输速率，0为不限制，单位字节/秒# 传输速率的控制大概有20%的上下浮动，即范围为速度*80%到120%no_anon_password = NO # 匿名用户登录是否需要密码（NO为需要，YES为不需要，默认为NO） # 若为需要，登录时输入任意字符串即可 在客户端上匿名登录ftp服务器：只要在输用户名时输入anonymous，并任意输入字符串作为密码 本地用户使用ftp服务器本地的用户进行登录，会更加安全，也是最常用的方式。 配置文件相关参数：1234local_enable = YES # 允许本地用户登录ftp，默认YES，在实际工作环境中，应该将这项设为NOlocal_umask = 022 # 本地用户上传文件的umask，默认为077local_root = /var/ftp # 本地用户的根目录local_max_rate = 0 # 本地用户最大传输速率，0为不限制，单位字节/秒 虚拟用户 本地用户登录时会自动转为虚拟用户，即使有大量用户登录，但最终也仅仅转为一个虚拟用户，避免了创建大量的系统用户。 12guest_enable = YES # 是否开启虚拟账户guest_username = ftp # 虚拟账户映射的用户名 使用本地用户认证创建FTP用户限制该用户仅能登录FTP服务器useradd ftpuser -s /sbin/nologin并设置密码。为该用户创建一个主目录，即用户登录FTP后的根目录。mkdir -p /data/ftp/ftpuser/pub。其中/data/ftp/ftpuser为用户ftpuser的主目录，该目录不得上传文件，该目录下的pub目录供ftpuser用户上传文件。usermod -d /data/ftp/ftpuser ftpuserchmod a-w /data/ftp/ftpuserchmod a+w -R /data/ftp/ftpuser/pub 配置文件中几条修改项：12local_enable = YESlocal_root = /data/ftp 使用虚拟账户首先创建虚拟用户文件/etc/vsftpd/visualusers，文件中列出虚拟用户名和密码 1234ftp_visual_1123456ftp_visual_2234567 生成虚拟用户数据库（可选）。需要工具libdb4-utils（Berkeley DB工具，CentOS中是该软件包） db_load -T -t hash -f /etc/vsftpd/visualusers /etc/vsftpd/visualusers.db ，然后修改该备份文件的访问权限chmod 600 /etc/vsftpd/{visualusers,visualusers.db} 创建PAM文件，设置账户验证。 PAM配置文件位于/etc/pam.d/vsftpd，该文件的名称取决于vsftpd主配置文件的pam_service_name字段。将默认配置注释，然后添加以下内容： 12auth required /lib64/security/pam_userdb.so db=/etc/vsftpd/visualusers.dbaccount required /lib64/security/pam_userdb.so db=/etc/vsftpd/visualusers.db 所有的虚拟用户都需要映射到一个真实的系统用户，因此需要添加一个系统账户并设置家目录。 useradd -s /sbin/nologin -d /home/virtual virtual 查看修改主配置文件（有的不用改）： 1234local_enable = YESchroot_local_user = YESpam_service_name = vsftpduser_config_dir = /etc/vsftpd/visual_config # 设置虚拟用户配置文件主目录 创建虚拟用户配置文件的存放目录/etc/vsftpd/visual_config，这样可以为每个账户做单独的权限设置 创建用户visual的独立配置（举例）： 1234# vim /etc/vsftpd/visual_config/visualguest_enable = YESguest_username = ftp_visual_1anon_max_rate = 100000 常用客户端软件TFTP原理Trivial File Transfer Protocol简单文件传输协议，基于UDP协议，端口号69特点： 仅提供简单文件传输功能（上传，下载） 无存取授权与认证机制，无目录功能 由客户端发起 下载过程： 客户端向服务器发送读请求 服务器根据请求回应数据报文（块编号从1开始） 客户端收到数据后回应确认报文。重复2.3步直至完成下载 上传过程： 客户端向服务器发送写请求 服务器回应确认报文（块编号为0） 客户端发送数据报文（块编号从1开始） 服务器收到后回应确认报文。重复3，4步直至上传完成 文件传输时，将文件分成多个文件块，封装到数据报文中并打上文件块编号 传输文件模式： netASCII：对应FTP的ASCII模式 octet：对应FTP二进制模式 协议报文： RRQ读请求报文 WRQ写请求报文 数据报文 确认正确/错误报文 报文的头两个字节是操作码字段，1为读请求，2为写请求，3为数据报文，4为确认正确，5为错误。文件传输过程中读写出错就发送差错报文，数据传输就停止，差错报文不会被确认也不会重传。TFTP每次传输的数据报文中文件块大小固定为512字节，若文件大小刚好是512字节的整数倍，则传完文件后还要再发一个空文件块的数据报文表明文件传输完成。]]></content>
      <tags>
        <tag>server</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Iptables、Selinux与防火墙笔记]]></title>
    <url>%2F2018%2F06%2F06%2FIptables%E3%80%81Selinux%E4%B8%8E%E9%98%B2%E7%81%AB%E5%A2%99%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本片包含以下内容： Iptables Netfilter/Iptables框架 iptables规则 iptables应用 Selinux Selinux介绍 安全上下文 Selinux管理 firewalld 防火墙部署结构 firewalld服务 IptablesNetfilter/Iptables框架Netfilter是Linux 2.4.x引入的一个子系统，它作为一个通用的、抽象的框架，为每种网络协议都提供一整套的hook函数的管理机制，使得诸如数据包过滤、网络地址转换(NAT)和基于协议类型的连接跟踪成为了可能。Netfilter的架构就是在整个网络流程的若干位置放置了一些检测点（HOOK），而在每个检测点上登记了一些处理函数进行处理。 Netfilter采用的关键技术： 连线跟踪（Connection Tracking）：是包过滤、地址转换的基础，它作为一个独立的模块运行。在协议栈低层截取数据包，将当前数据包及其状态信息与历史数据包及其状态信息进行比较，从而得到当前数据包的控制信息，根据这些信息决定对网络数据包的操作，达到保护网络的目的。 包过滤（Packet Filtering）：检查通过的每个数据包的头部，然后根据规则处理 地址转换（NAT）：网络地址转换分为源NAT（SNAT）、目的NAT（DNAT）和端口转换（PNAT）。SNAT修改数据包的源IP，DNAT修改数据包的目的IP。SNAT在数据包送出之前的最后一刻做好转换工作，DNAT在数据包进入后立刻完成转换。 包处理（Packet Mangling）：可以设置或改变数据包的服务类型（TOS），改变包的生存期（TTL），在包中设置标志值，利用该标志值可以进行带宽限制和分类查询。 资料摘自百度百科-netfilter Netfilter为IPv4定义了5个hook函数，这些hook函数会在数据报流过协议栈的5个关键点被调用。 NF_IP_PRE_ROUTING：刚刚进入网络层的数据包通过此点（已完成版本号，校验和等检测）， 目的地址转换在此点进行 NF_IP_LOCAL_IN：经路由查找后，送往本机的数据包通过此检查点，INPUT包过滤在此点进行 NF_IP_FORWARD：要转发的包通过此检测点，FORWARD包过滤在此点进行 NF_IP_POST_ROUTING：所有马上要通过网络设备出去的包通过此检测点，内置的源地址转换SNAT功能（包括地址伪装）在此点进行 NF_IP_LOCAL_OUT：本机进程发出的包通过此检测点，OUTPUT包过滤在此点进行 Netfilter所有的过滤规则都以模块存放在/usr/lib/modules/$(uname -r)/kernel/net/netfilter/目录中。在Linux内核版本2.6前，netfilter分为IPv4版和IPv6版，分别存放在/usr/lib/modules/$(uname -r)/kernel/net/ipv4和/usr/lib/modules/$(uname -r)/kernel/net/ipv6中，Linux2.6后进行了整合，使得Netfilter更加简单高效。 iptables规则iptables是一个工具，位于用户空间，用于插入，修改，删除数据包过滤表的规则。 iptables分为三部分： 表：分为四张表 raw表：是否对该数据包进行状态跟踪 mangle表：为数据包设置标记，修改数据包（TOS，TTL，MARK） nat表：修改数据包中源、目的IP地址或端口 filter表：过滤数据包（对数据包） 顺序：raw -&gt; mangle -&gt; nat -&gt; filter 链：分为五条链 在路由选择前处理数据包（PREROUTING） 处理流入的数据包（这条规则起到保证内网不被侵犯的关键作用）（INPUT） 处理流出的数据包（OUTPUT） 处理转发的数据包（FORWARD） 在路由选择后处理数据包（POSTROUTING） 链顺序： 入站：prerouting -&gt; input 出站：output -&gt; postrouting 转发：prerouting -&gt; forward -&gt; postrouting 规则：规则被分组在链中，规则被添加到相应的链中，链被添加在表中。规则表默认是允许，则规则链就是被禁止的规则。若规则表是禁止的，则规则链就是被允许的规则 完整包过滤流程： 包到达网络接口 进入raw表的prerouting链（在连接跟踪前处理数据包） 连接跟踪（若要做） 进入mangle表的prerouting链，修改数据包 进入nat表的prerouting链，做DNAT（目标地址转换，改变数据包目的地址使包能到达内网某服务器），但不做过滤 路由判断 若是要转发：进入mangle表forward链，然后进入filter表的forward链过滤，进入mangle表的postrouting链，进入nat表的postrouting链，做SNAT，但不过滤，然后数据包离开本机。 若是发给本地的：进入mangle表的input链，进入filter表的input链，对数据包过滤，然后交给本地程序，处理完后先判断路由，进入raw表的output链，连接跟踪对包的处理，进入mangle表的output链，可修改数据包但不过滤，进入nat表的output链，做NAT，然后路由，进入filter表的output链，可过滤包，进入mangle表的postrouiting链，进入nat表的postrouting链，做SNAT但不过滤，包离开本机。 iptables应用iptables有八种匹配后的触发动作： ACCEPT：允许通过 DROP：丢弃 REJECT：拒绝 LOG：记录日志（syslog） DNAT：目的地址转换 SNAT：源地址转换 MASQUERADE：地址欺骗 REDIRECT：重定向 123456789101112131415161718192021iptables [-t 表名] 选项 [链名] [条件] [-j 控制类型（上面八种）] -P INPUT (DROP|ACCEPT) 设置默认策略 -L 查看规则链 -F 清空规则链 -A 在链末尾加新规则 -I num 在链头部加新规则 -D num 删除指定规则 -R 替换指定链中的一条匹配规则 -N 创建一个新链 -X 删除指定用户的定义链，若未指定就删除所有用户链 -C 检查数据包是否与指定链规则匹配 -Z 将指定链中的所有规则byte计数器清零 匹配参数： -s 匹配源IP/mask，加！表示除该IP -d 匹配目的地址 -i [网卡] 匹配流入网卡的数据 -o [网卡] 匹配流出网卡的数据 -p [协议] 匹配协议 -n ip地址会以数字显示 --dport num 匹配目标端口号 --sport num 匹配源端口号 SelinuxfirewalldRHEL7中firewalld取代了iptables。firewalld将所有网络流量都分类汇集到zones，然后通过zones管理防火墙规则。 firewalld匹配规则： 数据包进入系统，首先检查源IP地址和网卡接口，若与某个zone匹配，则按照该zone的规则过滤。每个zone都有开启或关闭的服务和端口列表，数据包根据列表决定是否放行。如果数据包不与任何定义的zone匹配，则进入默认zone，默认zone的名称为public。firewalld提供以下默认zone：home/drop/work/internal/block/public/trusted/dmz/external，在fedora中，还会默认提供FedoraWorkstation和FedoraServer两个zone。 firewall命令： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657firewall-cmd Status Options --state 返回firewalld状态 --reload 重新加载firewalld，会保留状态信息 --complete-reload 重载firewalld，不会保留状态信息 --runtime-to-permanent Create permanent from runtime configuration --permanent 设置为永久配置 --get-default-zone 显示默认zone --set-default-zone=&lt;zone&gt; 设置默认zone --get-active-zones 显示活跃的zone --get-zones 显示所有预设的zone --get-services 显示所有预设服务 --list-all-zones 列出所有zone的信息 --new-zone=&lt;zone&gt; 创建新的zone --delete-zone=&lt;zone&gt; 删除指定zone --load-zone-defaults=&lt;zone&gt; 加载zone的默认配置 --zone=&lt;zone&gt; 指定zone进行设置 --info-zone=&lt;zone&gt; 显示指定zone的信息 --list-all 列出活跃的zone的信息 --list-services 列出放行的服务 --add-service=&lt;service&gt; 添加放行的服务 --remove-service=&lt;service&gt; 取消放行服务 --query-service=&lt;service&gt; 返回服务是否放行 --list-ports 列出zone中放行的端口 --add-port=&lt;portid&gt;[-&lt;portid&gt;]/&lt;protocol&gt; 放行端口 --remove-port=&lt;portid&gt;[-&lt;portid&gt;]/&lt;protocol&gt; 取消放行端口 --query-port=&lt;portid&gt;[-&lt;portid&gt;]/&lt;protocol&gt; 返回端口是否放行 --list-protocols 列出指定区域添加的协议 --add-protocol=&lt;protocol&gt; 为指定区域添加协议 --remove-protocol=&lt;protocol&gt; 去除协议 --query-protocol=&lt;protocol&gt; 查询是否协议被添加到区域 --list-source-ports 查看区域中定义的源端口 --add-source-port=&lt;portid&gt;[-&lt;portid&gt;]/&lt;protocol&gt; 添加设置源端口 --remove-source-port=&lt;portid&gt;[-&lt;portid&gt;]/&lt;protocol&gt; 去除源端口 --query-source-port=&lt;portid&gt;[-&lt;portid&gt;]/&lt;protocol&gt; 查询源端口是否属于该区域 --list-rich-rules 列出所有rich rules --add-rich-rule=&lt;rule&gt; 添加rich rules --remove-rich-rule=&lt;rule&gt; 去除rich rules --query-rich-rule=&lt;rule&gt; 查询指定rich rules是否属于该域 --list-interfaces 列出区域中的网卡 --add-interface=&lt;interface&gt; 在区域中添加网卡 --query-interface=&lt;interface&gt; 查询网卡是否属于一个区域 --remove-interface=&lt;interface&gt; 从区域移除网卡 --list-sources 查看区域中定义的源 --add-source=&lt;source&gt;[/&lt;mask&gt;] 添加源 --query-source=&lt;source&gt;[/&lt;mask&gt;] 查询区域中是否有指定源 --remove-source=&lt;source&gt;[/&lt;mask&gt;] 去除区域中指定源 参考文章 firewall-cmd]]></content>
      <tags>
        <tag>iptables</tag>
        <tag>安全</tag>
        <tag>Linux</tag>
        <tag>Selinux</tag>
        <tag>防火墙</tag>
        <tag>firewalld</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP笔记]]></title>
    <url>%2F2018%2F06%2F05%2FDHCP%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容 DHCP原理 DHCP服务器配置 服务器端 客户端 DHCP中继 DHCP原理DHCP（Dynamic Host Configuration Protocol）用于为客户端动态分配IP地址、子网掩码并设置网关等信息。前身为BOOTP协议，工作在应用层，基于UDP协议，端口号67（服务器端），68（客户端），还有一个546端口用于DHCPv6的客户端。 DHCP与BOOTP最重要的区别：DHCP支持租期，BOOTP不支持，BOOTP分配的IP地址是永久的。 DHCP提供三种分配方式： 手动分配：静态绑定固定IP，这些IP固定给特定设备使用（打印机，DNS，web服务器等） 自动分配：服务器给客户端分配租期无限长的IP地址，只有客户释放，其他客户才能使用该地址 动态分配：服务器给客户端分配租期有限长的IP地址，一旦租期到期而未续约，地址就会释放。 DHCP的基本原则：尽可能为客户端分配原来使用的地址。DHCP的分配顺序：1.静态分配的 2.客户端曾经会用过的 3.最先找到的可用IP。 DHCP报文与请求过程 DHCP工作过程 发现阶段： 提供阶段： 选择阶段： 确认阶段： 重新申请： 更新租约： DHCP报文 Discover：客户端第一次向服务器发送的请求报文，广播发送 Offer：服务器对客户端Discover的回应，包含分配的IP、掩码、网关等信息，广播或单播发送 Request：客户端发送给服务器的请求报文，包括服务器的选择与租期更新等，单播或广播发送（根据客户端状态） Release：客户端若想释放当前地址，则单播发送给服务器 Ack/Nak：服务器对客户端的回应，请求报文正确时回复Ack，否则回复Nak Decline：客户端收到服务器的Ack后，对获取的IP进行确认，使用ARP，若发现该IP已被使用，则广播向服务器发送Decline报文，拒绝使用该IP。 Inform：当客户端通过其他方式已获取了IP，若还需要向服务器索取其他配置信息时，会向服务器发送Inform，若服务器能根据要求分配则会回复Ack，否则不操作。 DHCP续约 更新状态：使用时间达到租约的50%，客户端进入更新状态，单播向服务器发送Request，服务器若同意续约则回复Ack，否则回复Nak 重新绑定状态：使用时间达到租约的87.5%，客户端进入重新绑定状态。客户端广播Request请求，请求对有效租期进行更新。进入该状态的原因：客户端未收到服务器对续约Request的回应。若Request未收到回应，客户端会在一定时间内重发Request报文，若直到租期结束也未更新租期，则被迫释放IP地址。 DHCP中继DHCP只适用于客户端与服务器在同网段（原因：广播请求），但可以通过中继使客户端可向其他网段的DHCP服务器请求。实现：中继路由器收到请求广播报文，便向服务器单播发送，同理服务器也单播回应中继，中继再广播回应客户端。 DHCP服务器配置实验环境：全部为CentOS-7 服务器端：system2 192.168.163.102 客户端：system3 192.168.163.103 服务器端 安装DHCP服务yum install dhcp dhcp-devel dhcp为服务器端基础组件，dhcp-devel为服务器开发工具 开机自启 systemctl enable dhcpd systemctl start dhcpd 修改配置文件/etc/dhcp/dhcpd.conf注：该文件是空的，可以参考模板添加项，模板为/usr/share/doc/dhcp-4.2.5/dhcpd.conf.example，其中dhcp的版本号可能不一致，可用find命令查找 以下为配置文件常见参数的解析，可通过man 5 dhcpd.conf查看完整配置参数解析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# 服务器名server-name “system2”; # DNS域名option domain-name &quot;example.org&quot;;# DNS服务器域名（最多指定三个）option domain-name-servers ns1.example.org, ns2.example.org;# 默认租期，单位秒。在默认租期内，可以进行续约操作default-lease-time 600;# 最大租期，单位秒。max-lease-time 7200;# 最大租期即客户端IP租约时间的最大值，当客户端超过默认租约时间，虽此时已无法续约，但DHCP会仍然允许用户在最大租约时间内使用该IP，之后就收回该IP# dhcp与dns动态信息更新模式（必选）# 三种选择：interim--dns互动更新 ad-hoc--特殊dns更新 none--不支持# 全局设置中一定要有这个，否则不能成功启动#ddns-update-style none;# 如果该DHCP服务器是本地网络的授权服务器，则需要取消注解#authoritative;# 忽略客户端更新ignore client-updates;# 设置网关option routers 192.168.163.254;# 日志类型log-facility local7;# 设置ntp服务器ntp-server [IP地址]# 子网设置subnet 10.5.5.0 netmask 255.255.255.224 &#123; # 设置地址池 range 10.5.5.26 10.5.5.30; option domain-name-servers ns1.internal.example.org; option domain-name &quot;internal.example.org&quot;; option routers 10.5.5.1; # 广播地址 option broadcast-address 10.5.5.31; default-lease-time 600; max-lease-time 7200;&#125;# shared-network用于跨网段分配IP地址，多用于中继，形成超级作用域shared-network 224-29 &#123; # 配置子网1 subnet 10.17.224.0 netmask 255.255.255.0 &#123; option routers rtr-224.example.org; &#125; # 配置子网2 subnet 10.0.29.0 netmask 255.255.255.0 &#123; option routers rtr-29.example.org; &#125;&#125;# host指定客户端客户端的IP地址绑定# hostname仅仅是标识，无意义host hostname &#123; # 指定目标主机 hardware ethernet [MAC地址]; # 绑定IP地址 fixed-address [ip地址];&#125; 注：划分子网时，如果选择直接配置多作用域实现动态IP分配的任务，则必须要为DHCP服务器添加多块网卡，并配置多个IP地址，否则DHCP服务器只能分配与其现有网卡IP地址对应网段的作用域。 DHCP租约文件/var/lib/dhcpd/dhcpd.leases租约数据库文件用于保存一系列的租约声明，其中包含客户端的主机名、MAC地址、分配到的IP地址，以及IP地址的有效期等相关信息。这个数据库文件是可编辑的ASCII格式文本文件。每当发生租约变化的时候，都会在文件结尾添加新的租约记录。 客户端需要安装先dhclient，然后修改/etc/sysconfig-network-scripts/ifcfg-ens33（根据实际网卡名称），修改BOOTPROTO=dhcp，重启网络。 DHCP中继DHCP中继代理（DHCP Relay Agent）用于转发其他网段的客户端DHCP请求。当客户端请求]]></content>
      <tags>
        <tag>server</tag>
        <tag>dhcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP协议基础笔记]]></title>
    <url>%2F2018%2F05%2F31%2FHTTP%E5%8D%8F%E8%AE%AE%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容 Web概述 HTTP概述 HTTP报文 HTTP首部 状态码 HTTP请求方式 HTTP_Cookie Web概述WWW（World Wide Web）环球信息网，也称万维网，由W3C万维网联盟管理。万维网并不等同互联网，万维网只是互联网所能提供的服务其中之一，是靠着互联网运行的一项服务。WWW的三种技术：HTML，HTTP，URL URI：统一资源标识符，表示服务器资源名称，给定了URI，HTTP便能解析资源。URI有两种形式： URL统一资源定位符：描述特定服务器上指定资源的位置，是固定的。包含三部分： 方案：说明访问资源使用的协议方式，如http:// 服务器因特网地址 指定服务器上的指定资源几乎所有URI都是URL URN统一资源名：特定资源的唯一名称，与资源所在地址无关，资源可以四处搬运。 HTTP概述超文本传输​​协议Hyper Text Transfer Protocol（HTTP）是用于传输诸如HTML的超媒体文档的应用层协议，用于Web浏览器和Web服务器之间的通信，基于TCP/IP，采用C/S模式。HTTP是无状态协议，意味着服务器不会在两个请求之间保留任何数据（状态）。 HTTP的三个常见版本： HTTP/1.0：客户端只能从web服务器获取一个web资源 HTTP/1.1：客户端能在一个连接上获取多个web资源（有数量限制，超出部分请求被阻塞） HTTP/2.0：多流并行，一个连接可获取多个web资源 特点： 简单快速：HTTP协议简单，报文简单易懂，HTTP服务器程序规模 小，通信速度快。 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 可扩展：通过HTTP首部，只要服务端和客户端就新首部达成语义一致，新功能就可以被轻松加入进来。 无状态：在同一个连接中，两个执行成功的请求之间是没有关系的。但是可以通过HTTP的头部扩展和HTTP Cookies解决，把Cookies添加到头部中，让每次请求都能共享相同的上下文信息，来创建有状态的会话。 HTTP报文HTTP消息头（HEADER，也称首部）1.通用（一般）头：适用于请求和响应消息，但与最终消息主体中传输的数据无关2.请求头：包含有关要获取的资源或客户端本身更多信息3.响应头：包含有关服务器响应的补充信息，如其位置或服务器本身（名称和版本等）4.实体头：包含有关实体主体的更多信息，比如主体长(Content-Length)度或其MIME类型 HTTP请求方式 GET：请求访问已被URL识别的资源，不会对信息产生影响，每次GET方法都是相同的，GET放在URL首部，GET提交的数据大小一般限制为1024字节，大小随浏览器而。采用明文传输，速度快。只产生一个TCP数据包。GET能被缓存。 POST：请求服务器传输信息实体的主体，POST放在报文中，没有具体限制，由于放在报文中所以无法看见，安全，form表单必须使用POST。会产生两个TCP数据包。POST不可被缓存。POST提交数据大小没有限制。 PUT：传输文件，在请求报文的主体中包含文件内容，然后保存到请求URL指定的位置（出于安全，网站一般不会用） HEAD：获取报文首部，用于确认URI的有效性及资源更新的日期时间等 DELETE：请求URL删除指定的资源，与PUT相反（同样一般不用） OPTIONS：查询指定URL资源支持的方法 TRACE：追踪路径，让服务器将之前的请求通信返还给客户端 CONNECT：要求在与代理服务器通信时建立隧道，实现用隧道协议进行TCP通信，主要使用SSL（安全套接层）和TLS（传输层安全）协议把通信内容加密后经过网络传输。 GET与POST的区别： GET POST 请求访问已被URL识别的资源 将实体提交到指定资源 放在URL首部，明文传输，可见 封装在报文中，不可见 产生一个TCP包 产生两个TCP包 能被缓存 不可被缓存 数据传输大小随浏览器而定，一般为1024字节 没有具体限制 HTTP首部HTTP请求报文（Request）12345678GET https://developer.mozilla.org/zh-CN/docs/Web/HTTP HTTP/2.0Host: developer.mozilla.orgUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:60.0) Gecko/20100101 Firefox/60.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflate, brCookie: dwf_sg_task_completion=False; messages=&quot;67ba01ba64d7aac589a5e34d72bb89050449f64e$[[\&quot;__json_message\&quot;\0541\05430\054\&quot;Redirected from https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/Forms\&quot;\054\&quot;wiki_redirect\&quot;]]&quot;Connection: keep-alive 报文解析：第一行为请求行，包含三个部分： 执行动作：即请求方式。 请求目标：完整路径，通常是一个URL，或者是协议、端口和域名的绝对路径 绝对路径，末尾加上?与查询字符串，称为原始形式 完整URL，称为绝对形式，通常GET使用 域名:端口，仅在使用 CONNECT 建立 HTTP 隧道时才使用 星号形式*，配合 OPTIONS 方法使用，代表整个服务器 HTTP版本 第二行以后的内容都称为HTTP首部（Headers）。 Host：请求的服务器主机名User-Agent：用户代理端，即客户端（浏览器），包含详细的浏览器名和 HTTP响应报文（Response）1234567891011121314151617HTTP/2.0 200 OKcontent-type: text/css; charset=&quot;utf-8&quot;access-control-allow-origin: *cache-control: max-age=315360000, public, immutabledate: Tue, 05 Jun 2018 16:24:09 GMTlast-modified: Tue, 05 Jun 2018 15:59:27 GMTserver: meinheld/0.6.1strict-transport-security: max-age=63072000x-content-type-options: nosniffx-xss-protection: 1; mode=blockcontent-encoding: gzipvary: Accept-Encodingage: 336026x-cache: Hit from cloudfrontvia: 1.1 ec1e0045303188984bc160bff8921bbd.cloudfront.net (CloudFront)x-amz-cf-id: D0Bs8VzYr7qYkVfUiXYivsQqygQPctoPwabrnWC0zSPCwYedUyHAWg==X-Firefox-Spdy: h2 响应报文解析：第一行为响应行，包含两个部分： HTTP版本 状态码第二行开始为响应首部 Content-Type：指示服务器文档的MIME类型。帮助用户代理（浏览器）去处理接收到的数据。 状态码类别： 1XX：信息类——-&gt;请求正在处理，属于临时响应 2XX：成功类——-&gt;请求正常处理完毕 3XX：重定向——-&gt;需要附加操作完成请求 4XX：客户端错误—-&gt;服务器无法处理请求 5XX：服务器错误—-&gt;服务器处理请求出错 常见状态码： 1XX信息响应 100 Continue：迄今为止的所有内容都是可行的，客户端应该继续请求，如果已经完成，则忽略它。 101 Switching Protocol：响应客户端的 Upgrade 标头发送的，并且指示服务器也正在切换的协议。 102 Processing (WebDAV)：服务器已收到并正在处理该请求，但没有响应可用。 2XX成功响应 200 OK：正常，客户端的请求在服务器被正常处理 201 Created：该请求已成功，并因此创建了一个新的资源。这通常是在PUT请求之后发送的响应。 202 Accepted：请求已经接收到，但还未响应，没有结果。意味着不会有一个异步的响应去表明当前请求的结果，预期另外的进程和服务去处理请求，或者批处理。 203 Non-Authoritative Information：服务器已成功处理了请求，但返回的信息可能来自另一来源。 204 No Content：正常处理，但无资源返回，响应报文中不含实体主体 205 Reset Content：服务器成功处理了请求，且没有返回任何内容。 206 Partial Content：客户端进行了范围请求且服务器成功执行了这部分的GET请求 3XX重定向 300 Multiple Choice：针对请求，服务器可执行多种操作。 服务器可根据user agent选择一项操作，或提供操作列表供请求者选择。 301 Moved Permanently：永久性重定向，请求的资源已被分配了新的URI（以后都用新URI） 302 Found：临时性重定向，请求的资源被暂时的移动到了由Location 头部指定的 URL 上（本次使用新URI访问） 303 See Other：请求对应的资源存在另一个URI,应该使用GET方法定向获取请求的资源当301、302、303响应状态码返回，几乎所有浏览器都会把POST改成GET，并删除请求报文内的主体，之后请求自动再次发送 304 Not Modified：如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。304响应禁止包含消息体，因此始终以消息头后的第一个空行结尾。 305 Use Proxy：请求者只能使用代理访问请求的网页。 （已不再使用，但目前仍能生效） 307 Temporary Redirect：服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 308 Permanent Redirect：资源现在永久位于响应头中Location指定的另一个URI。 4XX请求错误 400 Bad Request：响应状态码表示由于语法无效，服务器无法理解该请求 401 Unauthorized：发送的请求需要有通过http认证（BASIC认证、DIGEST认证）的认证信息。该响应必须包含一个适用于被请求资源的 WWW-Authenticate 信息头用以询问用户信息。若之前已经进行了一次请求，则表示用户认证失败 403 Forbidden：服务器端有能力处理该请求，但是拒绝授权访问 404 Not Found：服务器端无法找到所请求的资源 405 Method Not Allowed：禁用请求中指定的方法。 406 Not Acceptable：无法使用请求的内容特性响应请求的网页。 407 Proxy Authentication Required：此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。 408 Request Timeout：服务器等候请求时发生超时。 409 Conflict：服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。 410 Gone：如果请求的资源已永久删除，服务器就会返回此响应。 411 Length Required：服务器不接受不含有效内容长度标头字段的请求。 412 Precondition Failed：服务器未满足请求者在请求中设置的其中一个前提条件。 413 Payload Too Large：服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。 414 URI Too Long：请求的URI过长，服务器无法处理。 415 Unsupported Media Type：请求的格式不受请求页面的支持。 416 Requested Range Not Satisfiable：如果页面无法提供请求的范围，则服务器会返回此状态代码。 417 Expectation Failed：服务器未满足”期望”请求标头字段的要求。 5XX服务器错误 500 Internal Server Error ：服务器端错误，所请求的服务器遇到意外的情况并阻止其执行请求。 502 Bad Gateway：服务器作为网关或代理，从上游服务器收到无效响应。 503 Server Unavailable：服务器暂时处于超负载或者正在停机维护，现在无法处理请求 504 Gateway Timeout：服务器作为网关或代理，但是没有及时从上游服务器收到请求。 505 HTTP Version Not Supported：服务器不支持请求中所用的 HTTP 协议版本。 参考文章 HTTP | MDN https://developer.mozilla.org/zh-CN/docs/Web/HTTP关于HTTP协议，一篇就够了 https://www.cnblogs.com/ranyonsue/p/5984001.html开发之前应该了解的HTTP https://blog.csdn.net/qq_35414779/article/details/78981151]]></content>
      <tags>
        <tag>http</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAProxy笔记-1]]></title>
    <url>%2F2018%2F05%2F31%2FHAProxy%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容： HAProxy介绍 HAProxy配置文件 HAProxy介绍HAProxy是一个提供高可用性、负载均衡，以及可基于TCP（第四层）和HTTP（第七层）的应用代理软件。 HAProxy适合处理高负载Web站点的HTTP请求，这些站点通常需要会话保持或七层处理，HAProxy完全支持数以万计的并发连接，并且能使后端的Web服务器不会暴露。HAProxy还支持服务器健康检查，当后端服务器出现故障后，HAProxy会自动移除该服务器，在故障排除后自动将该服务器加入。 HAProxy特点： 支持连接拒绝：通过限制连接防御攻击蠕虫，降低被DDOS攻陷的可能 支持全透明代理 自带服务器状态监控页面 原生配置了SSL证书 支持虚拟主机 支持双机热备 支持服务器健康检查 单进程 HAProxy支持的代理模式： 基于四层的TCP代理：仅在客户端和服务器间进行流量转发。可用于邮件服务（SMTP、POP3等）、内部协议通信服务器、MySQL、https等 基于七层的HTTP代理：能分析应用层协议，且能根据协议信息灵活控制访问 HAProxy的frontend和backend功能： frontend：ACL规则匹配，根据任意HTTP请求头内容做规则匹配，然后将请求重定向到指定的backend backend：事先定义的server pool，等待前端将请求转到的服务器组 HAProxy配置文件直接通过yum install haproxy安装，版本为1.6。安装后会自动创建用户haproxy。 HAProxy命令： 1234567891011121314151617181920212223haproxy -v 显示版本 -vv 显示详细的构建选项信息 -d 进入debug模式 -f 指定配置文件 -dM[&lt;byte&gt;] poisons memory with &lt;byte&gt; (defaults to 0x50) -D 后台运行; -C changes to &lt;dir&gt; before loading files. -q 静默模式 -c 检查配置文件语法 -n 设置最大连接数，默认2000 -m 限制可用的内存量，单位MB -N sets the default, per-proxy maximum # of connections (2000) -L 设置本地peer name，默认为主机名 -p writes pids of all children to this file -de 禁止使用epoll()函数 -dp 禁止使用poll()函数 -dS disables splice usage (broken on old kernels) -dR disables SO_REUSEPORT usage -dV 禁止服务器端的SSL -sf/-st [pid ]* finishes/terminates old pids.常用操作：选项不可连起来，只能分开haproxy -c -f /etc/haproxy/haproxy.cfg 检查配置文件，一定要-c -f都指定haproxy -D -f /etc/haproxy/haproxy.cfg 以daemon模式启动 HAProxy主配置文件/etc/haproxy/haproxy.cfg HAProxy的配置有五个部分：global，defaults，frontend，backend，listen 全局global配置： 1234567891011121314151617global进程管理与安全性参数 log 127.0.0.1 local2 #日志使用local2输出到本地 chroot /var/lib/haproxy #改变haproxy的工作目录 pidfile /var/run/haproxy.pid #指定PID文件路径 user haproxy #执行HAProxy进程的用户 group haproxy #执行HAProxy进程的用户组 daemon #后台执行 stats socket /var/lib/haproxy/stats #用户访问统计数据的接口 stats maxconn 10 #默认stats socket仅限10个并发连接 nbproc 1 #启动的haproxy进程的个数，只能用于守护进程模式性能调整参数 maxconn 4000 #最大连接数 spread-checks #设置HealthCheck时间间隔 noepoll #禁用使用epoll事件轮询系统 nopoll #禁用poll事件轮询系统 nosplice #禁用套接字之间使用内核tcp拼接 默认defaults配置： 1234567891011121314151617defaults mode http #默认模式，tcp为4层，http为7层，health只返回ok option httplog #采用http日志格式 option httpclose #防止多余的cookie信息影响到客户端请求的处理结果 retries 3 #尝试连接的次数，若连接失败则认为服务器不可用 option http_proxy #开启代理（仅是基本的代理功能） option dontlognull #不记录空连接 option http-server-close #开启connection closing option forwardfor except 127.0.0.0/8 option redispatch #当客户端将请求发往了故障的服务器，则会自动将请求发往其他正常的机器 timeout http-request 10s # timeout queue 1m # timeout connect 10s # timeout client 1m # timeout server 1m # timeout http-keep-alive 10s # timeout check 10s # 参考文章 HAProxy用法详解 全网最详细中文文档]]></content>
      <tags>
        <tag>server</tag>
        <tag>负载均衡</tag>
        <tag>代理</tag>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Varnish笔记-1]]></title>
    <url>%2F2018%2F05%2F31%2FVarnish%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Squid笔记-1]]></title>
    <url>%2F2018%2F05%2F31%2FSquid%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Squid介绍 代理服务器概念 Squid安装 Squid常规配置 Squid访问控制 Squid多级代理配置 Squid实验 cachemgr.cgi管理Squid Squid日志 Squid调优 Squid介绍Squid是一个支持HTTP、HTTPS、FTP等服务的Web缓存软件，可通过缓存页面实现降低带宽占用并优化页面相应时间。 Squid特点与功能： 不仅能缓存Web页面资源，还能对DNS查询结果进行缓存 强大的访问控制功能 保护内网，并加速内网对外网的连接 记录内网用户访问外网行为 提供用户认证 减少出口流量 工作在TCP/IP的应用层，TCP端口3128 Squid支持的网络协议：HTTP、FTP、Gopher（信息查找协议）、WAIS（广域信息查询系统）、SSL Squid支持的内部缓存和管理协议：HTTP、ICP（互联网缓存协议，用于从缓存中查找指定对象）、Cache Digests（用于生成缓存中对象的索引）、SNMP（用于为外部工具提供缓存信息）、HTCP（用于发现HTTP缓存区，存储管理HTTP数据） Squid请求过程： 客户端访问Squid服务器，由代理服务器代表客户端向web服务器（后端Real Server）请求资源 Web服务器将相应数据返回给代理服务器 代理服务器将数据返回给客户端，并保留一份在本地 其他客户端向该代理服务器请求相同的资源 代理服务器直接将本地的该资源缓存返回给客户端 squid的硬件环境：内存与磁盘是缓存性能的重要体现。所有对象都会尽可能缓存到内存中，更大的磁盘空间实现更多的缓存目标和更高的命中率，最好使用SAS，尽量不用SATA。磁盘与内存间也有关联，最好每G的磁盘空间有32M的内存对应。 代理服务器概念代理服务器一般构建于内网和Internet间，负责转发内网对Internet的访问，并进行访问控制与记录，可实现安全保护、缓存数据、内容过滤、访问控制等功能。 Web代理维护着庞大的缓存数据，因此对内存和硬盘的要求很高，更大的内存和硬盘意味着更多的缓存和更高的缓存命中率。 Web缓存类型： 客户端缓存：一般就存放在浏览器中。有两个缺点：1.缓存容量小，不能存储大的Web对象，因此命中率较低。2.缓存在本地，不能共享，因此存在大量重复数据。 代理服务器缓存：位于网络中间位置。容量大，缓存能与内网所有客户端共享。但若性能达不到要求，反而会造成网络瓶颈。代理缓存应具有健壮性、可扩展性、稳定性、负载均衡的特点 服务器缓存：是为了减轻web服务器的负载，并不是为了提高资源命中率。服务器缓存减少了web服务器的流量、并保护了web服务器的安全，因为web服务器仅向服务器缓存提供数据，并不直接面向客户机。并且提高了网站的可靠性，因为各个服务器缓存间可实现共享。 三种典型代理方式： 传统代理：在浏览器中设置，指出代理服务器的IP地址和网络端口。便于用户对访问管理控制，配置简单。 透明代理（正向代理）：为内网提供外网的访问，即普通的代理服务器。但增加了网络设备的负担，并需要做好更详细的配置，会有一定的延时。若程序的一系列请求是相关的并涉及多个目标对象，有可能会出问题。 反向代理：能代理外部网络访问内网服务器。主要为本地网站做缓存，加快web服务器的响应速度。相当于服务器缓存。反向代理结合智能DNS即可实现基本的CDN Squid安装Squid版本：3.5 可直接通过yum install squid安装。然后systemctl start squid启动。 安装时会自动创建用户squid，并且是系统用户，家目录为/var/spool/squid，且禁止登录。 注：一定要做到squid服务器的时间同步，否则无法进行缓存 Squid的相关配置文件： /etc/httpd/conf.d/squid.conf：用于在Apache中添加运行cachemgr.cgi的配置 /etc/logrotate.d/squid：Squid的日志轮替配置 /etc/squid/squid.conf：Squid主配置文件 /etc/squid/cachemgr.conf：设置可通过cachemgr.cgi管理的主机 /etc/squid/mime.conf：定义MIME类型的文件 Squid其他相关文件： /var/log/squid/：存放squid日志的目录 /var/spool/squid/：存放squid缓存的目录 /usr/share/squid/errors/：存放给客户端的报错信息HTML，目录中包含各个语言的子目录 /usr/lib64/squid/cachemgr.cgi：squid cache manager，用于管理主机的动态网页 squid提供两个命令： squid：用于管理squid守护进程 squidclinet：用于管理squid客户端 1234567891011121314151617181920212223squid [options] -a port 指定HTTP端口，默认3128 -d level 将指定调试等级的信息发送到标准错误输出 -f file 指定配置文件启动 -k 向squid服务器发送指令 reconfigure 重载配置文件 rotate 轮替日志文件 shutdown 安全关闭 restart 重启服务 interrupt 中断服务 kill 杀死服务 debug 开启debug check 检查运行状态 parse 检查配置文件 -s 启用syslog -u port 指定ICP端口，默认3130，若要关闭，就指定0 -z 创建缓存目录，即初始化缓存 -C 不捕获fatal信号 -D 不进行DNS参数测试 -F 不响应任何请求直到存储重建 -N 不使用daemon模式 -S 在重建期间仔细检查swap分区 -X 强制进入完全调试模式 123456789101112131415161718192021222324252627squidclient [Basic Options] [HTTP Options] -s | --quiet 静默模式，不打印输出 -v | --verbose 显示详细信息，最多-vv -v：显示向外发的请求信息 -vv：显示动作跟踪信息 -h | --host host 指定将信息发给的主机，默认为localhost -l | --local host 指定绑定的本地IP地址，默认为空 -p | --port port 指定服务端口，默认3128 -T timeout 指定读写操作的超时时间 --ping [options] 允许ping模式 -g count 指定ping包的个数，默认一直ping -I interval 指定ping包发送间隔，默认1sHTTP Options: -a 不包含“accept:header” -j hosthdr Host header content -k 保持长连接，默认只接收一个请求就关闭连接 -m method 指定请求方法，默认GET -n 代理协商认证（kerberos） -N www协商认证（kerberos） -P file 将指定文件作为请求载荷 -r 强制缓存重新加载URL -t count 跟踪计数缓存跳数 -u user 代理认证用户名 -U user www认证用户名 -w password 代理认证密码 -W password www认证密码 Squid常规配置12345678910111213141516171819202122232425262728293031323334353637383940414243http_port 3128 [模式] [options] #Squid监听的端口# 若要添加多个端口，用空格隔开 常用模式： accel：加速或反向代理模式 intercept：支持IP层NAT拦截传输到该Squid端口的流量 从squid3开始就没有transparent透明模式了icp_port 3130 #ICP端口# ICP是专门运行在代理服务器间交换缓存数据的协议。ICP使用UDP端口3130cache_effective_user squid #运行squid进程的用户#squid进程是root启动的，但启动后会由指定的普通用户继续运行cache_effective_group squid #运行squid进程的用户组pid_filename /var/run/squid.pid #squid的PID文件位置# 此文件由root在启动squid时创建logformat squid %ts.%03tu %6tr %&gt;a %Ss/%03&gt;Hs %&lt;st %rm %ru %un %Sh/%&lt;A %mt #指定日志记录格式access_log /var/log/squid/access.log squid #日志路径，类型为squidcache_mem 8 MB #cache内存#设定squid能用多少额外的内存来缓存对象的限制值cache_dir ufs /var/spool/squid 100 16 256 #指定缓存类型为ufs，保存在/var/spool/squid，是默认值#大小限制为100MB，第1层子目录为16个，第2层子目录为256个cache_store_log /var/log/squid/store.log #数据缓存的日志，是默认值maximum_object_size_in_memory 8 KB #squid保存在内存中的对象最大为8KB#内存中的对象访问速度最快，但内存有限，需要根据内存大小设置maximum_object_size 4096 KB #最大的缓存对象的字节数4096KB#只有小于该值的对象才会被缓存，若硬盘足够大，可适度提高cache_swap_low 90 #设置Squid缓存空间的使用策略。cache_swap_high 95 #当缓存中数据占到整个缓存大小的95%时 #就会按算法删除缓存中的数据 #直到缓存数据占到整个缓存大小的90% #可以最大限度利用缓存空间，但也不会出现空间溢出coredump_dir /var/spool/squid #放置squid进程运行时coredump文件的目录cache_mgr root #Squid管理员用户的Emailvisible_hostname proxy.example.com #设置对外可见的主机名，会在错误信息中显示 logformat日志格式设置 Squid会设置在缓存目录下建立多个目录，每个目录又建立多个子目录，在最里层的目录存放缓存文件，缓存文件是通过对客户端请求的URL进行哈希运算生成的。Squid会在内存建立一张哈希表，记录硬盘中缓存文件配置的情形。 使用squid -k parse检查配置文件语法，确认没有报错后squid -z初始化缓存目录，会显示Making directories in /var/spool/squid/00等信息，发现，第一层的目录数量是16，第二层目录的数量是256，目录名都是由十六进制标号，与配置文件cache_dir配置的一致。若无法创建，可能是该目录的权限问题。 再使用squid -N -d1测试，没有报错，则说明启动完成。 通过浏览器测试，设置代理服务器 Squid访问控制123acl name type value1 value2... #设置ACL名字和对象的值http_access &lt;allow|deny&gt; [!]ACL对象1 ... #将客户端请求与http_access的对象匹配，指定allow或deny。!为取反。#若一个请求与所有http_access都不匹配，则执行与最后一条http_access指定的动作相反的动作 常见的ACL类型： 类型 含义 src 源IP地址，可以单个IP地址，可以是地址范围 dst 目的IP地址，同上 myip 本地网络接口IP地址 srcdomain 客户所属的域，Squid会根据客户IP地址进行反向DNS查询 dstdomain 服务器所属的域，与客户请求的URL匹配 time 时间段 port 指向其他计算机的网络端口，即是目标服务器上的端口 myport 指向squid服务器的端口，是squid服务器上的端口 proto 客户端请求所使用的协议，如http、https、ftp、gopher method HTTP请求方法 proxy_auth squid认证的用户名 url_regex 关于URL的正则表达式（域名） urlpath_regex 关于URL资源的正则表达式（资源路径，不带有域名） ident 指定用户 acl对象的值间的关系为”或“，只要满足一个就匹配了该acl规则。而http_access与其他规则的设置使用”与“逻辑。squid默认配置拒绝每个请求，因此在使用代理前，必须先添加访问控制规则。 若value为文件名，对象的值实际上是文件的内容。 常见案例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354Squid3已默认定义acl名：all、localhost、manager、to_localhost acl all src 0.0.0.0/0 acl localhost src 127.0.0.1/32 acl manager proto cache_object #cache_object是squid自定义的协议，用于访问squid的缓存管理接口 acl to_localhost dst 127.0.0.1/8因此以上四个acl名字不能再使用，且可以直接调用，无需再定义acl worktime time MTWHF 08:00-17:00 #时间从周一到周五，早上8点到下午5点 S-Sun M-Mon T-Tue W-Wed H-Thu F-Fri A-Satacl mynet src 10.1.1.1/24#源10.1.1.1/24的子网命名为mynetacl aim dstdomain .baidu.com .google.com#匹配指定目的域名acl giffile url_regex -i \.gif$#匹配以.gif结尾的URLacl other srcdomain &quot;/etc/squid/other&quot;#匹配文件中指定的源域名acl safe_port port 80#匹配指定的目标服务器端口acl Users ident tomhttp_access allow tom#只允许tom访问acl mynet src 10.1.1.1-10.1.1.10http_access allow mynethttp_access deny all#仅允许mynet子网访问acl user1 src 10.1.1.1acl user2 src 10.1.1.2acl user1_time time MTWHT 08:00-12:00acl user2_time time MTWHT 08:00-13:00http_access allow user1 user1_timehttp_access allow user2 user2_time#给两个用户分别指定上外网的时间acl ftpmp3 url_regex -i &quot;^ftp://.*\.mp3$&quot;http_access deny ftpmp3#禁止从任何ftp上下载mp3文件acl cgi urlpath_regex -i &quot;^/cgi-bin&quot;http_access deny cgi#禁止访问cgi网页acl limit maxconn 16http_access deny limit#限制同一IP客户端的最大连接数 squid默认acl配置： 12345678910111213141516171819202122232425262728#所有内网acl localnet src 10.0.0.0/8 acl localnet src 172.16.0.0/12 acl localnet src 192.168.0.0/16 acl localnet src fc00::/7 acl localnet src fe80::/10 acl SSL_ports port 443 #SSL443端口acl Safe_ports port 80 # 放行httpacl Safe_ports port 21 # 放行ftpacl Safe_ports port 443 # 放行https..... #放行的其他服务acl CONNECT method CONNECT #connect方法，是HTTP中用于代理的方法http_access deny !Safe_ports ##只允许本机转发客户机对非Safe_ports的请求http_access deny CONNECT !SSL_ports #拒绝所有非SSL_ports的CONNECT请求，只允许本机用connect连接非SSL_portshttp_access allow localhost manager #允许localhost使用cache_object协议http_access deny manager #拒绝所有其他网络使用cache_objecthttp_access allow localnet #允许内网访问http_access allow localhost #允许本地访问http_access deny all #剩下的都不允许http_port 3128 coredump_dir /var/spool/squid refresh_pattern ^ftp: 1440 20% 10080refresh_pattern ^gopher: 1440 0% 1440refresh_pattern -i (/cgi-bin/|\?) 0 0% 0refresh_pattern . 0 20% 4320 Squid多级代理配置在大型网络中一台Squid服务器的性能不能应对巨大的访问量，需要构建多级代理服务器，类似与计算机集群，使用ICP交换缓存，形成一个逻辑上的大型Squid服务器。 代理服务器间的结构可分为：同级结构、层次结构、网状结构。最常见是层次结构。 需要配置参数cache_peer hostname type http_port icp_port options hostname为另一台Squid服务器的域名或IP地址 type为ICP请求的类型：parent或sibling http_port为对端的Squid监听请求端口 icp_port为对端ICP的端口 ICP的两种请求类型type： parent：会把客户端的请求发送给对方，对方的缓存中若有请求的数据，则返回，若没有，则对方向web服务器读取数据，再返回。（类似DNS的递归查询）一般对象处于上一级时使用此类型，因为上一级会更加接近于web服务器。 sibling：不会把客户端请求发给对方，仅仅询问有没有缓存。如果没有，则对方仅仅告诉回复没有，并不会向web服务器请求数据。一般对象处于同等级别时用此类型。de 常见的options参数： 选项 含义 proxy-only 从对方得到的数据不做缓存，默认会做 weight=n 指定对方的权重，有多个cache_peer时会按权重选择，默认根据网络响应时间自动选择 no-query 不向对方发送ICP请求，只发送HTTP代理请求，一般用于对方不支持ICP或不可用的情况 default 与no-query一起用，当对方都不支持ICP时，就用该peer no-digest 不使用内存摘要表查询，直接ICP通信 login=user:password 若对方需要认证，就提供用户名和密码 示例： 12cache_peer system3.example.com parent 3128 3130 proxy-only defaultcache_peer system4.example.com sibling 3128 3130 proxy-only 若要通过规则选择不同的上级代理服务器，达到负载均衡，还需要配置： cache_peer_domain cache-host domain ... cache_peer_access cache-host allow|deny [!]ACL对象... 示例： 12345cache_peer system1.example.com parent 3128 3130cache_peer system2.example.com sibling 3128 3130 proxy-onlycache_peer_domain system1.example.com examplecache_peer_domain system2.example.com !example#system1为example域的代理服务器，system2为非example域的代理服务器 Squid实验透明二级代理环境： client1：192.168.1.128 server1：192.168.1.129 server2：192.168.1.130,192.168.205.140 web1：192.168.205.139 server1 上的配置squid.conf添加或修改以下内容： 12345678910111213141516171819202122http_port 3128 accel #配置为透明代理icp_port 3130cache_effective_user squidpid_filename /var/run/squid.pidlogformat squid %ts.%03tu %6tr %&gt;a %Ss/%03&gt;Hs %&lt;st %rm %ru %un %Sh/%&lt;A %mtaccess_log /var/log/squid/access.log squidcache_dir ufs /var/spool/squid 100 16 256cache_store_log /var/log/squid/store.loghosts_file /etc/hosts #用于解析IP地址visible_hostname system1.example.com #错误信息中显示的主机名cache_effective_user squid #若不设置user和group，会默认使用nobodycache_effective_group squidacl PURGE method PURGE #purge是squid自定义的方法，用于删除squid缓存中的对象（能让管理员强制删除） #squid是默认拒绝Purge请求的http_access allow localhost manager #只允许本机使用cache_object协议http_access allow localhost PURGE #只允许本机使用purge方法http_access deny manager PURGEicp_access allow all #允许所有客户机访问ICP端口http_reply_access allow all #允许对所有客户机进行请求的回复 并且需要进行端口转发，即重定向，因为代理服务器需要将客户端发往80端口的数据包改为发往自己的3128端口，实现代理。因此需要开启防火墙firewalld或iptables服务。 若是使用firewalld，则先要确定是否开启了伪装IP功能（Masquerade） firewall-cmd --query-masquerade，若为no，则需要开启firewall-cmd --add-masquerade --permanent。 设置端口转发：firewall-cmd --add-forward-port=port=80:proto=tcp:toport=3128 --permanent 若为iptables，则添加两条规则： 123iptables -t nat -A PREROUTING -i ens33 -p tcp --dport 80 -j --REDIRECT --to-ports=3128iptables -t nat -A POSTROUTING -o ens36 -s 192.168.205.0/24 MASQUERADE# ens33为内网卡，ens36为外网卡 然后打开转发，无论是firewalld还是iptables，都要打开。 12echo &quot;net.ipv4.ip_forward=1&quot; &gt;&gt; /etc/sysctl.conf sysctl -p 最后放行80和443端口，放行http和https服务 12firewall-cmd --permanent --add-port=80/tcp --add-port=443/tcpfirewall-cmd --permanent --add-service=http --add-service=https 反向二级代理cachemgr.cgi管理Squid通过web界面管理Squid，需要cachemgr.cgi动态网页文件，存放在/usr/lib64/squid/中。可以将该cgi文件复制到/var/www/cgi-bin中，也可不动，但要注意文件的权限问题，一定要改为apache。然后在httpd的主配置文件中添加，Location配置 12345ScriptAlias &quot;/squidcgi&quot; &quot;/var/www/cgi-bin/cachemgr.cgi&quot;&lt;Location &quot;/squidcgi&quot;&gt; Order deny,allow #逗号后不能有空格 Allow from all&lt;/Location&gt; 然后浏览器通过主机IP/squidcgi访问。 默认不需要填用户名密码即可登录。若要设置登录用户名密码，只需要在主配置文件中添加cachemgr_password参数。 1234cachemgr 密码 行为action要禁用一个操作，就把密码设为disable，后面跟上要禁止的操作要允许不输入密码的操作，就把密码设为none，后面跟上允许的操作action为all表示为所有操作设置相同密码 Squid日志Squid日志不仅记录服务器进程的运行，还记录用户的访问情况、缓存存储状况、缓存访问状况等。 Squid三个日志：access.log，cache.log，store.log 和日志文件相关的配置： cache_log /var/log/squid/cache.log：指定缓存信息日志的路径。包含了缓存的起始配置信息，分类的错误信息，性能警告。 cache_store_log /var/log/squid/store.log：指定对象存储记录日志的路径。包含被写入缓存空间的对象、被从缓存空间清除的对象等。可设为none禁止 cache_swap_log /var/spool/squid/cache_swap.log：指定每个交换日志的路径。包含存储在交换空间的对象元数据。这类日志最好不要删除，否则可能会导致Squid故障。 debug_options ALL,1：控制日志记录内容的多少，第一个参数决定对哪些行为做记录，ALL表示对所有行为做记录，第二个参数表示详细程度，1表示详细程度最低。 log_fqdn：控制access.log日志中客户机地址的记录方式。on表示会记录客户机的域名，off则记录IP地址。开启会增加系统负担 logformat squid %ts.%03tu %6tr %&gt;a %Ss/%03Hs %&lt;st %rm %ru %un %Sh/%&lt;A %mt是在配置文件中日志格式的参数配置。 %ts.03tu：记录请求完成时间。%ts为相对于Unix纪元（1970-1-1）的秒数，%03tu表示3个宽度的毫秒数，.为写入日志的固定符号。 %6tr：响应时间，表明了Squid处理请求的时间（接收到HTTP请求到响应报文发出），单位毫秒。ICP响应时间一般为0，非常快速。 %&gt;a：记录客户端地址，若开启了log_fqdn，则会记录客户端主机名。还可通过client_netmask隐藏客户端IP的一部分 %Ss/%03Hs：记录请求结果和状态码，%Ss是Squid特有的请求结果码，%03Hs是HTTP状态码 %&lt;st：记录传输的字节数。是整个数据包的大小，会比实际载荷信息大。 %rm：记录请求的方法。HTTP的常见请求和ICP的ICP_QUERY请求 %ru：记录客户端请求的URI。默认不会记录URL中第一个?后所有信息 %un：记录客户端用户身份。Squid使用RFC1413或HTTP的验证头部确认用户身份 %Sh/%&lt;A：记录peer主机（其他代理服务器）信息 %mt：记录MIME类型。从响应的Content-type域获取信息，若没有就使用一个-代替。 logfile_rotate：轮询保存的文件数，超过限制就会从头开始覆盖 日志轮询Squid并没有自动轮询的机制，只能使用squid -k rotate命令，并编写脚本通过cron周期执行。 1234#!/bin/bash cd /var/log/squid/[ -f access.log ] &amp;&amp; mv access.log access_$(date +%F).logsquid -k rotate Sarg工具分析日志Sarg是一个Squid的日志分析工具，输出为html文件。Sarg下载-tar.gz包 依赖gd库，pcre库。在sarg安装完成后，进入安装目录的bin目录，执行sarg命令，sarg会自动寻找Squid的日志文件，并分析。SARG: Records in file: 595935, reading: 100.00%，然后会生成一个目录，是自动存放在/var/www/html/squid-reports下，目录名为起始日期-结束日期，该目录下有index.html 通过浏览器访问该index文件，数据量相当庞大，并提供图表和日期时间的数据记录 sarg命令： 123456789101112131415sarg [options] --convert 将access.log文件转换为易读的日期格式 -d DATE 指定报告的日志范围dd/mm/yyyy-dd/mm/yyyy -e MAIL 将报告发送给指定email -f FILE 指定配置文件，默认为安装目录的etc/sarg.conf --keeplogs 保留以前生成的每个报告 -l FILE 指定日志文件 -n 使用rDNS将IP地址解析成域名 -o DIR 报告存放目录 -p 使用IP地址而不是userid --split 按-d指定的日期切割日志文件 -t TIME 指定时间范围[HH:MM 或 HH:MM-HH:MM] -u USER 只报告指定用户的行为 -x 开始分析，且会先输出完整的配置信息 -z 显示完整的输出信息 Sarg配置，存放在安装目录的etc/sarg.conf 1234access_log /usr/local/squid/var/logs/access.log #squid日志路径output_dir /var/www/html/squid-reports #报告输出目录date_format u #日期格式，u为美国格式mm/dd/yy，e为欧洲格式dd/mm/yyoverwrite_report no #是否对已存在的日期的报告覆盖 Squid调优调整文件描述符Squid在高负载下，需要大量内核资源，又因为Squid是做缓存服务器，所以极度消耗文件描述符，而unix对文件描述符是有限制的（1024），这样会造成极大的性能影响，当squid用完所有文件描述符后，就不能接收新的请求了，并且squid发现文件描述符短缺后，就会发布警告。 因此，需要先查看文件描述符是否满足使用，大多数情况1024已经足够使用，当出现高负载情况时，则需要更多，因此最好将系统限制的文件描述符数量设为每个进程限制的两倍。 123456ulimit -a 查看当前的资源限制信息找到open files，就是同时能打开的文件数量，即文件描述符，默认为1024优化性能，将此值设为2048ulimit -Hn 2048 # -H 设定资源的硬性限制，也就是管理员所设下的限制# -n 设置同时最多能打开的文件数 注：ulimit仅仅作为临时设置，可以作用于通过使用其命令登录的 shell 会话，在会话终止时便结束限制，并不影响于其他 shell 会话。 若要永久设置，可写入/etc/profile：echo &quot;ulimit -Hn 2048&quot;&gt;&gt;/etc/profile 或写入/etc/security/limits.conf：echo &quot;* - nofile 2048&quot;&gt;&gt;/etc/security/limits.conf 调整临时端口范围临时端口是TCP/IP栈分配出连接的本地端口，当squid发起一条连接到另一台服务器，内核给本地socket分配一个端口号。CentOS默认的临时端口范围是32768到60999 当squid高负载时，若临时端口号短缺，会造成很大的性能影响，因为一些TCP连接在关闭时会进入TIME_WAIT状态，此状态下临时端口不能重用。 可通过sysctl -a | grep net.ipv4.ip_local_port_range查看 设置范围4000到65000，sysctl -w net.ipv4.ip_local_port_range=&quot;4000 65000&quot; 参考文章 Linux服务器架设指南（第二版） Linux系统管理与网络管理（第二版） Linux运维之道（第二版） 高性能网站构建实战]]></content>
      <tags>
        <tag>server</tag>
        <tag>squid</tag>
        <tag>缓存</tag>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nagios监控搭建-1]]></title>
    <url>%2F2018%2F05%2F31%2FNagios%E7%9B%91%E6%8E%A7%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容 Nagios概述 Nagios搭建 服务器端 客户端安装 目录与配置文件概述 Nagios监控界面解析 Nagios性能分析图表 邮件告警配置 基于Nagios4.4.1，Nagios-Plugin2.2.1 Nagios概述Nagios是一款用于监控系统和网络的开源应用软件，能有效的监控windows，linux和unix的主机状态。采用C/S结构。Nagios由ANSI C编写。 Nagios结构分为Nagios Core核心主程序和Nagios Plugins插件。核心只提供很少的监控功能，用户需要给Nagios安装相应插件以搭建完善的监控系统。 Nagios如何工作 监控：监控关键IT基础架构组件，包括系统指标，网络协议，应用程序，服务，服务器和网络基础架构。 告警：在关键基础架构组件发生故障和恢复时发送警报，为管理员提供重要事件的通知。警报可以通过电子邮件，短信或自定义脚本提供。 响应：IT人员可以确认警报并开始解决中断并立即调查安全警报。如果未及时确认警报，则警报可以升级到不同的组。 报告：报告提供中断，事件，通知和警报响应的历史记录，供以后查看。 维护：计划停机可防止在计划维护和升级窗口期间发出警报。 计划：通过趋势和容量规划图表和报告，运维人员可以在发生故障之前识别必要的基础架构升级。 Nagios特点 网络服务监控（SMTP、POP3、HTTP、NNTP、ICMP、SNMP、FTP、SSH、端口，URL，丢包，进程数，网络流量、交换机端口流量，路由器，打印机） 本地和远端主机资源监控（CPU、内存、磁盘、日志、负载uptime、I/O，Raid级别，温度，passwd文件的变化，本地所有文件指纹识别），也包括Windows主机（使用NSClient++ plugin） 业务数据监控（用户登陆失败次数，用户登陆网站次数，输入验证码失败次数，某个API接口流量并发，网站订单，支付交易数量） 可以指定自己编写的Plugin通过网络收集数据来监控任何情况（温度、警告……）。可以通过配置Nagios远程执行插件远程执行脚本 远程监控支持SSH或SSL加通道方式进行监控 简单的plugin设计允许用户很容易的开发自己需要的检查服务，支持很多开发语言（shell scripts、C++、Perl、ruby、Python、PHP、C#等） 包含很多图形化数据Plugins（Nagiosgraph、Nagiosgrapher、PNP4Nagios等） 可并行服务检查 能够定义网络主机的层次，允许逐级检查，就是从父主机开始向下检查 当服务或主机出现问题时发出通告，可通过email, pager, sms 或任意用户自定义的plugin进行通知 能够自定义事件处理机制重新激活出问题的服务或主机 自动日志循环 支持冗余监控 包括Web界面可以查看当前网络状态，通知，问题历史，日志文件等 Nagios插件概述默认搭建的Nagios服务器只能监控简单的几个项目，而其他服务之类的监控项目都是需要插件来实现，插件可用官方提供的，也可以自己编写。插件是Nagios Core的独立扩展，可以使用Core监控任何事情。插件处理命令行参数，执行特定检查，然后将结果返回给Nagios Core。它们可以是编译的二进制文件（用C，C ++等编写）或可执行的脚本（shell，Perl，PHP等）。 NRPE概述NRPE 总共由两部分组成: check_nrpe 插件，位于监控主机上 NRPE daemon，运行在远程被监控的 Linux 主机上 当监控远程主机服务或资源时，工作流程如下： nagios会运行check_nrpe插件并指定检查项 check_nrpe插件会通过ssl连接到远程的NRPE daemon NRPE daemon会运行相应的Nagios插件来执行检查动作 NPRE daemon将检查的结果返回给check_nrpe插件，插件将其递交给Nagios做处理 NRPE 的检测类型分为两种: 直接检测：检测的对象是运行NRPE的那台Linux主机的本地资源，直接使用NRPE插件监控远程Linux主机的本地或者私有资源 间接检测：当运行Nagios的监控主机无法访问到某台被监控主机，但是运行NRPE的机器可以访问得到的时候，运行NRPE的主机就充当一个中间代理，将监控请求发送到被监控对象上 就如下图中check_disk和check_load是直接检测，check_http和check_ftp是间接检测。 Nagios搭建服务器端需要安装的软件： LAMP：因为Nagios需要web端显示，所以需要LAMP的web环境，也可以是LNMP。 Nagios-core：Nagios的主程序 Nagios-plugins：Nagios的插件 NRPE：Nagios的一个功能扩展，可在远程主机上执行插件程序，是客户端程序。 客户端需要安装的软件 Nagios-plugins NRPE 服务器端 首先搭建LAMP环境yum install httpd php php-gd gd* gcc* glibc* openssl*注：gd是图像处理库 创建用户nagios，创建用户组nagcmd，将apache和nagios都添加到nagcmd副组中。组nagcmd用于从Web接口执行外部命令 创建安装目录/usr/local/nagios，编译安装123456789101112131415161718192021222324252627282930313233进入nagios-4.4.1解压目录./configure \ --prefix=/usr/local/nagios \ --with-command-group=nagcmd General Options: ------------------------- Nagios executable: nagios Nagios user/group: nagios,nagios Command user/group: nagios,nagcmd Event Broker: yes Install $&#123;prefix&#125;: /usr/local/nagios Install $&#123;includedir&#125;: /usr/local/nagios/include/nagios Lock file: /run/nagios.lock Check result directory: /usr/local/nagios/var/spool/checkresults Init directory: /lib/systemd/system Apache conf.d directory: /etc/httpd/conf.d Mail program: /usr/bin/mail Host OS: linux-gnu IOBroker Method: epoll Web Interface Options: ------------------------ HTML URL: http://localhost/nagios/ CGI URL: http://localhost/nagios/cgi-bin/ Traceroute (used by WAP): /usr/bin/traceroutemake all \ &amp;&amp; make install \ # 安装Nagios主程序的CGI和HTML &amp;&amp; make install-init \ # 在/lib/systemd/system创建Nagios启动脚本，即可通过systemctl操作 &amp;&amp; make install-commandmode \ # 配置目录权限 &amp;&amp; make install-config \ # 安装示例配置文件，在/usr/local/nagios/etc目录 &amp;&amp; make install-webconf # 生成配置文件/etc/httpd/conf.d/nagios.conf 至此，Nagios Core安装完成。 下面安装nagios plugins 1234567进入nagios-plugins-2.2.1解压目录./configure \ --prefix=/usr/local/nagios make &amp;&amp; make install查看/usr/local/nagios/libexec目录下是否有插件文件，若有则安装成功 nagios plugins安装后，继续安装NRPE。 123456789101112131415进入nrpe-3.2.1解压目录./configuremake all \&amp;&amp; make install \&amp;&amp; make install-plugin \&amp;&amp; make install-daemon \&amp;&amp; make install-config General Options: ------------------------- NRPE port: 5666 NRPE user: nagios NRPE group: nagios Nagios user: nagios Nagios group: nagios 因为可能开启邮件告警功能，所以要启动sendmail服务，不需要做任何配置。yum install sendmail*systemctl enable sendmailsystemctl start sendmail 也可以使用postfix服务进行邮件告警，同样不需要任何配置yum install postfix*systemctl enable postfixsystemctl start postfix注：sendmail和postfix同时只开启一个，一个开启则另一个会自动停止 至此，服务器端核心组件安装完成。 如果要进行汉化，则可以安装中文插件nagios-cn。下载后直接解压进入目录，然后./configure，make &amp;&amp; make install即可。 先检查下/usr/local/nagios/bin中是否有命令nagios和nagiostats，如果没有，就将nagios-4.4.1目录中base目录下的nagios命令和nagiostats命令复制到/usr/local/nagios/bin/中，因为通过systemctl启动nagios时，会调用该目录的nagios命令。若不存在会报错无法启动。 为配置文件还有nagios和nagiostats命令创软链接。ln -s /usr/local/nagios/etc/nagios.cfg /etc/nagios.cfgln -s /usr/local/nagios/etc/cgi.cfg /etc/cgi.cfg 为nagios默认登录用户nagiosadmin创建http验证密码。htpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin 将/usr/local/nagios的所有者和所属组都改为nagios 使用nagios -v /etc/nagios.cfg检查配置文件是否正确。 确保Selinux关闭，确保防火墙放行80端口或关闭。 启动httpd和nagios以及nrpe服务，并设为开机自启。systemctl start httpd nagios nrpesystemctl enable httpd nagios nrpe 在浏览器上输入IP地址/nagios，会先要求输入htpasswd设置的用户名密码登录验证。登录成功后跳转到Nagios主页面。 服务器端配置NRPEln -s /usr/local/nagios/etc/nrpe.cfg /etc/nrpe.cfg 修改commands.cfg文件，添加check_nrpe命令 1234define command &#123; command_name check_nrpe command_line $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$&#125; 修改service.cfg，添加服务 123456define service &#123; use local-service host_name system3 service_description users check_command check_nrpe!check_users # 在check_nrpe!后直接使用nrpe.cfg定义的command变量&#125; 完成后重启nrpe 客户端安装 安装nagios plugins 123进入nagios-plugins-2.2.1解压目录./configure --prefix=/usr/local/nagios make &amp;&amp; make install 安装NRPE 12345678进入nrpe-3.2.1解压目录./configuremake all \ 构建nrpe和check_nrpe&amp;&amp; make install \ 安装nrpe和check_nrpe&amp;&amp; make install-plugin \ 安装check_nrpe插件&amp;&amp; make install-daemon \ 安装nrpe daemon&amp;&amp; make install-config 安装nrpe 配置文件&amp;&amp; make install-init 安装systemd文件 查看配置文件/usr/local/nagios/etc/nrpe.cfg，若要添加监控命令，便找到以下配置，按照格式进行添加command 1234567command[check_users]=/usr/local/nagios/libexec/check_users -w 5 -c 10command[check_load]=/usr/local/nagios/libexec/check_load -r -w .15,.10,.05 -c .30,.25,.20command[check_hda1]=/usr/local/nagios/libexec/check_disk -w 20% -c 10% -p /dev/hda1command[check_zombie_procs]=/usr/local/nagios/libexec/check_procs -w 5 -c 10 -s Zcommand[check_total_procs]=/usr/local/nagios/libexec/check_procs -w 150 -c 200# command后中括号里内容就是定义的变量，名称可任意指定 （可选）修改/etc/services，添加nrpe 5666/tcp # Nagios_client。 启动nrpe，systemctl start nrpe，并使用ps -ef查看nrpe是否启动。 使用插件/usr/local/nagios/libexec/check_nrpe -H localhost检验nrpe是否启动成功。若成功，会输出NRPE的版本号。 修改配置文件/usr/local/nagios/nrpe.cfg 12345#server_address=127.0.0.1 # 客户端主机IP地址# 添加监控服务器地址，声明合法的NRPE服务对象allowed_hosts=127.0.0.1,监控服务器地址或域名 # 若没有在这指定监控服务器地址，则监控服务器无法获取本机的服务信息 给命令nrpe和配置文件nrpe.cfg创软链接，并以守护进程启动。nrpe -c /etc/nrpe.cfg -d也可通过systemctl start nrpe启动。 测试nrpe是否成功启动/usr/local/nagios/libexec/check_nrpe -H 127.0.0.1，输出NRPE版本号则启动成功。 测试nrpe是否能与客户端通信，同样使用check_nrpe指定对端IP地址或域名，输出NRPE版本号则通信正常。若报错 目录与配置文件概述在Nagios服务器端安装完后，/usr/local/nagios中有以下目录：bin，etc，sbin，share，libexec，var，var/archives，var/rw。其中libexec是存放外部插件的。share是存放网页文件的。var/archives是存放归档日志的。var/rw是存放外部命令的。 配置文件或目录 说明 cgi.cfg 控制cgi访问的配置文件 nagios.cfg Nagios主配置文件 resource.cfg 变量定义文件 objects 目录，存放配置文件模板，用于定义Nagios对象 objects/commands.cfg 命令定义配置文件，定义的命令可悲其他配置文件使用 objects/contacts.cfg 定义联系人和联系人组 objects/localhost.cfg 定义监控本地主机 objects/printer.cfg 定义监控打印机，默认未开启 objects/switch.cfg 定义监控路由器，默认未开启 objects/templates.cfg 定义主机、服务，默认未开启 objects/timeperiods.cfg 定义监控时间段 objects/windows.cfg 定义windows主机，默认未开启 Nagios配置中涉及到的定义：（建议按以下顺序配置） 主机、主机组、服务、服务组 监控命令 监控时间 联系人、联系人组 Nagios监控的主机资源和服务在配置文件中称为对象。建议将Nagios各个定义对象创建独立的配置文件，如： 创建hosts.cfg定义主机和主机组 创建services.cfg定义服务和服务组 其余的对象都用默认文件即可。 templates.cfg定义主机和服务的模板1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162define contact &#123; # 定义联系人 name generic-contact ; 联系人名 service_notification_period 24x7 ; 服务通知时间，默认24x7任何时间 host_notification_period 24x7 ; 主机通知时间，默认24x7任何时间 service_notification_options w,u,c,r,f,s ; 服务发送通知的状态条件 # w：警告warn u：未知unknown c：紧急criticle r：重新恢复recover host_notification_options d,u,r,f,s ; 主机发送通知的状态条件 # d：宕机down u：未知/不可达unreachable r：重新恢复 service_notification_commands notify-service-by-email ; 服务发送通知的方式 host_notification_commands notify-host-by-email ; 主机发送通知的方式&#125;define host &#123; # 定义主机 name generic-host ; 主机名（对于配置文件，并非系统主机名） notifications_enabled 1 ; 是否开启主机通知，1为开启，2为不开启 event_handler_enabled 1 ; 是否开启事件处理 flap_detection_enabled 1 ; 是否启用报警延时 process_perf_data 1 ; 是否启用数据输出 retain_status_information 1 ; 是否在程序重启期间保留状态信息 retain_nonstatus_information 1 ; 是否在程序重启期间保留非状态信息 notification_period 24x7 ; 主机通知时间，默认任何时间&#125;define host &#123; name linux-server ; 主机名 use generic-host ; 引用指定的主机，此处引用了上面定义的主机的配置 check_period 24x7 ; 检查主机的时间段，默认不间断 check_interval 5 ; 检查主机的时间间隔，默认5分钟 retry_interval 1 ; 重试检查时间间隔，默认1分钟 max_check_attempts 10 ; 对主机检查的最多次数。并不是检查一次就判断，而是多检查几次才判断是否故障。单位次 check_command check-host-alive ; 默认检查命令 notification_period workhours ; 发送通知的时间段 notification_interval 120 ; 发送通知的间隔，单位分钟 notification_options d,u,r ; 发送通知的状态条件 contact_groups admins ; 联系人组&#125;后面还有对打印机、交换机的主机定义然后就是对服务的定义define service &#123; # 定义服务 name generic-service ; 服务名 active_checks_enabled 1 ; 是否开启动态检查 passive_checks_enabled 1 ; 是否开启主动检查 parallelize_check 1 ; 应该并行化活动服务检查（禁用此功能可能会导致严重的性能问题） obsess_over_service 1 ; 默认为1 check_freshness 0 ; 默认为0 notifications_enabled 1 ; 是否启用服务通知 event_handler_enabled 1 ; 是否启用事件处理 flap_detection_enabled 1 ; 是否启用报警延时 process_perf_data 1 ; 是否启用数据输出 retain_status_information 1 ; 是否在程序重启期间保留状态信息 retain_nonstatus_information 1 ; 是否在程序重启期间保留非状态信息 is_volatile 0 ; 是否稳定，0为稳定，1为不稳定 check_period 24x7 ; 检查服务的时间段，默认不间断 max_check_attempts 3 ; 对服务检查的最多次数 check_interval 10 ; 检查时间间隔，默认10分钟 retry_interval 2 ; 重试检查时间间隔，默认2分钟 contact_groups admins ; 联系人组 notification_options w,u,c,r ; 发送通知的状态条件 notification_interval 60 ; 发送通知的间隔，单位分钟 notification_period 24x7 ; 发送通知的时间段&#125; resource.cfg定义变量的模板。变量需要先定义才能在别的配置文件中调用，否则nagios就会报错。1234# 变量$USER1$指定了nagios插件的安装路径$USER1$=/usr/local/nagios/libexec# $USER2$定义了事件处理的安装路径$USER2$=/usr/local/nagios/libexec/eventhandlers Nagios宏Nagios配置有两个特征：继承与引用，在命令行定义中使用宏，通过宏，Nagios可灵活获取主机、服务等对象的信息。在命令执行前，Nagios会对命令进行宏替换。宏分为：默认宏、按需而成的宏、用户自定义宏 默认宏：主机IP地址宏 1234567891011define host&#123; host_name linuxbox address 192.168.1.2 check_command check_ping...&#125;define command&#123; command_name check_ping command_line /usr/local/nagios/libexec/check_ping -H $HOSTADDRESS$ -w 100.0,90% -c 200.0,60%&#125;在执行时，就会把宏替换为IP地址 命令参数宏向命令传递参数，参数指定在对象中定义，用一个!分隔。 1234567891011define service&#123; host_name linuxbox service_description PING check_command check_ping!200.0,80%!400.0,40%...&#125;define command&#123; command_name check_ping command_line /usr/local/nagios/libexec/check_ping -H $HOSTADDRESS$ -w $ARG1$ -c $ARG2$&#125;在执行时，会将分隔的两个参数替换到命令中的ARG1和ARG2 注：如果要在命令中使用!，\都要使用反斜杠转义 Nagios可用的所有宏： 主机宏$HOSTNAME$：主机名，取自主机定义中host_name$HOSTADDRESS$：主机IP地址，取自主机定义中address 服务宏$SERVICESTATE$：服务状态描述，三个可能：w，u，c$SERVICEDESC$：对当前服务的描述 联系人宏$CONTACTNAME$：联系人名，在联系人文件中定义 通知宏$NOTIFICATIONTYPE$：返回状态信息。 日期宏$LONGDATETIME$：当前日期，时间戳 文件宏$LOGFILE$：日志文件保存位置$MAINCONFIGFILE：主配置文件保存位置 其他宏$ADMINMAIL$：管理员E-mail地址$ARGn$：第n个命令参数，n是数字。最多支持32个参数宏。 commands.cfg定义命令。123456define command &#123; command_name check-host-alive # 命令名 # 命令执行 command_line $USER1$/check_ping -H $HOSTADDRESS$ -w 3000.0,80% -c 5000.0,100% -p 5 # 调用插件check_ping，-w为warning警告状态，-c为紧急，80%表示ping的临界值。-p 5表示每次发5个ping包&#125; hosts.cfg默认不存在，定义主机。123456789101112define host &#123; use linux-server # 引用templates.cfg中linux-server的配置 host_name web # 主机名 alias web-system5 # 别名 address 192.168.163.137 # IP地址&#125;define hostgroup &#123; hostgroup_name web-servers # 主机组名 alias web-servers # 别名 members web # 组成员（填host_name，逗号分隔）&#125; services.cfg默认不存在，定义服务。123456789101112define service &#123; use local-service # 引用templates.cfg中local-service的配置 host_name web # 主机名 service_description ping # 服务描述 check command check_ping..... #引用命令&#125;define servicegroup &#123; # 服务组，配置类似主机组 servicegroup_name alias members &#125; contacts.cfg定义联系人。1234567891011define contact &#123; contact_name # 联系人名 use # 使用templates.cfg中指定模板信息 alias email # 联系人邮箱&#125;define contactgroup &#123; contactgroup_name # 联系人组名 alias members&#125; timeperiods.cfg定义监控时段。123456789101112131415define timeperiod &#123; name 24x7 #定义时段名 # 之前host和service中的24x7就是引用这里定义的时段名 timeperiod_name 24x7 alias 24 Hours A Day, 7 Days A Week # 定义监控时间，若某天不监控则不要写那天 sunday 00:00-24:00 monday 00:00-24:00 tuesday 00:00-24:00 wednesday 00:00-24:00 thursday 00:00-24:00 friday 00:00-24:00 saturday 00:00-24:00&#125; cgi.cfg控制cgi脚本。用于在web界面执行cgi脚本，如重启nagios进程、关闭通知、停止检测等。以下为修改权限涉及的参数12345678default_user_name=guestauthorized_for_system_information=nagiosadmin # 验证系统信息authorized_for_configuration_information=nagiosadmin # 验证配置信息authorized_for_system_commands=nagiosadmin # 验证系统命令authorized_for_all_services=nagiosadmin # 验证所有服务authorized_for_all_hosts=nagiosadmin # 验证所有主机authorized_for_all_service_commands=nagiosadmin # 验证所有服务命令authorized_for_all_host_commands=nagiosadmin # 验证所有主机命令 nagios.cfgNagios的核心配置文件，所有配置文件必须在此文件中引用才有作用。1234567891011121314151617181920log_file=/usr/local/nagios/var/nagios.log # 日志文件路径cfg_file=/usr/local/nagios/etc/objects/commands.cfgcfg_file=/usr/local/nagios/etc/objects/contacts.cfgcfg_file=/usr/local/nagios/etc/objects/timeperiods.cfgcfg_file=/usr/local/nagios/etc/objects/templates.cfgcfg_file=/usr/local/nagios/etc/objects/localhost.cfg# 继续添加配置文件即可启用指定配置文件。# 也可以直接将文件放入一个目录，然后通过cfg_dir=指定object_cache_file=/usr/local/nagios/var/objects.cache # 指定一个所有对象配置文件的副本文件，也称为对象缓冲文件。# nagios会将所有对象文件的内容都写入该文件resource_file=/usr/local/nagios/etc/resource.cfg # 指定nagios资源文件的路径，可在nagios.cfg定义多个资源文件status_file=/usr/local/nagios/var/status.dat # 指定状态文件，用于保存nagios当前状态、注释、宕机信息等status_update_interval=10 # 状态文件的更新周期，单位秒，最小1秒nagios_user=nagios # nagios进程所属用户nagios_group=nagios # nagios进程所属用户组check_external_commands=1 # 是否允许nagios在web界面执行cgi命令interval_length=60 # 指定nagios时间单位，默认60s，即nagios配置中所有 时间单位为分钟 Nagios监控界面解析左侧菜单栏中Current Status目录如下123456789101112Tactical Overview 总览Map 拓扑图Hosts 主机Services 服务Host Groups 主机组- Summary 汇总- Grid 表格Service Groups 服务组，也分为汇总和表格Problems 问题故障- Service(Unhandled) 未解决的服务故障- Hosts(Unhandled) 未解决的主机故障- Network Outages 网络整体 Reports目录如下：12345678Availability 可用性Trends 趋势Alerts 报警- History 历史- Summary 汇总- Histogram 历史图Notification 通知Event Log 事件日志 System目录如下：123456Comments 注释Downtime 停机计划Process Info 进程信息Performance Info 性能查询Scheduling Queue 定时查询Configuration 配置 常用操作Nagios对主机和服务有几个描述的状态 Hosts Up启动（绿） Down未启动（红） Unreachable不可达（黄） Pending等待（灰色） Services Ok正常（绿） Warning警告（黄） Unknown未知（橙） Critical紧急（红） Pending等待（灰） Nagios性能分析图表 需要安装pnp软件包，基于PHP和Perl，利用rrdtool工具将nagios收集的数据绘制成图表。pnp官网首先，需要安装gd库、zlib库、jpeg库yum install gd gd-devel zlib zlib-devel jpeg*接着安装rrdtool工具yum install rrdtool*安装perl环境yum install perl最后去pnp官网下载源码包安装12345678910111213141516171819202122232425262728./configure \ --with-nagios-user=nagios \ --with-nagios-group=nagios \ --with-rrdtool=/usr/bin/rrdtool \ --with-perfdata-dir=/usr/local/nagios/share/perfdatamake all \ &amp;&amp; make install \ &amp;&amp; make install-config \ &amp;&amp; make install-init \ &amp;&amp; make install-webconf或者直接make fullinstall（包含以上所有make） General Options: ------------------------- ------------------- Nagios user/group: nagios nagios Install directory: /usr/local/pnp4nagios HTML Dir: /usr/local/pnp4nagios/share Config Dir: /usr/local/pnp4nagios/etc Location of rrdtool binary: /usr/bin/rrdtool Version 1.7.0 RRDs Perl Modules: FOUND (Version 1.6999) RRD Files stored in: /usr/local/nagios/share/perfdata process_perfdata.pl Logfile: /usr/local/pnp4nagios/var/perfdata.log Perfdata files (NPCD) stored in: /usr/local/pnp4nagios/var/spool Web Interface Options: ------------------------- ------------------- HTML URL: http://localhost/pnp4nagios Apache Config File: /etc/httpd/conf.d/pnp4nagios.conf 安装完后，将/usr/local/pnp4nagios的所有者和所属组都改为nagios 配置pnp将/usr/local/pnp4nagios/share目录下所有文件复制到/usr/local/nagios/share/pnp中。将/usr/local/pnp4nagios/etc中npcd.cfg、rra.cfg、process_perfdata.cfg后面的-sample去除（如果有的话）。 首先修改process_perfdata.cfg。12345# 指定日志路径LOG_FILE = /usr/local/pnp4nagios/var/perfdata.log# 日志输出级别，默认为0，最好改为2，即debugLOG_LEVEL = 2# 三个等级：0==slient 1==normal 2==debug 然后将pnp与nagios进行整合，对templcates.cfg配置，添加以下定义。1234567891011121314define host &#123; name hosts-pnp register 0 action_url /nagios/pnp/index.php?host=$HOSTNAME$ process_perf_data 1&#125;define service &#123; name services-pnp register 0 action_url /nagios/pnp/index.php?host=$HOSTNAME$&amp;srv=$SERVICEDESC$ process_perf_data 1&#125;# 注：必须在不应处理其性能数据的每个主机或服务的定义中禁用数据处理（process_perf_data 设为0）。 然后在hosts.cfg和services.cfg和localhost.cfg中要进行数据分析的服务或主机的name参数后加上hosts-pnp或service-pnp，如下：123456define service &#123; use local-service,serviecs-pnp host_name web service_description ping check command check_ping..... &#125; 修改nagios.cfg123456789101112131415161718192021# 开启Nagios数据输出。会将收集到的数据写入文件process_performance_data=1# 取消注释，启用主机和服务的输出功能host_perfdata_command=process-host-perfdata service_perfdata_command=process-service-perfdatahost_perfdata_file=/usr/local/pnp4nagios/var/host-perfdataservice_perfdata_file=/usr/local/pnp4nagios/var/service-perfdatahost_perfdata_file_template=[HOSTPERFDATA]\t$TIMET$\t$HOSTNAME$\t$HOSTEXECUTIONTIME$\t$HOSTOUTPUT$\t$HOSTPERFDATA$service_perfdata_file_template=[SERVICEPERFDATA]\t$TIMET$\t$HOSTNAME$\t$SERVICEDESC$\t$SERVICEEXECUTIONTIME$\t$SERVICELATENCY$\t$SERVICEOUTPUT$\t$SERVICEPERFDATA$host_perfdata_file_mode=aservice_perfdata_file_mode=ahost_perfdata_file_processing_interval=0service_perfdata_file_processing_interval=0host_perfdata_file_processing_command=process-host-perfdata-fileservice_perfdata_file_processing_command=process-service-perfdata-file 修改commands.cfg1234567891011define command &#123; command_name process-host-perfdata-file # 将原来的command_line注释，改为如下参数 command_line /usr/local/pnp4nagios/libexec/process_perfdata.pl --bulk=/usr/local/pnp4nagios/var/host-perfdata&#125;define command &#123; command_name process-service-perfdata-file # 将原来的command_line注释，改为如下参数 command_line /usr/local/pnp4nagios/libexec/process_perfdata.pl --bulk=/usr/local/pnp4nagios/var/service-perfdata&#125; 重启nagios和httpd进入web端，点击左侧菜单services。进入如下页面 点击红框框出的图标，即可进入pnp测试界面 若全部通过，便会提示删除或重命名/usr/local/nagios/share/pnp/install.php。于是将该php文件删除。rm -f /usr/local/nagios/share/pnp/install.php 如果在点击pnp图标时，出现以下报错： 则需要检查nagios.cfg和commands.cfg配置文件，查看commands.cfg配置可知command_name为process-host-perfdata的默认存放路径bulk为/usr/local/pnp4nagios/var/host-perfdata，同理，process-service-perfdata的存放路径为/usr/local/pnp4nagios/var/service-perfdata。 而在nagios.cfg中host_perfdata_file默认路径为/usr/local/nagios/var/host-perfdata，service_perfdata_file默认路径为/usr/local/nagios/var/service-perfdata，两个文件不一致，导致pnp4nagios无法获取。 将nagios.cfg的两条配置，改为与commands.cfg的一致即可 12host_perfdata_file=/usr/local/pnp4nagios/var/host-perfdataservice_perfdata_file=/usr/local/pnp4nagios/var/service-perfdata 邮件告警配置先安装sendmail或postfix，安装完后开启。本篇使用sendmail服务。使用mail命令发送测试邮件。若没有mail命令，需要先下载mailx软件mail -s test XXXX@XX.com输入内容完后ctrl+d结束。 关于邮件告警主要涉及以下几个文件： templates.cfg 12345678910111213其中有关于contact的定义define contact &#123; name generic-contact service_notification_period 24x7 host_notification_period 24x7 service_notification_options w,u,c,r,f,s host_notification_options d,u,r,f,s service_notification_commands notify-service-by-email host_notification_commands notify-host-by-email register 0 &#125;# 发送服务通知使用的是notify-service-by-email命令 发送主机同时使用的是notify-host-by-email命令 于是查找commands.cfg文件 1234567891011如果不成功，一定要注意到此文件中发送通知的命令默认使用sendmail命令，若主机没有就不可能发送成功。需要替换为mail或mailx。还要注意这两个命令的目录，是/bin还是/sbindefine command &#123; command_name notify-host-by-email command_line /usr/bin/printf &quot;%b&quot; &quot;***** Nagios *****\n\nNotification Type: $NOTIFICATIONTYPE$\nHost: $HOSTNAME$\nState: $HOSTSTATE$\nAddress: $HOSTADDRESS$\nInfo: $HOSTOUTPUT$\n\nDate/Time: $LONGDATETIME$\n&quot; | /usr/bin/mail -s &quot;** $NOTIFICATIONTYPE$ Host Alert: $HOSTNAME$ is $HOSTSTATE$ **&quot; $CONTACTEMAIL$&#125;define command &#123; command_name notify-service-by-email command_line /usr/bin/printf &quot;%b&quot; &quot;***** Nagios *****\n\nNotification Type: $NOTIFICATIONTYPE$\n\nService: $SERVICEDESC$\nHost: $HOSTALIAS$\nAddress: $HOSTADDRESS$\nState: $SERVICESTATE$\n\nDate/Time: $LONGDATETIME$\n\nAdditional Info:\n\n$SERVICEOUTPUT$\n&quot; | /usr/bin/mail -s &quot;** $NOTIFICATIONTYPE$ Service Alert: $HOSTALIAS$/$SERVICEDESC$ is $SERVICESTATE$ **&quot; $CONTACTEMAIL$&#125; 最后通过contacts.cfg设置联系人，在email中填写自己的邮箱 123456define contact &#123; contact_name nagiosadmin use generic-contact alias Nagios Admin email XXXX@XX.com&#125; 当服务出现重启或故障时，系统会自动发送邮件。 参考资料 Nagios配置安装详解使用 Nagios 搭建监控服务器Nagios官方文档Pnp官方配置文档Nagios 监控系统架设全攻略CentOS7安装nagios并配置出图详解2017年11月最新Nagios4.3.4部署高性能Linux服务器构建实战：运维监控、性能调优与集群应用]]></content>
      <tags>
        <tag>运维</tag>
        <tag>监控</tag>
        <tag>Nagios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible基础学习笔记]]></title>
    <url>%2F2018%2F05%2F28%2FAnsible%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容 Ansible结构 Ansible安装 Inventory 动态Inventory Ansible常见模块 Playbook Jinja2过滤器 Ansible结构Ansible具有以下核心组件： ansible core：ansible核心程序 Host Inventory：主机信息文件 Playbooks：剧本，用于简便管理主机 Core Modules：核心模块，Ansible通过模块进行管理 Custom Modules：自定义模块，补充核心模块的功能 Connection Plugins：连接插件，用于Ansible和主机的通信 Plugins：其他各种插件，提供连接或功能接口 Ansible特性： 基于Python实现，有三个关键模块：Paramiko（ssh连接插件）、PyYAML（YAML语言）、jinja2（定义模板，即Playbook） 部署简单，轻量级，无需在客户端安装agent，去中心化 默认使用SSH。1.基于密钥 2.在inventory文件指定密码 支持自定义模块，支持各种编程语言 主从模式master和slave 使用playbook进行主机管理 幂等性：一种操作重复多次结果相同，只需运行一次playbook就可将需要配置的机器都置为期望状态，同一台机器多次执行一个playbook是安全的 Ansible是模块化的，通过调用模块来实现管理 支持多层部署，可通过VM和容器为多层应用程序的部署配置提供支持 为架构的多个层次带来一致性，借助Ansible可通过编程操作计算架构中从基础设施到应用程序的每一层 Ansible支持异构IT环境，支持Windows和Linux及多个硬件平台和云平台 实验系统CentOS-7主节点服务器：192.168.163.102从节点服务器：192.168.163.103 Ansible安装首先安装epel-release，能够获得更多的Ansible包资源。 yum install epel-release然后安装Ansible yum install ansible Ansible有以下配置文件： /etc/ansible/ansible.cfg 主配置文件 /etc/ansible/hosts Inventory配置文件 Ansible配置以ini格式存储数据，Ansible几乎所有配置都可通过Playbook或环境变量重新赋值。当运行Ansible命令时，会按照以下顺序查找并读取配置文件。 ANSIBLE_CONFIG：环境变量指定的路径 ./ansible.cfg：当前目录的ansible.cfg配置文件 ~/ansible.cfg：家目录的ansible.cfg配置文件 /etc/ansible/ansible.cfg：ansible主配置文件 Ansible主配置文件中的几个重要参数1234567891011inventory = /root/ansible/hosts # inventory文件的位置library = /usr/share/my_modules/ # ansible模块位置forks = 5 # 默认情况下Ansible最多能有多少个进程同时工作，默认5个进程并行处理。 # 可以根据控制端性能和被管理节点的数量来确定sudo_user = root # 默认执行命令的用户remote_port = 22 # 指定连接被管理节点的管理端口，默认是22host_key_checking = False # 是否检查SSH主机的密钥timeout = 20 # SSH连接的超时间隔，单位：秒log_path = /var/log/ansible.log # Ansible默认不记录日志# 若开启了日志，则要通过该参数设置日志文件路径# 模块将会调用被管节点的rsyslog来记录，执行Ansible的用户需要有写入日志的权限 Ansible提供文档命令可查看指定的用法说明ansible-doc命令用于查看Ansible帮助文档123-h 查看帮助-l 列出所有Ansible模块-s &lt;module&gt; 查找指定模块的用法 公钥认证Ansible默认开启公钥认证，Ansible主节点应该与所有要管理的节点进行ssh验证。主要使用以下命令：12ssh-keygen 创建密钥对ssh-copy-id -i ~/.ssh/id_rsa.pub root@&lt;节点IP地址&gt; 然后在/etc/ansible/hosts添加该节点的IP地址 如果有个主机重新安装并在/home/.ssh/known_hosts文件中中有了不同的key，就会一直提示错误。若节点主机未进行公钥认证，即没有在该文件中初始化，则每次使用ansible命令时都会要求确认key信息。 若要禁用ansible确认密钥的行为，可在主配置文件中参数host_key_checking = False设置，也可以通过环境变量ANSIBLE_HOST_KEY_CHECKING=False设置。 ansible主命令1234567ansible &lt;host-pattern&gt; # host-pattern可填inventory的组名，ip地址，all（所有主机） # 一些简单常用参数 -f 设置一次处理的主机个数 -m 设置使用的模块 -a 模块的参数 -i 指定inventory文件 InventoryAnsible可同时操作属于一个组的多台主机,组和主机之间的关系通过inventory文件配置，默认的文件路径为/etc/ansible/hosts。inventory文件遵循INI文件风格，方括号[]中是组名,用于对系统进行分类,便于对不同系统进行个别的管理。一个系统可以属于不同的组，属于两个组的变量都可以为这台主机所用。组名可自定义。 1234567891011121314151617181920212223242526272829# 可以直接写要管理的主机IP地址或域名192.168.163.103#也可设置管理组[test]192.168.163.103system[1:5].example.com# 数字简写模式，表示system1--sysetm5# 也支持字母简写，system[a:f].example.com# 可对每个服务器设置连接类型和连接用户名localhost ansible_connection=localsystem3.example.com ansible_connection=ssh ansible_ssh_user=ansible# 可定义变量，可使用变量定义的配置主机变量host1 http_port=80 maxRequestsPerChild=808# 也可定义组变量[test:vars]ntp_server=ntp.example.com# 还可组嵌套，即在其他组中引用一个组# 这些变量可以给ansible-playbook使用,但不能给ansible使用。[team1]host1[team2]host2[test:hosts]team1team2 当Inventory中存在有效主机时，ansible就默认隐式地可以使用localhost作为本机，但inventory中没有任何主机时是不允许使用它的，且all或*所代表的所有主机也不会包含localhost。 一些常见的Inventory参数：123456789101112ansible_ssh_host # ansible使用ssh要连接的主机ansible_ssh_port # ssh的端口。默认为22ansible_ssh_user # ssh登录的用户名。默认为rootansible_ssh_pass # ssh登录远程用户时的认证密码 # 不安全，最好使用 --ask-passansible_sudo_pass # sudo命令输入的root密码（当使用非root用户操作时） # 不安全，最好使用 --ask-sudo-passansible_connection # 连接远程主机使用的模式，默认为smart智能模式 # smart：若本地ssh支持持久连接时采用ssh连接，否则采用python的paramiko ssh连接ansible_ssh_private_key_file # ssh登录远程用户时的认证私钥ansible_shell_type # 指定远程主机执行命令时的shell解析器，默认为shansible_python_interpreter # 远程主机上的python解释器路径。默认为/usr/bin/python Inventory配置文件可以有多个，且可以通过Dynamic Inventory来动态生成只需在ansible的主配置文件中将inventory参数设置为对应的文件或目录即可，如果是目录，那么此目录下的所有文件都是inventory文件。 可创建多个独立文件用于保存变量，然后在主文件中引用注：这些独立文件的格式为YAML在独立文件/etc/ansible/group_vars/servers中添加123---ntp_server: ntp.example.comdatabase_server: system2.example.com 然后在inventory文件中指定该文件/etc/ansible/group_vars/servers可以为一个主机，或一个组，创建一个目录，目录名就是主机名或组名。目录中的可以创建多个文件，文件中的变量都会被读取为主机或组的变量。 动态InventoryAnsible Tower提供了一个数据库来存储inventory配置信息，这个数据库可以通过web访问，或通过REST访问。Tower与所有使用的Ansible动态inventory源保持同步，并提供了一个图形化的inventory编辑器。 Ansible常见模块cron1234567891011121314151617181920cron 计划任务模块 month # 指定月份 minute # 指定分钟 job # 指定任务（需要state=present） day # 指定小时 hour # 指定小时 weekday # 周几 name # 指定名称（默认为*） user # 使用的用户身份去执行 special_time # 指定执行的时间 reboot # 重启时 yearly # 每年 # 还有annually monthly weekly daily hourly state # 添加或删除 present # 安装 absent # 移除 backup # 对远程主机上原有任务计划做备份 cron_file # 使用指定文件替换远程主机上/etc/cron.d/中的任务计划 例：ansible webserver -m cron -a &apos; minute=&quot;*/10&quot; job=&quot;/bin/echo hello&quot; name=&quot;test&quot; state=present &apos; user123456789101112131415161718user 用户账号管理 name # 用户名 uid # UID state # 状态 present # 添加 absent # 移除 password # 设置密码 group # 所属组 groups # 附加组（用逗号分隔） home # 家目录 createhome # 是否创建家目录 comment # 注释 system # 是否设为系统用户 generate_ssh_key=yes # 是否加密密码 ssh_key_bits=2048 # 加密密钥长度 ssh_key_file=.ssh/id_rsa # 密码文件 注：指定password参数时，不能使用后面这一串密码会被直接传送到被管理主机的/etc/shadow文件中，所以需要先将密码字符串进行加密处理。然后将得到的字符串放到password中即可。 默认加密方式是根据/etc/login.defs的ENCRYPT_METHOD指定，默认为SHA512 group12345group 组管理 gid # GID name # 组名 state # 状态 system # 是否是系统组 copy123456789101112131415copy 复制文件，类似scp，需要关闭所有机器的selinux，否则会报错 src # 本地源路径 dest # 远程主机目标路径 owner # 指定拥有者 group # 指定所属组 mode # 设置权限 content # 取代src=，表示直接用此处信息生成文件内容 backup # 在覆盖前备份原文件，两个选项（yes | no） directory_mode # 递归设置目录权限，默认为系统默认权限 force # 用于设置当目标主机包含该文件，但内容不同时的操作 # 若设置为yes，则强制覆盖，若为no，则只有当目标主机的目标位置不存在该文件时，才复制。 # 默认为yes# 所有的file模块里的选项都可以在这里使用# 若出现了有关selinux的报错，可在被控机上安装libselinux-python解决# ansible all -m yum template用法和copy模块用法基本一致，主要用于复制配置文件。123456789101112template backup # 拷贝的同时也创建一个包含时间戳信息的备份文件，默认为no dest= # 目标路径 force # 设置为yes (默认)时，将覆盖远程同名文件。设置为no时，忽略同名文件的拷贝 group # 设置远程文件的所属组 owner # 设置远程文件的所有者 mode # 设置远程文件的权限。使用数值表示时不能省略第一位，如0644。 # 也可以使用&apos;u+rwx&apos;或&apos;u=rw,g=r,o=r&apos;等方式设置 src= # ansible控制器上Jinja2格式的模板所在位置，可以是相对或绝对路径 validate # 在复制到目标主机后但放到目标位置之前，执行此选项指定的命令。 # 一般用于检查配置文件语法，语法正确则保存到目标位置。 # 如果要引用目标文件名，则使用%s，下面的示例中的s%即表示目标机器上的/etc/nginx/nginx.conf。 file12345678910111213141516171819file 设置文件属性 path # 设置文件路径（必填） dest # 设置目的路径 name # 设置文件名 owner # 指定拥有者 group # 指定所属组 mode # 设置权限 recurse # 递归设置目录属性 state # 文件状态 file # 文件不存在就不会被创建 dictionary # 若目录不存在，就自动创建 link # 创建软连接 hard # 创建硬链接 touch # 若不存在就自动创建 absent # 删除文件或目录 src # 指定源文件，只应用于state=link的情况 force # 强制创建软链接。 # 两种情况：1.当源文件不存在，但之后会建立 2.要先取消已创建的软链接，再重新创 service123456789101112131415service 管理服务运行状态 enabled # 是否开机自启（yes| no） name # 指定服务名（必填） state # 指定服务状态 started # 启动 stoped # 停止 restarted # 重启 reloaded # 重新加载 arguments # 服务参数 pattern # 设置模式 # 通过status指令来查看服务的状态时 # 若没有响应，就会通过ps指令在进程中根据该模式进行查找 # 如果匹配到，则认为该服务依然在运行 runlevel # 运行级别 sleep # 若执行restarted，则在stop和start键沉睡几秒 command若不指定模块，则默认使用command模块。command模块不能解析变量(如$HOME)和某些操作符(“&lt;”, “&gt;”, “|“, “;”以及”&amp;”)，若需要使用以上符号，就要用shell模块。12345command chdir # 在执行定义的命令前进入指定目录 creates # 创建文件，参数为一个文件或一个glob表达式，若已经存在就不会执行 removes: # 删除文件，参数为一个文件或一个glob表达式，若不存在就不会执行 stdin: # 可要求输入读取指定值 shell12shell 在远程主机上运行命令，一般要使用管道符语法时，会使用shell模块。与raw模块类似 例：ansible all -m shell -a &apos;echo hello&apos; script12script 将本地脚本复制到远程主机并运行 例：ansible all -m script -a &apos;/tmp/a.sh&apos; yum12345678910yum 安装程序包 config_file # yum的配置文件 disable_gpg_check # 关闭gpg_check disablerepo # 不启用某个源 enablerepo # 启用某个源 name # 程序包名 state # 设置状态 present # 安装 latest # 安装 absent # 卸载 注：yum模块是基于python2，若要基于python3安装，需要模块dnf。否则会以下报错：1234 192.168.163.103 | FAILED! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;The Python 2 bindings for rpm are needed for this module. If you require Python 3 support use the `dnf` Ansible module instead.. The Python 2 yum module is needed for this module. If you require Python 3 support use the `dnf` Ansible module instead.&quot;&#125; 也可通过command模块直接安装：ansible 主机 -m command -a &#39;yum -y install 软件&#39; dnf类似yum，但由于yum基于python2，若有依赖于python3的软件包则会报错，因此可用dnf代替，并且dnf的安装速度都有提升。常用参数与yum一致。 setup1234setup 收集远程主机的facts，获取主机信息 # 每个被管理节点在接受并运行管理命令前，会将自己主机相关信息（如操作系统信息，IP地址等报告给ansible） filter # 过滤器（正则表达式） 例：ansible 192.168.163.103 -m setup -a &apos;filter=ansible_eth[0-2]&apos; synchronize1234567891011121314synchronize 使用rsync同步文件 archive # 归档，相当于同时开启recursive(递归)、links、perms、times、owner、group、-D选项都为yes ，默认该项为开启 checksum # 跳过检测sum值，默认关闭 compress # 是否开启压缩，默认yes copy_links # 复制链接文件，默认为no ，注意后面还有一个links参数 delete # 删除不存在的文件，默认no dest # 目录路径 dest_port # 默认目录主机上的端口 ，默认是22，走的ssh协议 dirs # 传速目录不进行递归，默认为no，即进行目录递归 rsync_opts # rsync参数部分 set_remote_user # 主要用于/etc/ansible/hosts中定义或默认使用的用户-与rsync使用的用户不同的情况 mode # push或pull 模块 # push模式一般用于从本机向远程主机上传文件 # pull 模式用于从远程主机上取文件 mount1234567891011mount 设置挂载点 dump fstype # 必选项，挂载文件的类型 name # 必选项，挂载点 opts # 传递给mount命令的参数 src # 必选项，要挂载的文件 state # 必选项present：只处理fstab中的配置 present # 只处理fstab中的配置 absent # 删除挂载点 mounted # 自动创建挂载点并挂载 umounted # 卸载 get_url1234567get_url 用于从http、ftp、https服务器上下载文件（类似于wget） sha256sum # 下载完成后进行sha256 check； timeout # 下载超时时间，默认10s url # 下载的URL dest # 本地存放路径 url_password/url_username # 主要用于需要用户名密码进行验证的情况 use_proxy # 是事使用代理，代理需事先在环境变更中定义 Playbook一个简单的配置管理和多主机部署系统。Playbook是由一个或多个“Plays”组成的列表。将事先归为一组的主机装扮为通过Ansible的任务Task定义好的角色。任务也就是调用Ansible的模块将多个“play”组织到一个playbook中。playbook的模板使用Python的jinja2模块处理。 Playbook的组成： Inventory Modules Ad Hoc Commands Playbooks，包含四个部分12345Tasks：任务，即调用模块完成的某操作Variables：变量Template：模板Handlers：处理器，由某事件触发执行的操作Roles：角色 playbook基本组件play的主体部分是task list，task list中各个任务按次序逐个在hosts指定的主机上运行，即在所有主机上完成第一个任务后再按顺序完成第二个，若中途某个主机出现错误，则所有执行的任务都可能回滚。 建议每个任务都定义一个name标签，且每个task执行一个模块123456789- hosts: test # 指定主机组，也可指定单个主机 remote_user: root # 指定远程主机上执行任务的用户（也可用于各个task中） sudo: yes # sudo执行命令，也可在task中添加 sudo_user: # sudo身份 tasks: # 任务列表 - name: install latest apache yum: name=httpd state=latest - name: run apache service: name=httpd state=started # 运行service模块，后面跟上参数选项 命令解析ansible-playbook对yaml文件进行执行123456789ansible-playbook [选项] yml文件 -f # 指定并行进程数，默认为5 -e 或 --extra-vars= # 设置额外的环境变量 --flush-cache # 清空收集到的facts缓存 --list-tasks # 列出所有将被执行的tasks --list-tags # 列出所有可获得的tags --step # 每执行一步都进行交互式确认 --syntax-check # 检查playbook语法 --list-hosts # 列出执行该playbook会影响的主机 ansible-pull拉取指定主机的配置 变量引用12345678910- hosts: test vars: service: httpd package: httpd tasks: - name: install latest apache # 若要通过上面定义的变量引用，则需要两对大括号调用 yum: name=&#123;&#123;package&#125;&#125; state=latest - name: run apache service: name=&#123;&#123;service&#125;&#125; state=started 简单试验分析：12345678910111213141516171819202122232425262728293031323334353637创建test.yml- hosts: system3 tasks: - name: echo hello command: &apos;echo hello&apos; - name: create user user: name=apache password=redhat state=present uid=1003root@system2 ~ &gt; ansible-playbook test.ymlPLAY [system3] *****************************************************************TASK [Gathering Facts] *********************************************************ok: [192.168.163.103]TASK [echo hello] **************************************************************changed: [192.168.163.103]TASK [create user] *************************************************************changed: [192.168.163.103]PLAY RECAP *********************************************************************192.168.163.103 : ok=3 changed=2 unreachable=0 failed=0 # changed说明发生了改变。# 若再次执行一遍，会出现以下改变TASK [echo hello] **************************************************************changed: [192.168.163.103]TASK [create user] *************************************************************ok: [192.168.163.103]PLAY RECAP *********************************************************************192.168.163.103 : ok=3 changed=1 unreachable=0 failed=0 # 创建用户不再是changed，而是ok，而输出打印hello仍然为changed。# 因为用户已创建了，就不会再创建，这体现了playbook的幂等性。而打印文字并不符合只需要执行一遍的特性。 notify与handler当远端发生改动时，playbooks本身可以识别这种改动,并且有一个基本的事件系统,可以响应这种改动。notify会在playbook的每一个task结束时触发,即使有多个不同的task通知发生了改动，notify只会被触发一次。Handlers也是task的列表，若notify有定义，则handlers一定要有对应的处理方法。handlers主要用在重启服务，或系统重启。1234567891011- hosts: test tasks: - name: install apache yum: name=httpd state=latest notify: yum error # 关注可能发生的错误（不一定是错误），类似抛出异常 # 若notify有多个，可通过列表定义 - yum error - httpd error # 定义了多个，则handler也要有对应处理 handlers: # 当关注的资源发生变化时采取的措施 - name: yum error # 当有notify抛出，也要有对应的解决方案，name要与对应的notify的名字一致。 service: name=httpd state=restarted 条件测试当需要根据变量等信息判断是否需要执行某task时，则需要条件判断123456789101112131415161718192021tasks: - name: echo hello command: echo hello when: ansible_fqdn == &apos;system3.example.com&apos;# 在task后添加when子句即可进行条件测试，when语句支持jinja2语法# when语句中还能使用Jinja2的很多&apos;filter&apos;执行结果：TASK [Gathering Facts] *********************************************************ok: [192.168.163.104]ok: [192.168.163.103]TASK [echo hello] **************************************************************skipping: [192.168.163.104]changed: [192.168.163.103]PLAY RECAP *********************************************************************192.168.163.103 : ok=2 changed=1 unreachable=0 failed=0192.168.163.104 : ok=1 changed=0 unreachable=0 failed=0# 经过判断system4不满足when条件，所以skipping跳过，而system3满足，所以changed 迭代重复同类的task时使用。item定义迭代，with_items定义循环列表。with_items中的列表值可以使字典，若是字典，引用时要使用item.键名12345678910111213141516列表形式- apache- php字典形式- &#123;name: apache, conf: /etc/httpd.conf&#125;- &#123;name: php, conf: /etc/php.ini&#125;试验：- name: create user user: name=&#123;&#123;item&#125;&#125; state=present with_items: - zhangsan - lisi就相当于 user: name=zhangsan state=present user: name=lisi state=present 模板通过配置模板，可将配置文件中的参数按照inventory文件中变量以及ansible facts中变量动态赋值，使得每个指定的主机的配置都是定制的。首先要创建一个templates目录。mkdir /etc/ansible/templates将配置文件放入该目录，并最好改名为xxx.conf.j212345678910111213141516171819202122232425262728293031323334以httpd为例，修改配置文件/etc/ansible/templates/httpd.conf.j2Listen &#123;&#123; http_port &#125;&#125; # 使用inventory定义变量User &#123;&#123; username &#125;&#125; # 同上Group &#123;&#123; groupname &#125;&#125; # 同上ServerName &#123;&#123; ansible_fqdn &#125;&#125; # 使用facts变量然后修改/etc/ansible/hosts文件[test]192.168.163.103 http_port=8081 username=system3 groupname=system3 192.168.163.104 http_port=8082 username=system4 groupname=system4 然后在playbook中将本地的配置文件复制到远端，以下是完整试验- hosts: test vars: service: httpd tasks: - name: alter config template: src=/etc/ansible/templates/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf notify: - restart httpd - name: start httpd service: name=&#123;&#123; service &#125;&#125; enabled=true state=started handlers: - name: restart httpd service: name=&#123;&#123; service &#125;&#125; state=restarted执行ansible-playbook test.yml。之后查看103和104主机的httpd配置文件system3和system4上，httpd配置文件都更改成功。以下为system3上的配置Listen 8081Include conf.modules.d/*.confUser system3Group system3ServerAdmin root@localhostServerName system3.example.com tags标签可以为playbook中的每个任务都打上标签，标签的主要作用是可以在ansible-playbook中设置只执行被打上tag的任务或忽略被打上tag的任务。123456789tasks:- name: install apache yum: name=httpd state=present tags: apache- name: install mysql yum: name=mysql-server state=present tags: mysql当执行playbook时，可通过--tags= 运行打上指定tag的taskansible-playbook test.yml --tags=&quot;apache&quot; 则只运行安装打上apache标签的task include和roles如果把所有play都写在一个playbook中，会导致文件不易阅读。ansible可以将多个不同任务分别写在不同的playbook中，然后使用include将其包含进去。roles也是一种整合playbook的方式。 include使用include语句引用task文件的方法，可允许你将一个配置策略分解到更小的文件中，将tasks从其他文件拉取过来（handlers也是tasks）。即include可以导入两种文件：导入task、导入playbook。12345678910111213141516171819202122232425导入task：创建一个单独的yml配置文件，a.yml--- - name: echo hello command: echo &apos;hello&apos; - name: echo value command: echo &#123;&#123;value&#125;&#125;在主playbook中便可通过include引用该文件- hosts: test tasks: - include: a.yml value=&apos;hello&apos; # 可以直接在文件名后传参数 # 也可以通过vars传参 tasks: - include: a.yml vars: value: hello导入playbook：并不在task中通过include调用yml了，而是直接在最外层导入playbook- hosts: test.....- include: test1.yml- include: apache.yml http_port=8000 # 传参方式与上面一样 roles角色，封装playbook，实现复用性，能够根据层次型结构自动加载变量文件、tasks以及handlers等。roles就是通过分别将变量、文件、任务、模板以及处理器放置于单独的目录中，然后通过include调用的一种机制。roles一般用于基于主机构建服务的场景中，也可以使用于构建守护进程的场景中。 创建role的步骤： 在playbooks目录中创建roles目录 在roles目录中创建角色名的目录 在每个角色命令的目录中创建files、handlers、meta、tasks、templates、vars目录。若用不到的目录也可不创 在playbook中调用各角色 roles中各目录： tasks目录：至少包含一个main.yml，其定义了此角色的任务列表，此文件可用include包含其他task目录 files目录：存放有copy或script等模块调用的文件 templates目录：template模块会自动在此文件中寻找jinja2模板 handlers目录：此目录中应包含一个main.yml，定义此角色用到的handler yml文件：用于定义此角色用到的个handler， vars目录：应包含一个main.yml，定义此角色用到的变量 meta目录：应包含一个main.yml，定义此角色的特殊设定和依赖关系 default目录：应包含一个main.yml，为当前角色设定默认变量时使用此目录 案例目录结构123456789101112131415roles├── test1│ ├── files│ ├── handlers│ ├── meta│ ├── tasks│ ├── templates│ └── vars└── test2 ├── files ├── handlers ├── meta ├── tasks ├── templates └── vars 将要编写的task文件存放在tasks目录中，编写main.yml。将httpd的配置文件复制到files目录中。1234567891011- name: install httpd yum: name=httpd state=present- name: install config copy: src=httpd.conf dest=/etc/httpd/conf/httpd.conf # 这里copy的源可直接写文件名，会自动定位到files目录中 tags: - conf notify: - restart httpd- name: start httpd service: name=httpd state=started 然后在handlers中添加handler文件，在目录中创建main.yml12- name: restart httpd service: name=httpd state=restarted 在于roles平级的目录中创建site.yml文件（名字可自定义），就是主配置文件。roles后面也可跟上参数，也可跟上条件判断。1234567891011- hosts: system1 remote_port: root roles: - test1- hosts: system3 roles: - test2- hosts: system4 roles: - test1 - test2 常用技巧 若要使command或shell的成功返回值不为0，有以下两种方式12345678tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true或tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand ignore_errors: True Jinja2过滤器 格式化数据 强制定义变量对于未定义变量，Ansible默认行为是fail，也可关闭。 未定义变量默认值Jinja2提供一个有用default过滤器，设置默认变量值。比强制定义变量更好。 忽略未定义变量和参数可使用default过滤器忽略未定义的变量和模块参数 参考资料 Ansible中文权威指南Ansible ：一个配置管理和IT自动化工具Ansible系列大神带你 20 分钟学会 Ansible！Ansible详解（一）Ansible详解（二）Linux集群与自动化运维]]></content>
      <tags>
        <tag>ansible</tag>
        <tag>运维</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS负载均衡学习笔记]]></title>
    <url>%2F2018%2F05%2F27%2FLVS%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇笔记包含以下内容 LVS原理 LVS集群的通用体系结构 三种IP负载均衡技术 LVS两种调度方式与八种算法 KeepAlived原理 LVS+KeepAlived搭建 VS/NAT模式搭建 VS/DR模式搭建 LVS原理LVS（Linux Virtual Server）Linux虚拟服务器是由章文嵩于1998年开发的负载均衡软件，提供传输层和应用层的负载均衡，传输层的负载均衡工具为IPVS，应用层的负载均衡工具为KTCPVS。 LVS集群的通用体系结构LVS集群采用三层结构： 负载调度器（load balancer）：整个集群的前端机，将网络请求无缝调度到真实服务器上，使服务器集群的结构对客户透明。因为所有的操作都是在Linux内核完成的，调度开销很小，所以具有很高的吞吐率。 服务器池（server pool）：是一组真正执行客户请求的服务器。服务器池的结点数目是可变的，可以在服务器池中增加服务器来满足不断增长的请求负载。对大多数网络服务来说，请求间不存在很强的相关性，请求可以在不同的结点上并行执行。 共享存储（shared storage）：为服务器池提供一个共享的存储区，通常是数据库、网络文件系统或者分布式文件系统，这样很容易使得服务器池拥有相同的内容，提供相同的服务。需要一个分布式锁管理器（Distributed Lock Manager）来保证应用程序在不同结点上并发访问的一致性。 前端负载均衡器称为Director Server（DR），后端的实际服务器称为Real Server(RS)，IP虚拟服务器软件称为IP Virtual Server（IPVS），IPVS工作在Linux内核中。在调度器的实现技术中，IP负载均衡技术的效率是最高的。 LVS的几种IP地址 VIP：virtual IP，DR上接收外网数据包的网卡IP地址 DIP：director IP，DR上转发数据包到RS的网卡IP地址 RIP：real IP，RS的IP地址 CIP：client IP，客户端IP地址 为什么要用共享存储？共享存储是可选的，但若网络服务需要相同的内容，应该使用共享存储，否则无共享结构的代价会很大，每台服务器需要一样大的存储空间，任何更新需要涉及每一台服务器，系统的维护代价会非常高。分布式文件系统提供良好的伸缩性和可用性，分布式文件系统在每台服务器使用本地硬盘作Cache，可以使得访问分布式文件系统的速度接近于访问本地硬盘。 如何实现高可用性？调度器上有资源监测进程时刻监视各个服务器结点的健康状况，当服务器对ICMP ping不可达时或者网络服务在指定的时间内没有响应时，资源监测进程会通知内核将该服务器从调度列表中删除。一旦监测到服务器恢复工作，通知调度器将其加入调度列表，管理员也可通过命令随时向调度列表添加或移除服务器。调度器存在单点故障问题，因此需要对调度器进行主从备份，并用HeartBeat机制进行主从故障监测。当从调度器不能听得主调度器的心跳时，从调度器通过ARP欺骗 （Gratuitous ARP）来接管集群对外的VIP，同时接管主调度器的工作来提供负载调度服务。当主调度器恢复后，有两种恢复机制。第一种为主调度器自动变成从调度器（类似抢占），另一种为从调度器释放VIP，主调度器收回VIP继续提供负载调度服务。当主调度器失效时，主调度器上所有已建立连接的状态信息将丢失，已有连接会中断。客户需要重新连接从调度器，从调度器才会将新连接调度到各个服务器上。因此，调度器在内核中实现了一种高效同步机制，将主调度器的状态信息及时同步到从调度器。当从调度器接管时，绝大部分已建立的连接会持续下去。 三种IP负载均衡技术 VS/NAT：调度器重写请求报文的目标地址，根据预设算法，将请求分派给实际服务器，实际服务器在响应报文通过调度器时，报文的源地址被重写，再返回给客户。优点：节约IP地址，能对内部进行伪装缺点：效率低，返回给请求方的流量需经过DR且请求和响应报文都要DR进行地址的重写，当客户端请求增多时，DR的处理能力会成为瓶颈完整过程： PC向调度器发送请求报文，调度器收到后根据调度算法选择后端的实际服务器，将报文中目的IP与目的端口改写为实际服务器的IP地址与端口，并进行转发。 实际服务器收到后，进行处理，将结果返回给调度器 调度器再将源IP地址与源端口改回为调度器的IP和端口，回复给PC。 数据包流向：客户端–&gt;调度器–&gt;实际服务器–&gt;调度器–&gt;客户端 VS/TUN（IP Tunneling）：调度器将请求报文通过IP隧道转发到实际服务器，实际服务器将响应报文直接回复给客户，调度器仅需处理请求报文，将请求报文的地址重写，无需重写响应报文的地址，极大解放了调度器，集群系统的最大吞吐量能提高10倍。 IP隧道技术：又称为IP封装技术，可以将带有源和目标IP地址的数据报文使用新的源和目标IP进行第二次封装，这样这个报文就可以发送到一个指定的目标主机上 由于多个RS都共享一个隧道IP（为VIP），所以需要通过ARP进行IP地址解析出MAC，而为了不让RS响应ARP请求导致出现错误，必须对RS进行抑制操作，这样只有DR进行ARP响应，也就让PC认为DR就是实际服务器。 注：由于调度器不会对IP报文进行修改，所以TCP报文中的目的端口也不会修改，因此要求RS与DR的端口号必须一致 完整过程： PC发送请求给调度器，调度器进行调度算法选择后端的实际服务器，将原报文进行第二次封装，源地址变为DIP，目的地址变为RIP，然后通过IP隧道发给指定实际服务器。 实际服务器处理完数据后直接回复给PC 实际服务器的RIP和DR的DIP可以不处于同一物理网络中，且RIP必须可以和公网通信，即集群节点可以跨互联网实现。实际服务器的隧道接口上需要配置VIP地址，以便接收DR转发的数据包，以及作为响应报文的源IP。DR给RS时需要借助隧道，隧道外层的IP头部的源IP是DIP，目标IP是RIP。而RS响应给客户端的IP头部是根据隧道内层的IP头分析得到的，源IP是VIP，目标IP是CIP。这样客户端就无法区分这个VIP到底是DR的还是服务器组中的。 VS/TUN模式一般会用来负载调度缓存服务器组，这些缓存服务器一般放置在不同网络环境，可以就近返回数据给客户端。在请求对象不能在缓存服务器本地找到的情况下，缓存服务器要向源服务器发请求，将结果取回，最后将结果返回给客户。 数据包流向：客户端–&gt;调度器–&gt;实际服务器–&gt;客户端 VS/DR（Direct Routing）：与VS/TUN类似，但调度器改写的是数据包的目的MAC地址，通过链路层进行负载分担。此法没有IP隧道的开销，但要求调度器与实际服务器必须在同一网段，也就是说RIP可用公网地址。 完整过程： PC向调度器发送请求，调度器根据调度算法选择后端实际服务器，将数据帧的目的MAC改写为该实际服务器的MAC地址，并转发。 实际服务器收到后处理完数据后直接将结果回复给PC 注：因为与VS/TUN类似，直接修改以太网帧，所以对于IP报文不会做修改，因此RS的端口号必须与DR一致。且RS上必须配置VIP（通过配置环回口IP地址），VIP为网卡别名的IP地址，仅用于回复数据包时使用作为源地址，不能用于通信。由于流出接口为RIP所在网卡接口，因此源MAC地址为RIP所在接口的MAC地址。且并不支持端口映射。 数据包流向：客户端–&gt;调度器–&gt;实际服务器–&gt;客户端 三种模式的比较DR和TUN模式的性能高于NAT，因为不需要DR对响应报文的操作DR性能高于TUN，因为不需要维护IP隧道DR中调度器和实际服务器必须在同一个网段中，TUN可实现跨网段负载均衡。 只有NAT支持端口映射，DR与TUN都不支持。 为什么VS/TUN与VS/DR要在环回口L0上配置VIP，能不能在出口网卡上配置VIP？在环回口上配置VIP使得RS能通过路由收到请求数据包，并将结果返回给客户。不可以将VIP配置在出口网卡上，否则真实服务器会响应客户端的ARP请求，客户端上的ARP表就会记录真实服务器的MAC，造成混乱，LB就失效了。必须保证路由器只保存DR上的VIP对应的MAC，即只允许DR进行ARP响应。在环回口配置VIP后，还需要设置arp_ignore=1和arp_announce=2来隐藏RS上的VIP。应该在配置VIP之前就设置arp参数，防止配置VIP后、设置arp抑制之前被外界主机发现。 arp_ignore：接收到ARP请求时的响应级别。默认为0。 0：响应目的地址是本地任意网卡上的所有IP地址的包 1：只响应目的地址恰好是入网卡的IP地址的包 arp_announce：将自己的地址向外通告时的通告级别。默认为0。 0：使用本地任意接口上的任意地址向外通告 1：尽量避免使用本地属于对方子网的IP地址向外通告 2：总是使用最佳本地地址向外通告 IPVS如何解决HTTPS连接问题？当客户访问HTTPS服务时，会先建立一个SSL连接，来交换对称公钥加密的证书并协商一个SSL Key，来加密以后的会话。在SSL Key的生命周期内，后续的所有HTTPS连接都使用这个SSL Key，所以同一客户的不同HTTPS连接也存在相关性。IPVS调度器提供了持久服务的功能，使得在设定的时间内，来自同一IP地址的不同连接会被发送到集群中同一个服务器结点，可以很好地解决客户连接的相关性问题。 可伸缩的缓存服务调度器一般使用IP隧道方法（VS/TUN）来架构缓存集群，因为缓存服务器可能在不同地方，而调度器与缓存服务器池可能不在同一个物理网段。若请求对象不能在本地找到，缓存服务器会向源服务器发请求，将结果取回并返回给客户。使用此方法，调度器只调度网页缓存服务器，而缓存服务器将响应数据直接返回给客户，调度器只需要调度一次请求，其余三次都由缓存服务器直接访问Web服务器完成。缓存服务器间有专用的组播通道，通过ICP（Internet Cache Protocol）协议交互信息。当一台Cache服务器在本地硬盘中未命中当前请求时，它可以通过ICP查询其他Cache服务器是否有请求对象的副本，若存在，则从邻近的Cache服务器取该对象的副本，这样可以进一步提高Cache服务的命中率。 可伸缩邮件服务服务器池有LDAP服务器和一组邮件服务器，调度器将SMTP、POP3、IMAP4和HTTP/HTTPS请求流负载较均衡地分发到各邮件服务器上。系统中可能的瓶颈是LDAP服务器，可对LDAP服务中B+树的参数进行优化。若分布式文件系统没有多个存储结点间的负载均衡机制，则需要相应的邮件迁移机制来避免邮件访问的倾斜。 LVS两种调度方式与八种算法两种调度方式 静态调度：仅根据调度算法进行调度，不管实际服务器的系统负载 动态反馈调度：会根据实际服务器的系统负载及性能，计算出可以调度的服务器对象 八种算法 静态调度 轮询（Round Robin）：调度器将请求根据调度算法按顺序轮流分配到实际服务器。调度器均等地对待每一台服务器，不管服务器上实际的连接数和系统负载。 加权轮询（Weighted Round Robin）：根据实际服务器的不同处理能力调度访问请求。使处理能力强的服务器处理更多访问流量，调度器自动询问实际服务器负载情况，并动态调整权值。 目标地址散列（Destination Hashing）：将请求的目标地址作为散列键，从静态分配的散列表中找出对应的服务器。 源地址散列（Source Hashing）：将请求的源地址作为散列键，从静态分配的散列表中找出对应服务器。 动态反馈调度 最少连接（Least Connections）：动态将网络请求调度到已建立的连接数最少的服务器上。计算方法：活跃连接数active*256+非活跃连接数inactive 加权最少连接（Weighted Least Connections）：当集群中服务器性能差异较大的情况下使用。具有较高权值的服务器将承受较大比例的活动连接负载。调度器可以自动问询真实服务器的负载情况并动态调整权值。此算法为默认调度算法。计算方法：(active*256+inactive)/weight 基于局部性最少连接（Locality-Based Least Connections）：针对IP地址的负载均衡，用于缓存集群系统。根据请求的IP地址找出该目标IP地址最近使用的服务器，若该服务器不可用，则用最少连接原则选出一个可用的服务器。该算法维护的是从一个目标IP地址到一台服务器的映射。 带复制的基于局部性最少连接（Locality-Based Least Connections with Replication）：针对IP地址的负载均衡，根据请求的目标IP地址找出与之对应的服务器组，按最小连接原则选出一台服务器。若该服务器超载，就在集群中按最小连接原则选出一台服务器，添加到服务器组中。该算法维护的是从一个目标IP地址到一组服务器的映射。 KeepAlived原理KeepAlived用于RS的健康状态检查与LB主从之间的故障转移（Failover）实现。 Keepalived实现了一组健康检查器，根据其健康状况动态自适应地维护和管理负载平衡的服务器池。使用VRRP实现高可用性，VRRP是路由器故障转移的基础实现方法。此外，keepalived实现了一组到VRRP有限状态机的挂钩，提供低级别的高速协议交互。每个Keepalived框架可以独立使用或一起使用，以提供弹性基础设施。 Keepalived采用纯ANSI/ISO C编写，围绕一个中央I/O多路复用器提供实时网络设计（Realtime Networking Design）。设计重点是在所有元素之间提供均匀的模块化功能。 为了确保鲁棒性和稳定性，守护进程keepalived分为3个不同的进程： 一个精简的父进程负责分支子进程的监控 两个子进程，一个负责VRRP框架，另一个负责健康检查 每个子进程都有自己的调度I/O多路复用器，这样VRRP调度抖动得到了优化，因为VRRP调度比健康检查者更关键。这种拆分设计可最小化健康检查外部库的使用情况，并将其自身行为降至最低，使主机闲置，从而避免由其本身造成的故障。 父进程监视框架称为Watchdog，每个子进程打开一个套接字，当守护进程引导时，父进程连接到套接字并向子进程周期（5s）发送hello包。若父进程无法向子进程套接字发送hello，则只要重启子进程即可。 Watchdog设计的优点：从父进程发送到子进程的hello数据包通过I/O多路复用器调度程序完成，这样可以检测到子进程调度框架中的死循环并能通过使用sysV信号来检测死亡的子进程。 Keepalived使用四个Linux内核组件： LVS框架：使用getsockopt和setsockopt调用来获取和设置套接字上的选项。 Netfilter框架：支持NAT和伪装（ Masquerading）的IPVS代码。 Netlink接口：设置和删除网络接口上的VRRP虚拟IP。 组播：通过组播地址224.0.0.18发送VRRP通告。 LVS+KeepAlived搭建首先在DR上安装依赖工具包libnl3-devel、popt-static，然后安装ipvsadm。ipvsadm是ipvs的命令行管理工具，可以定义、删除、查看virtual service和Real Server的属性。 可通过grep -i &#39;ip_vs&#39; /boot/config-内核版本号查看是否内核中编译了IPVS功能 ipvsadm的下载地址也可以通过yum安装，安装完成后启动并设置开机自启systemctl enable ipvsadm,systemctl start ipvsadm ipvsadm命令12345678910111213141516171819202122232425262728293031ipvsadm选项中，大写选项管理虚拟服务virtual service，小写选项管理关联了虚拟服务的真实服务器RealServer1. 管理virtual service -A --add-service # 添加virtual service -t --tcp-service 服务器IP[:端口] # TCP服务 -u --udp-service 服务器IP[:端口] # UDP服务 -f --fwmark-service 防火墙标记 # 防火墙标记 -s --scheduler 算法 # 指定算法 -E # 修改，参数与-A一致 -D # 删除，参数与-A一致 -t|-u|-f -C # 清空所有虚拟服务（IPVS规则） -L # 查看所有虚拟服务 -n 数字格式显示主机地址和端口 --stats 显示更详细的统计信息（连接数、入站包、出站包量等） --rate 显示速率（每秒连接数CPS、每秒入站包个数InPPS、出站包个数OutPPS等）且是实时的 --timeout 显示会话超时时间（tcp、tcpfin、udp） -c 显示当前IPVS的连接状况，实时的 --sort 排序，是实时的 -S # 保存IPVS规则，并输出到屏幕。可通过 &gt;文件，导入到文件 -R #载入之前的规则（要指定规则文件）。一般通过 &lt;文件，导入规则 2. 管理RealServer -a # 添加real server -r 指定RS的IP地址和端口 -g DR模式 -i TUN模式 -m NAT模式 -t|-u|-f -w 权重 -e # 编辑real server -d # 删除real server VS/NAT模式搭建实验环境： Client：192.168.205.151 VIP：192.168.205.152 DIP：172.16.184.130 RIP1：172.16.184.131 RIP2：172.16.184.132 Client和RS都采用单网卡，但非同一网段。DR采用双网卡，一张连接Client，一张连接RS。且此实验RS要用host-only网卡，需要设置网关 route add default gw 172.16.184.130 确保Server3和Server4的网关配置生效，否则无法给Client连接。 注：一定要将网卡配置为静态IP地址，不能使用DHCP获取，否则配置的网关会自动消失。 12345678# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 172.16.184.130 0.0.0.0 UG 0 0 0 ens36172.16.184.0 0.0.0.0 255.255.255.0 U 100 0 0 ens36# ip route default via 172.16.184.130 dev ens36 172.16.184.0/24 dev ens36 proto kernel scope link src 172.16.184.131 metric 100 Client请求过程：Client向DR发请求包，VIP接收，经过ip_forward转发到DIP，然后根据算法选择RS，将数据包发往RS。RS响应过程：RS向DR发响应包，DR的DIP接收响应包，经过ip_forward转发到VIP，最后将包回复给Client。因为VIP与DIP不是一个网段，所以DR上要开启ip_forward，并且要注意iptables与ipvs不可同时配置。 echo &quot;net.ipv4.ip_forward=1&quot; &gt;&gt; /etc/sysctl.conf &amp;&amp; sysctl -p 在Server2上配置： 123ipvsadm -A -t 192.168.205.152:80 -s rripvsadm -a -t 192.168.205.152:80 -r 172.16.184.131 -mipvsadm -a -t 192.168.205.152:80 -r 172.16.184.131 -m 通过ipvsadm -nL查看LVS服务 1234567# ipvsadm -LnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.205.152:80 rr -&gt; 172.16.184.131:80 Masq 1 0 0 -&gt; 172.16.184.132:80 Masq 1 0 0 LVS需要服务器间的时间同步，因此需要在Server2上配置chronyd服务。修改/etc/chronyd.conf，添加更新源。然后chronyc sources -v自动同步。 然后在Server3和Server4的chronyd配置文件中修改更新源server 192.168.205.152 iburst并自动更新。 在Client上多次访问192.168.205.152，因为选择的算法是轮询，所以会有以下现象。 12345678# curl 192.168.205.152Server 3# curl 192.168.205.152Server 4# curl 192.168.205.152Server 3# curl 192.168.205.152Server 4 在Server2上查看ipvsadm -L --stats 1234567# ipvsadm -L --statsIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Conns InPkts OutPkts InBytes OutBytes -&gt; RemoteAddress:PortTCP server2:http 7 34 20 2235 2240 -&gt; server3:http 3 14 8 918 896 -&gt; server4:http 4 20 12 1317 1344 修改为wrr算法。在Server2上修改IPVS规则： 123ipvsadm -E -t 192.168.205.152:80 -s wrripvsadm -e -t 192.168.205.152:80 -r 172.16.184.131:80 -m -w 5ipvsadm -e -t 192.168.205.152:80 -r 172.16.184.132:80 -m -w 3 Client上访问几次，再在Server2上查看，可发现访问Server3和Server4的包数量比例大约为5:3 1234567# ipvsadm -L -nIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.205.152:80 wrr -&gt; 172.16.184.131:80 Masq 5 0 22 -&gt; 172.16.184.132:80 Masq 3 0 13 VS/DR模式搭建环境： Client:192.168.205.151 DR的VIP:192.168.43.100 DIP:192.168.43.155 RIP1:192.168.43.156 RS1的VIP：192.168.43.100 RIP2:192.168.43.157 RS2的VIP：192.168.43.100 一定要确保DR和RS在同一个交换机上，即将网络模式改为桥接bridged。并且需要将RS的内核参数arp_ignore和arp_announce分别调整。 1234sysctl -w net.ipv4.conf.all.arp_ignore=1sysctl -w net.ipv4.conf.ens33.arp_ignore=1sysctl -w net.ipv4.conf.all.arp_announce=2sysctl -w net.ipv4.conf.ens33.arp_announce=2 然后配置VIP，保证DR、RS的VIP相同。ifconfig ens33:0 192.168.43.100 参考文档LVS中文官方文档骏马金龙LVS系列文章负载均衡的原理高性能网站构建实战Linux之虚拟服务器LVS搭建]]></content>
      <tags>
        <tag>server</tag>
        <tag>LVS</tag>
        <tag>keepalived</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Wireshark学习笔记]]></title>
    <url>%2F2018%2F05%2F18%2Fwireshark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于wireshark v2.4.5本篇包含以下内容 基本操作 抓包过滤器 高级功能 tshark命令使用 基本操作两种过滤器： 捕获过滤器 Capture Filter：也称抓包过滤器，使用伯克利包过滤语言（BPF），依赖于BPF的库（libpcap，Winpcap），用于限制抓的包，即抓包前的设定 显示过滤器 Display Capture：用于限制已经抓的包的显示，即抓包后的设定 捕获过滤器 type（类型）限定词 host、net、port、portrange dir（方向）限定词 src、dst proto（协议）限定词 ether、arp、icmp、ip、tcp、udp、http、ftp 逻辑运算：&amp;&amp;或and（与）、||或or（或）、!或not（非）过滤器基本语法[protocol] [direction] [host] [value] [logical operations] [other expression] 捕获–&gt;捕获过滤器 有常用的语法案例 常用过滤表达式举例：ether]]></content>
      <tags>
        <tag>网络</tag>
        <tag>wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis基础学习笔记]]></title>
    <url>%2F2018%2F05%2F17%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇笔记主要包含以下内容 Redis介绍 Redis安装 Redis数据类型 排序 发布与订阅 事务 过期时间 持久化 Redis优化技术 管道 内部编码优化 性能测试 集群 管理 Redis配置文件参数 在Docker上搭建Redis Redis报错问题 Redis介绍Redis（Remote Dictionary Server）是由C语言写成的高性能key-value非关系型数据库。为了保证效率，Redis的数据都缓存在内存中，并周期性地将更新的数据写入磁盘，或将修改写入记录文件，在此基础上实现了主从同步。 Redis安装 因为Redis是由C语言写的，所以要装gcc。yum install gcc 安装jemalloc，用于动态内存分配，是malloc的一个优化版本yum install jemalloc 安装工具命令语言TCLyum install tcl 解压redis包到/usr/local，进入后make &amp;&amp; make install即可编译安装，可先make test检查是否出错 建立软连接，redis的命令都存放在/usr/local/redis/src/目录下1234ln -s /usr/local/redis/src/redis-server /bin/redis-serverln -s /usr/local/redis/src/redis-cli /bin/redis-cliln -s /usr/local/redis/src/redis-benchmark /bin/redis-benchmarkln -s /usr/local/redis/redis.conf /etc/redis.conf redis命令 redis-server用于开启redis服务器端 1234[redis.conf文件路径] 设置配置文件路径，即可按照指定配置启动redis-server--[配置参数] 设置指定参数例：--port=6378-v 查看redis版本 redis-cli开启客户端命令行 123456-h [hostname] 指定要连接的redis服务器主机名，默认127.0.0.1-p [port] 指定服务器端口，默认6379-s [socket] 指定服务器socket，会覆盖主机名和端口-a [password] 设置连接redis服务器时要用的密码-u [uri] 设置服务器的URIshutdown 关闭redis 注：若要让redis默认在后台启动，可修改配置文件中daemonize 参数，若为no，则是前台启动，若为yes，则是后台启动 redis-cli基本操作exists [key] 查看键是否存在，存在返回1，否则返回0del [key] 删除键type [key] 返回键的数据类型keys [pattern] 返回符合指定匹配规则的键，支持glob风格通配符格式。rename [old-key] [new-key] 重命名键dbsize 返回当前数据库的键数量expire [key] [time] 指定键的生存时间（单位秒），返回1说明设置成功。未设置默认键的生存时间是无穷，会一直占用空间。ttl [key] 返回键的剩余生存时间，-1表示永久，-2表示不存在（已删除）select [db-num] 选择数据库编号 0为默认，从1开始会在端口后显示，最大为15，即最多有16个数据库。若超出范围，虽会显示该编号，但是仅会对15号数据库操作。 move [key] [db-num] 将指定键移动到指定数据库（不是复制）flushdb 删除当前数据库中所有键flushall 删除所有数据库的所有键 glob风格通配符 符号 含义 ? 匹配一个字符 * 匹配任意个字符 [] 匹配括号建的任一字符 Redis数据类型 字符串String：可包含任意数据，包括图片和序列化对象，单个值上限512MB 列表List：双向链表，通过push和pop从链表头部或尾部添加删除元素，因此即可用作栈也可用作队列，且都是双向的 哈希Hash：也称散列，字符串类型的键值对的映射表，适合存储对象，每个Hash可存储2^32-1个键值对 集合Set：字符串类型的无序集合，通过Hash表实现，所有操作的复杂度都为O(1)，最多可包含2^32-1个键值对 有序集合Sorted Set：也称ZSet，每个元素都会关联一个double类型的分数，称为权。redis正是通过权来为集合中的成员进行从小到大的排序。有序集合的成员是唯一的,但权却可以重复。 redis-cli操作 字符串set [key] [value] 设置键值mset [key1] [value1] [key2] [value2] ... 同时设置多个键值get [key] 获取键值mget [key1] [key2] ...同时获取多个键的值getrange [key] [start] [end] 返回键中字符串值的子字符串setrange [key] [start] [end] 设置字符串值的子串值getset [key] [value] 设置键的值并返回旧值strlen [key] 返回该键的字符串值的长度incr [key] 设置键值自增，返回新值decr [key] 设置键值自减，返回新值incrby [key] [value] 设置键值自增指定value，返回新值descby [key] [value] 设置键值自减指定value，返回新值append [key] [value] 指定键追加值value，返回新值长度substr [key] [start] [end] 取字符串（字符编号从0开始） 列表lpush [key] [member1] [member2]... 在list头部添加元素rpush [key] [member1] [member2]... 在list尾部添加元素lpop [key] 在list头部删除元素，返回删除元素rpop [key] 在list尾部删除元素，返回删除元素llen [key] 返回list的长度lindex [key] [index] 获取列表中对应索引的元素lrange [key] [start] [end] 返回list指定区间的元素（编号从0开始）ltrim [key] [start] [end] 截取list，只保留截取区间的元素 集合sadd [key] [member1] [member2]... 添加集合元素srem [key] [member1] [member2]... 删除集合元素scard [key] 返回集合元素个数smove [key1] [key2] [member] 将指定元素从key1移到key2sismember [key] [member] 判断该元素是否属于指定集合smembers [key] 返回集合中所有元素sinter [key1] [key2] 返回集合的交集sinterstore [key3] [key1] [key2] 将集合的交集存储到key3集合中sunion [key1] [key2] 返回集合的并集sunionstore [key3] [key1] [key2] 将集合的并集存储到key3集合中sdiff [key1] [key2] 返回集合的差集sdiffstore [key3] [key1] [key2] 将集合的差集存储到key3集合中 有序集合zadd [key] [score1] [member1]... 向有序集合添加成员并设置权值zrem [key] [member] 删除集合元素zincrby [key] [incr] [member] 设置元素的增加值zrank [key] [member] 返回指定元素的下标（从小到大）zrevrank [key] [member] 返回指定元素的下标（从大到小）zrange [key] [start] [end] 返回集合的指定区间元素zrerange [key] [start] [end] 返回集合的指定区间元素（逆序）zcard [key] 返回集合元素个数zscore [key] [member] 返回元素的权值zremrangebyrank [key] [start] [end] 删除集合中给定排名区间的元素 哈希hset [table] [column] [value] 设置字段column的值hget [table] [column] 获取字段的值hmset [table] [column1] [value1]... 设置多个字段的值hmget [table] [column1] [column2]... 获取多个字段的值hincrby [table] [column] [incr] 字段增加指定值hexists [table] [column] 字段是否存在hdel [table] [column]... 删除表中字段hdel [table] 删除表hkeys [table] 返回表的所有字段hvals [table] 返回表的所有值hgetall [table] 返回表的所有字段与值 排序Redis支持对list、set、sorted set的排序。sort [key] [BY partten][LIMIT offset count][GET pattern][ASC|DESC][ALPHA][STORE dstkey] sort默认排序为从小到大，若要按照字母顺序排可选择ALPHA选项，ALPHA可以和ASC DESC一起用。 在对有序集合类型排序时会忽略元素的分数，只针对元素自身的值进行排序。 123456789101112131415&gt; lpush list1 1 2 3 4&gt; sort list11) &quot;1&quot;2) &quot;2&quot;3) &quot;3&quot;4) &quot;4&quot;&gt; lpush list2 a b c A B C&gt; sort list2 alpha1) &quot;a&quot;2) &quot;A&quot;3) &quot;b&quot;4) &quot;B&quot;5) &quot;c&quot;6) &quot;C&quot; BY partten 设置条件进行排序 1&gt; sort list1 by a* LIMIT offset count 表示跳过前offset个元素，并获取之后的countge元素 1234&gt; sort list2 alpha limit 2 31) &quot;b&quot;2) &quot;B&quot;3) &quot;c&quot; GET pattern 发布与订阅发布/订阅是一种消息通信模式，主要目的是解除消息发布者与消息订阅者的耦合。 订阅者可以通过subscribe和psubscribe命令向redis server订阅自己感兴趣的消息类型，redis将消息类型称为频道(channel)。当发布者通过publish命令向redis server发送特定类型的消息时，该频道的全部订阅者都会收到此消息。这里消息的传递是多对多的。一个订阅者可以订阅多个频道,也可以向多个频道发送消息。publish [channel] [message]向指定频道发布信息subscribe [channel] 订阅频道实验：开启两个终端123456# 终端2&gt; SUBSCRIBE chan1Reading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;chan1&quot;3) (integer) 1 此时该终端处于订阅状态，该状态下客户端不可使用除subscribe、unsubscribe、psubscribe、punsubscribe以外的命令。在订阅频道后客户端会收到三种类型的回复，每种回复都包含三个值。第一个值为消息类型。有以下三种消息类型 subscribe：表示订阅成功的反馈信息。此时第二个值为订阅的频道名，第三个值为当前客户端订阅的频道数 1234# 终端21) &quot;subscribe&quot;2) &quot;chan1&quot;3) (integer) 1 message：表示接收到的消息。此时第二个值为产生消息的频道，第三个值为消息的内容另一个终端在该频道发布消息 123456# 终端1&gt; PUBLISH chan1 hello# 终端21) &quot;message&quot;2) &quot;chan1&quot;3) &quot;hello&quot; unsubscribe：表示成功取消订阅某个频道。此时第二个值为对应频道名，第三个值为当前频道数量。 12345# 频道2&gt; UNSUBSCRIBE chan11) &quot;unsubscribe&quot;2) &quot;chan1&quot;3) (integer) 0 unsubscribe命令可退订频道，若不指定频道则退订所有频道 按照规则订阅使用psubscribe订阅符合指定规则的频道。规则支持glob风格的通配符。123456789101112131415161718# 频道2&gt; PSUBSCRIBE chan*Reading messages... (press Ctrl-C to quit)1) &quot;psubscribe&quot;2) &quot;chan*&quot;3) (integer) 1# 频道1&gt; PUBLISH chan2 hello&gt; PUBLISH chan100 hello# 频道21) &quot;pmessage&quot;2) &quot;chan*&quot;3) &quot;chan2&quot;4) &quot;hello&quot;1) &quot;pmessage&quot;2) &quot;chan*&quot;3) &quot;chan100&quot;4) &quot;hello&quot; 频道2收到了任意以chan开头的频道的信息第一个值：表示该信息的通过psubscribe命令订阅得到的第二个值：订阅使用的通配符第三个值：收到消息的具体频道名第四个值：收到的消息内容 punsubscribe命令可退订规则，若不指定频道则退订所有规则，且只会退订由规则加入的频道，并不会退订subscribe加入的频道。退订的规则必须严格匹配，与订阅时的一致。 发布订阅存在的问题： 如果订阅者读取消息的速度很慢，会使得消息不断积压在发布者的输出缓存区中，造成内存占用过多； 如果订阅者在执行订阅的过程中网络出现问题，那么就会丢失断线期间发送的所有消息。 事务事务的原理是先将属于一个事务的命令发送给Redis，使Redis依次执行这些命令。 使用multi开启事务，之后的所有操作都属于该事务，直到提交exec，在事务中若有失误，可通过discard回滚，取消事务中所有操作。使用事务可保证一个事务内不会有其他的客户端的命令的插入。123456789101112131415161718&gt; set num1 11OK&gt; set num2 abcOK&gt; set num3 111OK&gt; MULTIOK&gt; incr num1QUEUED&gt; incr num2QUEUED&gt; incr num3QUEUED&gt; exec1) (integer) 122) (error) ERR value is not an integer or out of range3) (integer) 112 可见，事务中若有错误命令，仅会影响该命令，不会影响接下来的命令的执行。 事务的所有操作都是在事务提交时操作并一起返回值的，而有时需要先获得一条命令的返回值，再根据这个值执行下一条命令，即前一条命令的返回值需要作为后一条命令的参数。于是需要另一条命令watch，用于监视一个或多个键，一旦其中一个键被修改了，之后的事务都不会执行，监控一直持续到事务提交1234567891011121314151617181920212223242526&gt; set key 1OK&gt; watch keyOK&gt; set key 2 # 由于这里key被修改，于是之后的事务不会执行OK&gt; multiOK&gt; incr keyQUEUED&gt; exec(nil)&gt; get key&quot;2&quot;# 若在开启监视后，事务开启前，该键未被修改，则事务中对该键的操作仍有效&gt; set key 1OK&gt; watch keyOK&gt; multiOK&gt; incr keyQUEUED&gt; exec1) (integer) 2 在执行exec后会取消对所有键的监视，若不想在执行事务中的命令也可使用unwatch命令取消监控。 过期时间在实际开发中会遇到有时效的数据，过了一定时间就应该清除，在Redis中可使用expire设置一个键的过期时间，到达该时间后Redis会自动删除该键。expire &lt;key&gt; &lt;time&gt; （时间单位：秒，且必须是整数）返回值为1表示设置成功，0表示未成功或键不存在。 若要设置更加精确的时间，可用命令pexpire，单位：毫秒。可使用ttl命令查看指定键的剩余时间。若该键被删除了，则返回值为-2，若未设置该键的过期时间，，则返回-1。可使用persist &lt;key&gt;命令取消设置指定键的过期时间，成功则返回1，否则（键不存在，或键原来就没有过期时间设置）返回0。 注：set或getset命令对键重新赋值也会清除过期时间。 若watch监视一个没有过期时间的键，该键到期自动删除后并不会被watch认为该键被修改。 命令expireat &lt;key&gt; &lt;time&gt; 用Unix时间作为过期时间（1970年1月1日到现在的秒数）命令pexpireat &lt;key&gt; &lt;time&gt;同上，但单位为毫秒 当Redis用作缓存系统时，可以限制Redis能够使用的最大内存，并让Redis按照一定规则淘汰不需要的缓存键。修改配置文件maxmemory参数，限制最大可用内存大小（单位：字节）。当超出限制后，Redis会根据maxmemory-policy参数指定的策略删除键直到Redis占用的内存小于指定内存。 以下为Redis提供的策略规则： 规则名 作用 volatile-lru 使用LRU算法删除一个键（只对设置了过期时间的键起作用） allkeys-lru 使用LRU算法删除一个键（会不断删除） volatile-random 随机删除一个键（只对设置了过期时间的键起作用） allkeys-random 随机删除一个键 volatile-ttl 删除过期时间最近的一个键 noeviction 不开启策略 LRU算法：Least Recently Used 最近最少使用。该算法认为最近最少使用的键在未来一段时间内也不会被用到，即当需要空间时这些键是可以被删除的。 注：实际上，Redis不会准确将整个数据库中最久未使用的键删除，而是每次从数据库中随机取5个键（可修改）并删除其中最久未被使用的键。随机取的键个数可通过配置文件的maxmemory-samples参数设置。默认为5个能产生最优的结果。10个最接近LRU算法的要求，但会消耗更多的CPU资源。3个会更快，但并不准确。 持久化redis为了内部数据安全考虑，会把数据以文件形式保存一份在硬盘中，服务器重启后会自动将数据还原到内存中，将数据保存到硬盘称为持久化。持久化分为以下两种： 快照持久化（snap shotting），也称RDB AOF持久化（append only file） RDB默认开启，一次性将所有数据保存在硬盘中，整个数据库只保存为一个文件，便于数据迁移，也便于数据库毁坏后的恢复。在开始初始化时，唯一要做到的只是fork出子进程，再由子进程完成持久化工作，极大避免了服务进程执行IO操作，而父进程仍然处理客户端的请求，实现性能最大化。相较于AOF，若数据集很大，RDB的启动效率会很高。 若要保证数据的高可用性，最大限度避免数据丢失，则不宜选择RDB。因为依靠子进程完成持久化，所以当数据集较大时，可能会导致整个服务器延时增大。 写时复制策略保证了在fork的时刻虽然生成了两份内存副本，但内存的占用量并不会增加一倍，因此需要确保linux系统允许应用申请超过可用内存的空间。可通过/etc/sysctl.conf中修改vm.overcommit_memory参数为1。 当快照时，若写入操作交到，造成fork前后差异较大，是会使内存使用量显著超过实际数据大小的，因为内存不仅保存了当前数据库数据，还保存了快照时的内存数据。 快照方式 根据配置规则自动进行快照redis目录中的dump.rdb就是快照持久化的数据备份文件。配置文件/etc/redis.conf的RDB参数1234567# 设置备份频率save 900 1 # 900秒中有一个键发生变化就触发RDB备份save 300 10 # 300秒中有10个键发生变化就触发RDB备份save 60 10000 # 60秒中有10000个键发生变化就触发RDB备份dbfilename dump.rdb # 备份数据库文件名dir ./ # 备份数据库文件存放位置 在RDB中可实现精细持续化，将每个修改的键保存，频率可达到秒级。 只有当快照结束时，新的rdb文件才会覆盖旧的文件，而在备份过程中，redis是不会修改原rdb文件的，即任何时刻rdb文件都是完整的。于是可通过定时备份rdb文件实现redis数据库备份。rdb文件是经过压缩的二进制格式，可通过配置文件的rdbcompression yes参数禁用来压缩节省CPU占用。 Redis启动后会读取RDB文件，将数据从硬盘载入内存。通常一个记录1000万个字符串类型键、大小为1GB的快照文件载入到内存中需要花费20-30秒。 使用save或bgsave命令快照save命令：Redis会同步进行快照，快照时会自动阻塞所有来自客户端的请求。若数据量大会导致Redis长时间无法访问，在生产环境中尽量不要用。bgsave命令：推荐使用，可在后台异步快照，快照时Redis仍能响应客户端请求。可通过lastsave命令查看快照是否完成，返回unix时间戳。 执行flushall命令Redis会清空数据库中所有数据。无论清空数据库过程中是否触发了自动快照条件，只要自动快照条件不为空，redis就会执行一次快照。若未指定自动快照条件，则flushall并不会执行快照。 执行复制（replication）时当设置了主从模式时，Redis会在复制初始化时自动执行快照，并生成RDB文件，并不需要定义快照条件或手动执行。 AOF将用户执行的写指令都备份到日志文件中，还原数据就是执行写指令。AOF可带来更高的数据安全性，即持久性。注：开启AOF持久化会清空redis数据库所有数据，所以若要选择AOF持久化，应该在安装完redis服务器后就要立刻开启。 Redis有三种同步策略：每秒同步，每修改同步，不同步。 每秒同步为异步持久化，效率高。若服务器突然宕机，则在这一秒中的数据会丢失。 每修改同步为同步持久化，每次数据发生变化就会立刻记录到磁盘中，效率低。 该机制对日志文件的写入操作采用append模式，即使在写入过程中出现宕机，也不会破坏日志中已写入的数据，在Redis重启后可通过命令redis-check-aof解决数据一致性问题。当日志过大时，Redis会自动启用重写rewrite机制，以append模式不断将修改数据写入老磁盘文件，并会创建一个新文件用于记录期间哪些修改命令被执行，保证了数据持久性。 对于相同数量的数据集，AOF文件通常比RDB文件大。AOF的运行效率通常慢于RDB，但其中每秒同步的效率较高。 配置文件/etc/redis.conf的AOF参数1234567891011# 若要开启AOF，将此项改为yesappendonly no # 还可设置AOF的备份文件位置appendfilename appendonly.aof# 设置同步机制，三种机制always，everysec，no。# always：每修改同步# everysec：每秒同步，默认# no：同步禁用appendfsync everysec AOF是将Redis客户端向Redis发送的所有命令全部记录下来，这就造成了有很多冗余无用的命令，如SELECT等也会记录，随着执行命令的增多，AOF文件的大小也会逐渐增大。因此，Redis提供了优化策略，可在配置文件中修改以下两个参数：auto-aof-rewrite-percentage 100：设置当目前AOF文件的大小超过上一次AOF文件大小的指定百分比时就会再次进行重写，若之前未重写过，则会根据启动时的AOF文件大小作依据。auto-aof-rewrite-min-size 64mb：限制允许重写的最小AOF文件大小。 若不满足重写条件，可通过命令bgrewriteaof手动重写。 Redis优化技术管道客户端使用TCP与服务器建立连接，若执行较多的命令，每个命令的往返时延累加起来对性能有一定的影响。在执行多个命令时每条命令都需要等待上一条命令执行完（即收到Redis的返回结果）才能执行。Redis支持管道（pipelining），可一次性发送多条命令并在执行后一次性返回结果。通过减少客户端与服务器的通信次数来实现降低往返时累计值。注：每一组中的命令都不能依赖之前命令的执行结果。 内部编码优化Redis为每种数据类型都提供了两种内部编码的方式，并且会自动根据实际情况进行编码的转变，对于开发者而言是透明的。其中一种为复杂度是O(1)的编码，而当键的元素个数大时，变会采用复杂度为O(n)的编码。可通过object encoding &lt;key&gt;查看指定键的编码方式。 Redis的每个键值都是使用一个redisObject的结构体保存的。12345678typedef struct redisObject &#123; unsigned type:4; unsigned notused:2; # not used unsigned encoding:4; unsigned lru:22; # lru时间 int refcount; # 存储某个键值被引用的数量 void *ptr;&#125;robj; 每个数据类型的编码 数据类型 内部编码方式 object encoding命令结果 字符串 REDIS_ENCODING_RAW “raw” REDIS_ENCODING_INT “int” REDIS_ENCODING_EMBSTR “embstr” 散列 REDIS_ENCODING_HT “hashtable” REDIS_ENCODING_ZIPLIST “ziplist” 列表 REDIS_ENCODING_LINKEDLIST “linkedlist” REDIS_ENCODING_ZIPLIST “ziplist” 集合 REDIS_ENCODING_HT “hashtable” REDIS_ENCODING_INTSET “intset” 有序集合 REDIS_ENCODING_SKIPLIST “skiplist” REDIS_ENCODING_ZIPLIST “ziplist” EMBSTR字符串编码方式与RAW类似，都是基于sdshdr实现。 字符串类型Redis使用sdshdr类型变量存储一个键值能被多个键引用，Redis会预先建立10000个分别存储从0到9999的redisObject型的变量对象，若设置的键值在10000以内，则该键就会直接引用这个共享对象，并不会再建立一个redisObject对象了。 当配置文件设定了macmemoryRedis可用最大空间后，就不会使用共享对象，因为对于每个键值都需要使用一个redisObject记录LRU信息 集群Redis集群主要用于防止单点故障，以及解决存储、性能瓶颈问题。 复制（主从）Redis提供的复制功能，可实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。因此，将数据库分为主数据库（master）与从数据库（slave）。主数据库可进行读写操作，当数据更新时将更新的数据同步到从数据库。而从数据库一般为只读操作，接收主数据库的同步数据。一个从数据库只能有一个主数据库。从数据库默认只读，若创建键会报错。 在一台主机上模拟主从数据库首先启动主数据库redis-server /etc/redis.conf然后可直接通过命令redis-server --port 6666 --slaveof 127.0.0.1 6379再打开一个数据库，并作为从数据库连接到从数据库redis-cli -p 6666并执行INFO replication，查看从数据库的信息1234567&gt; INFO replication# Replicationrole:slavemaster_host:127.0.0.1master_port:6379master_link_status:up...... 在主数据库上创建键，在从数据库上就能得到该键了。123127.0.0.1:6379&gt; set key1 123127.0.0.1:6666&gt; get key1&quot;123&quot; 也可通过修改数据库的配置文件将该数据库设为从数据库在redis从服务器上修改配置文件参数bind &lt;主服务器IP&gt;slaveof &lt;主服务器IP&gt; &lt;主服务器端口&gt;主数据库上不需要任何配置。 还可在一个已开启的数据库中输入命令slaveof &lt;ip-addr&gt; &lt;port&gt;将本数据库设为指定主数据库的从数据库。若该数据库已是其他数据库的从数据库了，则这条命令会取消与原主数据库的同步，而与新指定的主数据库同步。还可通过命令slaveof no one使当前数据库停止接收主数据库同步，并转变为主数据库。 主从同步流程： 当一个从数据库启动后，会向主数据库发送SYNC命令。 主数据库收到SYNC后，会在后台保存RDB快照，并将快照与缓存的命令都发送给从数据库。 从数据库收到后载入快照，并将执行缓存命令。1到3步称为复制初始化 复制初始化完成后，主数据库每当收到写命令后就会将命令同步到从数据库。 当主从数据库断开连接并重连后，Redis提供有条件的增量数据传输，主数据库只需将断线期间执行的命令传送给从数据库即可。 试验同步：先使用telnet伪装成一个从数据库与主数据库通信123# telnet 127.0.0.1 6379Trying 127.0.0.1...Connected to 127.0.0.1. 然后在从数据库中使用ping确认与主数据库的连接，若正常则主数据库会返回PONG。再输入REPLCONF listening-port 6666说明自己端口号。开始同步SYNC，此时telnet的界面会出现以下信息1234567* Slave 127.0.0.1:6666 asks for synchronization* Starting BGSAVE for SYNC with target: disk* Background saving started by pid 4079* DB saved on disk* RDB: 6 MB of memory used by copy-on-write* Background saving terminated with success* Synchronization with slave 127.0.0.1:6666 succeeded 默认从数据库会使用同步前的数据响应客户端请求，可以在从数据库上修改配置文件参数slave-serve-stale-data为no，使从数据库再同步完成前对所有命令都返回错误（除INFO和SLAVEOF）。复制同步阶段会贯穿整个主从同步始终，直到主从关系终止。 乐观复制：允许一定时间内主从数据库的内容不一致，但最终是会同步的。主从数据库的数据同步是异步的，会产生主从数据库数据不一致的时间窗口（即网络传输的时间加上命令执行的时间），因此，主数据库是不知道命令最终同步给多少个数据库的。Redis提供配置文件参数限制至少同步给的从数据库的数量时，主数据库才是可写的。min-slaves-to-write 3 表示有3个以上的从数据库连接到主数据库时，主数据库才是可写的。min-slaves-max-lag 10 表示允许从数据库失去与主数据库连接的最长时间。若从数据库最后一次与主数据库的联系（即发送replconf ack命令）的时间小于该值，则认为从数据库仍与主数据库连接，否则就断开主从连接。这一特性默认关闭。 图结构：从数据库不仅能从主数据库接收同步数据，还能再以自身作为主数据库，将数据再同步给下属的从数据库。 通过复制可实现读写分离，提高负载能力。往往读的频率大于写的频率，当单机的Redis无法应对大量读请求时，可通过复制建立多个从数据库节点，主数据库只进行写操作，从数据库负责读操作。 从数据库的持久化可通过复制建立一个或多个从数据库，并在从数据库启动持久化，在主数据库禁用持久化。当从数据库崩溃重启后主数据库会自动同步数据。当主数据库崩溃后则需要按照以下步骤进行恢复。121. 在从数据库中使用命令slaveof no one将从数据库提升为主数据库继续对外提供服务2. 启动崩溃的主数据库，再使用slaveof将其设置为新的主数据库的从数据库，再将数据进行同步。 当开启复制且主数据库关闭持久化功能时，不要使用supervisor等进程管理工具使主数据库崩溃后自动重启。同样当主数据库所在服务器因故关闭时，也要避免直接重启。因为主数据库重启后没有开启持久化功能，所以主数据库中所有数据都会被清空，而从数据库又会与从主数据库中同步数据，导致从数据库所有数据也被清空。 无硬盘复制Redis的复制是基于RDB方式持久化实现的，即主数据库端在后台保存RDB快照，从数据库接收并载入快照文件。缺点： 当主数据库禁用RDB快照后，如果执行复制初始化，Redis依然会生成RDB快照，所以下次启动后主数据库会以该快照恢复数据。因为复制发生的时间不能确定，这使得恢复的数据可能是任何时间点的。 因为复制初始化时需要在硬盘中创建RDB快照文件，所以如果硬盘性能很慢（如网络硬盘）时这一过程会对性能产生影响。举例来说，当使用Redis做缓存系统时，因为不需要持久化，所以服务器的硬盘读写速度可能较差。但是当该缓存系统使用一主多从的集群架构时，每次和从数据库同步，Redis都会执行一次快照，同时对硬盘进行读写，导致性能降低。 因此Redis引入了无硬盘复制选项，开启该选项时，Redis在与从数据库进行复制初始化时将不会将快照内容存储到硬盘上，而是直接通过网络发送给从数据库，避免了硬盘的性能瓶颈。 可修改配置文件中repl-diskless-sync参数为yes开启。 增量复制场景：当主从数据库连接断开后，从数据库会发送SYNC命令来重新进行一次完整复制操作。虽然断开期间数据库的变化很小，但也需要将数据库中的所有数据重新快照并传送一次。因此Redis实现了主从断线重连的情况下的增量复制。 增量复制是基于如下3点实现的。 从数据库会存储主数据库的运行ID（run id）。每个Redis运行实例均会拥有一个唯一的运行ID，每当实例重启后，就会自动生成一个新的运行ID。 在复制同步阶段，主数据库每将一个命令传送给从数据库时，都会同时把该命令存放到一个积压队列（backlog）中，并记录下当前积压队列中存放的命令的偏移量范围。 同时，从数据库接收到主数据库传来的命令时，会记录下该命令的偏移量。 当主从连接准备就绪后，从数据库会发送一条PSYNC命令来告诉主数据库可以开始把所有数据同步过夹了，格式为PSYNC 主数据库的运行ID断开前最新的命令偏移量。主数据库收到PSYNC命令后，会执行以下判断来决定此次重连是否可以执行增量复制。 首先主数据库会判断从数据库传送来的运行ID是否和自己的运行ID相同，确保从数据库之前确实是和自己同步的。 然后判断从数据库最后同步成功的备今信移景是否在积压队列中，如果在则可以执行增量复制，并将积压队列中相应的命令发送给从数据库。如果此次重连不满足增量复制的条件，主数据库会进行一次全部同步。 增量复制的过程对开发者来说是完全透明的，唯一需要开发者设置的就是积压队列的大小了。主数据库可以正常地和旧版本的从数据库同步（通过接收SYNC命令），从数据库也可以与旧版本的主数据库同步（通过发送SYNC命令）。积压队列在本质上是一个固定长度的循环队列，默认情况下积压队列的大小为1MB，可以通过配置文件的rep1-backlog-size选项来调整。积压队列越大，其允许的主从数据库断线的时间就越长。根据主从数据库之间的网络状态，设置一个合理的积压队列很重要。因为积压队列存储的内容是命令本身，所以估算积压队列的大小只需估计主数据库可能执行的命令的大小即可。另一个配置参数是rep1-backlog-ttl，当所有从数据库与主数据库断开连接后，经过多久时间可以释放积压队列的内存空间，默认为1小时。 哨兵Redis提供哨兵实现自动化的系统监控和故障恢复功能，哨兵是一个独立的进程。哨兵有以下功能： 监控主数据库和从数据库是否正常运行。 主数据库出现故障时自动将从数据库转换为主数据库。 在一个主从Redis系统中，可使用多个哨兵进行监控任务以保证系统足够稳健。哨兵不仅能监控主从数据库，还能与其他哨兵互相监控。 哨兵实验1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283实验环境：system2 192.168.163.102主服务器：127.0.0.1 6379redis-server /etc/redis.conf 从服务器：127.0.0.1 6380 6381redis-server --port 6380 --slaveof 127.0.0.1 6379redis-server --port 6381 --slaveof 127.0.0.1 6379127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=6380,state=online,offset=266,lag=0slave1:ip=127.0.0.1,port=6381,state=online,offset=266,lag=0设置哨兵创建配置文件/etc/sentinel.conf，并添加以下内容：sentinel monitor MyMaster_1 127.0.0.1 6379 1sentinel monitor master-name ip port quoram# MyMaster_1为要监视的主数据库的名字，可自定义# 后面跟上主数据库的IP地址和端口号# 最后一个数字quoram表示最低通过票数# 配置哨兵时，只需要配置监视的主数据库即可，哨兵会自动发现主数据库下的所有从数据库。然后启动Sentinel进程redis-sentinel /etc/sentinel.conf启动哨兵后会报如下信息Sentinel ID is 33766bbd6ec93b3574240b6a4ac5c8ea498207d4+monitor master MyMaster_1 127.0.0.1 6379 quorum 1* +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ MyMaster_1 127.0.0.1 6379* +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ MyMaster_1 127.0.0.1 6379# +slave表示发现了从数据库然后在另一个终端中关闭主数据库在原终端中会出现一连串的以下信息* Connecting to MASTER 127.0.0.1:6379* MASTER &lt;-&gt; SLAVE sync startedError condition on socket for SYNC: Connection refused在过了一段时间（默认30s，可配置修改）后，会出现以下信息+sdown master MyMaster_1 127.0.0.1 6379+odown master MyMaster_1 127.0.0.1 6379 #quorum 1/1# +sdown 表示哨兵主观认为主数据库停止服务了# +odown 表示哨兵客观认为主数据库停止服务了# 此时哨兵执行故障恢复，挑选一个从数据库提升为主数据库然后会报出许多信息，下面列举出几条重要的信息+try-failover master MyMaster_1 127.0.0.1 6379+vote-for-leader 33766bbd6ec93b3574240b6a4ac5c8ea498207d4 1......+failover-end master MyMaster_1 127.0.0.1 6379+switch-master MyMaster_1 127.0.0.1 6379 127.0.0.1 6380+slave slave 127.0.0.1:6381 127.0.0.1 6381 @ MyMaster_1 127.0.0.1 6380+slave slave 127.0.0.1:6379 127.0.0.1 6379 @ MyMaster_1 127.0.0.1 6380# +try-failover 表示哨兵开始故障恢复# +failover-end 表示哨兵完成故障恢复，故障恢复步骤包括领头哨兵选举、备份从数据库的选择等# +switch-master 表示主数据库从6379端口迁移到6380，即6380端口的从数据库提升为主数据库# 两个+slave，原主数据库变为了现主数据库的从数据库，但此时6379的数据库并未启动，说明哨兵并不会清除已停止服务的实例的信息再次登录上127.0.0.1:6380127.0.0.1:6380&gt; info replication# Replicationrole:masterconnected_slaves:1slave0:ip=127.0.0.1,port=6381,state=online,offset=99027,lag=1# 因为6379端口数据库未启动，所以此时只有一个从数据库然后重启6379端口数据库-sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ MyMaster_1 127.0.0.1 6380+convert-to-slave slave 127.0.0.1:6379 127.0.0.1 6379 @ MyMaster_1 127.0.0.1 6380# -sdown 表示实例6379已恢复服务（与+sdown相反）# +convert-to-slave 表示将6379端口实例设置为6380端口实例的从数据库。在6379端会报以下信息：SLAVE OF 127.0.0.1:6380 enabled再在6380端查看127.0.0.1:6380&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=6381,state=online,offset=541686,lag=0slave1:ip=127.0.0.1,port=6379,state=online,offset=541686,lag=0 一个哨兵节点可同时监控多个Redis主从系统，只要提供多个sentinel monitor配置即可。多个哨兵节点也可监控一个主从系统。 sentinel.conf配置文件的其他配置12# sentinel down-after-milliseconds 主数据库名 值# 这条参数用于设置哨兵发送ping命令检测数据库节点状态的周期时间，单位为毫秒 当超过该参数时间而未收到回复后，则哨兵认为该节点主观下线。若该节点为主数据库，则哨兵会进一步判断是否需要故障恢复。哨兵会向其他节点发送sentinel is-master-down-by-addr命令询问其他节点是否他们也认为主数据库主观下线，当赞同的节点达到指定数目后，哨兵会认为主数据库客观下线，并进行故障恢复。这个指定数目就是sentinel.conf中sentinel monitor最后一项数值quoram。 哨兵启动后，会与要监控的主数据库建立两条连接。一条连接用来订阅该主数据的_sentinel_:he11o频道以获取其他同样监控该数据库的哨兵节点的信息，另外哨兵也需要定期向主数据库发送INFO等命令来获取主数据库本身的信息。 哨兵创建后与立刻做的事情：发送INFO命令获得当前数据库的相关信息（包括运行ID、复制信息等）从而实现新节点的自动发现。哨兵向主数据库发送INFO命令，通过解析返回结果来得知从数据库列表，而后对每个从数据库同样建立两个连接。至此，与主数据库的连接建立成功。 和主数据库的连接建立完成后，哨兵会定时执行下面3个操作。 每10秒哨兵会向主数据库和从数据库发送INFO命令。 每2秒哨兵会向主数据库和从数据库的_sentinel_:hel1o频道发送自己的信息。发送的消息内容为：&lt;哨兵IP&gt;，&lt;哨兵port&gt;，&lt;哨兵运行ID&gt;，&lt;哨兵配置版本&gt;，&lt;主数据库名&gt;，&lt;主数据库IP&gt;，&lt;主数据库port&gt;，&lt;主数据库配置版本&gt; 每1秒哨兵会向主数据库、从数据库和其他哨兵节点发送PING命令。 选举领头哨兵的过程使用了Raft算法，过程如下： 发现主数据库客观下线的哨兵节点向每个哨兵节点发送命令，要求对方选自己为领头哨兵。 如果目标哨兵节点没有选过其他人，则会同意将该节点设为领头哨兵。 如果该节点发现有超过半数且超过该数值的哨兵节点同意选自己为领头哨兵，则此节点会成功成为领头哨兵。 当有多个哨兵节点同时参选领头哨兵，会出现没有一个节点当选的情况。此时参选节点会等待一个随机时间重新发起参选请求，进行下一轮直到选举成功。 故障恢复过程： 领头哨兵会从从数据库中挑选一个作为新的主数据库。 挑选的依据分为三点： 所有在线的从数据库中选择优先级最高的，优先级可通过配置文件slave-priority参数设置 若有多个最高优先级的从数据库，则复制的命令偏移量大的优先 若上述都相同，则运行ID小的优先 选出符合的从数据库后，会向该数据库发送slaveof no one使其提升为主数据库，然后再向其他数据库发送slaveof使其成为新的主数据库的从数据库。最后再更新数据记录，原的主数据库变为从数据库。 哨兵的部署方案： 每个节点部署一个哨兵 每个哨兵与其对应节点网络环境相同或相近 这样可以保证哨兵的视角具有代表性和可靠性。最好将quoram的值设为N/2+1（N为哨兵节点个数）。若每个节点都部署一个哨兵的话，可能会因为Redis不支持连接复用而造成产生大量冗余连接。 集群集群往往用于水平扩容。若要开启集群，只要将配置文件的cluster-enabled参数设为yes即可，默认开启。每个集群至少需要三个主数据库。 集群实验1234实验环境6个数据库，3个主数据库，3个从数据库三个主数据库端口分别为6000，6001，6002三个从数据库端口分别为6003，6004，6005 集群会将当前节点记录的集群状态持久化到指定文件，默认为当前目录下的nodes.conf，这里还是存放在/etc/nodes.conf，每个节点对应的文件必须不同，否则会启动失败，因此启动节点时要注意最后为每个节点使用不同的工作目录，或通过配置文件cluster-config-file 节点文件路径修改。最好给每个节点都创建一个目录，然后每个节点都复制一份配置文件，并修改port参数，cluster-config-file参数。然后通过redis-server 配置文件启动。使用ps查看，每个节点都是显示类似redis-server *:6000 [cluster]。然后进入节点123127.0.0.1:6000&gt; info cluster# Clustercluster_enabled:1 # 1说明集群启动正常 目前仅仅节点运行正常，但并未加入集群。需要使用redis的ruby插件。首先需要安装ruby，最好不要yum安装，应该下最新版本的源码包编译安装。安装完后可以在/usr/local/redis/src/目录下找到redis-trib.rb命令，创软链接。然后使用该命令初始化集群12345678910111213141516171819202122redis-trib.rb create --replicas 1 \ 127.0.0.1:6000 \ 127.0.0.1:6001 \ 127.0.0.1:6002 \ 127.0.0.1:6003 \ 127.0.0.1:6004 \ 127.0.0.1:6005# --replicas 1 表示每个主数据库拥有的从数据库个数为1会出现以下信息：&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:127.0.0.1:6000127.0.0.1:6001127.0.0.1:6002Adding replica 127.0.0.1:6004 to 127.0.0.1:6000Adding replica 127.0.0.1:6005 to 127.0.0.1:6001Adding replica 127.0.0.1:6003 to 127.0.0.1:6002......Can I set the above configuration? (type &apos;yes&apos; to accept):确认输入yes创建集群 通过redis-trib.rb创建集群的过程： 首先该命令会以客户端形式尝试连接所有节点，并发送ping确定节点正常，同时发送info获取节点运行ID、验证是否开启了集群 集群会向每个节点发送cluster meet IP地址 端口告诉当前节点指定的节点也是集群成员。 redis-trib.rb会分配主从数据库节点，分配原则为尽量保证每个主数据库运行在不同IP地址上，同时每个从数据库和主数据库都不运行在同一IP地址。 分配完成后，会为主数据库分配插槽，即分配哪些键归哪些节点复制。对每个要成为子数据库的节点发送cluster replicate 主数据库运行ID将当前节点转换为从数据库并复制指定主数据库。 1234567127.0.0.1:6000&gt; CLUSTER nodes5c15caa067f96e557d73704e961ee08504fe3ac1 127.0.0.1:6004@16004 slave b098c2ddc169cc6e5411e8c42fb5afa96fa91764 0 1531150828178 5 connected6808731e0d12e8ec740509ef060c81306d5cd9bd 127.0.0.1:6000@16000 myself,master - 0 1531150825000 1 connected 0-54608e885e28b530491468b76bb8084cf7c22a8166f4 127.0.0.1:6005@16005 slave 9de0340daaf29f81b32c96d8010e9e443d66be0b 0 1531150827000 6 connectedb098c2ddc169cc6e5411e8c42fb5afa96fa91764 127.0.0.1:6001@16001 master - 0 1531150825153 2 connected 5461-10922e219bc21f1ab59f4cf00ca1b35da84e955424556 127.0.0.1:6003@16003 slave 6808731e0d12e8ec740509ef060c81306d5cd9bd 0 1531150827000 4 connected9de0340daaf29f81b32c96d8010e9e443d66be0b 127.0.0.1:6002@16002 master - 0 1531150827169 3 connected 10923-16383 可通过cluster meet IP地址 端口向新节点发送使新节点加入集群当新节点收到该命令后，会根据命令中的IP地址和端口与目标建立握手连接，然后目标会认为此节点为集群中的一员，并使用Gossip协议（一种分布式系统通信协议）向集群中所有节点发送此节点的信息。 新节点加入集群后可进行以下操作： 使用cluster replicate复制每个主数据库，以从数据库运行 向集群申请分配插槽（slot）以主数据库运行 在一个集群中，所有键会被分配给16384个插槽，每个主数据库会负责处理其中一部分插槽。12345678910111213141516确认创建集群后的报出的信息&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:6000)M: 6808731e...... 127.0.0.1:6000 slots:0-5460 (5461 slots) master 1 additional replica(s)S: 5c15caa0...... 127.0.0.1:6004 slots: (0 slots) slave replicates b098c2d......S: 8e885e28...... 127.0.0.1:6005 slots: (0 slots) slave replicates 9de0340......M: b098c2dd...... 127.0.0.1:6001 slots:5461-10922 (5462 slots) master 1 additional replica(s)......由此也可看出，只有主数据库才会分配插槽，从数据库无插槽。 初始化集群时分配给每个节点的插槽是连续的，但实际上Redis没有限制，可将任意几个插槽分配给任意节点。 键与插槽的关系键名的有效部分通过算法计算出散列值并取16384的余数。使得每个键都可以分配到16384个插槽中，进而分配的指定的一个节点中处理。 有效部分：若键名包含大括号，则有效部分为大括号内的内容，若不包含大括号，则整个键名都是有效部分 12345678910111213141516171819202122232425262728293031323334可使用命令cluster slots查看插槽分配情况127.0.0.1:6000&gt; CLUSTER SLOTS1) 1) (integer) 0 2) (integer) 5460 3) 1) &quot;127.0.0.1&quot; 2) (integer) 6000 3) &quot;6808731e0d12e8ec740509ef060c81306d5cd9bd&quot; 4) 1) &quot;127.0.0.1&quot; 2) (integer) 6003 3) &quot;e219bc21f1ab59f4cf00ca1b35da84e955424556&quot;2) 1) (integer) 5461 2) (integer) 10922 3) 1) &quot;127.0.0.1&quot; 2) (integer) 6001 3) &quot;b098c2ddc169cc6e5411e8c42fb5afa96fa91764&quot; 4) 1) &quot;127.0.0.1&quot; 2) (integer) 6004 3) &quot;5c15caa067f96e557d73704e961ee08504fe3ac1&quot;3) 1) (integer) 10923 2) (integer) 16383 3) 1) &quot;127.0.0.1&quot; 2) (integer) 6002 3) &quot;9de0340daaf29f81b32c96d8010e9e443d66be0b&quot; 4) 1) &quot;127.0.0.1&quot; 2) (integer) 6005 3) &quot;8e885e28b530491468b76bb8084cf7c22a8166f4&quot;因为有3个master，所以有三条记录，每条记录中包含四个值：1) 插槽的开始号2) 插槽的结束号3) 所有负责该插槽的节点（第一个是主数据库，后面都是从数据库）。包含以下内容： 1) 节点的IP地址 2) 节点端口号 3) 节点运行ID 插槽的分配的情况 插槽之前没被分配过，现在想分配给指定节点 插槽之前被分配过，现在想移动到指定节点 将插槽分配给节点的过程 若是上述的第一种情况，即插槽未被分配过。使用cluster addslots [插槽号]....可分配多个插槽。 若被分配过则会报错(error) ERR Slot 100 is already busy 若是第二种情况，即插槽被分配过。redis-trib.rb提供简便迁移方法 redis-trib.rb reshard 目标IP地址:端口 其中reshard表示需要重新分片。1234567891011121314151617181920212223242526272829303132333435363738394041424344目标：将6000端口的插槽分1000个到6001端口redis-trib.rb reshard 127.0.0.1:6000# 然后会询问要迁移的插槽个数How many slots do you want to move (from 1 to 16384)? 1000# 询问要迁移到的节点ID（redis-trib.rb会给出，也可以进入数据库cluster nodes查看）What is the receiving node ID? b098c2ddc169cc6e5411e8c42fb5afa96fa91764# 询问从哪个节点开始移出插槽，输入6000端口节点的ID# 在结束输入后回车，并输入donePlease enter all the source node IDs. Type &apos;all&apos; to use all the nodes as source nodes for the hash slots. Type &apos;done&apos; once you entered all the source nodes IDs.Source node #1:6808731e0d12e8ec740509ef060c81306d5cd9bdSource node #2:done# 然后会要求再次确认，输入yesDo you want to proceed with the proposed reshard plan (yes/no)? yes# 再进redis查看cluster slots127.0.0.1:6000&gt; CLUSTER SLOTS1) 1) (integer) 1000 2) (integer) 5460 3) 1) &quot;127.0.0.1&quot; 2) (integer) 6000 3) &quot;6808731e0d12e8ec740509ef060c81306d5cd9bd&quot; 4) 1) &quot;127.0.0.1&quot; 2) (integer) 6003 3) &quot;e219bc21f1ab59f4cf00ca1b35da84e955424556&quot;2) 1) (integer) 0 2) (integer) 999 3) 1) &quot;127.0.0.1&quot; 2) (integer) 6001 3) &quot;b098c2ddc169cc6e5411e8c42fb5afa96fa91764&quot; 4) 1) &quot;127.0.0.1&quot; 2) (integer) 6004 3) &quot;5c15caa067f96e557d73704e961ee08504fe3ac1&quot;3) 1) (integer) 5461 2) (integer) 10922 3) 1) &quot;127.0.0.1&quot; 2) (integer) 6001 3) &quot;b098c2ddc169cc6e5411e8c42fb5afa96fa91764&quot; 4) 1) &quot;127.0.0.1&quot; 2) (integer) 6004 3) &quot;5c15caa067f96e557d73704e961ee08504fe3ac1&quot; 若不使用redis-trib.rb命令。也可通过cluster setslot命令分片。1234cluster setslot 插槽号 node 新节点运行ID例：若要将上面分好的1000个插槽迁移回到6000管理前提：插槽中没有任何键。因为这样迁移时并不会连同相应键一起迁移，会造成键的丢失。 可通过cluster getkeysinslot 插槽号 要返回的键的数量获取指定插槽中的键，以查看要迁移的插槽中是否存在键。然后把每个键迁移迁移到目标节点：123migrate 目标节点地址 目标节点端口 键名 数据库号 超时时间 [copy] [replace]`其中copy和replace可选，copy表示不会将键从当前数据库删除，只是复制。replace表示目标节点若存在同名键则覆盖。因为集群模式数据库只能使用0号数据库，所以数据库号始终是0 Redis还提供以下命令实现集群不下线的数据迁移：123456789clsuter setslot 插槽号 migrating 新节点运行IDcluster setslot 插槽号 importing 原节点运行ID迁移时若要把N号插槽从A迁移到B，需要如下操作在B执行cluster setslot N importing A在A执行clsuter setslot N migrating B在A执行cluster getkeysinslot N 获取N号插槽的键列表对列表的每个键都执行migrate命令执行cluster setslot 0 B 完成迁移 当客户端向集群中任一节点发送命令后，该节点都会判断相应键是否在当前节点，若在则立刻处理，若不在则返回一个MOVE重定向请求，告诉客户端目前负责该键的节点。返回的错误信息格式为：(error) MOVED 键所在的插槽号 IP地址:端口redis-cli也提供集群模式支持自动重定向，通过-c参数启动客户端。 集群中每个节点都会每隔1秒随机选5个节点，并选择其中最久无响应的节点发送一个ping，若超时无回复，则变为主观下线，进行判断，与哨兵类似。选择主数据库的过程也与哨兵一致，都使用Raft算法。若一个至少负责一个插槽的主数据库下线且无相应从数据库可进行故障恢复，则整个集群默认会进入下线状态无法工作。也可修改配置文件的cluster-require-full-coverage设为no，使集群在这种情况下继续工作。 管理安全可通过配置文件的requirepass参数设置密码，于是客户端每次连接数据库时必须发送密码验证，否则Redis会拒绝执行客户端发来的命令，会报错：(error)NOAUTH Authentication required。使用auth 密码验证。也可在redis中通过命令config set requirepass 密码设置密码。也可通过命令config get requirepass获取密码（已验证后才能看） 攻击者会通过穷举法破解Redis密码（1秒内可尝试十几万个密码）。 配置Redis复制时，若主数据库设置了密码，需要在从数据库的配置文件中通过masterauth参数设置验证密码，在从数据库连接主数据库时会自动auth验证。 Redis支持对命令的重命名，可在配置文件中的rename-command进行设置。格式为rename-command 命令 重命名后的命令。若要禁用某命令可直接将该命令重命名为空字符串即可。 通信协议Redis支持两种通信协议： 统一请求协议：二进制安全 简单协议：便于在telnet中输入（已废弃） 简单协议中提供五种telnet返回值表示形式已被封装到redis-cli中，而就成为了redis的返回形式。 错误回复error reply以-开头，并跟上错误信息，以\r\n结尾 状态回复status reply以+开头，跟上状态信息，以\r\n结尾 整数回复integer reply以:开头，跟上数值，以\r\n结尾 字符串回复bulk reply以$开头，跟上字符串长度，\r\n分隔，再跟上字符串内容，再以\r\n结尾。若返回值为空，会返回$-1 多行字符串回复multi-bulk reply以*开头，跟上字符串个数，\r\n分隔，再跟上字符串内容，再以\r\n结尾。 统一请求协议命令格式类似于多行字符串回复的格式，每个命令都可以包含二进制字符。Redis的AOF文件和主从复制时发送的内容都使用了统一请求协议。若发送命令set foo bar，则在传输中的写法为*3\r\n$3\r\nSET\r\n*3\r\n$3\r\nFOO\r\n*3\r\n$3\r\nBAR\r\n。 一些管理命令 耗时命令日志当一条命令执行时间超时后，Redis会将该命令的执行时间等信息加入耗时命令日志（slow log）。可通过配置文件的slowlog-log-slower-than参数设置该限制时间，单位为微秒（1s=10^6μs），默认为10000μs。耗时命令日志会存储在内存中，也可通过配置文件slowlog-max-len设置记录的最多条数，默认128。 可在rediscli中使用slowlog get获取当前耗时命令日志。每条日志由四个部分组成： 该日志的唯一ID 该命令执行的Unix时间 该命令的耗时时间，单位微秒 命令和参数 命令监控Redis提供monitor命令监控Redis执行的所有命令。在一个终端中输入monitor，便开始监视任何执行操作（该终端被挂起，不能执行命令）。123456789在第一个终端中输入127.0.0.1:6379&gt; MONITOROK在另一个终端中执行一条命令set foo bar于是在第一个终端中就会打印出以下内容1531104811.876088 [0 127.0.0.1:41664] &quot;COMMAND&quot;1531104820.923283 [0 127.0.0.1:41664] &quot;set&quot; &quot;foo&quot; &quot;bar&quot; monitor命令十分影响redis的性能，会降低近一半的负载能力，因此只适合进行排错和调试。 Redis配置文件参数按照配置文件中的出现顺序 bind 指定Redis只接收该地址的请求。默认接收所有IP地址的请求，这样会造成安全隐患，最好填写需要调用redis的服务器的IP地址，或者直接写127.0.0.1仅允许本地用户调用。 在Docker上搭建RedisRedis报错问题 Redis被配置为保存数据库快照，但它目前不能持久化到硬盘。用来修改集合数据的命令不能用1报错：(error) MISCONF Redis is configured to save RDB snapshots, but it is currently not able to persist on disk. Commands that may modify the data set are disabled, because this instance is configured to report errors during writes if RDB snapshotting fails (stop-writes-on-bgsave-error option). Please check the Redis logs for details about the RDB error. 原因：强制关闭Redis快照导致不能持久化解决：将配置文件stop-writes-on-bgsave-error设置为no 参考资料 Redis入门指南（第二版）Linux_基于Docker搭建Redis集群Docker Redis的官方镜像简单使用【Redis】基于 Redis3.2.4 集群搭建说明]]></content>
      <tags>
        <tag>数据库</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维小技巧整理]]></title>
    <url>%2F2018%2F05%2F09%2F%E8%BF%90%E7%BB%B4%E5%B0%8F%E6%8A%80%E5%B7%A7%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[网上、书上的运维技巧整理 删除脚本-1为防止rm -rf失误造成破坏，可将删除写成一个脚本remove.sh 首先在指定目录创建.trash目录，作为回收站 创建脚本，放在一个固定位置/root/shell/ vim /root/shell/remove.sh 1234567#!/bin/bashTRASH_DIR="/root/.trash"for i in $*;do TIME_STAMP=$(date +%F) filename=$i mv $i $TRASH_DIR/$TIME_STAMP.$filename done 设置rm别名vim /root/.bashrc修改alias rm=&quot;sh /root/shell/remove.sh&quot; 设置定时任务echo &quot;0 0 * * * rm -rf /root/.trash/*&quot; &gt;&gt; /etc/crontab这样删除的文件也能尽快恢复]]></content>
      <tags>
        <tag>运维</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx笔记-1]]></title>
    <url>%2F2018%2F05%2F02%2FNginx%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下知识点： Nginx介绍 Nginx安装 Nginx配置文件解析 Nginx访问控制 Nginx日志 Nginx虚拟主机 Nginx缓存 Nginx负载均衡 Nginx反向代理 Nginx邮件服务 Nginx常见模块 Nginx配置简单优化 LNMP分布式集群方案 Docker部署LNMP Nginx介绍Nginx有以下功能： 负载均衡 作为静态web服务器 http协议的反向代理服务器 pop3\smtp\imap4等邮件协议的反向代理 能缓存打开的文件（元数据） ，支持FastCGI、uWSGI协议 模块化（非DSO机制），过滤器zip，SSI，SSL 特性： 模块化设计，较好扩展性 高可靠性：master/worker支持多进程，也支持多线程 支持热备份：不停机更新配置文件，更换日志，更新服务器程序版本 低内存消耗：10000个 keep-alive连接模式下非活动连接仅消耗2.5M内存 Nginx架构：nginx会以daemon方式启动进程，后台进程包含一个master进程和多个worker进程。master进程用于启动管理多个worker进程，若取消master进程，则nginx会以单进程运行一个请求只能在一个worker进程中处理，一个worker进程只能处理一个请求。worker进程个数一般设置为cpu核数 master：加载配置文件、管理worker进程、平滑升级 worker：http服务、http代理、fastcgi代理 事件驱动：epoll 消息通知：select、poll、rt signals 模块类型：核心模块、标准http模块、可选http模块、邮件模块、第三方模块 请求过程： 在master进程里面，先建立好需要listen的socket（listenfd）之后，然后再fork出多个worker进程 所有worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。 当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接 Nginx安装在安装nginx前需要安装以下环境： gcc与gcc-c++等，可直接组安装Development Tools prce-devel(perl的正则表达库) zlib与zlib-devel(资料压缩的函数库) openssl与openssl-devel(安全套接字密码库) 创建系统用户组groupadd -r nginx创建系统useradd -r nginx -M -g nginx -r为创建系统用户（组），-M为不创建该用户家目录 创建目录/var/tmp/nginx/client，否则在后面运行时可能报错。 初始化文件模块配置 123456789101112131415./configure --prefix=/usr/local/nginx \ # 设置nginx安装目录 --sbin-path=/usr/sbin/nginx \ # 命令放在/sbin下 --conf-path=/etc/nginx/nginx.conf \ # 配置文件位置 --pid-path=/var/run/nginx/nginx.pid \ # nginx进程号文件 --lock-path=/var/lock/nginx.lock \ # nginx锁文件 --user=nginx \ # 指定用户 --group=nginx \ # 指定用户组 --http-log-path=/var/log/nginx/access.log \ # 运行日志位置 --error-log-path=/var/log/nginx/error.log \ # 报错日志 --http-client-body-temp-path=/var/tmp/nginx/client \ # 指定客户端post上传的$_FILES上传的文件地址，该目录需要自己创 --with-http_ssl_module \ # 加载ssl模块，默认没加载 --with-http_stub_status_module \ # 加载监控模块 --with-http_gzip_static_module \ # 加载gzip压缩模块 --with-debug # 允许debug 之后make &amp;&amp; make install Nginx配置文件解析配置文件/etc/nginx.conf配置文件组织结构： 全局配置 模块配置 全局配置 正常运行配置： 1234user Username [Groupname] # 指定运行worker进程的用户pid PATH # 指定nginx进程的pid文件worker_rlimit_nofile # 指定一个worker进程所能打开的最大文件描述符数量worker_rlimit_sigpending # 指定每个用户能发给worker进程的最大的信号数量 性能优化配置： 12345worker_processes # worker进程个数，通常为物理CPU核心数量-1可填auto，自动使用所有CPU。worker_cpu_affinity CPUMask # 指定使用的cpu，cpumask为cpu掩码。# cpumask：0001,0010,0100,1000work_priority NICE # 指定nice值，即优先级 调试定位配置： 1234daemon &#123;on|off&#125; # 是否以守护进程方式启动master_process &#123;on|off &#125; # 是否以master模型运行error_log PATH [level] # 错误日志文件路径及日志等级。# 可设置为debug，但需要在编译时指定--with-debug才能用 模块配置event块event { }事件驱动，并发响应连接包含以下配置： 1234worker_connections # 每个worker进程能响应的最大并发请求数量use &#123;epoll | select | poll &#125; # 选择使用事件类型，最好让nginx自动选择accept_mutex &#123;on|off&#125; # 是否开启负载均衡锁，启用时，表示让多个worker进程轮流响应请求。lock_file PATH # 锁文件路径 http块http { }配置web响应包含以下配置：123456789101112include mime.types;default_type application/octet-stream;#log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on;server &#123; &#125; # 虚拟主机模块]]></content>
      <tags>
        <tag>server</tag>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache-Server笔记]]></title>
    <url>%2F2018%2F05%2F02%2FApache-Server%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本片包含以下内容： Apache-httpd服务器介绍 httpd服务器安装 httpd服务器配置文件 httpd虚拟主机 httpd认证授权 页面重定向 .htaccess文件 CGI 动态httpd httpd与SSL httpd日志 httpd代理 Apache实用第三方模块 Apache-MPM模式 Apache安全措施 Apache-httpd服务器介绍Apache服务器全称Apache-HTTP-Server，而httpd就是Apache服务器端运行的软件，提供WWW服务器平台。 Apache特性 简单强大的配置文件 支持虚拟主机 支持多种HTTP认证 集成Perl脚本，代理服务器模块 支持通用网关接口、FastCGI 支持实时监视服务器状态和定制服务器日志 支持SSL、服务器端包含指令SSI 可通过第三方模块支持Java Servlets 提供对用户会话的跟踪 采用模块化设计模型 Apache最重要的特性就是：采用模块化设计模型。模块分为： 静态模块：是Apache最基本的模块，无法随时添加和卸载，在编译安装时设定 动态模块：是可以随时添加和卸载的模块，使得部署有最大的灵活性 Apache的模块会被编译为动态共享对象DSO，这些DSO独立于httpd，可以在编译时就添加，也可以后期通过Apache Extension Tool工具编译添加模块，可使用httpd -M查看模块加载清单。 httpd服务器安装httpd版本2.4.34。可以使用源码安装，可进行更精细的设定。 12345678./configure --enable-so # 开启模块化功能，支持DSO --enable-mods-shared # 指明以DSO方式编译的模块，all表示所有模块，most表示大部分模块 --enable-ssl # 支持ssl加密 --enable-rewrite # 支持地址重写 --with-mpm # 设置httpd工作模式 --with-suexec-bin # suexec库的路径，用于支持SUID、SGID --with-apr # 指定apr程序的绝对路径 apr：Apache Portable Runtime（APR）项目的任务是创建和维护软件库，为底层平台特定的实现提供可预测且一致的接口。主要目标是提供一个API，软件开发人员可以对其进行编码，并确保可预测的行为，如果不是相同的行为，无论他们的软件构建在哪个平台上，都可以减轻他们编写特殊情况条件以解决问题的需要。 源码安装前需要安装apr和apr-util，仍然需要源码安装 下载apr和apr-util的源码包，先安装apr，先要确保安装了gcc ./configure --prefix=/usr/local/apr-1.6然后make &amp;&amp; make install 再安装apr-util，需要--with-apr指定apr的安装路径 ./configure --prefix=/usr/local/apr-util-1.6 --with-apr=/usr/local/apr-1.6然后make &amp;&amp; make install 可能会报一个错xml/apr_xml.c:35:19: 致命错误：expat.h：No such file or directory，需要安装expat-devel，yum install expat expat-devel即可。 最后安装httpd，需要先安装pcre库，yum install pcre pcre-devel。然后 --prefix1234./configure --prefix=/usr/local/httpd-2.4 \ --with-apr=/usr/local/apr-1.6 \ --with-apr-util=/usr/local/apr-util-1.6 # 若不指定--prefix，会默认安装在/usr/local/apache2中 并make &amp;&amp; make install即可。源码安装后可能不能直接使用Apache的管理命令，需要添加环境变量，export PATH=/usr/local/httpd-2.4/bin:$PATH，也可以永久添加。 httpd提供两种编译方式：静态编译和动态编译 静态编译：把模块直接编译进httpd核心，httpd启动时所有静态编译的模块都会启动 动态编译：将模块编译好，但不编译进httpd核心，httpd启动动态模块并不会启动，而是需要在配置文件中LoadModule加载才能启动，实现了模块热插拔。 可在编译时指定--enable-模块名=shared|static指定模块是动态或静态编译。 httpd能够实现动态编译的原因在于httpd默认会安装mod_so，此模块提供了配置文件的LoadModule和LoadFile指令，在编译时指定--enable-so即可，而此模块只能使用静态编译，若指定为shared则编译时会出错。 动静态编译的优先级： 不指定模块编译选项，则默认值为--enable-mods-shared=most即动态编译大部分模块 显式指定的优先级高，如果某个模块既指定了静态，又指定了动态，则静态优先。 静态关键字规则优先于动态关键字规则，即若--enable-mods-static=few和--enable-mod-shared=all同时配置，静态优于动态，静态生效。 也可通过各种源安装。yum|dnf install httpd。安装完成后，Apache会提供apachectl脚本命令，可进行httpd的启动、关闭和测试，若没有修改配置文件下使用start启动httpd，会报以下错误信息： 1Could not reliably determine the server&apos;s fully qualified domain name 报错说明httpd无法确定服务器域的名称，可通过修改主配置文件的ServerName解决。修改后再通过apachectl starts启动httpd，再直接打命令apachectl能看到httpd已在运行的消息httpd (pid 2012) already running。也可以通过systemctl start httpd启动httpd。 若开启了firewalld服务，需要放行80/tcp端口，放行http服务。 httpd的主要目录（yum源安装）： /etc/httpd：httpd服务根目录 /etc/httpd/conf和/etc/httpd/conf.d：httpd服务配置文件目录 /var/www/html：网站数据目录 /var/log/httpd：httpd日志目录，里面存放有access_log访问日志和error_log错误日志 若是通过yum源安装的httpd，则在/etc/httpd中的logs，modules和run目录都是软连接。 123/etc/httpd/logs --&gt; /var/log/httpd/etc/httpd/modules --&gt; /usr/lib64/httpd/modules/etc/httpd/run --&gt; /run/httpd apachectl命令： 1234567891011apachectl -V # 查看apache版本信息，以及模块、编译信息 -l # 查看已被编译的模块 start # 启动httpd，如果已在运行就会返回错误 stop # 停止httpd restart # 重启httpd fullstatus # 显示mod_status的完整状态报告。需要在服务器上启用mod_status，并在系统上使用基于文本的浏览器 status # 显示简要状态报告，信息与systemctl status httpd一致 graceful # 优雅地重启Apache httpd守护进程。如果守护程序未运行，则启动它。这与正常重启不同，因为当前打开的连接不会中止。副作用是旧的日志文件不会立即关闭。这意味着，如果在日志轮换脚本中使用，则可能需要大量延迟才能确保在处理旧日志文件之前将其关闭。 graceful-stop # 让已运行的httpd进程不再接受新请求，并给他们足够的时间处理当前正在处理的事情，处理完成后才退出。所以在进程退出前，日志文件暂时不会关闭，正在进行的连接暂时不会断开。 configtest # 配置文件语法测试，相当于apachectl -t httpd命令：与apachectl一致 12345678910111213141516171819202122httpd # 可直接启动httpd -D name # 定义一个在&lt; IfDefine name &gt;中使用的name，以此容器中的指令 -d directory # 指定ServerRoot -f file # 指定配置文件 -C &quot;directive&quot; # 指定在加载配置文件前要处理的指令(directive) -c &quot;directive&quot; # 指定在加载配置文件后要处理的指令 -e level # 显示httpd启动时的日志调试级别 -E file # 将启动信息记录到指定文件中 -v # 显示版本号 -V # 显示编译配置选项 -h # 显示帮助信息 -l # 显示已编译但非动态编译的模块，即静态编译的模块 -L # 显示静态模块可用的指令列表 -t -D DUMP_VHOSTS # 显示虚拟主机的设置信息 -t -D DUMP_RUN_CFG # 显示运行参数 -S # 等价于-t -D DUMP_VHOSTS -D DUMP_RUN_CFG。在调试如何解析配置文件时非常有用 -t -D DUMP_MODULES # 显示所有已被加载的模块，包括静态和动态编译的模块 -M # 等价于-t -D DUMP_MODULES -t # 检查配置文件语法 -T # 不检查DocumentRoot，直接启动 -X # 调试模式，此模式下httpd进程依赖于终端 -k # 管理httpd进程，接受start|restart|graceful|graceful-stop|stop httpd配置文件httpd主配置文件主要由指令和容器构成，容器使用&lt;容器名&gt;&lt;/容器名&gt;作为开始和结束，容器的指令一般只在容器内生效，每个指令都是某个模块提供的，指令生效方式是从上往下读取，所以不要变更指令位置。 主配置文件重点指令： ServerRoot：设置Apache的安装主目录，若采用源码安装，默认路径为/usr/local/apache2 Listen：设置服务器监听端口IP及端口号，默认监听服务器本机所有IP地址的80端口。格式：Listen [IP地址:]端口 [协议]，默认监听所有IP，使用TCP协议。可多次使用Listen以开启多个端口 LoadModule：加载模块。格式 LoadModule 模块名 模块文件名，模块文件一般存放在ServerRoot的module目录中 ServerAdmin：主服务器返回给客户端的错误消息中的管理员邮箱地址 ServerName：设置服务器本机的主机名和端口，用于URL重定向 User：apache在本地系统上运行的用户名 Group：apache在本地系统上运行的组名 DocumentRoot：网络路径相对路径的根，是文档的根目录，使用rpm包安装则默认值为/var/www，使用源码安装则默认为$ServerRoot/htdocs ErrorLog：服务器错误日志存放位置，默认使用相对路径logs/error_log ErrorLogFormat：错误日志格式 CustomLog：客户端访问日志文件路径及日志格式，格式：CustomLog 文件名 格式，默认相对路径为logs/access_log LogFormat：用户日志文件格式，一般用这里指定的格式创建别名，然后通过CustomLog调用该格式 LogLevel：日志消息等级，分为debug/info/notice/warm/error/crit/alert/emerg AllowOverride：支持从.htaccess文件中重写前面的指令，若值为None，表示不支持 Require：给所有用户或特定用户/组授予或拒绝对目录的访问 Include：允许Apache在主配置目录加载其他配置文件，默认为conf.d/*.conf Options：为特殊目录设置选项，语法格式为Options [+|-]选项。 All：开启除MultiViews之外的所有选项 None：不启用额外功能 FollowSymlinks：允许Options指定目录下的文件链接到目录外的文件或目录 Indexes：若与URL对应的Options目录下找不到DirectoryIndex指定的首页文件，则会将当前目录的所有文件索引出来 Order：控制默认访问状态以及Allow和Deny的顺序 若为Order deny,allow则先检查拒绝，当拒绝与允许冲突时，allow优先，默认规则allow，即只要是deny排在前面，就只要写拒绝的IP地址即可，使用Deny from [IP地址]|all 若为Order allow,deny则先检查允许，当拒绝与允许冲突时，deny优先，默认规则deny，即只要是allow排在前面，就只要写拒绝的IP地址即可，使用Allow from [IP地址]|all Alias：用于将URL路径映射到本地文件系统的路径，且本地路径不受DocumentRoot的限制，该目录中的脚本不允许执行。格式：Alias URL路径 &quot;本地资源的文件系统路径&quot;。Alias不支持正则，而AliasMatch支持，格式一致。 ScriptAlias：类似于Alias，并且能将Web路径映射到DocumentRoot之外的文件系统位置，还告诉Apache指定的目录存在CGI脚本，可以执行脚本 DirectoryIndex：作为索引的文件名，默认找index.html。若url中未指定网页文件，则会返回该目录下DirectoryIndex定义的文件，可指定多个文件，若都不存在，会生成所有文件列表，此时Option Indexes必须打开。 UserDir：定义和本地用户的主目录相对的目录，可将公共的html文件放入该目录，即每个用户的个人站点。默认设置为public_html，每个用户都可在自己的主目录下创建名为public_html的目录，该目录下的html文件可通过域名/~用户名访问。若值为disabled表示禁止使用个人站点。 Timeout：客户端与服务器连接的超时间隔 KeepAlive：开启长连接。HTTP/1.1中支持一次连接多次传输，可在一次连接中传递多个HTTP请求 KeepAliveTimeout：一次连接中多次请求间的超时间隔 MaxKeepAliveRequests：一个HTTP连接中最多可请求的次数，若为0，表示无限制 指令文档 常用容器： IfDefine：使管理员能采用多种配置方式启动Apache，当启动httpd时使用命令httpd -D 自定义名便会匹配，若测试条件为真，就会加载该容器中定义的参数。格式：&lt;IfDefine [!]自定义名&gt; IfModule：可以封装仅在条件满足时才会处理的命令，根据模块是否加载决定条件是否满足。语法：&lt;IfModule [!] 模块&gt;指令&lt;/IfModule&gt; Directory：仅用于特定的文件系统目录、子目录及目录下内容，通常用绝对路径，即使是相对路径，也是相对于文件系统的根目录。语法：&lt;Directory 路径&gt;指令&lt;/Directory&gt;，路径可使用~匹配正则表达式。 DirectoryMatch：类似Directory，可直接用正则表达式匹配 Files：类似Directory，但Files内指令仅能应用与特定文件，匹配的范围是它所在的上下文。语法：&lt;Files 文件名&gt;指令&lt;/Files&gt;，可使用~匹配正则表达式 FilesMatch：与Files类似，可直接用正则表达式匹配 Location：该容器内的指令仅对特定URL有效。格式&lt;Location URL&gt;指令&lt;/Location&gt;，可使用~匹配正则表达式。Location支持三种匹配模式： 精确匹配：精确到资源的URL路径 加尾随斜线：匹配目录内容，如&lt;Location &quot;/myapp/&quot;&gt; 无尾随斜线：匹配目录和目录内容，如&lt;Location &quot;/myapp&quot;&gt; LocationMatch：类似Location，可直接用正则表达式匹配 在DirectoryMatch，Files，FilesMatch，Location，LocationMatch中，若出现包含关系，如一个目录同时匹配到了两个相同类型容器，则会选择匹配先定义的容器 VirtualHost：虚拟主机，可直接用正则表达式匹配。语法：VirtualHost IP地址:[端口号]，IP地址为监听的本地网卡IP，若为*则表示监听本地所有网卡 EnableSendfile：使用sendfile系统调用，把静态文件发送给客户端，获得更好的性能 httpd虚拟主机基于IP的虚拟主机可根据不同IP地址及端口号定位不同的网站请求，但需要独立的公网IP地址。基于域名的虚拟主机能实现在一台公网服务器上部署多个网站，服务器根据客户端访问HTTP头部信息实现网站的分离解析。 客户端请求到达后，服务器根据&lt;VirtualHost IP地址:[端口号]&gt;匹配主机，若IP地址 为*，表示匹配本地所有IP地址 匹配顺序： 匹配虚拟主机。匹配虚拟主机的规则为最佳匹配法，IP地址越精确，匹配就越优先。 如果基于名称的虚拟主机无法匹配上，则采用虚拟主机列表中的第一个虚拟主机作为响应主机。 如果所有虚拟主机都无法匹配上，则采用从主配置段落中的主机。 首先配置虚拟主机配置文件，将/usr/share/doc/httpd/httpd-vhosts.conf复制到/etc/httpd/conf.d/目录下，可改名，以此为模板，创建一台虚拟主机。配置完成后重启httpd。 1234567891011&lt;VirtualHost *:80&gt; DocumentRoot &quot;/var/www/virhost1&quot; ServerName virhost1.example.com ErrorLog &quot;/var/log/httpd/virhost1-error_log&quot; CustomLog &quot;/var/log/httpd/virhost1-access_log&quot; common&lt;/VirtualHost&gt;&lt;Directory &quot;/var/www/virhost1&quot;&gt; Require all granted Options Indexes AllowOverride None&lt;/Directory&gt; 注：在实验机上，需要将该地址解析出来，所以要修改/etc/hosts，在环回口后添加virhost1.example.com，再访问即可。 注：物理站点与虚拟站点不能同时存在，如果启动虚拟站点，物理站点立刻失效。若要让之前的物理站点恢复访问，就将该站点按虚拟站点的格式重新搭建 httpd认证授权httpd提供各种认证模块，名称以mod_auth开头。基础的http认证模块为mod_auth_basic。 可以通过命令htpasswd生成用于网页认证的用户信息文件，该命令在httpd-tools包中，支持3种加密算法：MD5、SHA和系统上的crypt()函数，默认为md5。 1234567891011121314htpasswd [-cimBdpsDv] [-C cost] passwordfile usernamehtpasswd -b[cmBdpsDv] [-C cost] passwordfile username password -c 创建一个新密码文件 -n 不会更新密码文件，仅仅在输出显示，因此不用指定密码文件。而若不指定此项就必须指定密码文件，不能与-c一起用 -b 在命令行中读取密码，若不指定，系统会提示输入 -i 从输入读取密码（类似echo XXX | htpasswd -i），常用于脚本 -m 使用md5加密（默认） -B 使用bcrypt函数加密，很安全 -C 使用bcrypt函数加密的次数，默认为5，范围是4到31，次数越多越安全，但会更慢 -d 使用crypt函数加密，不安全 -s 使用SHA加密密码，不安全 -p 不加密密码，不安全 -D 删除指定认证用户 主配置文件的认证指令： 12345678AuthType 指定web身份认证的类型，有四种类型： none 不认证 basic 文件认证（默认），需要mod_auth_basic模块 digest md5摘要认证，需要mod_auth_digest模块 form 表单认证，需要mod_auth_form模块AuthName 设置身份认证时的提示信息AuthUserFile 指定web用户认证列表，即htpasswd命令生成的密码文件AuthGroupFile 指定组认证文件，文件中分组格式为&quot;组名: 组成员....&quot; Require指令：只能放在Directory容器中，用于控制对目录的访问权限，功能由mod_authz_core模块提供。有以下配置： Require all granted | denied：允许|拒绝所有人访问该目录 Require method http方法 ...：只有指定的http方法（如get,post）才能访问该目录 Require expr 正则表达式：只要满足指定正则表达式才能访问 Require user 用户...：只有指定用户能访问 Require valid-user 用户...：认证列表中所有用户都可访问 关于用户的认证需要mod_authz_user模块 Require group 组...：指定组内的用户才能访问 Require file-owner：web用户名必须与请求文件的UID对应用户名一致才能访问 Require file-group：web用户名必须为请求文件的gid组中的一员才能访问 组认证需要mod_authz_groupfile模块 Require ip IP地址[/Mask]...：指定IP能访问该目录 Require host 域名...：指定域名能访问该目录 关于ip和host的认证需要mod_authz_host模块 若Require后加上not则是取反。 认证实验： 首先创建密码认证文件：htpasswd -cb /etc/httpd/secret mike 123456，认证用户并不需要在系统中存在。 配置文件中的认证配置： 123456789&lt;Directory &quot;/var/www/virhost1&quot;&gt; Options Indexes AllowOverride None #若通过.htaccess文件配置了以下认证信息，则需要将AllowOverride的值设为AuthConig AuthType Basic AuthName &quot;Enter Auth Username and Password:&quot; AuthUserFile /etc/httpd/secret Require user mike&lt;/Directory&gt; 重启httpd，通过浏览器访问，会提示输入用户名密码。 创建组认证文件echo &quot;group1: mike&quot; &gt; /etc/httpd/auth_group，修改配置文件： 12345678910&lt;Directory &quot;/var/www/virhost1&quot;&gt; Options Indexes AllowOverride None AuthType Basic AuthName &quot;Enter Auth Username and Password:&quot; AuthUserFile /etc/httpd/secret AuthGroupFile /etc/httpd/auth_group Require user mike Require group group1&lt;/Directory&gt; .htaccess文件.htaccess文件提供了一种基于每个目录进行配置更改的方法，该文件包含一个或多个配置，而该文件存放在某个Directory下，则该文件中的配置都应用于这个Directory。 如果有权限访问httpd主服务器配置文件，则应该完全避免使用.htaccess文件，使用.htaccess文件会降低Apache http服务器的速度。 如果想给.htaccess文件改名，则需要在配置文件中用指令AccessFileName &quot;文件名&quot;说明。 是否启用.htaccess文件取决于AllowOverride指令，该指令决定是否启用文件中定义的指令。 通常，只有在无法访问主服务器配置文件时才应使用.htaccess文件。.htaccess文件主要面向于没有root访问权限而无法改动主配置文件的用户，允许他们通过配置各自网站的.htaccess文件自行进行配置修改。 应该避免使用.htaccess文件的两点原因： 当AllowOverride设置为允许使用.htaccess文件时，httpd将在每个目录中查找.htaccess文件。因此，允许.htaccess文件会导致性能下降，且每次请求文档时都会加载.htaccess文件。 httpd必须在所有更高级别的目录中查找.htaccess文件，以便拥有必须应用的完整指令。 例如，如果从目录/www/htdocs/example中请求文件，httpd必须查找以下文件 1234/.htaccess/www/.htaccess/www/htdocs/.htaccess/www/htdocs/example/.htaccess 这样会查找四个文件，即使不存在。 若指定重定向的指令，则在.htaccess上下文中，必须重新编译每个对目录的请求的正则表达式 允许用户修改服务器配置可能导致无法控制的更改，必须对用户的权限进行精细的控制，准确地设置AllowOverride的内容。 由于会从最上级目录迭代向下查找.htaccess文件，所以，若不同的.htaccess文件中有相同指令，则最下层的.htaccess文件中的该指令生效，下层的文件中的指令会覆盖上层文件中相同的指令。 .htaccess文件的常用示例认证（Authentication）：需要在&lt;Directory&gt;中配置AllowOverride AuthConfig 12345AuthType BasicAuthName &quot;Password Required&quot;AuthUserFile &quot;/www/passwords/password.file&quot;AuthGroupFile &quot;/www/passwords/group.file&quot;Require group admins 服务器端包括（Server Side Includes，SSI）：提供了向现有HTML文档添加动态内容的方法，而无需通过CGI程序或其他动态技术。 SSI适用于在大部分内容都是静态的网页中添加小块动态信息，例如当前时间。若网页大部分内容都是动态生成的，则并不适用。 若要使能SSI，则需要在配置文件中或.htaccess文件中添加Options +Includes，表示允许为SSI指令解析文件。 还需要告诉Apache需要解析的文件，例如： 12AddType text/html .shtmlAddOutputFilter INCLUDES .shtml 缺点：如果想将SSI指令添加到现有页面，则必须更改该页面的名称以及该页面的所有链接。 重写规则（Rewrite Rules）：在.htaccess文件中使用RewriteRule时，每个目录的上下文会稍微改变一下，规则被认为是相对于当前目录，而不是原始请求的URI。 12345在根目录中的.htaccess文件RewriteRule &quot;^images/(.+)\.jpg&quot; &quot;images/$1.png&quot;在images中的.htaccess文件RewriteRule &quot;^(.+)\.jpg&quot; &quot;$1.png&quot; CGI配置：允许指定目录中的CGI程序运行 1234Options +ExecCGIAddHandler cgi-script cgi pl若要将目录中的所有文件都看做CGI程序，则将AddHandler替换为SetHandler cgi-script 页面重定向CGICGI（common gateway interface，通用网关接口）是Web 服务器运行时外部程序的规范，按CGI 编写的程序可以扩展服务器功能，处理动态内容。CGI 应用程序能与浏览器进行交互，还可通过数据库API与数据库服务器等外部数据源进行通信,从数据库服务器中获取数据。对于HTTP，只有get和post方法允许执行cgi脚本。 常见的CGI术语： fastcgi：是cgi协议的优化版本 php-cgi：php-cgi实现了fastcgi，但性能不佳，单进程处理请求。 php-fpm：全称：php-fastcgi process manager，是php-cgi的改进版，管理多个php-cgi的进程及线程 cgi进程或线程：用于接收web服务器的动态请求，调用并初始化zend虚拟机 zend虚拟机：对php文件的语法分析、编译并执行，执行完成后关闭 CGI的三种交互模式： cgi模式：httpd每收到一个动态请求就fork一个cgi进程，该进程返回结果后就自动销毁 动态模块模式：将php-cgi模块编译进httpd php-fpm模式：使用php-fpm管理php-cgi，httpd不再控制php-cgi进程的启动，可将php-fpm独立运行在其他非web服务器上，实现动静分离 动态httpd安装Apache后，会在存放网页的目录中生成一个目录cgi-bin，关于CGI的配置在主配置文件中。 指令ScriptAlias：使Apache允许执行一个特定目录中的CGI程序，当客户端请求此特定目录中的资源时，Apache假定其中所有的文件都是CGI程序并试图运行它。格式：ScriptAlias /cgi-bin/ &quot;CGI存放目录&quot; 12345678&lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/var/www/cgi-bin/&quot;&lt;/IfModule&gt;&lt;Directory &quot;/var/www/cgi-bin&quot;&gt; AllowOverride None Options None Require all granted&lt;/Directory&gt; 关于CGI模块加载的配置在conf.modules.d/01-cgi.conf中。 12345678910&lt;IfModule mpm_worker_module&gt; LoadModule cgid_module modules/mod_cgid.so&lt;/IfModule&gt;&lt;IfModule mpm_event_module&gt; LoadModule cgid_module modules/mod_cgid.so&lt;/IfModule&gt;# worker和event使用mod_cgid，而prefork使用mod_cgi&lt;IfModule mpm_prefork_module&gt; LoadModule cgi_module modules/mod_cgi.so&lt;/IfModule&gt; 若开启了Selinux，则还需要修改cgi-bin的上下文chcon -R -t httpd_sys_script_exec_t /var/www/cgi-bin httpd与SSLSSL对Apache能提供的功能： 认证用户与服务器 提供数据保密性和完整性 SSL协议的工作流程包括服务器认证阶段和用户认证阶段 客户端向服务器发送一个hello开始消息，发起一个会话连接 服务器根据客户端信息确定是否生成新的主密钥，如果需要就会在响应hello信息中添加生成主密钥需要的信息 客户端收到响应信息，根据信息生成一个主密钥，用服务器的公钥加密发给服务器 服务器收到后返回客户一个用主密钥认证的信息，让客户端认证服务器 服务器通过客户端认证后，进入用户认证阶段，由服务器开始对客户端的认证 服务器向客户端发起提问（封装在数字签名中） 客户端返回答案和公钥，提供认证信息 HTTPS安全超文本传输协议，内置在浏览器中，对数据压缩和解密。HTTPS就是用SSL作为HTTP应用层的子层，使用TCP443端口。 Apache通过mod_ssl模块实现对TLS/SSL的支持，该模块存放在/usr/lib64/httpd/modules/mod_ssl.so，并有配置文件/etc/httpd/conf.modules.d/00-ssl.conf。还有相关模块mod_socache_shmcb，是一个共享对象缓存提供程序，提供对共享内存段内高性能循环缓冲区支持的缓存的创建和访问，已默认加载。 httpd服务器配置自签名证书： 123456789openssl genrsa -out /etc/pki/tls/private/server.key 2048 #生成私钥openssl req -new -x509 -key /etc/pki/tls/private/server.key -out /etc/pki/tls/certs/server.crt #根据私钥生成根证书 Country Name (2 letter code) [XX]:CN #国家名 State or Province Name (full name) []:jiangsu #省名 Locality Name (eg, city) [Default City]:Yangzhou #地名 Organization Name (eg, company) [Default Company Ltd]:NJUPT #公司名 Organizational Unit Name (eg, section) []:Tech #部门名 Common Name (eg, your name or your server&apos;s hostname) []:system1 #主机名 Email Address []:system1@example.com #邮箱 也可以通过进入/etc/pki/tls/certs并使用命令make server.key创建私钥。 配置SSL虚拟主机，需要引用/etc/httpd/conf.d/ssl.conf中的配置，并做修改。 12345678910111213&lt;VirtualHost *:443&gt; SSLEngine on SSLProtocol all -SSLv2 -SSLv3 SSLCipherSuite HIGH:3DES:!aNULL:!MD5:!SEED:!IDEA SSLHonorCipherOrder on SSLCertificateFile /etc/pki/tls/certs/server.crt SSLCertificateKeyFile /etc/pki/tls/private/server.key DocumentRoot &quot;/var/www/html&quot; ServerName system1.example.com ErrorLog &quot;/var/log/httpd/error_log&quot; CustomLog &quot;/var/log/httpd/access_log&quot; common&lt;/VirtualHost&gt; 由于是对已存在的虚拟主机进行SSL封装，所以，需要在原虚拟主机中添加两条指令进行重定向，使任何访问原http地址的客户端都跳转到https地址。 12345678&lt;VirtualHost *:80&gt; DocumentRoot &quot;/var/www/html&quot; ServerName system1.example.com ErrorLog &quot;/var/log/httpd/error_log&quot; CustomLog &quot;/var/log/httpd/access_log&quot; common RewriteEngine on RewriteRule ^(/.*)$ https://%&#123;HTTP_HOST&#125;$1 [redirect=301]&lt;/VirtualHost&gt; 通过浏览器访问http://system1.example.com，会出现不安全提示 确认添加例外后，就能自动跳转到https://system1.example.com。 httpd日志当Apache开始运行后，会生成4种标准日志文件： 错误日志error_log 访问日志access_log 传输日志 cookie日志 若使用SSL加密，还会生成ssl_access_log、ssl_error_log、ssl_request_log。当日志文件过大时，Apache会自动生成新的日志文件，文件的名称以配置文件中指定。 LogFormat指定的日志记录格式变量： 变量 含义 %b 发送字节（不含HTTP标题） %f 文件名 %h 远程主机 %a 远程IP地址 %{HEADER}i HEADER内容：发送给服务器的请求 %p 服务器的服务端口 %r 请求的第一行，类似GET / HTTP/1.0 %s 状态（起始请求），最后请求状态为%&gt;s %t 时间，格式是common日志格式中的时间格式 %{format}t 时间，格式由format给出 %T 服务器请求花费的时间（单位秒） %u 来自auth的远程用户，若返回码为401则可能是假的 %U 请求的URL路径 %v 服务器的提供服务ServerName 错误日志记录的等级： 等级 解释 Emerg 紧急，系统不可用 Alert 需要立刻注意 Crit 危险警告 Error 除上述三种外的其他情况 Warm 警告 Notice 需要引起注意 Info 一般消息 Debug Debug模式产生的消息 访问日志的种类： 普通日志：在LogFormat定义的名字为common 参考日志：记录客户访问站点的用户身份，名字为referer 代理日志：记录请求的用户代理，名字为agent 综合日志：结合了上面三种，名字为combined 日志切割Apache提供了命令rotatelogs，对日志进行切割，将庞大的日志文件切割为相对小的文件。 12345678910111213141516以轮替时间做切割：rotatelogs [options] 日志文件 [轮替时间（单位秒）][偏移量]以日志大小做切割：rotatelogs [options] 日志文件 [日志文件大小]偏移量为相对于UTC的分钟数，若省略，默认为0，即使用UTC时间。东八区即为8x60=480可以把以下配置添加到主配置文件：TransferLog &quot;|rotatelogs 日志文件 86400&quot;TransferLog &quot;|rotatelogs 日志文件 5M&quot;默认生成的日志名为&quot;日志名.日志开始记录的时间&quot;，如果使用轮替时间，则该值就是轮替时间的倍数，可通过cron服务设置。如果日志文件包含了strftime转换格式，则使用该格式。当轮替时间结束或日志文件大小达到指定值，就会生成一个新日志文件 -v 详细的操作信息会被错误输出(strerr) -l 使用本地时间。不要在改变了GMT偏移量的环境中使用该选项，若设置了此选项，也就不用设置偏移量了 -f 在程序启动时强制开启日志 -t 截断日志 -e 输出日志到标准输出 -c 创建日志，无论是否为空 若要按时间轮替日志文件： ErrorLog &quot;|rotatelogs 日志存放目录/%Y%m%d_error.log 86400 480&quot; CustomLog &quot;|rotatelogs 日志存放目录/%Y%m%d_access.log 86400 480&quot; common 若要按日志大小轮替日志文件： ErrorLog &quot;|rotatelogs -l 目录/%Y%m%d_error.log 5M&quot; CustomLog &quot;|rotatelogs -l 目录/%Y%m%d_access.log 5M&quot; common Webalizer分析统计日志Webalizer是一个高效的web服务器日志分析程序。webalizer基本支持所有的日志文件格式，包括common，combined。目前还支持ftp日志、squid日志分析。 直接yum install webalizer即可。webalizer的配置主要通过配置文件webalizer.conf实现。 12345678910111213LogFile /var/log/httpd/access_log #日志文件的路径，也可通过命令行选项指定OutputDir /var/www/usage #统计报表的输出位置HistoryName /var/lib/webalizer/webalizer.hist #webalizer生成的历史文件名Incremental yes #设置是否增量IncrementalName /var/lib/webalizer/webalizer.current #保存当前数据的文件名PageType htm* #定义哪些类型的URL属于页面访问UseHTTPS no #若在一台安全服务器上运行，需要开启DNSCache /var/lib/webalizer/dns_cache.db #反向DNS解析的缓存文件DNSChildren 10 #设置用于DNS解析的子进程，值要在5到20间Quiet yes #不显示输出信息FoldSeqErr yes #强制忽略次序错误，因为Apache HTTP服务器可能会生成无序日志条目HideURL *.gif #设置需要隐藏的内容SearchEngine yahoo.com p= #设置搜索引擎和URL查询格式 一般只要配置LogFile和OutputDir即可。 123456789101112131415161718webalizer [options] [log file] -v 显示日志详细信息 -d 显示额外的debug信息 -F type 设置日志类型（clf | ftp | squid | w3c） -f 忽略次序错误 -i 忽略历史文件 -p 保留状态（递增） -b 忽视状态（递增） -q 忽略消息信息 -Q 忽略所有信息 -T 显示时间信息 -c file 指定配置文件 -n name 指定服务器主机名 -o dir 指定存放结果的文件 -t name 指定报告题目的主机名 --ip 查看指定IP地址的访问情况 --start 指定开始时间 --end 指定结束时间 在/var/www/usage下生成了几张图片和两个html文件，其中index.html是简要信息，usage_日期.html是详细的分析文件 index.html usage_日期.html httpd代理httpd通过ProxyRequests指令配置正向代理的功能 123456ProxyRequests onProxyVia on&lt;Proxy &quot;*&quot;&gt; #访问任意外网URL Require host 允许通过代理访问外网的内网服务器 #也可以是Require all granted&lt;/Proxy&gt; Apache-MPM模式MPM(Multi-Processing Modules)，Apache的多路处理模块，有三种模式：prefork、worker、event。 编译时可通过--with-mpm指定模式，也可以通过--enable-mpms-shared=all支持全部三种。httpd2.4以上默认采用event模式。并可通过apachectl -l看到编译了event.c模块。 httpd2.4通过rpm安装会发现仍采用prefork模式，而源码安装则已使用event模式 可以修改httpd.conf中添加以下模块（源码安装）或/etc/httpd/conf.modules.d/00-mpm.conf（rpm安装）改变模式 123LoadModule mpm_prefork_module modules/mod_mpm_prefork.so 或LoadModule mpm_worker_module modules/mod_mpm_worker.so 或LoadModule mpm_event_module modules/mod_mpm_event.so prefork：实现了一个非线程、预派生的工作模式。在Apache启动之初，就会预派生一些子进程，然后等待连接。可以减少频繁创建和销毁进程的开销，每个子进程只有一个线程。成熟稳定，可以兼容新老模块，也不需要担心线程安全问题。效率比worker略高 缺点：一个进程相对地占用更多的资源，消耗大量内存，不擅长处理高并发的场景。 worker：使用了多进程和多线程的混合模式，也同样会预派生一些子进程，然后每个子进程创建一些线程，同时包括一个监听线程，每个请求过来会被分配到一个线程来服务。占用内存少，适合高并发环境 使用线程的原因：线程比进程更加轻量级，因为线程通常会共享父进程的内存地址的，因此内存占用会减少一些。如果一个线程异常挂了，会导致父进程和它的其他正常子线程都挂了，只会影响Apache的一部分，而不是整个服务。 缺点：必须考虑线程安全问题，因为多个子进程时共享父进程的内存地址的。若使用keepalive的长连接方式，某个线程一直占据，若过多的线程被占用，会导致高并发时无服务线程可用。 event：从Apache2.2才被加入MPM，Apache2.4开始成为默认MPM。类似worker模式，但解决了keepalive问题。有一个专门的线程来管理这些keep-alive线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放，这样增强了在高并发场景下的请求处理能力。 各MPM模式的简单优化：若是rpm安装，就在httpd.conf中添加，若为源码安装，就在/usr/local/httpd-2.4/conf/extra/httpd-mpm.conf中找到对应模块修改。以下参数基本采用配置文件默认值。 worker模式 1234567891011121314151617181920212223242526&lt;IfModule mpm_worker_module&gt; ServerLimit 25 #服务器允许配置的上限进程数 # 与ThreadLimit结合使用，可设置MaxClients允许配置的最大数值 # 在重启期间对ServerLimit的修改都会被忽略，但对MaxClients的修改可生效 ThreadLimit 200 #每个子进程可配置的线程数的上限 # 也设置了ThreadPerChild的上限，默认为64 StartServers 3 #服务器启动时建立的子进程数，默认为3 MinSpareThreads 75 #最小空闲线程数，默认75。 #若服务器中空闲进程太少，子进程会自动产生空闲进程等待 MaxSpareThreads 250 #最大空闲线程数，默认250。 #若服务器中空闲进程太多，子进程会杀死多余的空闲进程。 #取值范围：&gt;= MinSpareThreads+ThreadsPerChild MaxClients 2500 #允许同时运行的最大进程数，任何超过限制的请求进入等待队列 #默认值为ServerLimit*ThreadsPerChild。若要增加此项，则同时也要增加ServerLimit ThreadsPerChild 25 #每个子进程建立的常驻执行线程数，默认25。 #子进程创建这些线程后就不创建新线程了 MaxConnectionsPerChild 0 #处理多少个请求后子进程自动销毁，默认值0意味着永不销毁。 # 在Apache2.4版本以前，叫做MaxRequestsPerChild #当负载较高时，为了使每个进程处理更多的请求，避免销毁、创建进程的开销，一般建议设置为0或较大的数字。&lt;/IfModule&gt; prefork模式 12345678&lt;IfModule mpm_prefork_module&gt; StartServers 5 MinSpareServers 5 #最小空闲进程数，与MinSpareThreads同理 MaxSpareServers 10 #最大空闲进程数，与MaxSpareThreads同理 ServerLimit 2000 MaxClients 1000 #默认MaxClients最多有256个线程 MaxConnectionsPerChild 0 &lt;/IfModule&gt; 修改模式重启httpd，查看进程，能看到五个子进程 1234567ps -ef | grep httpdroot 2241 1 1 22:05 ? 00:00:00 /usr/sbin/httpd -DFOREGROUNDapache 2242 2241 0 22:05 ? 00:00:00 /usr/sbin/httpd -DFOREGROUNDapache 2243 2241 0 22:05 ? 00:00:00 /usr/sbin/httpd -DFOREGROUNDapache 2244 2241 0 22:05 ? 00:00:00 /usr/sbin/httpd -DFOREGROUNDapache 2245 2241 0 22:05 ? 00:00:00 /usr/sbin/httpd -DFOREGROUNDapache 2248 2241 0 22:05 ? 00:00:00 /usr/sbin/httpd -DFOREGROUND event模式 12345678&lt;IfModule mpm_event_module&gt; StartServers 3 MinSpareThreads 75 MaxSpareThreads 250 ThreadsPerChild 25 MaxRequestWorkers 400 MaxConnectionsPerChild 0&lt;/IfModule&gt; Apache实用第三方模块若要在httpd上添加新的模块，可以通过修改模块配置文件增加LoalModule指令添加，也可以使用httpd-devel提供的工具apxs直接添加，需要httpd开启了DSO。 123456apxs -n 模块名 指定模块名，可与-i和-g组合 -i 安装模块，可指定多个 -a 自动在主配置文件加上LoadModule -A 自动在主配置文件加上#LoadModule，即安装了但先不启用 -c C文件 将.c文件编译为.so文件 模块间可能存在依赖，可根据报错信息解决。 Gzip压缩Gzip将Apache网页内容压缩后传输给客户端，加快网页加载速度，建议开启。Gzip有两个模块：mod_gzip和mod_deflate， 防DDOS攻击应对DDOS攻击的模块为mod_evasive，可通过yum install mod_evasive获取。安装完成后会生成/usr/lib64/httpd/modules/mod_evasive24.so，以及/etc/httpd/conf.d/mod_evasive.conf 参考文章 高性能网站构建实战 Linux系统管理与网络管理 Linux就该这么学 Linux运维之道（第二版） Linux服务器架设指南（第二版） 防线-企业Linux安全运维理念和实战 RHCSA/RHCE红帽Linux认证学习指南（第7版） Apache性能优化之MPM选择和配置 Apache的三种MPM模式比较：prefork，worker，event apache的三种mpm模式 浅谈.htaccess文件–避免滥用.htaccess文件 Apache HTTP Server Tutorial: .htaccess files Apache httpd Tutorial: Introduction to Server Side Includes 简单说明CGI和动态请求是什么]]></content>
      <tags>
        <tag>server</tag>
        <tag>Apache</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS基础笔记]]></title>
    <url>%2F2018%2F05%2F02%2FNFS%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇笔记包含以下内容： NFS原理 NFS基础配置 服务器端 客户端 NFS原理NFS（Network Files Network）网络文件系统，允许网络中主机通过通过TCP/IP进行资源共享。采用C/S工作模式，NFS服务器相当于文件服务器，将某个目录设置为输出目录，客户端可将服务器端的输出目录挂载在本地进行访问。NFSv4基于TCP，端口号2049。RPC（Remote Procedure Call）远程过程调用，是一种通过网络从远程计算机程序上请求服务，跨越了传输层和应用层的协议。 NFS基础配置环境： 两台虚拟机 192.168.163.103/24 192.168.163.104/24 系统：CentOS7 Selinux：关闭 防火墙：关闭 服务器端NFS服务依赖于RPC服务与外界通信，所以需要安装rpcbind程序而NFS 安装NFS主程序和RPC程序yum install nfs-utils rpcbindsystemctl enable nfs-serversystemctl start nfs-server rpcbind.service 配置文件/etc/exports12# 格式为：共享目录 分享给的主机1(参数) 主机2(参数) .../var/nfsshare 192.168.163.*(rw,sync) *.example.com(rw) 参数列表 参数 含义 ro 客户端只读 rw 客户端可读写 sync 数据同步写入内存与磁盘，保证数据一致性，效率低 async 异步IO，数据先暂时存与内存，待需要时写入硬盘，效率高，但数据丢失风险高 noaccess 阻止访问该目录及其子目录 all_squash 无论NFS客户端使用什么用户访问，都映射为NFS服务器端的匿名用户，即nfsnobody root_squash 当NFS客户端使用root访问时，映射为NFS服务器端的匿名用户，即nfsnobody no_root_squash 当NFS客户端使用root访问时，仍映射为NFS服务器端的root，并不安全 wdelay 为合并多次更新而延迟写入磁盘 no_wdelay 尽可能快地写入磁盘 secure 限制nfs服务只能使用小于1024的TCP/IP端口传输数据 insecure 可使用大于1024的端口 anounuid 指定NFS服务器中的用户为匿名用户 anoungid 指定NFS服务器中的用户组为匿名用户组 默认情况下，nfs服务会禁止客户端的root用户对共享目录进行写操作，目的是为了保证当nfs以共享目录工作时，共享目录的数据不会被客户端随意修改，但是当nfs以远程存储工作时，这个功能就不合理，所以当nfs以远程存储来工作时，需要在服务端设置no_root_squash选项关闭该功能。 配置完后重启nfs-server服务，或者使用exportfs命令12345exportfs -a 导出所有列在/etc/exports的目录 -v 显示所有被导出或取消导出的目录 -r 重新导出所有列在/etc/exports的目录 -u [目录] 取消指定目录的导出，与-a同时用时，会取消配置文件中所有目录的导出 nfsstat命令可查看当前NFS信息12345nfsstat -s 显示NFS服务器信息 -c 显示NFS客户端信息 -m 显示每个NFS文件系统的统计信息（在客户端上查看） -r 显示RPC信息 若开启了firewalld，则需要放行nfs和rpcbind还有mountd服务，放行端口20491234firewall-cmd --permanent --add-service=nfsfirewall-cmd --permanent --add-service=rpc-bindfirewall-cmd --permanent --add-service=mountdfirewall-cmd --permanent --add-port=2049/tcp 2049/udp mountd提供挂载服务，与nfs无关，只是为了方便客户端挂载 若开启了Selinux，需要添加上下文123chcon -R -t public_content_t /var/nfssharesetsebool -P nfs_export_all_rw onsetsebool -P nfs_export_all_ro on NFS客户端 需要安装nfs-utils rpcbindyum install nfs-utils rpcbind 通过showmount查看NFS服务器的共享信息123showmount [options] [NFS服务器] -e 显示NFS服务器的共享列表 -a 显示本机挂载NFS资源情况 123# showmount -e 192.168.163.102Export list for 192.168.163.102:/var/nfsshare 192.168.163.* 挂载到本机123456# mkdir /nfsshare #创建挂载目录# mount -t nfs 192.168.163.102:/var/nfsshare /nfsshare# df -hFilesystem Size Used Avail Use% Mounted on......192.168.163.102:/var/nfsshare 17G 8.1G 9.0G 48% /nfsshare 在mount时也可使用-o指定文件系统的选项12345678910rsize= 从NFS服务器读文件时每次使用的字节数，默认1024字节wsize= 向NFS服务器写文件时每次使用的字节数，默认1024字节timeo= RPC调用超时后，确定重试算法的参数soft 软挂载方式，当客户端请求得不到回应时，提示IO错误并退出hard 硬挂载方式，当客户端请求得不到回应时，提示服务器无响应，但继续请求。默认硬挂载intr NFS文件操作超时并时硬挂载时，允许中断文件操作并向调用它的程序返回EINTRro 只读方式挂载NFS文件系统rw 读写方式挂载NFS文件系统fg 在前台重试挂载bg 在后台重试挂载 也可通过配置文件/etc/fstab开机自动挂载123# vim /etc/fstab......192.168.163.102:/var/nfsshare /nfsshare nfs defaults 0 0 使用mount或配置文件/etc/fstab挂载的不足：NFS服务器与客户端的连接不是永久的，任何一方的掉线都会导致另一方等待超时。并且即使很多用户都挂载了共享目录，也会有大部分的用户在大部分时间是不会使用的，这样造成了NFS服务器资源的大量消耗。可通过autofs服务按需动态挂载解决该问题。 使用autofs自动挂载autofs是一个提供按需挂载的服务，只有在用户访问该挂载点时才会动态挂载该共享目录。安装autofs程序，并开机自启yum install autofssystemctl enable autofs.servicesystemctl start autofs.service创建autofs关于nfs主配置文件，也可以直接在autofs的主配置文件/etc/auto.master中添加内容。12345# vim /etc/auto.master.d/nfs.autofs主配置文件的配置格式：挂载点顶层目录 映射文件/nfs /etc/nfs.misc由于挂载点为/nfs/share，所以顶层目录为/nfs 创建nfs配置的映射文件/etc/nfs.misc12345# vim /etc/nfs.misc映射文件格式：挂载点 [-挂载选项] NFS服务器名或IP:共享目录挂载点是对于挂载点顶层目录的相对路径share -fstype=nfs,rw 192.168.163.102:/var/nfsshare 配置完成后重启autofs服务即可。进入/nfs目录中，查看并无内容。然后进入share便可查看到挂载目录的内容。再通过df查看，已成功挂载。 注：由于在客户端挂载时也会指定选项，若与服务器端选项不同，在执行操作时可能会报错，即：选项以服务器端配置为准。]]></content>
      <tags>
        <tag>server</tag>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Samba基础学习笔记]]></title>
    <url>%2F2018%2F05%2F02%2Fsamba%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇笔记包含以下内容： Samba原理 Samba基础配置 服务器端 客户端 Samba原理Samba最初的目的是为了Windows和Linux之间的沟通，实现不同操作系统的资源共享，如今成为了十分安全，高效的文件服务。Samba有以下主要功能： 共享文件与打印机 提供身份认证，给不同身份的用户不同的访问权限和文件 可进行域名解析，将计算机的NetBIOS名解析为IP地址 samba能收集局域网上用户广播的主机信息，提供检索服务，也称为浏览服务，能显示共享目录，打印机等资源 支持SSL Samba整合了SMB协议和NetBIOS协议，基于TCP/IP。NetBIOS协议NetBIOS（Network Basic Input/Output System），网络基本输入输出系统协议，属于会话层协议。能通过该协议获取计算机主机名，并解析为IP地址。SMB协议SMB（Send Messsage Block），运行于NBT协议（NetBIOS over TCP/IP），属于表示层与应用层协议。端口号：139/TCP，137、138/UDP。 SMB协议工作流程 协议协商客户端向Samba服务器发送Negport请求报文，列出所有支持的SMB版本。服务器收到后回应Negport报文，列出希望客户端使用的SMB版本。 建立连接确定了SMB版本，客户端会发送Session Setup请求报文，包含用户名与密码，建立连接。服务器收到后进行验证并回应报文，若验证通过，就返回为该用户分配的唯一UID，若失败则返回失败信息。 访问共享资源客户端向服务器发送Tree Connect请求报文，包含要访问的共享资源名。服务器收到后，根据配置文件确定是否该用户能访问，返回一个响应报文，若允许访问，就给该用户与共享资源连接分配一个TID，用户即可访问该资源。 断开连接客户端向服务器发送Tree Disconnect报文，请求服务器断开连接，服务器也回应一个响应，并断开连接。 Samba守护进程 用户若要访问Windows上的公共资源，必须加入该Windows主机的群组Workgroup，并该用户主机必须设置一个主机名（不是hostname），该主机名是建立在NetBIOS协议上的，可称为NetBIOS Name，在同一个群组中，该NetBIOS Name必须唯一。 用户是否能访问并对该文件进行操作不仅需要通过服务器身份认证，还需要对该文件具有权限。 Samba服务有两个守护进程 smbd：用于管理samba主机共享目录、文件、打印机等，利用TCP传输文件，开放端口为139/TCP和445/TCP nmbd：用于管理群组、NetBIOS Name的解析，基于UDP，开启端口137/UDP，138/UDP进行解析 Samba安装包： samba：包含samba的守护进程文件，samba文档，logrotate配置文件，开机默认选项配置文件 samba-common：包含samba主要配置文件smb.conf，配置文件检查程序testparm等 samba-client：samba客户端程序，提供客户端操作指令集 Samba基础配置实验环境： 两台虚拟机： samba服务器：192.168.163.103/24 samba客户端：192.168.163.104/24 系统：CentOS7 Selinux：未开启 firewalld：未开启 服务器端安装samba客户端123yum install samba-common sambasystemctl enable smb nmbsystemctl start smb nmb 创建共享目录，可随意创mkdir /var/smbshare修改配置文件/etc/samba/smb.conf配置文件中可在选项前加;使其不生效，相当于#注释配置文件存在以下配置块：[global] 全局选项，对所有资源生效基础配置则不需要修改123456789101112131415161718[global] workgroup = SAMBA #设置群组 server string = Samba Server #设置服务器描述 netbios name = MYSERVER #设置NetBIOS Name interfaces = lo eth0 192.168.163.0/24 # 设置监听接口、IP地址 hosts allow = 192.168.163. #白名单，设置允许的主机网段 hosts deny = #黑名单，黑白名单设置一个即可 security = user #samba的安全模式，有三种模式：user、share、server #user模式为每次访问服务器都会登录验证，share模式为不需登录。官方仅推荐user模式。 passdb backend = tdbsam #存放用户信息，有两种选择tdbsam和lsapsam，tdbsam不需要额外配置 log file = /var/log/samba/log.%m #设置日志文件路径，%m会替换为请求连接的NetBIOS名 username map = /etc/samba/smbusers #设置用户映射，记录samba账号和虚拟账号的对应关系 #---打印配置--- printing = cups #打印配置，使用cups服务 printcap name = cups #通常设置为printcap文件 load printers = yes #自动加载打印机列表 cups options = raw #设置cups的选项，raw为允许在windows客户端上加载驱动 [homes]为特殊共享目录，表示用户主目录[printers]为特殊共享目录，表示打印机配置共享资源：12345678910111213[smbshare] comment = smbshare #资源描述 path = /var/smbshare #共享目录 public = no #是否允许匿名访问 guest ok = no #是否允许不输入密码访问 printable = Yes #是否可读 writable = yes #是否可写，只有该目录有写权限且此项为yes，才能写入 browseable = yes #是否可见 write list = mike #设定特定用户写权限 #若writable为no，此项仍能生效 create mask = 0600 #创建文件默认权限 directory mask = 0775 #创建目录默认权限链路 hosts allow =192.168.163. #白名单 可通过testparm检查配置文件是否正确可通过man smb.conf查看详细配置文件选项创建用户并添加到samba由于该用户是提供给客户端用于登录samba的，所以在服务器端应设置为不能登陆，并且为了安全性，不要设密码。useradd mike -s /sbin/nologin注：samba并不是将系统中的用户变为samba用户的，samba的用户是独立于linux系统的，但必须在linux系统中存在，才能映射，所以linux系统中需要创建同名用户。将用户添加到smb服务器的用户列表中，并设置smb登录密码smbpasswd -a mike，然后输入登录密码12345smbpasswd [options] [username] -a add添加 -d disable禁止用户访问 -n no password不设置密码，需要smb.conf中global设置nullpasswords=true开启 -x delete删除用户 或者使用另一条命令pdbedit，用于管理SMB服务的账号信息数据库pdbedit -a -u mike12345pdbedit [options] [username] -a 添加 -x 删除 -L 列出用户列表 -v 详细信息 注： 若安装并开启了firewalld，需要开启端口TCP139端口，UDP137、138端口，并放行服务samba。 若安装并开启了Selinux，需要添加上下文12345678chcon -R -t samba_share_t /var/smbshare或semanage fcontext -a -t samba_share_t /var/smbshare然后setsebool -P samba_export_all_rw onsetsebool -P samba_export_all_ro on若分享的是/homesetsebool -P samba_enable_home_dirs on配置完后restorecon -Rv /var/smbshare 客户端安装samba客户端yum install samba-client cifs-utilscifs-utils是让Windows系统能使用公共文件系统的工具。CIFS是微软开发的公共Internet文件系统协议，能够支持网上邻居。查看服务器给指定用户提供的共享目录的信息123456789101112131415161718# smbclient -L //192.168.163.103/smbshare -U mikeEnter SAMBA\mike&apos;s password: Sharename Type Comment --------- ---- ------- print$ Disk Printer Drivers share Disk SHARE smbshare Disk smbshare IPC$ IPC IPC Service (Samba 4.7.1) mike Disk Home DirectoriesReconnecting with SMB1 for workgroup listing. Server Comment --------- ------- Workgroup Master --------- ------- SAMBA SYSTEM3 从返回信息可得知共享资源以及群组和服务器名登录smb服务器，进入指定资源1234# smbclient //192.168.163.103/smbshare -U mikeEnter SAMBA\mike&apos;s password:Try &quot;help&quot; to get a list of possible commands.smb: \&gt; 已进入该共享目录，并进入samba客户端命令行模式，可通过help查看能进行的操作常用命令如下：put [本机文件路径] [资源中相对路径] 上传文件get [资源路径] 下载文件 客户端挂载 创建认证文件1234# vim /root/secure/auth.smbusername=mikepassword=redhatdomain=SAMBA 设置该文件的权限，这个文件的机密性很重要chmod 700 /root/securechmod 600 /root/secure/auth.smb 挂载共享目录mount -t cifs -o rw,credentials=/root/secure/auth.smb //192.168.163.103/smbshare /shares/smbshare Windows端登录及挂载在Windows端，可在文件资源管理器的地址栏输入\\192.168.163.103\smbshare登录进入smb服务器的该资源。若要挂载，在“此电脑”中右击，选择“添加一个网络位置”，按“下一步”，进入以下界面，填入要挂载的共享目录 然后不断“下一步”，即可设置完成。在“此电脑”查看，已成功挂载。]]></content>
      <tags>
        <tag>server</tag>
        <tag>Samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL完全笔记]]></title>
    <url>%2F2018%2F04%2F30%2FMySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于MySQL5.7 本篇包含以下知识点： MySQL体系结构 存储引擎 数据类型 运算符 函数 表操作 数据操作 索引 视图 触发器 存储过程与函数 事务 安全 日志 维护 MySQL体系MySQL采用C/S体系，因此在使用时，是运行两个程序： mysqld：MySQL服务器程序，运行在数据库服务器上，负责监听并处理请求 mysql-client：运行在客户端上，负责连接到数据库服务器并发出指令。 存储引擎MySQL具有可替换存储引擎构架的特征。MySQL功能分为两部分： 外层部分：完成与客户端的连接，调查SQL语句的内容 内层部分：即存储引擎部分，负责接收外层的数据操作指令，完成实际的数据输入输出及文件操作。MySQL支持多种存储引擎，可通过show engines;查看mysql支持的存储引擎，MySQL共支持9种存储引擎，其中最主要的两个引擎为MyISAM和InnoDB，默认引擎为InnoDB。 MyISAM与InnoDB的区别： 特性 MyISAM InnoDB 存储限制 有 64TB 事务安全 不支持 支持 锁机制 表锁 行锁 B树索引 支持 支持 哈希索引 不支持 不支持 全文索引 支持 不支持 集群索引 不支持 支持 数据缓存 支持 索引缓存 支持 支持 数据可压缩 支持 不支持 空间使用 低 高 内存使用 低 高 批量插入速度 高 低 外键 不支持 支持 InnoDB只有表结构，数据全部存储在ibdata1文件中，算法复杂。 MyISAM将表，数据，索引全部单独存储。 MyISAM适合对事务完整型无要求并以访问为主的应用，访问速度快。 InnoDB适合频繁更新、删除操作，对事务要求高，需要实现并发控制的应用。 可通过show create table 表名查询表中使用的存储引擎。也可通过alter table 表名 engine=引擎更改表的存储引擎。 数据类型 整数 tinyint：1字节 smallint：2字节 mediumint：3字节 int：4字节 bigint：8字节 整数类型都分为有符号与无符号。默认有符号，可在类型前加上unsigned创建无符号类型。插入数据只能插入整数，若字段设置了是整数类型，就算插入浮点数也会转换为整数。零填充：zerofill，若数据位数不满设置位数值，则前面补充0，且若设置零填充，数据类型自动变为无符号类型。零填充意义：保持数据格式 12345678910111213141516171819mysql&gt; desc my_int;+-------------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------------+--------------+------+-----+---------+-------+| tinyint_1 | tinyint(4) | YES | | NULL | || smallint_1 | smallint(6) | YES | | NULL | || mediumint_1 | mediumint(9) | YES | | NULL | || int_1 | int(11) | YES | | NULL | || bigint_1 | bigint(20) | YES | | NULL | |+-------------+--------------+------+-----+---------+-------+# 括号中的数值为显示位数（宽度），可修改，不会影响数据。mysql&gt; alter table my_int modify int_1 int zerofill;# zerofill 会在显示宽度不满时用0填满mysql&gt; select int_1 from my_int;+------------+| int_1 |+------------+| 0000000004 |+------------+ 浮点数 float：4字节，也可设置为float(M,D) double：8字节 decimal(M,D)：定点数，M+2字节，取值范围与double一致，但有效范围由M与D决定，M为一共的位数，D为小数部分的位数。小数部分超出没问题，会自动四舍五入，但整数部分不能超出。12345678910111213create table my_float( float_1 float(5,2), double_1 double(5,2), decimal_1 decimal(5,2));mysql&gt; insert into my_float values(1.115,1.115,1.115);# 整数部分不能超出规定长度，但小数部分可以，小数的超出部分会四舍五入。mysql&gt; select * from my_float;+---------+----------+-----------+| float_1 | double_1 | decimal_1 |+---------+----------+-----------+| 1.12 | 1.12 | 1.12 |+---------+----------+-----------+ 字符串 char(length)：定长字符串，定义时指定长度，最大255字节。 varchar(length)：变长字符串，最大长度65536个字节，一般会自动多加一个字节。实际存储从第二个字节开始，接着要用1到2个字节表示实际长度（长度超过255时需要2个字节），因此最大长度不能超过65535。varchar 会保留字符串末尾的空格，而 char 会删除。 text：存储文字的文本字符串 blob：存储二进制的文本字符串若数据量非常大（超过255字节），可选用文本字符串。 枚举字符串：enum()，用于规定数据格式，节省空间（枚举实际存储的是数值）。 集合字符串：set()，集合存储的也是数值，且可以多选 存储数据 char(4) varchar(4) char占用字节 varchar占用字节 abcd abcd abcd 4x3 4x3+1 abcde 错误 错误 超出长度 超出长度 如何选择定长或变长字符串？ * 定长字符串：磁盘空间浪费，但效率高，若数据确定长度一样，就选定长（如身份证，电话号） * 变长字符串：磁盘空间节省，但效率低，若数据长度不确定，就选变长（如住址，姓名） 枚举字符串举例123456mysql&gt; create table my_enum(sex enum(&apos;m&apos;,&apos;f&apos;));mysql&gt; insert into my_enum values(&apos;m&apos;);Query OK, 1 row affected (0.01 sec)# 字段赋值必须填枚举中的字符串mysql&gt; insert into my_enum values(&apos;a&apos;);ERROR 1265 (01000): Data truncated for column &apos;sex&apos; at row 1 在MySQL中，系统会自动转换数据类型。枚举中字符串是数值的证明如下：1234567891011mysql&gt; select sex+0,sex from my_enum \G*************************** 1. row ***************************sex+0: 1 sex: m*************************** 2. row ***************************sex+0: 2 sex: f# 由此可知，枚举中字符串的数值是按照枚举顺序从1开始。# 于是也可以通过数值插入mysql&gt; insert into my_enum values(1),(2);Query OK, 2 rows affected (0.00 sec) 枚举原理：枚举在进行数据规范（定义）的时候，系统会自动建立一个数字与枚举元素的对应关系（存放在日志），然后在进行数据插入时，系统自动将字符转换成对应的数字存储，在进行数据提取时，系统自动将数值转换成对应字符串显示。 集合字符串举例：12mysql&gt; create table my_set(lang set(&apos;c&apos;,&apos;c++&apos;,&apos;python&apos;,&apos;java&apos;));# 与枚举类似，集合也可通过数值进行赋值 日期和时间 date：4字节，1001年到9999年的日期 datetime：8字节，1001年到9999年的日期，并能保存时间 timestamp：4字节，1970年1月1日到现在的秒数，最大到2038年 time：3字节 year：1字节，最小值1901，最大值2155MySQL提供函数from_unixtime()将unix时间戳转换为时间，unix_timestamp()将日期转换为unix时间戳。默认情况下，如果插入时没有指定 TIMESTAMP 列的值，会将这个值设置为当前时间。应该尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高。datetime与时区无关，timestamp与时区有关。 记录长度：任何一条记录的长度最长不能超过65535个字节，一条记录的最长字节数为65534，但可以人为填满。MySQL中text文本字符串不占用记录长度：额外存储，但text字符串也属于记录的一部分，所以一定要占据记录中的部分长度（10字节，保存数据的地址与长度） 运算符算数运算符：加、减、乘、除、模12345678910111213mysql&gt; select 6+4 加, 6-2 减, 6*4 乘, 6/4 除, 6 DIV 4 除, 6%4 模, 6 MOD 4 模;+----+----+----+--------+------+------+------+| 加 | 减 | 乘 | 除 | 除 | 模 | 模 |+----+----+----+--------+------+------+------+| 10 | 4 | 24 | 1.5000 | 1 | 2 | 2 |+----+----+----+--------+------+------+------+当除数为0时，结果为NULL 比较运算符：大于、小于、等于、不等于、IS NULL、BETWEEN AND、IN、LIKE、REGEXP 比较运算符 说明 &gt;或&gt;= 大于或大于等于 &lt;或&lt;= 小于或小于等于 =或&lt;=&gt; 等于 !=或&lt;&gt; 不等于 BETWEEN AND 在指定范围 IS NULL 为空 IN 在指定集合 LIKE 通配符匹配 REGEXP 正则表达式匹配 常用正则表达式 模式字符 说明 案例 ^ 匹配字符串开始 ‘^a’ $ 匹配字符串结束 ‘g$’ . 匹配字符串中任意一个字符 ‘a.c’ [字符集合] 匹配字符集合内的任意一个字符 ‘[abc]’ [\^字符集合] 匹配字符集合外的任意一个字符 ‘^abc’ str1｜str2 匹配符合的字符串 ‘abc｜cde’ * 匹配字符，包含0个和1个 ‘a*‘ + 匹配字符，包含1个 ‘a+‘ 字符串{N} 字符串出现N次 ‘abc{2}’ 字符串(M,N) 字符串至少出现M次，最多N次 ‘abc(2,3)’ 逻辑运算符AND(&amp;&amp;)：与，OR(||)：或，NOT(!)：非，XOR：异或 位运算符&amp;：按位与，|：按位或，~：按位取反，^：按位异或，&lt;&lt;：按位左移，&gt;&gt;：按位右移可使用BIN()函数显示二进制。 函数SQL语句的移植性较强，而函数的移植性不强，因为各种数据库软件都有自己特有的函数。Mysql函数分为： 字符串函数 数值函数 日期函数 系统信息函数 字符串函数 函数 功能 concat(str1,str2…) 连接字符串 insert(str,x,y,instr) 用字符串str的x位置开始y个字符长的子串替换字符串instr lower(str) 将str的所有字符换为小写 upper(str) 将str的所有字符换为大写 left(str,x) 返回str的最左边的x个字符 right(str,x) 返回str的最右边的x个字符 lpad(str,n,pad) 使用pad字符串对str最左边进行填充直到长度为n rpad(str,n,pad) 使用pad字符串对str最右边进行填充直到长度为n ltrim(str) 去掉str左边的空格 rtrim(str) 去掉str右边的空格 trim(str) 去除str行头和行尾的空格 repeat(str,x) 返回str重复x次的结果 replace(str,a,b) 使用字符串b替换str中所有字符串a strcmp(str1,str2) 比较字符串 substring(str,x,y) 返回str中从x位置起y个长度的字符串 数值函数 函数 功能 abs(x) 返回x的绝对值 ceil(x) 返回大于x的最小整数值 floor(x) 返回小于x的最大整数值 mod(x) 返回x%y rand() 返回0-1的随机数 rand(x) 返回0-1的随机数，x对应的随机数是固定的 round(x,y) 返回x的四舍五入后y位小数的值（y可选） truncate(x,y) 返回x截断为y位小数的值 日期和时间函数 函数 功能 curdate() 获取当前日期 curtime() 获取当前时间 now() 获取当前日期和时间 unix_timestamp(date) 获取date的unix时间戳 from_unixtime(timestamp) 获取unix时间戳 week(date) 返回date为一年中的第几周 year(date) 返回date的年份 monthname(date) 返回date的月份 hour(time) 返回time的小时值 minute(time) 返回time的分钟值 系统信息函数 函数 功能 version() 返回版本号 database() 返回当前数据库名 user() 返回当前用户 last_insert_id() 返回最近生成的Auto_Increment值 特殊功能函数|password(str)|对str加密||format(x,n)|对x格式化，保留n位小数||inet_aton(ip)|将IP地址转换为数字||inet_ntoa(x)|将数字转换为IP地址||get_loct(name,time)|创建一个持续时间time的名为name的锁||release_loct(name)|对名字为name的锁解锁||benchmark(count,expr)|将表达式expr执行count次||convert(s USING cs)|将字符串s的字符集变为cs||convert(x,type)|将x转为type类型| 表操作创建表123456create table 表名( 字段1 数据类型, 字段2 数据类型, ......);也可直接create table 数据库名.表名(); # 这样不需要先进入库，直接建表。 表创建后，数据库文件下会生成对应表的结构文件.frm（与存储引擎有关）。 查看创建语句show create table 表名;查看表结构desc/show 表名; 12345678mysql&gt; desc user;# field：字段名# type：字段类型# null：（列属性）是否允许为空，null不是数据类型# key：索引：pri主键，uni唯一键# defalut：（列属性）默认值# extra：（列属性）扩充属性 更改表名rename table 表名 to 新表名;更改表属性12345678alter table 表名 表选项 参数表选项:add column 字段名 数据类型 [位置]; # 新增字段modify 字段名 数据类型 [属性] [位置]; # 修改字段change 旧字段 新字段 数据类型 [属性] [位置]; # 重命名字段drop 字段名; # 删除字段位置：first：第一个，after 字段：在字段后 删除表drop table 表名; 若要删除多张表，用,分隔表名 表约束：保证数据的合法性 空属性：NULL（默认），NOT NULL（不为空） 要做到数据不为空，空就没有意义，空数据无法参与运算，所以定义字段时就要设置not null，若字段未指定该选项，当字段为空时，MySQL会用NULL填充，而NULL会占用一个字节，当指定了not null后，该字段必须有值，确保数据准确性。 列描述comment：无实际含义，描述字段 默认值default：可在字段设置时添加default ，在插入字段时不赋初值就会使用默认值 主键primary key：一张表只有一个字段可以使用对应键，用来唯一的约束该字段里的数据，不能重复，一张表最多只有一个主键，主键默认不为空（not null）。 增加主键： 12345678910111213141516171819202122法一：在创建字段时就添加primary key 关键字create table user( id int primary key, name varchar(20));法二：在创建表时，在所有字段后使用primary key(字段名) 创建主键，如有多个字段作为主键，可以是复合主键create table user( id int, name varchar(20), primary key(id,name));mysql&gt; desc user1;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(20) | NO | PRI | NULL | |+-------+-------------+------+-----+---------+-------+法三：追加主键alter table 表名 add primary key(字段); 或alter table 表名 modify 字段名 类型 primary key;# 前提：字段对应数据是独立的（不重复） 主键约束：主键字段数据不允许相同，若相同则数据操作失败 主键删除：无法更新主键，只有删除了以后才能再添加 alter table 表名 drop primary key; 分类 逻辑主键：字段无业务含义（如id），一般以此类字段做主键 业务主键：字段存放业务数据 自增长auto-increment：若该字段未赋值或仅有默认值，会自动触发，会给字段值不断+1（当前字段中最大值），形成新字段，常与主键搭配。 注： 字段做自增长的前提：本身是一个索引（key属性有值），字段值必须是整型数字。一张表最多只有一个字段自增长。 修改自增长：修改的值必须比该字段当前最大值大(小的话不生效) alter table 表 auto_increment = x; 查看自增长变量 show variables like &#39;auto_increment%&#39;; 123456789101112mysql&gt; show variables like &apos;auto_increment%&apos;;+--------------------------+-------+| Variable_name | Value |+--------------------------+-------+| auto_increment_increment | 1 || auto_increment_offset | 1 |+--------------------------+-------+increment为自增长步数offset为自增长起始值修改：set auto_increment_increment = x;# 修改是对整个数据库，且仅是会话级alter table 表 modify即可修改 唯一键unique key：数据不能重复，允许为空，也可多个为空，空字段不参与唯一键比较。 数据操作数据插入1234insert into 表名 values(字段1,字段2,...),(字段1,字段2,...),...; # 插入数据（直接插数据，字段要一一对应）insert into 表名 (字段1名,字段2名,...) values(字段1,字段2,字段3),...; # 可指定插入字段，就不用对齐了 若主键冲突，即主键对应的值已存在，插入就会失败。有以下两种解决方法。法一：更新insert into 表名(字段(要包含主键)) values() on duplicate key update 字段 = 值;法二：替换replace into 表名(字段(包含主键)) values(); 蠕虫复制：将已有的数据进行新增，数据成倍增加 用法1：从已有表创建新表（仅仅复制表结构） create table 表名 like 库名.表名; 例：mysql&gt; create table user_worm like user; 用法2：将查出的数据复制到一张表 insert into 表名(字段) select 字段 from 表名; 例：mysql&gt; insert into user_worm (id,name,sex,age) select id,name,sex,age from user;蠕虫复制的意义： 可以快速让表中数据膨胀到一定数量级以测试表的压力与效率 数据更新update 表名 set 字段 = 值 [where] [limit 限制更新数量（前几行）]; 数据删除delete from 表名 [where];数据删除不会改变表的结构，如自增长不会归零，只能删除表后再重建truncate 表名; # 先删除该表后再创建该表 数据查询123456select [选项] 字段[别名] from 表名 [where][group by][having][order by][limit];选项： all/* ：保留所有结果，默认（尽量不要打印所有） distinct：去重 别名： 字段名 as 别名 常用关键字： where：where子句用于过滤满足条件的数据。子句返回结果为0或1。where是唯一一个直接从磁盘读取数据时就开始判断的条件（从读取到第一条数据时就进行判断，成立就保存在内存）。where后的参数 参数 说明 between…and… 介于某个范围之内（闭区间） not between…and… 不在某个范围之内 in(项1,项2…) 在指定项内 not in(项1,项2…) 不在指定项内 like 搜索匹配，常与模式匹配符配合使用 not like like的反义 is null 空值判断符 is not null 非空判断符 not/and/or 逻辑运算符，分别表示否、并且、或，用于多个逻辑连接 % 模式匹配符，表示任意字串 优先级：NOT &gt; AND &gt; OR group by：根据某字段分组，用于按组统计数据常用统计函数：12345count()：统计分组后的记录数max()：每组中最大值min()：每组中最小值avg()：求平均值sum()：求和 可在group by后加上asc或desc，分别表示升序或降序。若只是分类，并不会显示所有数据，仅仅是分组，列出有哪些组。 可以设置多个字段进行排序，会按照字段的书写顺序进行先后排序。例如，group by age,score会先对age进行排序，然后对结果再进行score的排序。函数group_concat(字段名)可对分组结果中的某个字段进行字符串的连接。 with rollup：回溯统计，根据当前分组字段向上级分组汇报多字段回溯：考虑第一层分组会有回溯，第二层要看第一层分组的组数，组数是多少就回溯几次 having：进行条件判断在where判断后，由于数据已进入内存，所以不能再用where判断了，要对where判断的结果再次判断，就要用having。having能做where做到几乎所有事情，而where不能做having能做的很多事情。 分组统计的结果只能having使用123456789101112mysql&gt; select id,score,count(*),group_concat(name) from user group by score having count(*)&gt;=1;+-------+-------+----------+--------------------+| id | score | count(*) | group_concat(name) |+-------+-------+----------+--------------------+| 10002 | 68 | 2 | mike,jessie || 10001 | 78 | 3 | jack,kate,lisi || 10006 | 86 | 2 | zhangsan,wangwu || 10005 | 97 | 1 | jason |+-------+-------+----------+--------------------+ order by：排序，依赖校对集，显示所有记录，认升序排序。多字段排序：根据某个字段排序，然后对排序好的结果再按某字段排序 limit：限制数量 1234567891011121314151617181920用法1：limit 长度 限制记录数（排名前N个）mysql&gt; select * from user order by score desc limit 3;+-------+----------+------+------+-------+| id | name | sex | age | score |+-------+----------+------+------+-------+| 10005 | jason | m | 22 | 97 || 10008 | wangwu | m | 20 | 86 || 10006 | zhangsan | m | 21 | 86 |+-------+----------+------+------+-------+用法2：limit 起始,长度 从某起始位置（最小为0）开始限制（实现分页）mysql&gt; select * from user order by score desc limit 4,8;+-------+--------+------+------+-------+| id | name | sex | age | score |+-------+--------+------+------+-------+| 10003 | kate | f | 19 | 78 || 10007 | lisi | f | 19 | 78 || 10002 | mike | m | 21 | 68 || 10004 | jessie | f | 20 | 68 |+-------+--------+------+------+-------+ 多表查询关系分为： 一对一：一张表的一条记录最多只能与另一张表的一条数据对应 一对多：一张表的一条记录可与另一张表的多条数据对应 多对多：两张表互相存在一对多关系 联合查询也称“并”（UNOIN），多次查询（多条select），在记录上进行拼接。每一条select获取的字段数必须一致，字段名可以不一致，但字段数一定一致。会自动删除重复的记录（所有字段和值全部一致的记录）。1234select 语句1 union select 语句2union选项： all # 保留所有 distinct # 去重 联合查询的意义： 查询同一张表，但需求不同 多表查询：多张表结构完全一样，保存数据类型也一致 在联合查询中，order by不能直接使用，必须搭配limit限定最大数 例：12345678910111213141516171819202122232425262728mysql&gt; (select id,name,score from user order by score) union (select id,name,score from stu order by score);+-------+------------+-------+| id | name | score |+-------+------------+-------+| 10001 | jack | 78 || 10002 | mike | 68 || 10003 | kate | 78 || 10004 | jessie | 68 || 10005 | jason | 97 || 10006 | zhangsan | 86 |并没有排序，当加上limit 后即可实现排序mysql&gt; (select id,name,score from user order by score desc limit 999) union (select id,name,score from stu order by score desc limit 999);是两张表分别进行排序，然后合并 连接查询将多张表进行数据的拼接。分类：内连接（Inner Join），外连接（Outer Join），交叉连接（Cross Join）。连接查询的速度很慢，通常使用子查询。 内连接从左表中读取每一条记录与右表中所有记录匹配，只保留匹配的数据12345语法：select 字段 from 左表 inner join 右表 on 左表.字段 = 右表.字段; 若这两张表要查询的字段唯一，就不需要加表名。字段别名及表别名的使用：查询数据时，不同表有同名字段，可使用别名。 若内连接不指定on ，效果会和交叉连接一样。可用where代替on（但where没on效率高） 内连接根据不同的实现作用又分为： 自然连接：natural join，仅进行匹配以及去重。不能指定执行过程中的匹配条件。 等值连接：用=匹配字段值相等的记录 不等连接：用!=匹配字段值不相等的记录 注：内连接和外连接都可以模拟自然连接，只要在连接后面加using(字段名)，就可使用同名字段作为连接条件，自动合并1select * from stu join user using(id,name,score); 外连接从主表中读取每一条记录与另一张表中所有记录匹配，会保留所有记录以一张表为主，称为主表，根据主表的位置，外连接又分为左连接和右连接。 左连接left join：以左表为主表 右连接right join：以右表为主表 全外连接full outer join：除了匹配的记录，还包括不匹配的记录结果记录数至少为主表的总记录数，副表的为匹配的记录会显示为null显示仍为左连接在表的靠左部分，右连接在表的靠右部分12345语法：左连接select 字段 from 左表 left|right join 右表 on 左表.字段 = 右表.字段; 子查询虽然可通过连接查询实现多表查询，但性能很慢，因此推荐使用子查询进行多表查询。 子查询分类： 按位置分类：子查询在外部查询中出现的位置 from子查询：子查询在from之后 where子查询：在where中 exist子查询：在exists中 按结果分类：根据子查询得到的结果查询 标量子查询：子查询得到的结果是一行一列 列子查询：结果是一列多行 行子查询：结果是多列一行（也可以多行多列） 表子查询：子查询得到的结果是多行多列（出现在from后） 标量子查询123456mysql&gt; select * from stu_info where id = (select id from stu where id = 20001);+-------+------------+------------+| id | birthday | birthplace |+-------+------------+------------+| 20001 | 1998-07-03 | 河南 |+-------+------------+------------+ 列子查询123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657关键字IN的子查询mysql&gt; select * from stu_info where birthplace in (select birthplace from stu_info where birthplace = &apos;江苏&apos;);+-------+------------+------------+| id | birthday | birthplace |+-------+------------+------------+| 20003 | 1998-10-03 | 江苏 || 20005 | 1998-10-02 | 江苏 || 20007 | 1997-11-24 | 江苏 |+-------+------------+------------+关键字ANY（或SOME）的子查询 三种匹配规则： 1. = ANY ，与关键字IN作用相同 2. &gt; ANY（或&gt;=） ，比子查询中记录的最小值大的即可 3. &lt; ANY（或&lt;=） ，比子查询中记录的最大值小的即可mysql&gt; select * from stu where score &gt;= ANY ( select score from stu where age = 19);+-------+----------+------+------+-------+| id | name | sex | age | score |+-------+----------+------+------+-------+| 20001 | chenning | f | 20 | 98 || 20004 | yunlu | f | 19 | 93 || 20007 | chenliu | m | 20 | 94 |+-------+----------+------+------+-------+关键字ALL的子查询 两种匹配规则： 1. &gt; ALL ，比子查询中记录的最大值还要大 2. &lt; ALL ，比子查询中记录的最小值还要小mysql&gt; select * from stu where score &gt; ALL ( select score from stu where age = 19); +-------+----------+------+------+-------+| id | name | sex | age | score |+-------+----------+------+------+-------+| 20001 | chenning | f | 20 | 98 || 20007 | chenliu | m | 20 | 94 |+-------+----------+------+------+-------+关键字EXISTS的子查询用于判断是否满足（跨表），接在where后，exists返回值只有0和1 两种匹配： 1. EXISTS，存在 2. NOT EXISTS，不存在mysql&gt; select * from stu where not exists(select * from stu_info where birthplace = &apos;河南&apos;);解释：只要不存在河南的学生，就将所有学生信息打印出。EXISTS语句仅仅是判断where中的条件，并不会进行select的输出控制。 行子查询123456789mysql&gt; select * from stu where (age,score) = ( select age,score from stu where id = 20001);+-------+----------+------+------+-------+| id | name | sex | age | score |+-------+----------+------+------+-------+| 20001 | chenning | f | 20 | 98 |+-------+----------+------+------+-------+ 索引系统通过算法将已有的数据单独建立一个文件，文件能实现快速查找匹配数据作用：1.提高查询数据效率 2.约束数据的有效性增加索引的前提条件：因为索引本身会产生文件（较大），所以若某个数据经常使用时就可使用索引。 根据存储类型，可将索引分为：B树索引（默认索引）和哈希索引。InnoDB和MyISAM引擎都支持B树索引，Memory引擎支持哈希索引 Mysql支持六种索引： 普通索引 index 唯一索引 unique 全文索引 fulltext index 单列索引 多列索引 空间索引 以下情况时适合创建索引： 经常被查询的字段，即where子句出现的字段 在分组的字段，即group by子句出现的字段 存在依赖关系的子表和父表间的联合查询，即主键和外键字段 设置唯一完整性约束的字段 不适合创建索引的情况： 查询中很少被使用的字段 拥有许多重复值的字段 普通索引在创建索引时，不附加任何限制条件，可创建在任何数据类型上 1234567891011121. 创建表时创建普通索引create table 表名( 字段 类型, index|key 索引名(字段1(长度) &#123;ASC|DESC&#125;));2. 在已存在的表上创建普通索引create index 索引名 on 表名 (字段(长度) &#123;ASC|DESC&#125;);3. 修改表创建索引alter table 表名 add index|key 索引名(字段(长度) &#123;ASC|DESC&#125;); 用INDEX或KEY参数都可创建索引。索引名与字段关联，可设置索引长度（因为不同存储引擎定义了表的最大索引数和最大索引长度），还可设置升降序。 Mysql支持的存储引擎对每个表支持至少16个索引，总索引长度至少为256字节。 唯一索引创建索引时，限制索引的值必须唯一。根据创建索引的方式分为：自动索引和手动索引。自动索引：在数据库表中设置完整性约束时，该表会被系统自动创建索引。当设置表中的某个字段设置主键或唯一键完整性约束时，系统会自动关联该字段的唯一索引。1234567891011121. 在创建表时创建唯一索引create table 表名( 字段 类型, unique index|key 索引名(字段(长度) &#123;ASC|DESC&#125;);2. 在已存在的表上创建唯一索引create unique index 索引名 on 表名(字段(长度) &#123;ASC|DESC&#125;);3. 修改表创建索引alter table 表名 add unique index|key 索引名(字段(长度) &#123;ASC|DESC&#125;); 全文索引针对文章内部的关键字进行索引，表引擎必须为MyISAM。主要用于关联数据类型为char、varchar、text的字段，以便能够更加快速地查询数据量较大的字符串类型的字段。默认情况全文索引搜索不区分大小写，若全文索引所关联的字段为二进制类型，则以区分大小写搜索。 注：不要在导入数据时使用fulltext，应该在导入后使用1234567891011121. 创建表时创建全文索引create table 表名( 字段 属性, fulltext index|key 索引名(字段(长度) &#123;ASC|DESC&#125;))engine=MYISAM;2. 在已存在的表上创建全文索引create fulltext index 索引名 on 表名(字段(长度) &#123;ASC|DESC&#125;);3. 修改表创建索引alter table 表名 add fulltext index|key 索引名(字段(长度) &#123;ASC|DESC&#125;); 全文索引操作符： 操作符 说明 + 包含 - 排除 &lt; 包含且增加等级 &gt; 包含且减少等级 ( ) 表达式 * 词尾通配符 “ “ 字符串 多列索引在创建索引时所关联的字段不是一个字段，而是多个字段。只有查询条件使用了关联字段的第一个字段，多列字段才会被使用。1234567891011121314151617181920211. 创建表时创建多列索引create table 表名( 字段 类型, index|key 索引名( 字段1(长度) &#123;ASC|DESC&#125;, ... 字段n(长度) &#123;ASC|DESC&#125;);2. 在已存在的表上创建多列索引create index 索引名 on 表名 ( 字段1(长度) &#123;ASC|DESC&#125;, ... 字段n(长度) &#123;ASC|DESC&#125;);3. 修改表创建索引alter table 表名 add index|key 索引名( 字段1(长度) &#123;ASC|DESC&#125;, ... 字段n(长度) &#123;ASC|DESC&#125;); 视图本质是一种虚拟表，内容与真实表相似，但并不在数据库中以存储的数据值形式存在，数据来自自定义视图的查询所引用基本表，并在具体引用视图时动态生成。 创建视图：create view 视图名 as select语句;注：有多张基表时，要保证字段名不同，可用别名区分修改视图：123456781. 使用ALTER语句修改视图alter view 视图名 as select语句;2. 使用CREATE OR REPLACE语句修改视图create or replace view 视图名 as select 语句;这个方式修改视图会在视图存在的情况下直接修改，而若不存在就创建视图。 删除视图：drop view 视图名; 可以向单表中插数据，但不能向多表插数据，且插入数据只能插视图中有的字段 1234567891011查看视图show tables;查看视图详细信息show table status (from 数据库);查看视图定义信息show create view 视图名;查看视图设计信息desc 视图名; 触发器触发器的执行是由事件来触发、激活从而实现执行。为某张表绑定一段代码，当对表操作时，就会触发代码执行。触发器由三部分组成： 事件类型：增删改–insert、delete、update 触发时间：before、after 触发对象：表中记录123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172创建触发器：create trigger 触发器名 before|after 触发事件 on 表名 for each row 触发后动作;# for each row 表示任何一条记录上的操作满足触发事件# 后面跟上的是激活触发器后执行的语句创建包含多条执行语句的触发器：create trigger 触发器名 before|after 触发事件 on 表名 for each row begin 触发后动作 end# 在BEGIN和END间因为有多条语句需要使用分号隔开# 而在mysql中默认分号为结束，因此需要在创建触发器前将结束符重新设置，并在创建完成后再将触发器设置回分号。delimiter 结束符删除触发器drop trigger 触发器名;查看触发器show triggers;mysql&gt; show triggers\G*************************** 1. row *************************** Trigger: my_trigger1 # 触发器名 Event: INSERT # 触发事件 Table: stu # 操作表 Statement: begin # 激活触发器后的动作insert into stu_journal values(&apos;insert&apos;,now());end Timing: AFTER # 触发器执行的时间 Created: 2018-07-08 14:10:54.01 sql_mode: STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION Definer: root@localhostcharacter_set_client: gbkcollation_connection: gbk_chinese_ci Database Collation: utf8_general_ci查看系统表triggers中所有记录select * from information_schema.triggers\Gmysql&gt; select * from information_schema.triggers where trigger_name=&apos;my_trigger1&apos;\G*************************** 1. row *************************** TRIGGER_CATALOG: def TRIGGER_SCHEMA: test TRIGGER_NAME: my_trigger1 EVENT_MANIPULATION: INSERT EVENT_OBJECT_CATALOG: def EVENT_OBJECT_SCHEMA: test EVENT_OBJECT_TABLE: stu ACTION_ORDER: 1 ACTION_CONDITION: NULL ACTION_STATEMENT: begininsert into stu_journal values(&apos;insert&apos;,now());end ACTION_ORIENTATION: ROW ACTION_TIMING: AFTERACTION_REFERENCE_OLD_TABLE: NULLACTION_REFERENCE_NEW_TABLE: NULL ACTION_REFERENCE_OLD_ROW: OLD ACTION_REFERENCE_NEW_ROW: NEW CREATED: 2018-07-08 14:10:54.01 SQL_MODE: STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION DEFINER: root@localhost CHARACTER_SET_CLIENT: gbk COLLATION_CONNECTION: gbk_chinese_ci DATABASE_COLLATION: utf8_general_ci 存储过程与函数一个完整的操作会包含 多条SQL语句，在执行过程中需要根据前面的SQL语句的执行结果有选择的执行后面的SQL语句。存储过程与函数可理解为一条或多条SQL语句的集合，且也是事先经过编译并存储在数据库中的一段SQL语句集合，是一种没有返回值的函数。 存储过程与函数的优点： 允许表春组件式编程，提高了SQL语句的重用性、共享性、可移植性 实现较快执行速度，减少网络流量 可被作为一种安全机制 缺点： 编写复杂 需要创建数据库对象的权限 存储过程和函数的区别： 函数必须有返回值，存储过程没有 存储过程创建存储过程12345678delimiter 结束符create procedure 过程名(procedure_parameter参数) characteristic特性 begin 过程体 end 结束符delimiter ;与触发器类似，同样需要先用delimiter修改结束符 其中procedure_parameter参数的格式如下输入/输出类型 参数名 参数类型 输入输出类型有三种 IN：输入类型，数据只从外部传入内部，可是数值也可是变量。存储过程可能会修改这个值，但是对于调用者来说，在存储过程返回结果时，所做的修改是不可见的。 OUT：输出类型，只允许过程使用内部数据，外部传入内部只能是变量。其初始值为NULL，当存储过程返回时，这个值对调用者来说是可见的。 INOUT：输入输出类型，外部可在内部使用，内部修改也可在外部使用，只能传变量，存储过程可能会修改这个值，当存储过程返回的时候，所做的修改对调用者来说是可见的。 参数类型可为Mysql支持的任何类型 characteristic特性的可选参数12345678910111213141516[NOT] DETERMINSTIC：存储过程的执行结果是否确定# DETERMINSTIC表示确认，加NOT则为不确认&#123;CONTAINS SQL|NO SQL|READS SQL DATA|MODIFIES SQL DATA&#125;：表示使用SQL语句的限制# CONTAINS SQL：表示可包含SQL，但不包含读或写数据的语句# NO SQL：表示不包含SQL语句# READS SQL DATA：表示包含读数据语句# MODIFIES SQL DATA：表示包含写数据语句# 默认为CONTAINS SQLSQL SECURITY &#123;DEFINER|INVOKER&#125;：表示谁有权限执行# DEFINER：表示只有定义者自己能执行# INVOKER：表示调用者都可执行# 默认为DEFINERCOMMENT 注释 示例：1234567delimiter $create procedure proce_sel_stu(in stuid int)comment &apos;显示stu表指定学号的学生姓名和成绩&apos;bgein select name,score from stu where id=stuid;end$$delimiter ; 使用call 存储过程名(参数);对存储过程的调用。 查看存储过程查看存储过程创建语句show create procedure 存储过程名\G查看存储过程状态信息show procedure status like &#39;过程名&#39;\G 在information_schema库中存在一张存储所有存储过程和函数的表routines，因此此表也可查看存储过程和函数。 修改存储过程12alter procedure 过程名 特性 存储过程不能修改过程体，只能删除后重新创。删除存储过程drop procedure 存储过程名; 函数123456789101112创建函数delimiter 结束符create function 函数名(参数) returns 返回数据类型 特性 begin 函数体 end结束符delimiter ;# 特性与存储过程一致# 参数不用指定输入输出 注：函数不存在“重写”，即函数名不能相同。并且推荐函数名的格式为func_XXX或function_XXX示例：1234567delimiter $$create function func_sel_stu(stuid int) returns int begin return (select score from stu where id=stuid); end $$delimiter ; 使用select 函数(参数);调用函数。 查看函数查看函数创建函数show create function 函数名\G查看函数状态信息show function status like &#39;函数名&#39;\G修改函数12alter function 函数名 特性 存储过程不能修改函数体，只能删除后重新创。删除函数drop function 函数名; 存储过程和函数表达式 变量使用declare 变量名（可多个，逗号分隔） 类型 [默认值]声明变量使用set 变量名=XX（可以是值，也可以是赋值表达式，可多个，逗号分隔）;赋值变量也可以通过select 字段 into 变量（可多个） from ...;将查询结果赋给变量。注：将查询结果赋值给变量时，该查询语句的返回结果只能是单行 条件条件用于提高安全性。条件用于定义在处理过程中遇到问题时相应的处理步骤。12345678910111213141516171819202122232425262728定义条件declare 条件名 condition for condition_value状态值状态值：mysql_error_code mysql错误值SQLSTATE[VALUE] sqlstate_value 指定sql状态不要使用mysql error code 0或以‘00’开头的code或一个SQLSTATE，因为这些指示成功而不是一个错误条件。定义处理delimiter 结束符declare 处理类型 handler for 状态值（可多个） begin 处理 end 结束符delimiter ;处理类型，即当handler被触发后需要执行什么动作1. CONTINUE：继续执行2. EXIT：终止程序3. UNDO状态值，handler触发的条件：1. mysql error code或SQLSTATE value2. 定义条件时的条件名3. SQLWARNING：代表所有以01开头的SQLSTATE4. NOT FOUND：代表所有以02开头的SQLSTATE5. SQLEXCEPTION：代表除01和02开头的SQLSTATE 详细SQLSTATE表 示例：12345DECLARE no_such_table CONDITION FOR 1051;DECLARE CONTINUE HANDLER FOR no_such_table BEGIN -- body of handler END; 游标指定由select语句返回的行集合结果集，并遍历该结果集，可看做一种数据类型，类似指针或数组下标。使用declare 游标名 cursor for select语句;声明游标使用open 游标名打开游标。打开时，游标指向的是第一条数据的前一位。使用fetch 游标名 into 变量名（可多个，逗号分隔）使用游标，遍历赋值给变量。使用close 游标名关闭游标 流程控制条件控制1234567891011121314if条件分支if 条件 then 执行语句elseif 执行语句else 执行语句end if;case条件分支case 条件判断的变量 when 条件 then 执行语句 when 条件 then 执行语句end case 注：创建条件控制需要修改语句结束符循环控制1234567891011121314151617181920212223[标签:]where 条件 do 执行语句end where[标签];循环控制：循环内部进行循环判断和控制interate：迭代，类似continueleave：离开，类似break[标签:]where 条件 do 执行语句 leave | interate 循环名;end where[标签];[标签:]loop 执行语句end loop[标签][标签:]repeat 条件 do 执行语句end repeat[标签]可使用标签，两个标签分别代表循环的开始和结束，但必须一致，也可省略若要退出循环，使用leave 标签 事务为保证数据库记录的更新从一个一致性状态变更为另一个一致性状态。事务的四个特性： 原子性：事务中所有操作视为一个原子单元，对事务所进行的数据修改等操作只能是完全提交或完全回滚。 一致性：事务完成时，所有变更必须应用于事务的修改 隔离性：一个事务中的操作必须与其他事务所做的修改隔离，当前事务不会查看由另一个并发事务正在修改的数据（通过锁机制实现） 持久性：事务完成后，所做的所有修改对数据的影响是永久的 InnoDB支持事务，而MyISAM不支持事务事务安全：保护连续操作同时满足。意义：保证数据操作的完整性事务操作分为：自动事务（默认），手动事务 手动事务： 开启事务：告诉系统以下所有操作不直接写入数据表，先放到事务日志中。start transaction;或begin;此后的操作会保存在事务日志中，并不是真的对操作了数据表，所以若再通过另一个命令行用户登录查看时，该数据是未被操作的。 关闭事务：选择性的将日志文件中操作的结果同步到数据表包含两个操作： 提交事务commit：同步数据表，操作成功 回滚事务rollback：直接清空日志表，操作失败 自动事务：通过autocommit变量控制查看自动事务状态show variables like &#39;autocommit&#39;;默认开启set autocommit = off;关闭事务自动提交。关闭自动后，需要手动选择处理提交或回滚 事务原理：事务开启后，所有操作临时保存在事务日志，只有在commit时才会同步到数据表，其他情况都会导致清空。其中日志文件分为两个： REDO日志：记录事务日志。每条SQL进行数据库更新操作时，首先将REDO日志写入到日志缓存区中。当客户端执行COMMIT命令提交时，日志缓冲区的内容被刷新到磁盘。REDO日志对应ib_logfile文件，默认大小5MB，建议设置为512MB以便容纳较大的事务。在Mysql崩溃恢复时，会重新执行REDO日志记录。 UNDO日志：也称为回滚段。用于事务异常时的回滚处理，复制事务前得到数据库内容到UNDO缓冲区，然后在合适的时间将内容刷新到磁盘。磁盘上不存在单独的UNDO日志文件，而是存放在表空间对应的.ibd数据文件中。 回滚点：在某个成功的操作完成后，后续的操作可能成功可能失败，可以自当前成功的位置设置一个点，可以供后续失败操作返回到该位置，而不是返回所有操作。savepoint 回滚点名;rollback 回滚点名;12345# 使用start transaction 或 begin开启事务mysql&gt; start transaction;mysql&gt; update stu set age=22 where id=20007;mysql&gt; commit; 或mysql&gt; rollback; 事务隔离级别SQL定义了4种隔离级别，指定了事务中哪些数据改变其他事务可见，哪些数据改变其他事务不可见。低隔离级别可支持更高并发处理，同时占用的系统资源更少。可通过show variables like &#39;tx_isolation&#39;查看当前事务隔离级别。 READ-UNCOMMITTED：读取未提交内容，所有事务都可以看到其他未提交事务的执行结果。读取未提交的数据称为脏读。开启A与B事务，A更新，B不操作，但A在提交前，B能读到更新后的数据，而此时A回滚了，也就是B还是读到了错误的数据。 READ-COMMITTED：读取提交内容，一个事务从开始到提交前所做的任何改变都是不可见的，事务只能看见已经提交的变化。同一事务的其他实例在该实例处理时可能会有新的数据提交导致数据改变，所以同一查询可能返回不同结果。 REPEATABLE-READ：可重读，Mysql默认事务隔离级别。确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。存在问题：A的操作对表中所有行，B的操作是添加一行，于是A会发现有一行没有被修改。这个问题称为幻读。解决：InnoDB的多版本并发控制MVCC机制。InnoDB通过为每个数据行增加两个隐含值的方式实现，两个隐含值记录行的创建时间和过期时间。每行记录事件发生时的系统版本号。每一次开始一个新事务时版本号会自动加1，每个事务保存开始时的版本号，每个查询根据事务的版本号查询结果。 SERIALIZABLE：可串行化。最高的隔离级别。通过强制事务排序，使各事务不可能冲突。通过在每个读的数据行上加上共享锁实现。不推荐使用。 InnoDB锁机制锁机制：为解决数据库并发控制问题，保证数据一致性，需要对并发操作控制，并实现Mysql各个隔离级别。有以下类型： 共享锁：S（Share），锁粒度是单行或多行。一个事务获取了共享锁后，可对锁定范围内的数据执行读操作。事务A与B，若A获取了共享锁，B仍可获得共享锁，但不能获得排他锁。若A获得了排他锁，B不能获得共享锁和排他锁。 排他锁：X（eXclusive），排他锁的粒度与共享锁相同。事务获取排他锁后，可对锁定范围的数据执行写操作。 意向锁：一种表锁，粒度为整张表。分为意向共享锁IS和意向排他锁IX。表示一个事务有意对数据上共享锁或排他锁。锁与锁之间的关系，要么相容，要么互斥。相容：事务A获得了锁a，事务B还可获得锁b互斥：事务A获得了锁a，事务B在A释放a之前不能获得锁b 锁粒度锁粒度分为表锁和行锁。innodb默认是行锁，但如果在事务操作的过程中，没有使用索引，那么系统会自动全表检索数据，自动升级为表锁。行锁：只有当前行被锁住，别的用户不能操作。行锁支持最大并发。InnoDB使用行锁。支持并发读写。表锁：整张表被锁住，别的用户不能操作。开销最小，允许的并发量也最小。MyISAM使用表锁。当行或表被锁住时，若另一用户也要更改就只能等待锁被解除（commit或rollback），否则无法操作成功。 安全权限机制三张关于权限的表，存放在mysql库中。 user db host mysql.user表一共有45个字段，可分为4类：用户字段、权限字段、安全字段、资源控制字段 用户字段三个字段：host主机名，user用户名，password密码 权限字段一系列以_priv结尾的字段，这些字段决定了权限。两个返回值，Y和N，默认为N。 字段 权限名 权限范围 Select_priv select 查询表 Insert_priv insert 插入表 Update_priv update 更新表 Delete_priv delete 删除表 Create_priv create 库、表、索引 Drop_priv drop 库、表 Reload_priv reload 库、表 Shutdown_priv shutdown 关闭服务器 Process_priv process 服务器管理 File_priv file 加载服务器主机的文件 Grant_priv grant 库、表、存储过程、函数 References_priv references 库、表 Index_priv index 用索引查表 Alter_priv alter 修改表 Show_db_priv show databases 服务器 Super_priv super 超级权限 Create_tmp_table_priv create temporary tables 临时表 Lock_tables_priv lock tables 锁定表 Execute_priv execute 执行存储过程或函数 Repl_slave_priv replication slave 服务器管理 Repl_client_priv replication client 服务器管理 Create_view_priv create view 创建视图 Show_view_priv show view 查看视图 Create_routine_priv create routine 创建存储过程或函数 Alter_routine_priv alter routine 修改存储过程或函数 Create_user_priv create user 创建用户 Event_priv event 计时器 Trigger_priv create trigger 触发器 Create_tablespace_priv create tablespace 创建表空间 安全字段用于判断用户是否能够登录成功 字段 说明 ssl_type 支持ssl加密的安全字段 ssl_cipher 支持ssl加密的安全字段 x509_issuer 支持x509的字段 x509_subject 支持x509的字段 可通过以下方式查看是否字段支持ssl加密123456mysql&gt; show variables like &apos;have_openssl&apos;;+---------------+----------+| Variable_name | Value |+---------------+----------+| have_openssl | DISABLED |+---------------+----------+ 资源控制字段 字段 说明 max_questions 每小时允许执行多少次查询 max_updates 每小时允许执行多少次更新 max_connections 每小时允许建立多少次连接 max_user_connections 单个用户可同时具有的连接数 所有资源控制字段的默认值为0，表示是没有限制。 用户机制包括：登录和退出Mysql，创建用户，删除用户，修改用户密码，修改用户权限等。 连接Mysql服务器的命令：1234567mysql -h Mysql服务器的地址，可用域名，也可用IP地址 -p 指定所连接Mysql服务器的端口，默认3306 -u 登录Mysql使用的用户 -p 将提示输入密码 DBname 指定登录到的库 -e 指定执行的SQL语句 对用户的操作： 创建用户： 12345671. create user 用户名[@主机] [identified by &quot;密码&quot;];2. insert into mysql.user(Host,User,Password) values(主机名,用户名,PASSWORD(&quot;密码&quot;));# 要使用PASSWORD()对密码加密3. grant 权限 on 库.表 to 用户名[@主机] [identified by &quot;密码&quot;];在赋予权限后，要flush privileges;刷新权限 修改用户账户密码： 12345671. mysqladmin -u 用户名 -p 原密码 &quot;新密码&quot;# 新密码必须用双引号括起来2. set password=PASSWORD(&quot;新密码&quot;);# 修改当前登录用户的密码（即只修改自己的密码）3. update mysql.user set password=PASSWORD(&quot;新密码&quot;) where user=&quot;用户名&quot; and host=&quot;localhost&quot;; 修改普通用户账户密码： 123456781. grant 权限 on 库.表 to 用户名 [identified by &quot;密码&quot;];2. set password for 用户名[@主机]=PASSWORD(&quot;新密码&quot;);3. update mysql.user set password=PASSWORD(&quot;新密码&quot;) where user=&quot;用户名&quot; and host=&quot;主机名&quot;;4. set password=PASSWORD(&quot;新密码&quot;);# 修改当前登录用户的密码（即只修改自己的密码） 删除普通用户账号： 1231. drop user 用户名1,用户名2....2. delete from mysql.user where user=&quot;用户名&quot; and host=&quot;主机&quot;; 对用户的权限管理 对用户授权： 1234567grant 权限 on 库.表 to 用户 [identified by &quot;密码&quot;] with 选项;# with后有以下选项：GRANT OPTION：被授权用户可将权限授权给其他用户MAX_QUERIES_PER_HOUR count：设置每小时可执行count次查询MAX_UPDATES_PER_HOUR count：设置每小时可执行count次更新MAX_CONNECTIONS_PER_HOUR count：设置每小时可建立count次查询MAX_USER_CONNECTIONS count：设置单个用户可同时具有count个连接 查看用户拥有权限：show grant for 用户名[@主机]; 收回用户拥有权限：1234revoke 权限 on 库.表 from 用户名 [identified by &quot;密码&quot;];若要直接回收全部权限，可使用以下语句revoke all privileges,grant option from 用户名 [identified by &quot;密码&quot;]; 日志Mysql日志分为： 二进制日志：以二进制形式记录数据库的各种操作，但不记录查询语句 错误日志：记录Mysql服务器启动、关闭、运行时的错误信息 通用查询日志：记录Mysql启动和关闭信息、客户端连接信息、更新数据SQL语句、查询SQL语句 慢查询日志：记录执行时间超过指定时间的各种操作，可用于定位Mysql性能瓶颈 二进制日志二进制日志默认关闭。可通过mysql配置文件my.ini的log-bin参数，将注释去掉即可开启二进制日志。log-bin = 二进制日志路径路径是可选。若没指定路径，会使用默认名主机名-bin.number，number格式为000001开始的计数，并保存到默认目录：数据库的数据文件目录，即C:\ProgramData\MySQL\MySQL Server 5.7\Data。 每次重启Mysql服务器都会生成一个新的二进制日志文件，number会递增 可通过mysqlbinlog 二进制日志查看。不能直接打开，否则是乱码。 若要停止二进制日志，只要将my.ini中的log-bin恢复注释或删除即可。或者在数据库中通过对变量的设置实现开启或关闭二进制日志。set SQL_LOG_BIN=若为1表示开启，若为0表示关闭 只有有super权限的用户才能执行set语句 删除二进制日志reset master;可删除所有二进制日志文件purge master logs to 日志文件可删除number所有小于该日志的日志purge master logs before &#39;yyyy-mm-dd hh:MM:ss&#39;删除指定日期前创建的二进制日志 错误日志Mysql默认开启错误日志，也无法被禁止。同样该日志默认也存放在C:\ProgramData\MySQL\MySQL Server 5.7\Data中，文件名称格式为Mysql主机名.err。可修改my.ini的error-bin修改日志的路径。 错误日志以文本文件形式存储信息，可直接打开。命令mysqladmin -u root -p flush-logs会先创建一个新的错误日志，然后将旧的错误日志改名为原文件名-old。 通用查询日志由于该日志记录了客户端Mysql的所有请求，若实例的访问量较大，则此日志会急剧增大，影响Mysql性能，一般建议关闭。 若要开启通用查询日志，设置my.ini的general-log=1，默认未开启。general_log_file设置通用查询日志的路径，格式为文件名.log，默认为主机名.log。 也可通过设置环境变量开启或关闭，set global general_log = on;开启通用查询日志。若要关闭，设为off即可。通过show variables like &#39;%general_log%&#39;;查看相关变量（只有是否开启和文件路径）。 同样可以使用mysqladmin -u root -p flush-logs删除日志，但Mysql会创建一个新日志覆盖旧日志。 慢查询日志默认慢查询日志是关闭的。可通过my.ini的slow-query-log=1开启。可通过slow_query_log_file设置慢查询日志的路径，文件格式为文件名-slow.log，默认为主机名-slow.log。默认存放在C:\ProgramData\MySQL\MySQL Server 5.7\Data。可通过long_query_time设置超时时间，默认为10s。修改配置后需要重启Mysql才能生效。所以最好通过修改环境变量动态开启关闭。set global slow_query_log=on;开启慢查询日志set global long_query_time=3;设置超时时间，对设置后的新连接有效，可重新连接Mysql。 Mysql提供工具mysqldumpslow.pl对慢查询日志文件进行分析，该工具在C:\Program Files\MySQL\MySQL Server 5.7\bin中。该工具由perl语言编写，因此需要perl环境123456mysqldumpslow.pl -s 分析慢查询日志时指定排序参数，有以下可选参数 al 平均锁定时间 ar 平均返回记录数 at 平均查询时间 -t 只显示指定的行数 若要停止慢查询日志，可将my.ini的slow-query-log与long_query_time注释即可。或通过修改环境变量slow-query-log=off关闭。若要删除慢查询日志，可通过命令mysqladmin -u root -p flush-logs创建新的日志，会覆盖旧日志。 维护数据库备份与还原使用mysqldump命令进行数据备份mysqldump -u [username] -p [dbname] [table1]... &gt; [path]/[filename].sql备份单个数据库，可指定表（可多张），若不指定，就备份整个库。导出的sql文件路径与名称都可自定义。mysqldump -u [username] -p --databases [dbname]... &gt; [path]/[filename].sql备份多个数据库mysqldump -u [username] -p --all -databases &gt; [path]/[filename].sql备份所有数据库 还原数据需要先在mysql中创建对应库，然后在数据库外执行命令。mysql -u [username] -p [dbname] &lt; [path]/[filename].sql可指定数据库，指定就还原该数据库下的表，不指定就还原所有库。 若要通过复制对数据恢复，则需要保证两个Mysql的版本号一致，且只能对存储引擎为MYISAM的表有效。 将数据库表与文本文件互相导入导出导出有三种方法： select ...into outfile...;命令 mysqldump命令 mysql命令 1234567891011121314151617181920212223242526272829301. select 字段名 from 表名 过滤条件 # 第一部分是普通的查询语句 into outfile 文件名 选项; # 设置要导出到的文件以及文件的参数选项有六种选项： fields terminated by 字符串：用于设置字段的分隔符，默认为&apos;\t&apos; fields enclosed by 字符：用于设置括上字段值的字符符号，默认不使用任何符号 fields optionally enclosed by 字符：用于设置括上char、varchar、text等字段值的字符符号，默认不使用任何符号 fields escaped by 字符：用于设置转义字符的字符符号，默认为&apos;\&apos; lines starting by 字符：用于设置每行开头的字符符号，默认不使用任何符号 lines terminated by 字符串：用于设置每行结束时的字符串符号，默认为&apos;\n&apos;例：select * from user into outfile &apos;.\user.txt&apos; fields terminated by &apos;\,&apos; optionally enclosed by &apos;\&quot;&apos; lines terminated by &apos;\r\n&apos;;2. mysqldump -u 用户名 -p -T 文件目录 数据库 表名 选项有四种选项： --fields-terminated-by=字符串 ：设置字段的分隔符，默认为&apos;\t&apos; --fields-enclosed-by=字符 ：设置括上字段值的字符符号，默认不使用任何符号 --fields-optionally-enclosed-by=字符 ：设置括上char、varchar、text等字段值的字符符号，默认不使用任何符号 --lines-terminated-by=字符串 ：设置每行结束时的字符串符号，默认为&apos;\n&apos;例：mysqldump -u 用户名 -p -T &apos;.\&apos; test user &quot;--fields-terminated-by=,&quot; &quot;--lines-terminated-by=\r\n&quot;使用mysqldump命令不仅会在指定目录中生成[表名].txt文件，还会生成[表名].sql文件。3. mysql -u 用户名 -p -e &quot;select 字段 from 表名&quot; 数据库名 &gt; 文件名 -e选项用于执行查询语句例：mysql -u root -p -e &quot;select * from user&quot; test &gt; .\user.txt 导入有两种方法： load data infile命令 mysqlimport命令 1234567891011121314151617181. load data infile 文件名 into table 表名 选项;有九种选项。前六种与导出的select六种一致，后三种为： ignore N lines ：忽视文件的前N行数据 字段列表：实现根据字段列表中的字段和顺序加载记录 set column=EXPR ：设置列的转换条件EXPR，即所指定的列经过相应转换后才会被加载例：load data infile &apos;.\uesr.txt&apos; into table user into outfile &apos;.\user.txt&apos; fields terminated by &apos;\,&apos; optionally enclosed by &apos;\&quot;&apos; lines terminated by &apos;\r\n&apos;;2. mysqlimport -u 用户名 -p 数据库名 文件名 选项有六种选项。其中四种与导出的mysqldump选项一致，其余两种为： --fields-escaped-by=字符 ：设置转移字符 --ignore-lines=N ：忽略文件的前N行记录例：mysqlimport -u root -p test &quot;.\user.txt&quot; &quot;--fields-terminated-by=,&quot; &quot;--lines-terminated-by=\r\n&quot; 数据库迁移分为三种情况： 相同版本间迁移：使用mysqldump和mysql进行备份与恢复 12345案例：mysqldump -h 主机A -u root -p=密码 -all-databases | mysql -h 主机B -u root -p=密码# 其中 | 即为管道符 不同版本间迁移：又分为高版本向低版本迁移和低版本向高版本迁移 123456高版本向低版本迁移：高版本会兼容低版本若表的存储引擎为MYISAM，可直接复制或使用命令mysqlhotcopy。若表的存储引擎为InnoDB，可使用mysqldump与mysql的组合进行备份与恢复而低版本并不兼容高版本，所以迁移会较困难 不同数据库间迁移若从MYSQL迁移到SQL SERVER，可通过MyODBC实现。若从MYSQL迁移到ORACLE，可先导出sql文件，然后手动修改create语句。 简单的性能优化思路 可通过show variables和show status查看修改配置和变量参数进行调优 若多个任务中一个执行缓慢，会影响其他任务。可通过show processlist显示所有活动进程，或执行kill终结消耗资源过多的进程 最好多次试验连接或子查询，找到效率最高的搜索方法。在select时可通过explain语句查看select的执行情况 使用存储过程的速度会提高 若不必要，不要直接执行select *语句 使用UNION连接select语句，比一系列OR条件的select语句效率高 对象索引可改善数据检索的性能，但会损失插入、更新、删除的性能。对于不常查询的表最好不要创建索引 关键字like的执行效率很低，一般会通过full text代替like 常见查看命令显示解析SHOW TABLE STATUSshow table status (from 数据库名) (like 表达式);会直接显示该数据库中所有表的状态信息。123456789101112131415161718 Name: stu # 表名或视图名 Engine: InnoDB # 存储引擎 Version: 10 # .frm文件版本 Row_format: Dynamic # 行存储格式 Rows: 7 # 行数目 Avg_row_length: 2340 # 行平均长度 Data_length: 16384 # 文件长度Max_data_length: 0 # 文件最大长度 Index_length: 0 # 索引文件长度 Data_free: 0 # 表被整序后，但未使用的字节数目 Auto_increment: NULL # 下一个Auto_increment值 Create_time: 2018-07-07 08:58:34 # 表的创建时间 Update_time: 2018-07-07 09:01:00 # 最后一次更新时间 Check_time: NULL # 最后一次检查时间 Collation: utf8_general_ci # 字符集 Checksum: NULL # 表的活性校验 Create_options: # 表的额外选项 Comment: # 表的注释 参考资料 MYSQL数据库应用从入门到精通（第二版）Mysql 异常处理–condition和handlerMysql系列–骏马金龙]]></content>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YAML学习笔记]]></title>
    <url>%2F2018%2F04%2F29%2FYAML%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[YAML语言学习]]></content>
      <tags>
        <tag>Lang</tag>
        <tag>YAML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[I/O学习笔记]]></title>
    <url>%2F2018%2F04%2F29%2FI-O%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[I/O本篇包含以下知识点： 同、异步概念 五种Unix I/O模型 同步模型 异步模型 同、异步同步： 指的是在两个或多个数据库、文件、模块、线程之间用来保持数据内容一致性的机制。同步处理过程：提交请求-&gt;等待服务器处理（期间客户端浏览器不能干任何事）-&gt;处理完毕返回异步： 异步处理不用阻塞当前线程来等待处理完成，而是允许后续操作，直至其它线程将处理完成，并回调通知此线程。异步处理过程：请求通过事件触发-&gt;服务器处理（这是浏览器仍然可以作其他事情）-&gt;处理完毕 同步、异步关注的是消息通知机制，针对的是客户端。 阻塞与非阻塞阻塞：调用结果返回之前，调用者会被挂起（不可中断），调用者只有在得到返回结果后才能继续。非阻塞：调用结果返回前，不会被挂起，调用不会阻塞调用者。在内核的数据还未准备好时，会立即返回，进程可以去干其他事情。 阻塞、非阻塞关注的是调用者等待被调用者返回结果时的状态，针对的是服务器端。 阻塞、非阻塞与同步、异步的区别同步是在I/O中的一系列操作都是调用者（用户进程）自己完成（自己去问内核）。而异步是调用者在发起调用后，自己不管了，等内核数据准备好了以后，内核自己告诉进程，即让内核去通知进程，实现回调。 至于阻塞与非阻塞，是决定是否让调用者挂起。 网络I/O的本质是socket的读取，socket在linux系统被抽象为流，I/O可以理解为对流的操作。这个操作又分为两个阶段： 1.等待流数据准备，即等待网络上的数据分组到达，然后被复制到内核的某个缓冲区 2.从内核向进程复制数据，把数据从内核缓冲区复制到应用进程缓冲区 五种Unix I/O模型I/O模型：进程是无法直接操作I/O设备的，其必须通过系统调用请求内核来协助完成I/O动作，而内核会为每个I/O设备维护一个buffer。 用户进程发起请求，内核接受到请求后，从I/O设备中获取数据到buffer中，再将buffer中的数据copy到用户进程的地址空间，该用户进程获取到数据后再响应客户端。如下图中，真正称为I/O的就是内核内存与与进程内存间的过程 同步I/O模型阻塞I/O（Blocking I/O）： 当用户进程进行系统调用read()时，进程发起recvform系统调用，内核就开始了I/O的第一个阶段，准备数据到缓冲区中，当数据都准备完成后，则将数据从内核缓冲区中拷贝到用户进程的内存中，这时用户进程才解除block的状态重新运行。整个过程中用户进程都是阻塞的。不会消耗CPU时间，执行效率高。 非阻塞I/O（Non-Blocking I/O）： 用户进程只有在第二个阶段被阻塞了，而第一个阶段没有阻塞。在第一个阶段中，recvform系统调用调用之后，内核马上返回给进程，如果数据还没准备好，此时会返回一个error，进程在返回之后，可以干点别的事情，然后再发起recvform系统调用，用户进程需要盲等，不停的去轮询内核，看数据是否准备好了。在拷贝数据整个过程，进程仍然是属于阻塞的状态。由于用户进程轮询内核，所以该模型是比较消耗CPU的，效率较低。 I/O复用（I/O Multiplexing）： I/O执行的两个阶段都是用户进程都是阻塞的，但是两个阶段是独立的，在一次完整的I/O操作中，该用户进程是发起了两次系统调用。使用select()、poll()或epoll()（poll的改进版）进行调用，可支持两路调用。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。 select调用是内核级别的，select轮询可以等待多个socket，当其中任何一个socket的数据准备好了（通过内核监视），就能返回进行可读，然后进程再进行recvform系统调用。select在此模式下最多只支持1024个并发。 I/O复用应用场景： 服务器需要同时处理多个处于监听状态或多个连接状态的套接字。 服务器需要同时处理多种网络协议的套接字。 信号驱动I/O（Signal Driven I/O）： 也称基于事件的I/O。只有在I/O执行的第二阶段阻塞了用户进程，而在第一阶段是没有阻塞的。在I/O执行的第一阶段，当数据准备完成之后，内核会主动的通知用户进程数据已经准备完成（通过返回一个SIGIO信号），即对用户进程做一个回调。该通知分为两种，一为水平触发，即如果用户进程不响应则会一直发送通知，二为边缘触发，即只通知一次。 注：需要先开启套接字的信号驱动I/O功能，并使系统调用sigaction安装一个信号处理函数 异步I/O模型异步I/O（Asynchrnous I/O）： 当用户进程发起系统调用后，立刻就可以开始去做其它的事情，然后直到I/O执行的两个阶段都完成之后，内核会给用户进程发送通知，告诉用户进程操作已经完成了。由于在调用后进程会立刻返回，所以在整个输入操作的等待和复制期间，进程都不会阻塞。 异步I/O不需要select或poll 主动询问，也没有询问描述符的数量限制。 参考文章：简明网络I/O模型—同步异步阻塞非阻塞之惑 https://www.jianshu.com/p/55eb83d60ab1浅谈Linux下的五种I/O模型 https://www.cnblogs.com/chy2055/p/5220793.htmlLinux 网络 I/O 模型简介（图文） https://blog.csdn.net/anxpp/article/details/51503329socket 和 网络I/O模型 https://www.jianshu.com/p/7ac69db65a0e]]></content>
      <tags>
        <tag>网络</tag>
        <tag>I/O</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker网络学习笔记-1]]></title>
    <url>%2F2018%2F04%2F27%2FDocker%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Docker 容器网络主要是对docker文档(v18.03)的翻译以及自己的学习笔记 本篇涉及知识点： Docker网络模式 跨主机网络 Overlay Macvlan 补充知识点 支持IPv6 配置iptables Docker网络模式目前Docker容器共有5种网络模式： 桥接模式（bridge） 主机模式（host） 容器模式（container） 无网络模式（none） 用户自定义模式（user-defined） 当安装完docker后，会默认创建三个网络，可通过docker network ls查看12345# docker network lsNETWORK ID NAME DRIVER SCOPE01ec14a3a84c bridge bridge local56d5a7a9b06c host host local9cbd2d449df7 none null local 用户可在运行容器时通过--network=指定网络。 桥接模式bridgebridge是docker默认选择的网络，而网桥就是docker0通过ifconfig即可看到。1234# ifconfigdocker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt; mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 0.0.0.0 ...... 创建容器时若未指定network或网桥，就会默认挂到docker0网桥上。docker0的网段为172.17.0.0/16，网关地址为172.17.0.1，可通过docker inspect bridge查看。12345678910111213# docker inspect bridge[ &#123; &quot;Name&quot;: &quot;bridge&quot;, ...... &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot; &#125; ] &#125;, ...... docker daemon会创建一对对等接口：虚拟网桥上的vethxxx和容器的eth0。veth放置在宿主机的命名空间中，将宿主机上的所有网络为bridge的容器都连接到这个内部网络中，同时daemon会从网桥的私有地址空间中分配一个IP地址和子网给该容器。 123456789101112# ifconfig......veth7576df5: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::9023:faff:fe28:14b3 prefixlen 64 scopeid 0x20&lt;link&gt; ether 92:23:fa:28:14:b3 txqueuelen 0 (Ethernet) ......vethab244c0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::d047:b2ff:fee4:89c8 prefixlen 64 scopeid 0x20&lt;link&gt; ether d2:47:b2:e4:89:c8 txqueuelen 0 (Ethernet) ............ 连接同一个bridge网络的容器间能够通过IP地址互相通信。由于运行容器默认使用bridge网络，所以若要运行对外提供访问的服务，如web服务，就必须暴露端口，通过-p（指定容器暴露端口）或-P（发布容器所有端口）发布容器暴露的端口。 默认情况下，创建容器时不会将任何端口发布到外部。若通过-p或--publish发布端口，会创建一个防火墙规则，将容器端口映射到宿主机上的端口。 Docker在bridge网络上不支持服务自动发现。如果需要通过容器名实现容器间的互相通信，就要设置连接属性--link=容器名:别名（官方并不推荐，已快被淘汰，官方推荐用user-definded网络实现互通）。容器内所有的环境变量都可供连接到它的容器使用，可能会造成安全隐患。 主机模式host在此模式下，容器网络与宿主机网络间的隔离将被禁止，容器共享宿主机的网络命名空间，使容器直接暴露在公共网络中。因此，需要通过端口映射（Port Mapping）进行协调。 1234567891011121314# docker run -it --network=host alpine/ # ifconfigbr-7673688a6ae1 Link encap:Ethernet HWaddr 02:42:DC:D4:64:FA inet addr:172.22.0.1 Bcast:172.22.255.255 Mask:255.255.0.0 ......docker0 Link encap:Ethernet HWaddr 02:42:81:58:18:0C inet addr:172.17.0.1 Bcast:172.17.255.255 Mask:255.255.0.0 ......ens33 Link encap:Ethernet HWaddr 00:0C:29:58:0C:12 inet addr:192.168.163.101 Bcast:192.168.163.255 Mask:255.255.255.0 ............ 由此可知，当使用host模式网络时，容器实际上继承了宿主机的IP地址，并且在容器中可以看到宿主机的所有网卡。 因为没有路由开销，因此主机模式会比bridge模式更快。但是由于容器直接被暴露在公共网络中，会有安全隐患。 容器网络container在该模式，新创建的容器和已经存在的一个容器共享一个网络命名空间。两个容器除了网络的命名空间，其他的如文件系统、进程列表等仍然是隔离的。两个容器可以通过环回口进行设备通信。该模式也是Kubernetes使用的网络模式。 该模式通过--network=container:另一个已存在的容器实现。1234567891011# docker run -it --name container_A alpine/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:05 inet addr:172.17.0.5 Bcast:172.17.255.255 Mask:255.255.0.0 ......# docker run -it --name container_B --network=container:container_A alpine/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:05 inet addr:172.17.0.5 Bcast:172.17.255.255 Mask:255.255.0.0 ...... 无网络模式none该模式关闭了容器的网络功能，容器处于自己独立的网络命名空间中，且不进行任何配置。 使用场景：1.容器并不需要网络（例如只需要写磁盘卷的批处理任务，或生成随机密钥）2.自定义网络 用户自定义模式user-defined本模式使用户可自定义网络中的参数，以满足特定需求，例如DNS服务器。同一个自定义网络中，可以使用对方容器的容器名、服务名、网络别名来找到对方。这个时候帮助进行服务发现的是Docker内置的DNS。所以，无论容器是否重启、更换IP，内置的DNS都能正确指定到对方的位置。 docker内嵌DNS Server，但只有在用户自定义模式才能使用。 docker提供的网络驱动：bridge，overlay，macvlan，host，none，network plugins。可通过docker network create --driver=[driver] [network-name] [--subnet] [--gateway]指定网络驱动创建网络，并指定网段和网关。 bridge用于在同一主机内的通信。macvlan和overlay用于跨主机通信。host与none和网络模式对应的作用相同，host驱动仅可用于v17.06版本以上的docker swarm集群，none驱动不可用于swarm集群。network plugins是第三方为docker制作的网络插件。 bridge驱动: 用于创建类似bridge网络模式的网络，加入该网络的容器必须在同一台宿主机，仅适合一台主机上的小型网络。 123456789101112131415161718192021222324# docker network create --driver=bridge mybridge --subnet=10.1.1.0/24 --gateway=10.1.1.1# docker inspect mybridge[ &#123; &quot;Name&quot;: &quot;mybridge&quot;, ...... &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;10.1.1.0/24&quot;, &quot;Gateway&quot;: &quot;10.1.1.1&quot; &#125; ]......# docker run -it --network=mybridge alpine/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:0A:01:01:02 inet addr:10.1.1.2 Bcast:10.1.1.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 ...... 同主机容器间通信，分为：IP通信，DNS Server，Joined容器。 IP通信： 容器处于两个不同网络中，通过docker network connect [对端容器所处网络名][本端容器]连接容器。12345--alias 设置对端网络别名--ip 指定对端网络上该IP地址的容器--ip6 同上，为IPv6地址--link 指定连接的容器名--link-local-ip 为容器添加一个连接本地的地址 123456789101112131415161718192021222324# docker run -it --name container_A alpine# docker network connect mybridge container_A# docker run -it --network=mybridge --name=container_B alpine# docker inspect container_B -f &apos;&#123;&#123;.NetworkSettings.Networks.mybridge.IPAddress&#125;&#125;&apos;10.1.1.4# docker inspect container_A -f &apos;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&apos;172.17.0.3# docker attach container_A/ # ping 10.1.1.4PING 10.1.1.4 (10.1.1.4): 56 data bytes64 bytes from 10.1.1.4: seq=0 ttl=64 time=0.294 ms64 bytes from 10.1.1.4: seq=1 ttl=64 time=1.130 ms64 bytes from 10.1.1.4: seq=2 ttl=64 time=0.682 ms/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:03 inet addr:172.17.0.3 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 ......eth1 Link encap:Ethernet HWaddr 02:42:0A:01:01:03 inet addr:10.1.1.3 Bcast:10.1.1.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 ...... 原理如图（图为docker文档的，ip地址有偏差），docker会在本容器上创建一个新的网卡，由指定的网络分配IP地址，实现与指定的网桥中容器的连接（如上面ifconfig中eth1）。 DNS： 使用对方容器的容器名、服务名、网络别名来找到对方，无论容器是否重启、更换IP，内置的DNS都能正确指定到对方的位置。 Joined容器： 即container网络模式，使两个及以上的容器共享一个网络栈，共享网卡和配置。 容器访问外网容器默认就能访问外网，这里外网指容器外的网络，不只是互联网。 处理流程：1.容器发数据包，docker0收到数据包后查看IP头，发现是发往外网的，交给NAT处理。2.NAT将源地址转为宿主机IP地址，并从主机网卡发出。 外网访问容器外网通过端口映射访问容器，每个映射的端口，宿主机都会启动一个docker-proxy进程处理访问容器的流量，可在宿主机通过ps -ef | grep docker-proxy查看端口映射情况下图为内外网的完整访问流程图 跨主机网络docker容器有多种访问外网的方案，其中docker提供两个原生方案：overlay和macvlan。还可选择第三方方案：flannel，weave，calico。 众多的docker网络方案通过libnetwork与容器网络模型（Container Network Model）集成在一起，其中libnetwork为docker容器网络库，而其核心即为容器网络模型，对容器网络进行了抽象，由以下三个组件组成： Sandbox：容器的网络栈，包含容器接口、路由表和DNS设置。Sandbox的实现标准为Linux Network Namespace，可以包含来自不同Network的Endpoint。 Endpoint：将Sandbox接入Network，典型实现为Veth Pair。一个Endpoint只属于一个网络，也只属于一个Sandbox。 Network：包含一组Endpoint，同一Network的Endpoint可以直接通信。 OverlayOverlay网络驱动创建了多docker主机间的分布式网络，允许与其连接的容器互相安全地通信，服务和容器能同时连接多个网络，但也仅能在连接的网络间通信。虽然可以将集群服务和单独的容器都连入一个overlay网络，但overlay对于集群与单独容器的默认配置是不同的，对于不同对象有不同的选项。 在创建overlay网络之前，需要使用docker swarm初始化Docker daemon作为swarm manager，或者使用docker swarm join将其加入到现有swarm中。这两者都创建缺省的swarm服务使用的默认overlay网络ingress。 实验环境：swarm manager：192.168.163.102swarm worker：192.168.163.103 在manager上初始化docker swarmdocker swarm initworker上加入docker swarm（将manager上生成的命令复制粘贴到worker上运行）12# docker swarm join --token SWMTKN-1-077i43tqnp5df8y29nrrh8apm9y2a4khzggg8nydd2yy8nzzjw-0i1qu8z1xl2s7ngy8y1gcnfnb 192.168.163.102:2377This node joined a swarm as a worker. 创建overlay网络my_overlay：123456789# docker network create -d overlay my_overlay`# docker network lsNETWORK ID NAME DRIVER SCOPE8cc4b6f2ddfa bridge bridge local5db2b494b1af docker_gwbridge bridge local5a1cfdddfd60 host host localy6l4bambmqoj ingress overlay swarmbdv2xdmkujbu my_overlay overlay swarm7ec96e1718f1 none null local 若要创建一个overlay网络供群集服务或独立容器与其他Docker守护程序上运行的其他独立容器进行通信，要添加--attachable参数。ingress网络创建时没有--attachable选项，说明只有swarm服务可以使用它，而不是独立的容器。通过在创建网络时添加--attachable选项使得运行在不同Docker守护进程上的独立容器能够进行通信，而无需在各个Docker守护进程主机上设置路由。 容器发现对于大多数情况，应该连接到服务名，而不是单独容器，因为服务是负载均衡的且是由所有服务后的容器（即任务task）处理的。要获取支持该服务的所有任务（task）的列表，可以执行DNS查找tasks.&lt;service-name&gt; overlay网络加密默认docker对swarm服务在GCM模式下使用AES算法加密，集群中的manager节点每12小时就轮换用于加密gossip（反熵算法）数据的密钥。 要加密应用程序数据，需要在创建overlay网络时添加--opt encrypted。这使得vxlan级别的IPSEC加密成为可能。这种加密会带来不可忽视的性能损失，所以应该在生产中使用它之前对其进行测试。 当启用overlay加密时，Docker会在所有节点之间创建IPSEC隧道，在这些节点上调度连接到overlay网络服务的任务。这些通道在GCM模式下也使用AES算法，manager节点每12小时自动轮换一次密钥。 不要将Windows节点添加到加密的overlay网络。Windows上不支持overlay网络加密。如果Windows节点尝试连接到加密的overlay网络，虽不会报告错误，但节点无法通信。 默认ingress网络默认overlay网络ingress的作用：当自动选择的子网与网络中已存在的子网冲突或需要自定义某项低层的网络配置（例如MTU）时，默认的ingress网络会很有用。通常在Swarm中创建服务前对ingress网络进行删除或重建操作。如果已有发布端口的服务，在删除ingress网络前必须先删除这些服务。若没有ingress网络且不发布端口的服务在运行却没有进行负载平衡，那么那些发布端口的服务会受到影响。 可在创建网络时加上--ingress选项创建ingress网络并自定义网络参数。只能创建一个ingress网络。 默认docker_gwbridge网络docker_gwbridge是一个虚拟网桥，它将overlay网络（包括ingress网络）连接到单独的Docker守护进程的物理网络。初始化群集或将Docker主机加入群集时，Docker会自动创建它，但它不是Docker设备。它存在于Docker主机的内核中。如果需要自定义其设置，则必须在将Docker主机加入群集之前或临时从群集中暂时删除主机之后执行该自定义操作。 若要删除docker_gwbridge网络，需要先停止docker，再删除docker_gwbridge网络，由于停止了docker，所以要通过ip link删除该网络。12# ip link set docker_gwbridge down# ip link del docker_gwbridge 再启动docker，但不要加入或初始化swarm。重建一个docker_gwbridge网络，然后再加入或初始化swarm。 在overlay网络发布端口连接在同一个overlay网络的集群服务可以有效地互相发布所有端口。若要使一个端口能在服务外能访问，必须在docker service create或docker service update后加上-p选项发布指定端口。支持冒号分隔的旧语法-p 8080:80/tcp和逗号分隔的新语法-p published=8080,target=80,protocol=tcp。 绕过集群服务的路由网格（routing mesh）默认情况下，发布端口的群集服务使用路由网格来完成。当连接到任何swarm节点上的已发布端口（无论是否运行给定服务）时，都会透明地重定向到正在运行该服务的worker。实际上，Docker充当群集服务的负载平衡器。使用路由网格的服务以虚拟IP（VIP）模式运行。即使在每个节点上运行的服务（通过--global标志）也使用路由网格。使用路由网格时，不能保证哪个Docker节点服务客户端会请求。 要绕过路由网格，可以通过设置选项--endpoint-mode dnsrr来使用DNS Round Robin（DNSRR）模式启动服务且必须在服务前运行自定义的负载均衡器。对Docker主机上服务名的DNS查询会返回运行该服务的节点的IP地址列表，可以通过配置负载均衡器使用此列表并且平衡各节点间的流量。 单独控制和数据默认情况下，尽管群集控制流量是加密的，但群集管理和应用程序之间的控制流量运行在同一个网络上，可以配置Docker使用单独的网络接口来处理两种不同类型的流量。初始化或加入群集时，分别指定--advertise-addr和--datapath-addr，加入集群的每个节点都要执行此操作。 实验（根据官方文档的实验）Manager（system2）:192.168.163.102Worker-1（system3）：192.192.168.163.103Worker-2（system4）：192.192.168.163.104 在manager上初始化swarm，worker节点加入swarm。在manager上查看节点。12345# docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONohfkwg8uu4zkjtyk1l1nbze4p * system2.example.com Ready Active Leader 18.03.1-ce6dbboj25t5tws0ohd1pdhsahl system3.example.com Ready Active 18.03.1-ceaug4gnqnm0na4pwu835dku51x system4.example.com Ready Active 18.03.1-ce 可通过--filter role=worker|manager过滤节点信息 在manager上创建overlay网络。不需要在其他节点上创建overlay网络，当其中一个节点开始运行需要overlay网络的服务时，它将自动创建。docker network create -d overlay nginx-net在manager上创建一个nginx服务（只能在manager上创建服务）12345678910# docker service create \--name my-nginx \-p 80:80 \--replicas=5 \ #设置创建的任务个数--network nginx-net \nginx# docker service lsID NAME MODE REPLICAS IMAGE PORTSnvxzb5kzihl6 my-nginx replicated 5/5 nginx:latest *:80-&gt;80/tcp 在manager和worker上查看nginx-net网络情况，以及容器情况docker inspect nginx-net 新建overlay网络，将服务更新到新的网络上docker network create -d overlay nginx-net-21234# docker service update \--network-add nginx-net-2 \ # 将my-nginx添加进nginx-net-2网络中--network-rm nginx-net \ # 将my-nginx从nginx-net网络中删除my-nginx 注：overlay网络会因为需要自动创建，但不会自动删除（当服务不需要该网络后）。需要手动删除服务和网络。docker service rm my-nginxdocker network rm nginx-net nginx-net-2 Macvlan一些应用类似传统应用或监视网络流量的应用，希望直接连接到物理网络，可以使用macvlan网络驱动为每个容器的虚拟网络接口分配MAC地址，需要指定宿主机上的物理接口用于Macvlan，以及Macvlan的子网和网关。可以使用不同的物理网络接口来隔离Macvlan网络。网络设备需要能够处理“混杂模式”，其中一个物理接口可以分配多个MAC地址。网络模式最好是bridge或overlay。可以在bridge模式或vlan的trunk模式中创建macvlan网络。 在bridge网络模式中创建macvlan网络在docker network create后添加-d macvlan，也可再指定流量通过的实际网卡-o parent=ens33。若要排除在macvlan中使用的IP地址，可添加选项--aux-addresses=&quot;aux-addr=&quot;，参数值为一组键值对。一张网卡仅能被一个macvlan网络设为parent。 在vlan trunk模式中创建macvlan网络通过在网卡名后加.[数字]创建网卡子接口，例如-o parent=ens33.10。 使用IPvlan可以使用三层IPvlan取代二层Macvlan。通过指定-o ipvlan_mode=l2 补充知识点支持IPv6只有Linux主机的docker支持IPv6。修改/etc/docker/daemon.json，添加{&quot;ipv6&quot;: true}开启IPv6。然后重新加载配置文件systemctl daemon-reload或systemctl reload docker。在创建网络的时候可以加上--ipv6选项，在创建容器时加上--ip6选项 配置iptablesDocker通过iptables规则来提供网络隔离，不应修改Docker已设置的iptables规则。所有Docker的iptables规则都被添加到DOCKER链中，不要手动操作此表。如果需要添加能在加载Docker规则之前加载的规则，应该将它们添加到DOCKER-USER链中，这些规则在Docker自动创建任何规则之前加载。 默认情况下，所有外部源IP都被允许连接到Docker守护进程。若要只允许特定的IP或网络访问容器，可在DOCKER过滤器链的顶部插入否定规则。 例：iptables -I DOCKER-USER -i ens33 ! --source 192.168.163.0/24 -j DROP为防止Docker修改iptables策略，在/etc/docker/daemon.json中设置{&quot;iptables&quot;: false}，官方不推荐这样设置，因为这样所有关于docker的iptables配置都要手动管理。 DNS选项1234--dns 指定一个或多个DNS服务器--dns-search 设置dns搜索域--dns-opt 键值对，可参考/etc/resolv.conf--hostname 设置容器的主机名，默认就是容器名 docker代理在Docker客户端上编辑启动容器的用户主目录~/.docker/config.json文件。添加字段，可用httpsProxy或ftpProxy指定代理服务器的类型，并指定代理服务器的地址和端口，可以同时配置多个代理服务器。 通过将noProxy键设置为一个或多个逗号分隔的IP地址或主机，指定排除的代理服务器，支持*字符作为通配符。12345678910&#123; &quot;proxies&quot;: &#123; &quot;default&quot;: &#123; &quot;httpProxy&quot;: &quot;http://127.0.0.1:3001&quot;, &quot;noProxy&quot;: &quot;*.test.example.com,.example.com&quot; &#125; &#125;&#125; 在创建容器时可通过--env设置环境变量，通过环境变量指定代理服务器。1234--env HTTP_PROXY=&quot;&quot;--env HTTPS_PROXY=&quot;&quot;--env FTP_PROXY=&quot;&quot;--env NO_PROXY=&quot;&quot; 参考文档Cloudman 《每天五分钟玩转docker容器技术》docker官方文档-网络板块 https://docs.docker.com/networkdocker网络模式 http://dockone.io/article/1261]]></content>
      <tags>
        <tag>网络</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrony/NTP学习笔记]]></title>
    <url>%2F2018%2F01%2F31%2FChrony%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Chrony/NTP学习笔记本篇包含以下内容 chrony介绍 chrony配置 ntpd配置 NTP协议介绍NTP全称Network Time Protocol网络时间协议，用于同步计算机时间。保证局域网服务器与时间服务器的时间保持一致，并支持使用加密确认的方式防止恶意协议攻击。 自CentOS7.2后，chronyd服务代替原来的ntpd服务，性能提高且配置简单。 根据红帽文档，chronyd与ntpd的区别在于： chronyd使用更好的算法，同步精度、速度与对系统的影响都比ntpd更好。 chronyd可以在更大的范围内调整系统时间速率，且能在时钟损坏或不稳定的计算机上正常工作。 当网络故障时，chronyd仍能很好地工作，而ntpd必须定时轮询时间参考才能正常工作。 chronyd可以快速适应时钟速率的突然变化，ntpd则需要一段时间才能稳定。 chronyd提供对孤立网络的支持，手动输入校准时间，并通过算法计算实时时间，估计计算机增减时间的速率，从而调整时间。 实验环境 CentOS7.4 Chrony基础搭建步骤 安装chrony服务（默认已安装） yum install chrony 安装完后会有两个程序，一个chronyd服务，一个chronyc监控配置程序。 启动服务，设置开机自启 systemctl start chronyd systemctl enable chronyd chrony的配置文件/etc/chrony.conf 123456789101112131415161718192021222324server ntp.sjtu.edu.cn iburstserver s1a.time.edu.cn iburstserver s1b.time.edu.cn iburstserver s1d.time.edu.cn iburst//server 添加时间服务器，能添加很多driftfile /var/lib/chrony/drift//chronyd中的校准文件，根据实际时间计算出计算机增减时间的比率，能在重启后做出补偿makestep 1.0 3//当系统时钟漂移过快后，会通过很长的调整期纠正，该命令指定在调整期大于某阈值时才调整//此处是当偏移大于1秒，系统时钟调整3次。rtcsync//启用内核模式，系统时间每11分钟拷贝到实时时钟#allow 192.168.0.0/16//允许指定网段或主机使用服务#keyfile /etc/chrony.keys //设置密钥文件，可做NTP加密logdir /var/log/chrony//设置日志文件 防火墙放行并重启服务firewall-cmd --permanent --add-service=ntpfirewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 port port=123 protocol=udp accept&#39;firewall-cmd --reloadsystemctl restart chronyd 查看同步源信息 1234567891011chronyc sourcestats//查看同步源状态210 Number of sources = 4Name/IP Address NP NR Span Frequency Freq Skew Offset Std Dev==============================================================================202.120.2.100.dns.sjtu.e&gt; 0 0 0 +0.000 2000.000 +0ns 4000ms10.112.202.in-addr.arpa.&gt; 0 0 0 +0.000 2000.000 +0ns 4000msntpa.nic.edu.cn 0 0 0 +0.000 2000.000 +0ns 4000mstime.njnet.edu.cn 4 3 10 +810.140 43784.844 +7121us 14mschronyc sources //查看同步源，结果与上一条类似 自动同步时间chronyc sources -v 若要局域网内同步时间，只要客户端都安装chrony，且配置文件的server设置为此服务器ip即可。 ntpd基础搭建 安装ntpd服务yum install ntp 修改配置文件/etc/ntp.conf在restrict段添加允许的主机网段restrict 192.168.163.0 mask 255.255.255.0允许指定网段或主机使用服务（类似chrony的allow）server字段与chrony类似，指定上游ntp服务器。 重启ntpdsystemctl restart ntpd.service 在ntpd服务未开启时，可用命令ntpdate 0.centos.pool.ntp.org手动同步。这条命令只能在ntpd未开启时才有效。 命令ntpq -p列出NTP服务器与上游服务器的连接状态12345678910111213# ntpq -p remote refid st t when poll reach delay offset jitter==============================================================================*static-5-103-13 .GPS. 1 u 19 64 1 777.937 -99.910 133.624+mx.comglobalit. 128.227.205.3 2 u 19 64 1 413.258 84.278 15.570-ntp6.flashdance 192.36.143.130 2 u 18 64 1 438.957 196.165 32.565+119.79-161-57.c 129.242.4.241 2 u 50 64 1 670.566 58.678 51.049remote：上层ntp的IP地址或主机名，&apos;+&apos;表示优先，&apos;*&apos;表示次优先refid：参考的上一层NTP主机的地址st：stratum阶层poll：下次更新在几秒后offset：时间补偿的结果 扩展内容123456系统时间与BIOS时间不一定相同。查看硬件BIOS时间：# hwclock -rWed 02 May 2018 05:00:32 PM CST -0.854732 seconds将当前系统时间写入BIOS中# hwclock -w]]></content>
      <tags>
        <tag>server</tag>
        <tag>Chrony</tag>
        <tag>NTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iSCSI学习笔记]]></title>
    <url>%2F2018%2F01%2F29%2FiSCSI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[iSCSI学习笔记-1第一篇iSCSI笔记主要是基础配置，包含以下内容 iSCSI介绍 iSCSI基础搭建 常见存储方式 DAS 直接附加存储：外接存储设备直接连在服务器内部总线上，数据存储设备是整个服务器结构的一部分。 NAS 网络接入存储：存储设备独立于服务器，作为文件服务器独立存在与网络中。存储设备通过标准的网络拓扑（如以太网）添加到一群计算机。 SAN 存储区域网络：创造了存储的网络化。包含两种部署方式 FCSAN：使用光纤通道 IPSAN：使用IP通道（如以太网线与iSCSI技术） SCSI与iSCSI SCSI 小型计算机系统接口：一种通用接口标准，多用于服务器系统级接口。SCSI 结构基于C/S模式，其通常应用环境是：设备互相靠近，并且这些设备由 SCSI 总线连接。 iSCSI Internet小型计算机系统接口：一种基于TCP/IP的协议，用于建立管理IP存储设备、主机与客户机之间的连接，并创建SAN。SAN 使得 SCSI 协议应用于高速数据传输网络成为可能，这种传输以数据块级别（block-level）在多个数据存储网络间进行。 iSCSI 的主要功能是在 TCP/IP 网络上的主机系统（启动器 initiator）和存储设备（目标器 target）之间进行大量数据的封装和可靠传输。此外，iSCSI 提供了在 IP 网络封装 SCSI 命令，且运行在 TCP 上。 服务器：target 客户端：initiator 实验环境 CentOS7，内核3.10 两台虚拟机，system1与system2，system1为服务器，system2为客户端 虚拟机网段192.168.163.0/24 system1 IP：192.168.163.100/24 system2 IP：192.168.163.102/24 首先搭建服务器 安装target与targetcli并开机启动服务器端要安装的服务为targetd，还需安装targetcli程序进行配置 123yum install targetd targetclisystemctl enable targetd targetsystemctl start targetd target 确保系统有空闲可用的裸磁盘本处选择/dev/sdc1，大小5G 进入targetcli程序配置123456789目录结构o- / o- backstores | o- block | o- fileio | o- pscsi | o- ramdisk o- iscsi o- loopback 进入block，创建设备disk1create dev=/dev/sdc1 name=disk1另一种写法create disk1 /dev/sdc1然后进入iscsi目录，设置服务器端识别号 识别号规范：iqn.年-月.域名反置:服务器主机名 create wwn=iqn.2018-01.com.example:system1该标识符可以自己设定如上配置，也可让系统自动生成直接在iscsi目录中create设置后iscsi目录结构如下1234567o- iscsi o- iqn.2018-01.com.example:system1 o- tpg1 o- acls o- luns o- portals o- 0.0.0.0:3260 进入acls/ 添加客户端身份标识create wwn=iqn.2018-01.com.example:system2进入luns/ 给该组设置可用的存储设备create /backstores/block/disk1disk1就是block中创建的设备名此时iscsi目录结构12345678910o- iscsi o- iqn.2018-01.com.example:system1 o- tpg1 o- acls | o- iqn.2018-01.com.example:system2 | o- mapped_lun0 o- luns | o- lun0 o- portals o- 0.0.0.0:3260 进入portals/ 修改服务端端口号有可能里面没有默认配置，直接创建。若有默认配置就先删除再创建delete 0.0.0.0 ip_port=3260create 192.168.163.100 3260此处ip地址为服务器端IP，端口号为3260全部配置完exit退出配置程序 防火墙放行对应端口号，重启服务端口号3260，且tcp端口放行123firewall-cmd --permanent --add-port=3260/tcpfirewall-cmd --reloadsystemctl restart targetd target 然后是客户端搭建 安装客户端软件yum install iscsi-initiator-utils 设置客户端识别号该文件需要自己输入配置，输入客户端的识别码vim /etc/iscsi/initiatorname.iscsiinitiatorname=iqn.2018-01.com.example:system2 启动服务systemctl enable iscsi iscsidsystemctl start iscsi iscsid 获取硬盘iscsiadm -m discovery -t st -p 192.168.163.100 -l iscsiadm 用于管理iSCSI数据库配置文件的命令行工具-m discovery 表示发现查找-t senbtargets 表示发布的target，简写st-p IP 指定服务器地址-l 表示login，可不加 123连接成功信息:Logging in to [iface: default, target: iqn.2018-01.com.example:system1, portal: 192.168.163.100,3260] (multiple)Login to [iface: default, target: iqn.2018-01.com.example:system1, portal: 192.168.163.100,3260] successful. 通过命令lsblk查看是否拿到123456789[root@system2 ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot└─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP]sdb 8:16 0 5G 0 disk sr0 11:0 1 1024M 0 rom 发现出现了sdb，大小为5G，已成功获取]]></content>
      <tags>
        <tag>server</tag>
        <tag>iSCSI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS学习笔记（1）]]></title>
    <url>%2F2018%2F01%2F28%2FDNS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[DNS 学习笔记本篇DNS笔记包含以下内容 DNS简介 DNS解析原理 DNS深入理解 基本配置 DNS简介DNS全称Domain Name System域名解析服务，用于解析域名与IP地址对应关系。 DNS基于UDP，UDP端口号53，也会使用TCP的53端口，先会用UDP查找，若UDP查不到或请求大于512字节时才用TCP查找。同时，UDP进行名称解析，TCP进行区域解析。 DNS组成： 域名服务器：提供域名解析服务的软件。DNS域名解析服务中最高效的是Bind。Bind的程序名叫named。 解析器：访问域名服务器的客户端，负责解析从域名服务器获取的响应。如nslookup。 目前互联网的命名方式为层次树状结构，任何互联网上的主机或路由器都有唯一层次结构的名字，即域名。 功能 正向解析：根据域名查找对应IP 反向解析：根据IP查找对应域名 DNS解析原理DNS域名解析原理（迭代） 客户端将域名解析请求发给本地域名服务器或/etc/resolv.conf中列出的服务器 本地域名服务器收到后，查询本地缓存，若有就返回 若没有就把请求发给根域名服务器，迭代查询 本地域名服务器会将最终的结果存入缓存，同时将结果返回给主机。 /etc/resolv.conf用于定义dns查询指向的服务器以及解析顺序文件结构 1234domain domain_name # 声明本地域名，即解析时自动隐式补齐的域名search domain_name_list # 指定域名搜索顺序(最多6个)，和domain不能共存，若共存了，则后面的行生效nameserver IP-Address # 设置DNS指向，最多3个options timeout:n attempts:n # 指定解析超时时间(默认5秒)和解析次数(默认2次) 域名解析方法 递归：服务器收到请求时，若不能解析，则把请求转发到下一台服务器直到有一台解析成功。注：是收到请求的服务器去问，一个问下一个，最后解析完成后原路返回。 迭代：服务器收到请求时，若不能解析，则按根域-&gt;一级域名-&gt;二级域名-&gt;三级域名依次询问，直到解析成功。注：是本地服务器去不断问。 禁止递归查询的原因：对于授权域名服务器，若打开了递归查询，相当于配置为开放DNS服务器，会造成大量数据流量。所以在授权域名服务器上，应该禁用递归查询。recursion no; 反向解析：根据IP查找对应域名。将创建一个in-addr.arpa的专门的域处理。 高速缓存：DNS会将解析的信息保存在高速缓存中。每条记录都对应一个TTL，设置在缓存中保存的时间。 DNS深入理解DNS报文解析 分类 主域名服务器master server：在特定区域内具有唯一性的域名解析服务器 辅域名服务器slave server：从主服务器获取域名解析信息并维护，以防主服务器宕机。会通过TCP与主域名服务器通信，获取zone数据。 缓存服务器Caching-Only Server：向其他服务器查询域名解析信息，每获取一个就放在高速缓存中，提高重复查询效率。 域名服务器类型 根域名服务器：最高层次的域名服务器，存放所有顶级域名服务器的IP地址与域名。当一个本地域名服务器对一个域名无法解析时，就会直接找根域名服务器，根域名服务器会告知应该去哪个顶级域名服务器查询。全球共13个根域名服务器。可通过dig查看。 顶级域名服务器：负责管理在该服务器上注册的二级域名服务器的IP地址和域名。 授权域名服务器：DNS采用分区方式设置域名服务器。一个服务器所管理的范围为区。区的范围小于等于域的范围，每个区都设有一台权限域名服务器，负责将其分区的主机域名解析。由专业域名服务公司维护，若授权域名服务器出现故障，域名将不能被解析。 本地域名服务器：也称默认域名服务器，当主机发出DNS查询报文时，会最先询问本地域名服务器。 域名结构每一级域名都由英文字母与数字组成，不超过63字符，且不区分大小写，完整域名不超过255字符。目前顶级域名TLD（Top Level Domain）三大类：国家顶级域名、国际顶级域名、通用顶级域名。互联网的命名空间是按照机构的组织划分的，与物理网络无关，与IP子网无关。 . 根域，管理一级域名 com、or、gov、cn等一级域名，管理二级域名 baidu、google等二级域名，管理三级域名，当国家为一级域名时，com等一级域名便会下降一级别，依次类推 依次会有三级，四级 www、ftp、mail等主机域名，为提供服务的主机名 DNS系统采用阶层式管理，上一级的服务器只记录下一层的主机名（服务器名） 资源记录语法 {name} {TTL} class record-type record-specfic-data name：域记录名。通常只有第一个DNS资源记录会配置，其他资源记录的name可能为空，那么其他资源记录会接受先前资源记录的名字。 TTL：生存时间。指定该数据在数据库中保存的时间，此栏若为空，表示默认生存时间在授权资源记录中指定。 class：记录的类。大范围用于Internet地址和其他信息地址类为IN（基本都是IN）。 record-type：记录类型。常为A、NS、MX、CNAME record-specfic-data：记录指定数据。 记录类型： A：IPv4地址记录，将主机映射到IPv4地址 1234# host -v -t A baidu.com;; ANSWER SECTION:baidu.com. 5 IN A 123.125.115.110baidu.com. 5 IN A 220.181.57.216 AAAA：IPv6地址记录，将主机名映射到IPv6地址 CNAME：规范名称记录，将一个记录别名化为另一个记录，其中应具有A或AAAA记录。 当DNS解析器收到CNAME记录为查询响应时，DNS解析器会使用规范名称重新发出查询。CNAME记录数据可指向DNS中任何位置的名称，无论在区域内还是区域外。 应避免将CNAME记录指向其他CNAME记录以避免CNAME循环。CNAME记录链必须以A或AAAA记录结束。当使用CDN时，也可使用CNAME链。NS和MX记录不可指向CNAME记录。 123# host -v -t CNAME baidu.com;; ANSWER SECTION:www.baidu.com. 5 IN CNAME www.a.shifen.com. PTR：指针记录，将IPv4或IPv6地址映射到主机名，用于反向DNS解析。对行为类似于主机名的IP进行编码。 123# host -v -t PTR 202.108.22.220;; ANSWER SECTION:220.22.108.202.in-addr.arpa. 5 IN PTR xd-22-220-a8.bta.net.cn. NS：名称服务器记录，将域名映射到DNS名称服务器。区域的每个公开授权名称服务器必须具有NS记录。 123# host -v -t NS baidu.com;; ANSWER SECTION:baidu.com. 5 IN NS ns7.baidu.com. SOA：授权起始记录，提供有关DNS区域工作方式的信息。每个区域正好有一个SOA记录，指定主服务器，以及辅（从）服务器更新副本的方式。 12345678910# host -v -t SOA baidu.com;; AUTHORITY SECTION:baidu.com. 5 IN SOA dns.baidu.com. sa.baidu.com. 2012138777 300 300 2592000 7200# dns.baidu.com. 主名称服务器 # sa.baidu.com. DNS区域负责人的邮箱地址# 2012138777 区域版本号# 300 检查区域更新频率（单位s）# 300 在重试失败的刷新前应等待的时间（单位s）# 2592000 刷新失败，在停止使用其旧区域副本前等待的时间（单位s）# 7200 若解析器查询某个名称并该名称不存在，解析器将“记录不存在”信息进行缓存的时间（单位s） MX：邮件交换记录，将域名映射到邮件交换。邮件交换将接收该名称的电子邮件。 数据为优先级，用于在多个MX记录间确定顺序，以及用于该名称的邮件交换的主机名。 123# host -v -t MX baidu.com;; ANSWER SECTION:baidu.com. 5 IN MX 10 mx.maillb.baidu.com. TXT：文本记录，将名称映射到文本。通常用于提供发送方策略框架SPF、域密钥识别邮件DKIM、基于域的消息身份验证报告一致性DMARC等数据。 123# host -v -t TXT baidu.com;; ANSWER SECTION:baidu.com. 5 IN TXT &quot;google-site-verification=GHb98-6msqyx_qqjGl5eRatD3QTHyVB6-xQ3gJB5UwM&quot; SRV：服务记录，用于查找支持域的特定服务的主机。 使用格式设置为包含服务和协议名称的域名。如_service._protocol.domainname，SRV记录可记录为域提供服务的主机名和服务端口号，还包括优先级和权重值。 名称服务器Name Server：存储域名资源信息的程序，会响应解析器的请求。利用该服务器，整个网络可划分为一个域的分层结构。整个域名空间可划分为多个区域zone，zone通常表示管理界限的划分，也就是DNS树状结构上的一点。每个zone都有一个主域名服务器，还可有多个辅域名服务器。 基础配置环境 CentOS7，内核3.10 虚拟机网段：192.168.163.0/24 DNS服务器IP地址：192.168.163.102/24 DNS服务器主机名：system2.example.com 网关：192.168.163.254 客户端主机名：system3.example.com DNS服务相关配置文件 /etc/named.conf 主配置文件 /etc/named.rfc1912.zones 区域配置文件 步骤 安装bind服务yum groupinstall DNS\ Server 开启named服务防火墙放行dns，rich rules放行UDP和TCP的53端口systemctl enable named.servicefirewall-cmd --add-service=dns --permanentfirewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 port port=53 protocol=udp protocol=tcp accept&#39;firewall-cmd --reload 修改配置文件修改配置文件最好先做备份 cp -a XX XX.bak首先修改/etc/named.conf123456789101112131415161718192021只摘取部分options &#123; //指定bind服务参数 //listen-on 指定bind侦听的本机IP及端口 listen-on port 53 &#123; any; &#125;; //要将&#123;&#125;中改为any，本机的任意IP都监听（一台服务器可能有多个IP） listen-on-v6 port 53 &#123; ::1; &#125;; //directory 指定区域配置文件的路径 //若使用chroot则该路径是相对路径，对应/var/named/chroot/var/named/ directory &quot;/var/named&quot;; //改为any，接受任意IP的DNS查询请求 //也可指定网段，只给该网段做DNS allow-query &#123; any; &#125;;&#125;;zone &quot;.&quot; IN &#123; //指定当前bind可管辖的区域 type hint; //指定区域类型 file &quot;named.ca&quot;;//指定区域配置文件&#125;;//以下是区域配置文件和密钥文件include &quot;/etc/named.rfc1912.zones&quot;;include &quot;/etc/named.root.key&quot;; 然后修改/etc/named.rfc1912.zones配置正向解析区域文件named.conf中也能写区域配置，但为了安全和管理，将主配置和区域配置分开为两个文件 12345678zone &quot;example.com&quot; IN &#123; type master; //指定区域类型master file &quot;example.com.zone&quot;; //指定区域配置文件路径（相对路径，相对于named.conf中directory指定路径） //表示若要解析example.com的域名就要去该文件找 allow-update &#123; none; &#125;; //不允许客户机动态更新解析信息&#125; DNS区域类型 master：主要区域，拥有该区域数据文件，并对此区域提供管理数据 slave：辅助区域，拥有主要区域数据的只读副本，从主区域同步所有区域数据 hint：dns启动时，使用hint区域的信息查找最近的根域名服务器，没有就使用默认根服务器 然后配置解析数据信息文件/var/named/example.com.zone配置文件有模板，可复制/var/named/named.localhost并改名最好将文件名改为域名.zone123456789101112131415161718192021222324$TTL 1D@ IN SOA example.com. root.example.com. ( 0 ; serial //更新序列号 1D ; refresh //更新时间 1H ; retry //重试延时 1W ; expire //失效时间 3H ) ; minimum //无效解析记录的缓存时间 NS ns.example.com.ns IN A 192.168.163.102 IN MX 10 mail.example.com.mail IN A 192.168.163.102www IN A 192.168.163.102// TTL 指定资源记录存放在缓存中的时间，单位秒，一般直接调用$TTL的值// @为当前域，根据主配置文件的zone区域决定// IN是网络类型，表示自身// SOA记录：起始授权记录，在一个区域一定是唯一的，定义区域的全局参数// example.com. DNS区域地址（完整的，要加.根域）// root.example.com. 服务器邮箱地址（完整）//NS记录：名称服务器记录，在一个区域至少一条，记录区域的授权服务器，一般就指定为主机名ns//该记录下一行就指定该服务器的ip地址//ns 为主机名 A为地址记录，写域名对应IP//MX邮件交换记录：指定邮件服务器，用于根据收件人地址后缀定位邮件服务器，为管理员自己接收邮件的域名//其他主机名也是一样 主和辅服务器都应该列在上级域的NS记录中，才能形成一个正式的授权。也应该列在自己主机的域文件中，任何列在NS记录中的服务器必须配置为那个域的授权域名服务器。 反向解析配置修改/etc/named.rfc1912.zones，添加1234zone &quot;163.168.192.in-addr.arpa&quot; IN &#123; type master; # 服务类型master file &quot;192.168.163.arpa&quot;;&#125; 反向解析的参考配置文件为/var/named/named.loopback 可通过named-checkconf或named-checkzone检查配置文件语法是否正确。至此基础配置完成，重启服务 使用命令nslookup输入域名测试 常用命令host：查询某个域名或主机名所对应的所有IP地址123# host baidu.combaidu.com has address 123.125.115.110baidu.com has address 220.181.57.216 nslookup：查询一台主机IP及对应的域名12345678910两种模式：交互式：不加参数 非交互式：加参数# nslookup baidu.comServer: 192.168.163.254Address: 192.168.163.254#53# nslookup&gt; baidu.comServer: 192.168.163.254Address: 192.168.163.254#53 参考书籍：骏马金龙 DNS &amp; bind从基础到深入http://www.cnblogs.com/f-ck-need-u/p/7367503.html骏马金龙 Linux的网络管理http://www.cnblogs.com/f-ck-need-u/p/7074594.htmlLinux就该这么学Linux运维最佳实践Linux系统管理与网络管理Linux服务器架设指南Linux服务器架设、性能调优、集群管理教程]]></content>
      <tags>
        <tag>server</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
</search>
