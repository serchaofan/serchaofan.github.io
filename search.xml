<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[控制IGP路由笔记]]></title>
    <url>%2F2019%2F03%2F21%2F%E6%8E%A7%E5%88%B6IGP%E8%B7%AF%E7%94%B1%2F</url>
    <content type="text"></content>
      <tags>
        <tag>网络</tag>
        <tag>华三</tag>
        <tag>路由</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[园区网管理维护笔记]]></title>
    <url>%2F2019%2F03%2F21%2F%E5%9B%AD%E5%8C%BA%E7%BD%91%E7%AE%A1%E7%90%86%E7%BB%B4%E6%8A%A4%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <tags>
        <tag>网络</tag>
        <tag>华三</tag>
        <tag>园区网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[园区网安全技术笔记]]></title>
    <url>%2F2019%2F03%2F21%2F%E5%9B%AD%E5%8C%BA%E7%BD%91%E5%AE%89%E5%85%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <tags>
        <tag>网络</tag>
        <tag>华三</tag>
        <tag>园区网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VLAN基础笔记]]></title>
    <url>%2F2019%2F03%2F21%2FVLAN%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <tags>
        <tag>网络</tag>
        <tag>华三</tag>
        <tag>VLAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PPP协议基础笔记]]></title>
    <url>%2F2019%2F03%2F21%2FPPP%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[PPP协议概述Point to Point Protocol点对点协议 特点： 支持动态分配IP地址，允许连接时协商IP地址。 支持同步与异步线路。支持多种网络层协议（TCP/IP等） 支持错误检测及纠错，支持数据压缩 支持身份验证。无重传机制，网络开销小 组成： 链路控制协议LCP：用于建立、配置、测试管理数据链路连接 网络控制协议NCP：协商链路上所传输的数据包格式等参数，建立配置不同网络层协议 认证协议：用于对用户进行认证，包括PAP（Password Authentication Protocol密码认证协议）、CHAP（Challenge Handshake Authentication Protocol质询握手认证协议）、MS-CHAP（Microsoft CHAP微软CHAP协议） PPP会话过程：PPP的初始状态为不活动（dead）状态 链路建立阶段：当物理层可用时，进入Establish阶段，发送LCP报文检测链路可用情况（LCP协商），若可用（协商成功）就成功建立，LCP进入Opened状态并上报up事件，否则失败，上报fail事件，进入Dead阶段。 验证阶段（若配置了验证）：根据PPP帧中验证选项字段确定是否验证，若配置了验证，就进入Authenticate阶段，选择PAP或CHAP等验证。该阶段仅支持LCP和验证协议报文，其他报文都被丢弃。若验证失败进入Terminate状态，链路拆除，LCP变为Down。若成功就进入Network阶段 网络层协商阶段（若配置了网络层协议）：PPP双方发送NCP报文协商网络层协议（如IPCP）及地址，NCP状态从Initial变为Request。协商成功后NCP状态变为Opened，链路建立成功。 此后，PPP链路将一直保持通信，直至有明确的LCP或NCP消息关闭这条链路，或发生了某些外部事件（例如用户的干预）。 两种验证： PAP：两次握手。被验证方发起验证请求，向对端发送用户名和密码（明文），主验证方通过查询本地用户列表或RADIUS服务器，然后回应通过或拒绝。 PAP支持双向认证。 CHAP：三次握手。主验证方发起验证请求Challenge，发送本端主机名和随机报文。被验证方收到后查询本地密码，若本端配置了CHAP默认密码，就选用此密码。否则在用户表查找主验证方用户名对应的密码，并选用。被验证方通过MD5对报文ID、被验证方密码、原随机数生成一个摘要，回复Response。主验证方对本端密码、相同随机数、报文ID进行MD5摘要，并进行比对，若相同则验证成功，回复Acknowledge，否则回复失败。 CHAP不直接传输用户密码，而是传输通过MD5将密码与随机报文ID一起计算的结果，安全性高。认证方最多允许被认证方重传3次。 PPP帧格式： PPP MPMP是MultiLink PPP的简写。将多条PPP链路捆绑后当作一条链路，实现带宽增加，负载分担，降低报文延时，备份。 MP会将报文分片（小于最小分片包长时不分片）后，从MP链路下的多个PPP通道发送到对端，对端将这些分片组装起来传递给网络层处理。 通过配置虚拟模板（virtual-template）（华三设备）实现。可用用户名捆绑或通过一个VT口派生多个捆绑，也可通过MP-Group实现。MP-Group是MP专用接口，一个MP-Group只能对应一个绑定 PPPOEPPPoE描述了在以太网上建立PPPoE会话及封装PPP报文的方法。要求通信双方建立的是点到点关系，而不是在以太网中所出现的点到多点关系。 PPPoE利用以太网将大量主机组成网络，然后通过一个远端接入设备为以太网上的主机提供互联网接入服务，并对接入的每台主机实现控制、计费功能。由于很好地结合了以太网的经济性及PPP良好的可扩展性与管理控制功能，PPPoE被广泛应用于小区组网等环境中。 PPPoE协议将PPP报文封装在以太网帧之内，在以太网上提供点对点的连接。 PPPoE使用Client/Server模型。PPPoE Client向PPPoE Server发起连接请求，两者之间会话协商通过后，就建立PPPoE会话，此后PPPoE Server向PPPoE Client提供接入控制、认证等功能。 根据PPPoE会话的起点所在位置的不同，有两种组网结构： 第一种方式是在两台路由器之间建立PPPoE会话，所有主机通过同一个PPPoE会话传送数据，主机上不用安装PPPoE客户端拨号软件，一般是一个企业共用一个账号接入网络（图中PPPoE Client位于企业/公司内部，PPPoE Server是运营商的设备）。 第二种方式是将PPPoE会话建立在Host和运营商的路由器之间，为每一个Host建立一个PPPoE会话，每个Host都是PPPoE Client，每个Host使用一个帐号，方便运营商对用户进行计费和控制。Host上必须安装PPPoE客户端拨号软件。 华三PPP环境搭建实验环境：两台路由器RT1和RT2，RT1为主验证方，RT2为被验证方 1234567RT1:[RT1]interface Serial 1/0[RT1-Serial1/0]ip address 192.168.1.1 24RT2:[RT2]interface Serial 1/0[RT2-Serial1/0]ip address 192.168.1.2 24 PAP单向验证配置12345678910111213RT1:[RT1-Serial1/0]link-protocol ppp # 在串口配置封装的链路层协议为PPP# 缺省情况下，除以太网接口、VLAN接口、ATM接口外，其它接口封装的链路层协议均为PPP# 所以在串口可以不配这条[RT1-Serial1/0]ppp authentication-mode pap # 设置验证方式为pap[RT1]local-user zhangsan class network # 为RT2添加验证用户zhangsanNew local user added.[RT1-luser-network-zhangsan]password simple 123[RT1-luser-network-zhangsan]service-type ppp # 设置服务类型为pppRT2:[RT2-Serial1/0]link-protocol ppp[RT2-Serial1/0]ppp pap local-user zhangsan password simple 123 # 在串口配置验证信息 查看串口的端口信息，检查是否配置成功 12345678910111213141516[RT1]display interface SerialSerial1/0Current state: UP # 端口状态UPLine protocol state: UP # 链路协议UPDescription: Serial1/0 InterfaceBandwidth: 64kbpsMaximum Transmit Unit: 1500Hold timer: 10 seconds, retry times: 5Internet Address is 192.168.1.1/24 PrimaryLink layer protocol: PPPLCP: opened, IPCP: opened # LCP和IPCP都开启了Output queue - Urgent queuing: Size/Length/Discards 0/100/0Output queue - Protocol queuing: Size/Length/Discards 0/500/0Output queue - FIFO queuing: Size/Length/Discards 0/75/0Last link flapping: 0 hours 45 minutes 27 secondsLast clearing of counters: Never 此时互相ping，能够ping通 PAP双向验证配置互相配置验证用户 12345678910RT1:[RT1]local-user zhangsan class network[RT1-luser-network-zhangsan]password simple 123[RT1-luser-network-zhangsan]service-type pppRT2:[RT2]local-user lisi class networkNew local user added.[RT2-luser-network-lisi]password simple 321[RT2-luser-network-lisi]service-type ppp 双方都要在串口配置PPP验证 1234567RT1:[RT1-Serial1/0]ppp authentication-mode pap[RT1-Serial1/0]ppp pap local-user zhangsan password simple 123RT2:[RT2-Serial1/0]ppp authentication-mode pap[RT2-Serial1/0]ppp pap local-user lisi password simple 321 同理检查串口状态，并互相ping检查。 CHAP验证配置CHAP认证分为两种：认证方配置了用户名和认证方没有配置用户名。 当认证方配置了用户名： 123456789101112131415161718192021222324RT1（验证方）:# 配置对端的验证用户zhangsan[RT1]local-user zhangsan class networkNew local user added.[RT1-luser-network-zhangsan]password simple 123[RT1-luser-network-zhangsan]service-type ppp[RT1-Serial1/0]ppp authentication-mode chap# 配置对端验证本端的用户，即RT1对应了用户lisi[RT1-Serial1/0]ppp chap user lisi[RT1-Serial1/0]ppp chap password simple 321 # 密码，可选RT2:# 配置对端验证用户lisi[RT2]local-user lisi class networkNew local user added.[RT2-luser-network-lisi]password simple 321[RT2-luser-network-lisi]service-type ppp[RT2-Serial1/0]ppp authentication-mode chap[RT2-Serial1/0]ppp chap user zhangsan[RT2-Serial1/0]ppp chap password simple 123即：RT1的本地用户zhangsan是给RT2来验证的，RT2的本地用户lisi是给RT1来验证的 当验证方没有配置用户名： 1234567891011RT1:[RT1]local-user zhangsan class networkNew local user added.[RT1-luser-network-zhangsan]password simple 123[RT1-luser-network-zhangsan]service-type ppp[RT1-Serial1/0]ppp authentication-mode chapRT2:[RT2-Serial1/0]ppp chap user zhangsan[RT2-Serial1/0]ppp chap password simple 123 IP地址协商直接指定对端IP地址12345RT1:[RT1-Serial1/0]remote address 192.168.1.2RT2:[RT2-Serial1/0]ip address ppp-negotiate 然后查看RT2的串口端口IP 123456[RT2-Serial1/0]display interface Serial 1/0 briefBrief information on interface(s) under route mode:Link: ADM - administratively down; Stby - standbyProtocol: (s) - spoofingInterface Link Protocol Main IP DescriptionSer1/0 UP UP 192.168.1.2 配置地址池供对端选择123456RT1:[RT1]ip pool pool-1 192.168.1.10 192.168.1.20[RT1-Serial1/0]remote address pool pool-1RT2:[RT2-Serial1/0]ip address ppp-negotiate 可在RT1上查看地址池的分配情况 1234567[RT1]display ip pool pool-1Group name: default Pool name Start IP address End IP address Free In use pool-1 192.168.1.10 192.168.1.20 10 1In use IP addresses: IP address Interface 192.168.1.10 Ser1/0 ISP域关联IP地址池123456789101112131415RT1:[RT1]ip pool pool-1 192.168.1.10 192.168.1.20[RT1]local-user zhangsan class networkNew local user added.[RT1-luser-network-zhangsan]password simple 123[RT1-luser-network-zhangsan]service-type ppp[RT1]domain domain-1[RT1-isp-domain-1]authorization-attribute ip-pool pool-1[RT1-Serial1/0]ip address 192.168.1.1 24[RT1-Serial1/0]ppp authentication-mode pap domain domain-1RT2:[RT2-Serial1/0]ppp pap local-user zhangsan password simple 123[RT2-Serial1/0]ip address ppp-negotiate 之后链路会断开，等待一段时间后会再次up，RT2的IP也会分配好。 PPP常见配置项PPP协议可以为每条PPP链路提供基于流量的计费统计功能，具体统计内容包括出入两个方向上流经本链路的报文数和字节数。AAA可以获取这些流量统计信息用于计费控制。 缺省情况下，PPP计费统计功能处于关闭状态。 1ppp account-statistics enable 轮询时间间隔指的是接口发送keepalive报文的周期。当接口上封装的链路层协议为PPP时，链路层会周期性地向对端发送keepalive报文。如果接口在10个keepalive周期内无法收到对端发来的keepalive报文，链路层会认为对端故障，上报链路层Down。 用户可以通过timer-hold命令修改keepalive报文轮询的时间间隔。如果将轮询时间间隔配置为0秒，则不发送keepalive报文。 在速率非常低的链路上，轮询时间间隔不能配置过小。因为在低速链路上，大报文可能会需要很长的时间才能传送完毕，这样就会延迟keepalive报文的发送与接收。而接口如果在10个keepalive周期之后仍然无法收到对端的keepalive报文，它就会认为链路发生故障。如果keepalive报文被延迟的时间超过接口的这个限制，链路就会被认为发生故障而被关闭。 缺省情况下，轮询时间间隔为10秒。 1timer-hold [period] MP配置MP的配置主要有两种方式，一种是通过虚拟模板（Virtual Template，VT）接口，一种是通过MP-group接口。 通过虚拟模板接口配置MP VT是用于配置一个VA（Virtual Access，虚拟访问）接口的模板。将多个PPP链路捆绑成MP链路之后，需要创建一个VA接口与对端交换数据。此时，系统将选择一个VT，以便动态地创建一个VA接口。 虚拟模板接口配置方式可以与认证相结合，可以根据对端的用户名找到指定的虚拟模板接口，从而利用模板上的配置，创建相应的捆绑（Bundle），以对应一条MP链路。 由一个虚拟模板接口可以派生出若干个捆绑，每个捆绑对应一条MP链路。从网络层看来，这若干条MP链路会形成一个点对多点的网络拓扑。系统可以根据接口接收到的认证用户名或终端标识符来进行MP捆绑，并以此来区分虚模板接口下的多个捆绑（对应多条MP链路）。 系统支持3种绑定方式： authentication：根据PPP的认证用户名进行MP捆绑，每个认证用户名对应一个捆绑。认证用户名是指PPP链路进行PAP、CHAP、MS-CHAP或MS-CHAP-V2认证时所接收到的对端用户名。 descriptor：根据PPP的终端描述符进行MP捆绑，每个终端描述符对应一个捆绑。终端标识符是用来唯一标识一台设备的标志，是指进行LCP协商时所接收到的对端终端标识符。 both：同时根据PPP的认证用户名和终端描述符进行MP捆绑。 通过MP-group接口配置MP MP-group接口是MP的专用接口，不支持其它应用，也不能利用对端的用户名来指定捆绑，同时也不能派生多个捆绑。与虚拟模板接口配置方式相比，MP-group接口配置方式更加快速高效、配置简单、容易理解。 虚拟模板接口配置MP通过虚拟模板接口配置MP时，又可以细分为两种配置方式： 将物理接口与虚拟模板接口直接关联：使用命令ppp mp virtual-template直接将链路绑定到指定的虚拟模板接口上，这时可以配置认证也可以不配置认证。如果不配置认证，系统将通过对端的终端描述符捆绑出MP链路；如果配置了认证，系统将通过用户名和/或对端的终端描述符捆绑出MP链路。 将用户名与虚拟模板接口关联：根据认证通过后的用户名查找相关联的虚拟模板接口，然后根据用户名和对端终端描述符捆绑出MP链路。这种方式需在要绑定的接口下配置ppp mp及双向认证（PAP、CHAP、MS-CHAP或MS-CHAP-V2），否则链路协商不通。 配置时需要注意： ppp mp和ppp mp virtual-template命令互斥，即同一个接口只能采用一种配置方式。 对于需要绑在一起的接口，必须采用同样的配置方式。 实际使用中也可以配置单向认证，即一端直接将物理接口绑定到虚拟模板接口，另一端则通过用户名查找虚拟模板接口。 不推荐使用同一个虚拟模板接口配置多种业务（如MP、L2TP、PPPoE等）。 实验环境：两台路由器，连着两根串口线 将链路直接绑定到VT上1234567891011121314151617181920RT1:[RT1]interface Virtual-Template 1 # 进入虚模板，号码可选1-8[RT1-Virtual-Template1]ip address 192.168.1.1 24[RT1-Serial1/0]link-protocol ppp[RT1-Serial1/0]ppp mp Virtual-Template 1[RT1-Serial2/0]link-protocol ppp[RT1-Serial2/0]ppp mp Virtual-Template 1在端口配置完后就会自动重启端口同理在RT2上:[RT2]interface Virtual-Template 1[RT2-Virtual-Template1]ip address 192.168.1.2 24[RT2-Serial1/0]link-protocol ppp[RT2-Serial1/0]ppp mp Virtual-Template 1[RT2-Serial2/0]link-protocol ppp[RT2-Serial2/0]ppp mp Virtual-Template 1 可以查看ppp mp的状态 12345678910111213[RT1]dis ppp mp----------------------Slot0----------------------Template: Virtual-Template1max-bind: 16, fragment: enabled, min-fragment: 128 Master link: Virtual-Access0, Active members: 2, Bundle RT2 Peer&apos;s endPoint descriptor: RT2 Sequence format: long (rcv)/long (sent) Bundle Up Time: 2019/03/24 04:55:11:467 0 lost fragments, 0 reordered, 0 unassigned, 0 interleaved Sequence: 0 (rcv)/0 (sent) Active member channels: 2 members Serial1/0 Up-Time:2019/03/24 04:55:11:467 Serial2/0 Up-Time:2019/03/24 04:55:21:892 查看VA状态 1234567891011121314[RT1]dis interface Virtual-AccessVirtual-Access0Current state: UPLine protocol state: UPDescription: Virtual-Access0 InterfaceBandwidth: 128kbpsMaximum Transmit Unit: 1500Hold timer: 10 seconds, retry times: 5Internet Address is 192.168.1.1/24 PrimaryLink layer protocol: PPPLCP: opened, MP: opened, IPCP: openedPhysical: MP, baudrate: 128000 bpsMain interface: Virtual-Template1...... 按用户名查找VT123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354RT1:# 创建用户供RT2认证，需要为每个线路创一个[RT1]local-user rt2-user1 class networkNew local user added.[RT1-luser-network-rt2-user1]password simple rt2-user1[RT1-luser-network-rt2-user1]service-type ppp[RT1]local-user rt2-user2 class networkNew local user added.[RT1-luser-network-rt2-user2]password simple rt2-user2[RT1-luser-network-rt2-user2]service-type ppp# 用户绑定虚模板[RT1]ppp mp user rt2-user1 bind Virtual-Template 1[RT1]ppp mp user rt2-user2 bind Virtual-Template 1# 虚模板配置[RT1]interface Virtual-Template 1[RT1-Virtual-Template1]ip address 192.168.1.1 24[RT1-Virtual-Template1]ppp mp binding-mode authentication# 串口配置，填写对端提供给本端的用户# s1/0指定rt1-user1，s2/0指定rt1-user2[RT1-Serial1/0]link-protocol ppp[RT1-Serial1/0]ppp authentication-mode pap[RT1-Serial1/0]ppp pap local-user rt1-user1 password simple rt1-user1[RT1-Serial1/0]ppp mp[RT1-Serial2/0]link-protocol ppp[RT1-Serial2/0]ppp authentication-mode pap[RT1-Serial2/0]ppp pap local-user rt1-user2 password simple rt1-user2[RT1-Serial2/0]ppp mp同理RT2配置:[RT2]local-user rt1-user1 class networkNew local user added.[RT2-luser-network-rt1-user1]password simple rt1-user1[RT2-luser-network-rt1-user1]service-type ppp[RT2]local-user rt1-user2 class networkNew local user added.[RT2-luser-network-rt1-user2]password simple rt1-user2[RT2-luser-network-rt1-user2]service-type ppp[RT2]ppp mp user rt1-user1 bind Virtual-Template 1[RT2]ppp mp user rt1-user2 bind Virtual-Template 1[RT2]int Virtual-Template 1[RT2-Virtual-Template1]ip address 192.168.1.2 24[RT2-Virtual-Template1]ppp mp binding-mode authentication[RT2-Serial1/0]ppp authentication-mode pap[RT2-Serial1/0]ppp pap local-user rt2-user1 password simple rt2-user1[RT2-Serial1/0]ppp mp[RT2-Serial2/0]ppp authentication-mode pap[RT2-Serial2/0]ppp pap local-user rt2-user2 password simple rt2-user2[RT2-Serial2/0]ppp mp 查看ppp mp信息 1234567891011121314151617181920[RT1]dis ppp mp----------------------Slot0----------------------Template: Virtual-Template1max-bind: 16, fragment: enabled, min-fragment: 128 Master link: Virtual-Access0, Active members: 1, Bundle rt2-user1 # VA0，用户绑定 Peer&apos;s endPoint descriptor: RT2 Sequence format: long (rcv)/long (sent) Bundle Up Time: 2019/03/24 05:27:20:244 0 lost fragments, 0 reordered, 0 unassigned, 0 interleaved Sequence: 0 (rcv)/0 (sent) Active member channels: 1 members Serial1/0 Up-Time:2019/03/24 05:27:20:244 Master link: Virtual-Access1, Active members: 1, Bundle rt2-user2 # VA1 Peer&apos;s endPoint descriptor: RT2 Sequence format: long (rcv)/long (sent) Bundle Up Time: 2019/03/24 05:27:48:932 0 lost fragments, 0 reordered, 0 unassigned, 0 interleaved Sequence: 0 (rcv)/0 (sent) Active member channels: 1 members Serial2/0 Up-Time:2019/03/24 05:27:48:932 MP-group接口配置MP12345678910111213RT1:[RT1]interface MP-group 1[RT1-MP-group1]ip address 192.168.1.1 24[RT1-Serial1/0]ppp mp MP-group 1[RT1-Serial2/0]ppp mp MP-group 1RT2:[RT2]interface MP-group 1[RT2-MP-group1]ip address 192.168.1.2 24[RT2-Serial1/0]ppp mp MP-group 1[RT2-Serial2/0]ppp mp MP-group 1 查看PPP MP信息 12345678910111213[RT1]dis ppp mp----------------------Slot0----------------------Template: MP-group1max-bind: 16, fragment: enabled, min-fragment: 128 Master link: MP-group1, Active members: 2, Bundle Multilink Peer&apos;s endPoint descriptor: MP-group1 Sequence format: long (rcv)/long (sent) Bundle Up Time: 2019/03/24 05:41:40:229 0 lost fragments, 0 reordered, 0 unassigned, 0 interleaved Sequence: 0 (rcv)/0 (sent) Active member channels: 2 members Serial1/0 Up-Time:2019/03/24 05:41:40:229 Serial2/0 Up-Time:2019/03/24 05:41:49:213]]></content>
      <tags>
        <tag>网络</tag>
        <tag>华三</tag>
        <tag>PPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPv6基础笔记]]></title>
    <url>%2F2019%2F03%2F21%2FIPv6%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <tags>
        <tag>网络</tag>
        <tag>IPv6</tag>
        <tag>华三</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QoS完全笔记]]></title>
    <url>%2F2019%2F03%2F21%2FQoS%E5%AE%8C%E5%85%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <tags>
        <tag>网络</tag>
        <tag>华三</tag>
        <tag>QoS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高可靠技术笔记（华三网络设备）]]></title>
    <url>%2F2019%2F03%2F21%2F%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <tags>
        <tag>网络</tag>
        <tag>高可用</tag>
        <tag>华三</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP/IP基础笔记]]></title>
    <url>%2F2019%2F03%2F21%2FTCPIP%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含计算机网络和TCP/IP结构的重要知识点，以及华三设备的一些操作。 网络概述 TCP与UDP概述 IP基本原理 DHCP概述 FTP概述 DNS概述 Telnet概述 SSH概述 路由控制与转发 网络概述两种数据交换方式： 电路交换：基于电话网的电路交换 主要通过交换机连接，两台计算机独占线路 分组交换：以分组为单位存储转发 原理：将大数据分隔为一个一个包传输，每个包都打上报文头（标有分组序号、源目IP等），接收端收到后按照分组序号进行拼接 衡量计算机网络的指标： 带宽（一定时间内两个节点间数据量，单位bps） 延迟（数据在两个节点间传输的时间） OSI七层模型： 物理层：比特流传输，比特流与电子信号之间的转换，规定连接器与网线的规格 数据链路层：协商比特流一致性，数据帧与比特流之间的转换，流量控制，差错校验，编帧与识别帧 网络层：寻址，地址管理，路由选择，拥塞控制，异种网络互连 传输层：端到端逻辑连接的建立维护与断开、差错重传、数据排序、多路复用、流量控制、对应用层数据进行分段与封装 会话层：通信管理。主机间通信、建立维护及终止程序间会话、决定连接方式（SQL、NFS、RPC等） 表示层：定义数据格式与结构、协议上层数据格式、将设备固有的数据格式转化为网络标准传输格式（编码格式、图片格式等） 应用层：为程序进程提供网络服务，针对特定应用 可路由协议：定义数据包内各个字段格式与用途，对数据进行网络层封装（即IP协议） 路由协议：在路由器间传递信息，计算并形成路由表，为可路由协议选择路径（RIP、OSPF、BGP） 面向连接的服务（可靠连接）： 通信前建立连接，完成后断开连接 有序传递 应答确认 差错重传 无连接服务（不可靠连接）： 尽力而为 无需建立连接 无序列号机制 无确认机制 无重传机制 TCP/IP模型： 网络接口层：物理线路与链路层通信 网络层：数据包路由转发，路由表的维护 （IP、ICMP、IGMP） 传输层：端到端通信，数据完整性校验，差错重传，数据排序 （TCP、UDP） 应用层：处理特定应用细节 （Telnet、FTP、SMTP、HTTP等） 局域网CSMA/CD载波侦听机制：用于防止总线型局域网冲突。 实现：先听后发，边听边发，冲突停发，退避再发 广域网三种连接方式： 专线：点到点永久独占线路，带宽固定，链路层使用SDLC、HDLC、PPP等协议 电路交换：按需拨号建立连接，独占线路，带宽固定，链路层用PPP 分组交换：通过虚电路连接到多个对端，如帧中继、ATM等 ARP（Address Resolution Protocol）地址解析协议，根据IP地址解析出MAC地址。 ARP原理： 请求：广播发送ARP请求报文，请求获取目标IP的MAC地址 应答：单播回应，将自身MAC发送给请求方 RARP：反向地址转换协议，根据MAC地址解析出IP地址 代理ARP：路由器充当ARP中间代理去广播ARP请求 ICMP协议：Internet控制报文协议，用于检测网络是否通畅、主机是否可达等 TCP与UDP概述TCPTransmission Control Protocol传输控制协议，协议号6 特点： 面向连接，可靠，基于字节流 确认机制：应答接收 端口号：多路复用 序列号：丢失检测、乱序重排 完整性校验：差错校验 窗口机制：流量控制 三次握手：可靠连接 TCP报文头： Source Port(16 bit)：源端口 Destination Port(16 bit) ：目的端口 Sequence Number(32 bit)：数据包中第一个字节的序列号，取值范围[0,2^32-1]，是mod2^32运算的值 Acknowledge Number(32 bit) ：确认序列号，期望收到对方下一报文的第一个数据字段的序号 Data Offset(4 bit) ：数据偏移，值为TCP头的长度除以4 标志位(6 bit) #主要字段： URG：紧急，需要尽快传送 ACK：确认，建立连接后的报文确认 PSH：推送，接收方要尽快将此报文给上层处理 RST：复位，重新连接 SYN：同步，发起连接 FIN：终止，释放连接 Windows Size(16 bit)：接受缓冲区空闲空间，告诉对端自己能接收的最大数据长度 Checksum(16 bit)：校验和 常见服务：Telnet(23)、FTP(20\21)、SSH(22)、HTTP(80)、SMTP(25) 三次握手：连接建立 A向B发送SYN（seq=x），进入SYN_SEND状态 B收到SYN报文，回应SYN（seq=y）、ACK（ack=x+1）报文，进入SYN_RECV状态 A收到B的SYN报文，回应ACK（ack=y+1）进入Established状态，TCP连接建立 四次挥手：连接终止 A向B发送FIN，表示数据传输完毕 B收到后执行被动关闭，确认回复ACK B关闭套接字，向A发送FIN A接收到后向B确认，发送ACK 滑动窗口：限制每次发送的包数 1.A向B以默认发包数发送数据包 2.B回复ACK报文，其中除了ack外还带有win限制每次发送的数据长度 3.此后A便会按照要求长度发送数据包 UDPUser Datagram Protocol用户数据报协议，协议号17 特点：无连接，不可靠传输，无流量控制，直接封装应用层数据（不分段） 报文头： Source Port(16 bit) #源端口 Destination Port(16 bit) #目的端口 Length(16 bit) #数据包长度 Checksum(16 bit) #校验和 常见服务：DNS(53)、TFTP(69)、SNMP(161)、NFS、DHCP(67\68\546) IP基本原理IP作用： 标识结点与链路 用唯一IP地址标识每个节点 用唯一IP网络号标识每个链路 寻址与转发 确定节点所在网络位置进而确定节点位置 IP路由器选择适当路径将IP包转发到目的节点 适应各种数据链路 根据链路的MTU对IP包进行分片与重组（MTU：最大传输单元，能通过的最大数据包大小（以字节为单位）） 为了通过实际的数据链路传递信息，须建立IP地址到数据链路层地址的映射 IP头（20字节） Version(4 bit)：当前IP版本 IHL(4 bit) ：IP报文头长度，等同于数据字段的偏移量，最小为5（即5*32），最大为15 Type-of-Service(8 bit) ：上层协议对处理当前数据报所期望的服务质量，并对数据报按照重要性级别进行分配，分配优先级、延迟、吞吐量以及可靠性。 Total Length(16 bit) ：整个IP数据包的字节长度（数据+IP头），最大65535字节 Identification(16 bit)：用于识别当前数据包 Flags(3 bit)：低位控制分片，中位指出数据包是否可分片，高位保留 Fragment Offset(13 bit)：指出与源数据包的起始端相关的分片数据位置 Time-to-Live(8 bit) ：生存时间，每经过一节点就减少1直到为0 Protocol(8 bit) ：指出接收数据包的上层协议 Header Checksum(16 bit) ：头部校验和，保证IP头完整 Source Address(32 bit)：源IP Destination Address(32 bit) ：目IP VLSM：可变长子网掩码。使同一IP地址能划分为多个子网，能按照子网要求定制，每个子网都可自定义大小。 CIDR：无类域间路由。基于VLSM，CIDR使用网络前缀，可有各种长度，由掩码标识。可进行网段聚合。 DHCP概述UDP协议，采用C/S模式，服务器端口67，客户端端口68 三种分配方式： 手动分配：静态绑定固定IP，这些IP固定给特定设备使用（打印机，DNS，web服务器等） 自动分配：服务器给客户端分配租期无限长的IP地址，只有客户释放，其他客户才能使用该地址 动态分配：服务器给客户端分配租期有限长的IP地址，一旦租期到期而未续约，地址就会释放。 基本原则：尽可能为客户端分配原来使用的地址。 分配顺序： 静态分配的 客户端曾经会用过的 最先找到的可用IP DHCP报文： Discover：客户端第一次向服务器发送的请求报文，广播发送 Offer：服务器对客户端Discover的回应，包含分配的IP、掩码、网关等信息，广播或单播发送 Request：客户端发送给服务器的请求报文，包括服务器的选择与租期更新等，单播或广播发送（根据客户端状态） Release：客户端若想释放当前地址，则单播发送给服务器 Ack/Nak：服务器对客户端的回应，请求报文正确时回复Ack，否则回复Nak Decline：客户端收到服务器的Ack后，对获取的IP进行确认，使用ARP，若发现该IP已被使用，则广播向服务器发送Decline报文，拒绝使用该IP。 Inform：当客户端通过其他方式已获取了IP，若还需要向服务器索取其他配置信息时，会向服务器发送Inform，若服务器能根据要求分配则会回复Ack，否则不操作。 DHCP续约： 更新状态：使用时间达到租约的50%，客户端进入更新状态，单播向服务器发送Request，服务器若同意续约则回复Ack，否则回复Nak 重新绑定状态：使用时间达到租约的87.5%，客户端进入重新绑定状态。客户端广播Request请求，请求对有效租期进行更新。 进入该状态的原因：客户端未收到服务器对续约Request的回应。 若Request未收到回应，客户端会在一定时间内重发Request报文，若直到租期结束也未更新租期，则被迫释放IP地址。 DHCP中继：DHCP只适用于客户端与服务器在同网段（原因：广播请求）。可以通过中继使客户端可向其他网段的DHCP服务器请求。 ​ 实现：中继路由器收到请求广播报文，便向服务器单播发送，同理服务器也单播回应中继，中继再广播回应客户端。 FTP概述TCP协议，采用C/S模式，控制连接端口21，数据连接端口20 控制连接：负责FTP客户端与服务器交互命令与信息的传输，在整个会话过程中始终打开。 数据连接：负责客户端与服务器数据的传输，传输完毕就会关闭 文件传输模式： ASCII：默认模式，发送方将文件转为ASCII码传输，适合文本文件传输 二进制：也称图像文件传输模式，按比特流传输，适合程序文件传输 数据传输方式： 主动PORT 过程： 首先客户端（随机端口）与服务器（21端口）TCP三次握手建立连接，建立控制连接通道 客户端向服务器发送PORT命令，告知服务器使用主动模式。 其中PORT命令携带参数（客户端IP地址, P1, P2），P1与P2用于标识客户端数据连接的临时端口号，具体为256*P1+P2，IP地址也是四段，每段用逗号分隔 服务器收到PORT命令后按照参数用20端口与客户端指定端口三次握手建立数据传输通道。 数据传输完毕，发送方发送FIN报文，关闭数据连接 问题：若客户端在防火墙内部网络，主动方式会出现问题，因为客户端提供的端口是随机的，防火墙若未放行该端口，则无法建立FTP连接。 此时需要使用被动方式建立连接 被动PASV 过程： 首先客户端（随机端口）与服务器（21端口）TCP三次握手建立连接，建立控制连接通道 客户端向服务器发送PASV命令，参数与PORT一致。但IP是服务器的，标识的是服务器端的临时端口号。 客户端用随机端口与服务器的指定临时端口TCP三次握手建立数据连接通道。 数据传输完毕，发送方发送FIN报文，关闭数据连接 TFTP简单文件传输协议UDP协议，端口69 特点： 仅提供简单文件传输功能（上传，下载） 无存取授权与认证机制，无目录功能 由客户端发起 下载过程： 客户端向服务器发送读请求 服务器根据请求回应数据报文（块编号从1开始） 客户端收到数据后回应确认报文。 重复2.3步直至完成下载 上传过程： 客户端向服务器发送写请求 服务器回应确认报文（块编号为0） 客户端发送数据报文（块编号从1开始） 服务器收到后回应确认报文。 重复3.4步直至上传完成 文件传输时，将文件分成多个文件块，封装到数据报文中并打上文件块编号 传输文件模式： netASCII：对应FTP的ASCII模式 octet：对应FTP二进制模式 协议报文： RRQ读请求 WRQ写请求 数据报文 确认正确/错误报文 报文的头两个字节是操作码字段，1为读请求，2为写请求，3为数据报文，4为确认正确，5为错误。 文件传输过程中读写出错就发送差错报文，数据传输就停止，差错报文不会被确认也不会重传 TFTP每次传输的数据报文中文件块大小固定为512字节，若文件大小刚好是512字节的整数倍，则传完文件后还要再发一个空文件块的数据报文表明文件传输完成。 DNS概述TCP或UDP（基本是UDP）协议，端口号53，采用C/S模式，解析域名与IP映射。 查询方式： 递归：服务器收到请求时，若不能解析，则把请求转发到下一台服务器直到有一台解析成功 迭代：服务器收到请求时，若不能解析，则按根域 -&gt; 一级域名 -&gt; 二级域名 -&gt; 三级域名依次询问，直到解析成功 反向查询：根据IP解析域名，使用特殊域in-addr.arpa域，该域的子域是按照点分十进制表示法编号的IP地址相反顺序构造，即IP地址的四段倒置形成该域。 域名服务器类型： 本地域名服务器：自行管理的域名服务器，与客户端很近 根域名服务器：管理顶级域，本身不对域名解析，但知道相关域名服务器的地址 授权域名服务器：每个主机都必须在某个授权域名服务器上注册，通常该服务器就是本地域名服务器，最好有两个以防单点故障 主域名服务器：完成一个或多个域的域名解析的主用域名服务器 辅助域名服务器：协助主域名服务器，分担主服务器的压力，且能作为冗余服务器，本身不建立区域地址信息文件，而是获取主服务器上最新副本（两种获取方式：1.辅服务器启动或配置刷新时间到期后主动向主服务器获取 2.主服务器启动通知功能，区域数据变化后，将变化通知给辅服务器，辅服务器更新副本） DNS既可以TCP查询也可以UDP查询的原因： DNS响应报文中有特殊位—删减标志位TC，当响应报文采用UDP封装且长度大于512字节时，服务器仅回复前512字节，同时TC置位，表示报文进行了删减。当客户端收到TC置位的报文，客户端将用TCP重新封装请求报文并发送，此时服务器返回TCP封装的回应。 DNS特性 静态域名解析 设备上手动建立域名与IP的映射关系 动态域名解析 设备查询DNS服务器，由服务器完成解析 DNS代理 在客户端与服务器间转发DNS请求与应答报文。客户端将DNS代理当做服务器，代理再将请求转发给服务器，应答同理。 Telnet概述基于TCP，端口号23，采用C/S模式。使用Telnet进行远程访问设备进行配置维护。 telnet安全问题：无安全认证机制，数据以明文传输。 实现Telnet的条件： 服务器端： 内核命令行接口：操作系统内核与虚拟终端间的适配层 虚拟终端：类似实体终端的驱动程序。通过虚拟终端与内核交换信息 Telnet服务器进程 TCP/IP协议栈 客户端： Telnet客户端程序 TCP/IP协议栈 工作过程： 客户端与设备端23端口进行TCP连接 系统将客户端命令以NVT网络虚拟终端格式传送到服务器并执行 服务器端将NVT格式的命令执行结果再转化为客户端接受的格式传回客户端 客户端发送命令进行TCP断开连接。 华三路由器的Telnet默认关闭。 华三设备操作实验环境：两台交换机（需要配IP地址）或路由器 SW2作为telnet server，SW1作为telnet client 1234567SW2:[sw2]interface Vlan-interface 1[sw2-Vlan-interface1]ip address 192.168.1.2 24SW1:[sw1]interface Vlan-interface 1[sw1-Vlan-interface1]ip address 192.168.1.1 24 配置telnet 1234567891011SW2:[sw2]telnet server enable # 开启telnet[sw2]user-interface vty 0 10 # vty用户界面。# 两个数字是确定vty号的范围第一个数字范围0-63，第二个范围1-63[sw2-line-vty0-10]authentication-mode scheme # 设置验证方式，这里选了用户名密码方式[sw2-line-vty0-10]set authentication password simple 123456 #设置验证密码[sw2-line-vty0-10]user-role level-3 # 设置用户权限，权限等级0-15[sw2]local-user zhangsan # 创建用户zhangsanNew local user added.[sw2-luser-manage-zhangsan]service-type telnet # 设置为telnet服务，不设置无法登录[sw2-luser-manage-zhangsan]password simple 123456 # 设置提权密码 从SW1登录SW2 1telnet 192.168.1.2 SSH概述基于TCP，端口号22，安全的远程登录协议 特点： 数据机密性：支持DES、3DES加密算法，会对用户名与密码及数据进行加密。 支持多种认证方式：支持公钥验证方式（必支持）、密码验证方式（可选支持）、不验证方式（可选） 支持RSA认证：RSA非对称加密 SSH协议基本框架： 主要包含三个协议：1.传输层协议 2.用户认证协议 3.连接协议 连接建立过程： 版本号协商： 客户端与服务器端22端口TCP连接。连接建立后，服务器向客户端发送报文，包含版本标志字符串（SSH-&lt;主协议版本号&gt;.&lt;次协议版本号&gt;-&lt;软件版本号&gt;） 客户端收到后解析报文，若版本号比自己的低，就使用低版本号 客户端回应服务器，包含客户端决定的协议版本号 服务器端比较版本号，若协商成功，则进入密钥算法协商阶段，否则断开TCP连接 密钥与算法协商： 客户端与服务器端互相交换密钥算法协商报文，包含支持的公钥算法列表、加密算法列表、MAC（消息验证码）算法列表、压缩算法列表 通过对比双方都得出最终使用的算法 双方通过DH算法交换，生成会话密钥与会话ID 认证： 客户端向服务器发送认证请求，包含用户名、认证方式等 服务器端对客户端进行认证，若失败发送失败信息，包含可再次认证的方法列表 失败的情况下：客户端从认证方法中选一种再次认证 直到认证成功或次数达到上限服务器关闭连接为止 两种认证方式： password认证：客户端向服务器发送password认证请求并将用户名密码加密后发送，服务器收到解密并比对，返回成功或失败信息 publickey认证：采用数字签名认证。 会话请求： 认证通过后，客户端向服务器发送会话请求，服务器若成功处理请求就回复SUCCESS包，否则回复FAILURE包 交互会话： 会话请求通过后，进行双向数据传输，客户端发送加密的命令，服务器接收解密处理命令，将结果加密返回 SFTP：安全文件传输协议。建立在SSH基础上，默认采用加密方式传输数据。]]></content>
      <tags>
        <tag>网络</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无线安全渗透笔记]]></title>
    <url>%2F2019%2F02%2F18%2F%E6%97%A0%E7%BA%BF%E5%AE%89%E5%85%A8%E6%B8%97%E9%80%8F%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[无线相关知识点 常用无线工具使用以及密码破解操作 无线相关知识点WLAN无线局域网技术主要采用IEEE 802.11标准，包含802.11a/b/g/n/ac，是IEEE规定的数据链路层无线协议。以下是常见的一些无线标准。 IEEE 802.11 ，1997年，原始标准（2Mbit/s，工作在2.4GHz）。 IEEE 802.11a，1999年，物理层补充（54Mbit/s，工作在5GHz）。 IEEE 802.11b，1999年，物理层补充（11Mbit/s工作在2.4GHz）。 IEEE 802.11g，2003年，物理层补充（54Mbit/s，工作在2.4GHz）。 IEEE 802.11n，更高传输速率的改善，支持多输入多输出技术（Multi-Input Multi-Output，MIMO）。 提供标准速度300M，最高速度600M的连接速度 IEEE 802.11ac是802.11家族的一项无线网上标准，由IEEE标准协会制定，透过5GHz频带提供高通量的无线局域网（WLAN），俗称5G WiFi （5th Generation of Wi-Fi）。 IEEE定义了两种无线网络拓扑结构，一种是基础设施网络（Infrastructure Networking），一种是特殊网络（Ad Hoc Networking）。 在基础设施网络中，无线终端通过接入点AP接入访问骨干网。接入点负责在802.11和802.3 MAC间转换。 一个接入点覆盖的区域称为基本服务区（Basic Service Area，BSA），接入点控制的所有终端组成一个基本服务集（Basic Service Set，BSS） 多个基本服务集相互连接就形成了分布式系统（Distributed System，DS），DS支持的所有服务称为扩展服务集（Extended Service Set，ESS），由两个以上BSS组成。 AD Hoc是一种点对点网络，不需要有线网络和接入点的支持，终端设备间通过无线网卡可直接通信。 无线接入点AP（access point）： 扩展型AP，也称胖AP：类似家用无线路由器，能三层路由 单纯型AP，也称瘦AP：类似集线器、交换机，仅转发电信号与无线信号，通过将网络信号通过双绞线传送，再经过无线AP编译，将电信号转变为无线信号，形成wifi覆盖。一般无线AP最大覆盖范围400m Wi-Fi是WECA（无线以太网兼容性联盟）为普及IEEE 802.11的标准而打造的一个品牌。 Wi-Fi工作原理：wifi至少需要设置一个AP和一个以上的客户端，AP每100ms会将SSID通过beacons（信号台）封包广播一次。beacons包的传输速率是1Mb/s，长度短。wifi规定的最小传输速率为1Mb/s，所以所有客户端都能收到该SSID广播包。 SSID（Service Set Identifier）服务集标识，就是显示的无线网名称，用于区分网络，最多32字符。主要包含两种：ESSID和BSSID。 信道（channel），也称频段。通常有13个信道。信道频率范围从2413MHz到2472MHz，从小到大，每个信道都有一定的频率范围，范围也会有重叠。其中1,6,11三个信道之间是完全没有重叠的，就是不会相互干扰，同理2,7,12和3,8,13和4,9,14也是互不重叠的信道组。 频段带宽：发送无线信号频率的标准，频率越高越容易失真。在11n模式中，包含20MHZ和40MHZ两个频带，20MHZ能达到144Mbps带宽，距离100M，40MHZ能达到300Mbps，而穿透性差，仅有50M。 WDS：Wireless Distribution System无线分布式系统，是多个AP通过无线互联的系统，将无线网通过多个AP扩展。 无线网卡的几种模式： 广播模式 多播模式 直接模式：只收目的MAC是本身的帧 混杂模式：接收所有流过网卡的帧 网卡默认工作模式为广播和直接。 常用无线工具使用以及密码破解操作实验使用了HAYSENSE厂的HS-8515NS无线网卡，驱动为RT3070。 在虚拟机导入该网卡 实验虚拟机为kali linux。 字典工具crunch12345用法：crunch 密码最短长度 密码最长长度 字符集 [选项]选项： -f 指定字典配置文件，后面需要跟上该文件中的指定字符集 crunch自带的字符集配置文件为/usr/share/crunch/charset.lst -o 指定输出的字典文件 生成字典大小随密码位数指数增长，并且与指定的字符集长度有关。 123常见用法：crunch 6 10 123456abcdefg 生成包含前面字符集的所有密码可能的字典crunch 6 10 -f /usr/share/crunch/charset.lst lalpha -o ./wordlst-lalpha 字典工具cupp会根据输入的信息，生成可能的密码字典。需要安装cupp 1234cupp [options]选项： -i 进行交互式的信息输入 -w 改善已存在的字典 airmon-ng工具airmon-ng是aircrack-ng套件中的一个工具，用于开启无线网卡的监听模式。 12airmon-ng &lt;start|stop&gt; &lt;interface&gt; [channel] airmon-ng &lt;check&gt; [kill] 可使用iwconfig命令查看无线网卡的列表以及信息 kismet工具kismet是一个无线网卡监控工具。 打开kismet后会有一个是否选择灰色界面，最好选NO，否则界面是黑白的，没有彩色的图像 然后会有要求填写一个监控源。 可以看到监控到的信息，就是能看到的无线信号 点右下角的close console window即可进入图像界面 上面是网络信息，下面是客户端信息，其中MAC就是客户端的MAC地址 双击网络可查看该网络的详细信息 其中主要有以下参数信息： BSSID：该网络AP的MAC地址 Manuf：制造厂商 Type：类型，此处说明是AP Channel：信道为11 SSID：网络名称 Type：Beacon。被动信标帧 Encryption：WPA PSK 加密算法 airodump-ng工具属于aircrack-ng套件，用于无线网络抓包与分析，将无线网络数据传送到PCAP或IVS文件并显示网络信息。 将无线网卡置于监听模式后开始抓包。airodump-ng wlan0mon 主要有以下参数： BSSID：AP的MAC PWR：信号强度取决于驱动，值越高，与该AP的距离越近。 若BSSID的PWR为-1，则说明网卡驱动不支持报告信号水平。 若客户端的PWR为-1，则说明该客户端不在能探测到的范围内，但能捕获AP发往客户端的数据。 Beacons：AP发的通告 #Data：抓到的数据包量 CH：channel（是从Beacons中获取） MB：最大传输速率。 若为11，则协议为802.11b。 若为22，则协议为802.11b+。 若更高，则为802.11g。 e表示有802.11e（QoS）启用， . 表示短前导码。前导码是数据包的一组比特组，让接收者同步并准备接收实际的数据 ENC：加密方式 OPN（无加密） WEP?（WEP或WPA\WPA2） WEP（静态或动态WEP） TKIP或CCMP（WPA\WPA2） CIPHER：加密算法。WPAAP、TKIP、WEP、CCMP、WEP104。TKIP与WPA结合使用，CCMP与WPA2结合使用 AUTH：认证。 MGT（WPA/WPA2使用独立认证服务器（802.1x、redius、eap等）） PSK（WPA/WPA2的pre-shared key） OPN（无认证） SKA（WEP的共享密钥） ESSID：wifi名 STATION：每一个已连接或者正尝试连接用户的MAC地址 Rate：传输率 Lost：最近10s内的丢包数，基于序列号检测 Frames：客户端的数据帧数量 Probe：被客户端探查的ESSID。若客户端试图连接一个AP但没连上，则会显示在这 aircrack-ng破解WEP与WPA加密要对指定的wifi抓包 1airodump-ng -c 该wifi的channel --ivs -w ~/WEP --bssid 要抓的wifi的BSSID 如果信道正确，#Data的量会增长的比较快。-w会在指定位置生成握手包抓包文件，后面的破解就需要这个文件。 可使用aireplay-ng -0 5 -a B4:0B:44:93:11:C4 -c 18:01:F1:30:00:42 wlan0mon造成目标网络掉线，使设备不断发送arp请求，能更容易抓到有用的密码数据。需要连接的设备开启了自动重连，或者等待目标的用户再次输入密码。 生成密码字典cupp -i 填入可能的密码信息，然后aircrack-ng -w 字典文件 抓包文件。开始暴力破解。 自动化破解工具gerix-wifi-crackerairgeddon工具工具介绍地址：https://github.com/v1s1t0r1sh3r3/airgeddon git clone后，进入目录执行airgeddon.sh脚本。经过几次enter确认后，先会要求选择无线网卡。 选择后进入主菜单 有以下主要功能：DOS攻击、握手包工具、离线WPA解密、evil twin攻击、WPS攻击、WEP攻击、Enterprise协议攻击 DOS攻击简单操作首先会提示输入要攻击的wifi的BSSID，以及信道 可以选择攻击方式：Deauth攻击、mdk3攻击、WIDS攻击等。就会自动开始攻击 握手包工具操作同理填入目标BSSID和信道。 可直接选择5，开始抓取握手包. 关闭窗口后，会显示所有目标，按照开头标号选择，其中标号后面有*的说明有客户端连接着。 进入握手包抓取选项界面，选择攻击方式，与DOS一致。可直接选择deauth aireplay attack，与aireplay-ng效果一致，断开目标网络，抓取arp握手包。可以填写要抓取的时间，默认 20s。 若抓取成功，就会在主目录生成握手包抓包文件，然后同理使用aircrack-ng破解密码。 自动化破解工具wifite执行wifite后会自动开始扫描范围内的无线网络，ctrl+c停止扫描 选择一个目标后，开始自动检测 然后直接就能看到破解的wifi密码 hirte工具伪造AP不指定字典破解密码仍然是使用字典工具暴力破解握手包。 123crunch 最小长度 最大长度 字符集 | aircrack-ng 握手包 -e ESSID -w -示例：crunch 8 8 12345678 | aircrack-ng ~/wpa-B4\:0B\:44\:93\:11\:C4-02.cap -e gty123 -w - hashcat工具跑包1aircrack-ng 握手包 -J 输出hash文件 会生成一个.hccap文件 1aircrack-ng ~/wpa-B4\:0B\:44\:93\:11\:C4-02.cap -J ~/wpahash 需要hashcat工具，可—help查看加密方式对应的号码 12345# hashcat --help | grep WPA 2500 | WPA-EAPOL-PBKDF2 | Network Protocols 2501 | WPA-EAPOL-PMK | Network Protocols 16800 | WPA-PMKID-PBKDF2 | Network Protocols 16801 | WPA-PMKID-PMK | Network Protocols 使用-m指定编号 12用法：hashcat -m 2500 hccap文件 字典文件# hashcat -m 2500 ~/wpahash.hccap /usr/share/dict/wordlist-top4800-probable.txt cowpatty工具破解密码cowpatty功能与aircrack-ng类似 1cowpatty -f 字典文件 -r 握手包文件 -s ESSID hash-table加速破解可通过对字典文件生成hashtable，加快破解速度。但是对字典生成hash表文件需要消耗大量时间。 1genpmk -f 字典文件 -d 输出的hash表文件 -s ESSID 然后再用cowpatty破解 1cowpatty -d hash表文件 -r 握手包文件 -s ESSID 在本机的速度提升约有100倍。 batch-table加速破解生成batch-table与hash-table一样，需要耗费大量时间 先载入字典文件 pyrit -i 字典文件 import_passwords 添加ESSID，可添加多个 pyrit -e ESSID create_essid 生成batch-table pyrit batch 最后开始破解 pyrit -e ESSID -r 握手包 attack_batch pyrit工具补充pyrit也可以仅仅使用字典跑密码，功能仍然类似aircrack-ng 可以先通过pyrit的analyze模块分析，获取AP的BSSID pyrit -r 握手包 -i 字典文件 -b AP的BSSID（或者-e AP的ESSID）跑字典破解 pyrit也可以通过hash-table进行破解，同样使用-i指定输入hash表文件 airolib-ng生成彩虹表可通过彩虹表加速破解，可使用airolib-ng生成彩虹表 123airolib-ng &lt;database&gt; &lt;operation&gt; [options] --import [essid|passwd] &lt;file&gt; 传入ESSID或字典文件 --export cowpatty &lt;essid&gt; &lt;file&gt; 传出为一个cowpatty文件 需要先将目标ESSID写入一个文件 还需要将字典文件写入 最后生成batch-table 导出表供cowpatty使用 使用cowpatty破解密码]]></content>
      <tags>
        <tag>安全</tag>
        <tag>无线</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript基础完全笔记]]></title>
    <url>%2F2019%2F02%2F03%2FJavaScript%E5%9F%BA%E7%A1%80%E5%AE%8C%E5%85%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Python基础完全笔记]]></title>
    <url>%2F2019%2F02%2F03%2FPython%E5%9F%BA%E7%A1%80%E5%AE%8C%E5%85%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[函数式编程 面向对象编程 错误、调试与测试 进程与线程 正则表达式 网络编程 数据库编程 文本处理 协程与异步IO Redis编程 RabbitMQ队列 Web编程 Tornado编程 爬虫 常用内建模块 函数式编程高阶函数map与reducefiltersorted装饰器偏函数面向对象编程特殊方法与特殊变量所有保留属性： Class.__doc__：类的帮助信息 Class.__name__：类名 Class.__module__：类所在模块 Class.__bases__：类所继承的基类 Class.__dict__：类型字典，存储所有类的成员信息 Class().__class__：类型 Class().__module__：实例类所在模块 Class().__dict__：对象字典，存储所有实例成员信息 静态方法、类方法与继承静态方法虽然定义在类中，但与类没有实际关系。需要在定义时，添加@staticmethod，而调用时，仍然是通过类的对象或类调用。 1234567891011121314151617181920212223242526272829class Person(object): def __init__(self, name="AAA"): self.name = name def eat(self): print("&#123;&#125; is eating".format(self.name)) @staticmethod def drink(self): print("&#123;&#125; is drinking".format(self.name)) p = Person()# 普通方法可不需要参数p.eat()# 静态方法必须传入一个该类的对象print("通过对象p调用静态方法：")p.drink(p)print("-------------------------")print("通过类直接调用静态方法：")Person.drink(p)# 执行结果AAA is eating通过对象p调用静态方法：AAA is drinking-------------------------通过类直接调用静态方法：AAA is drinking 静态方法只是名义上归类管理，实际上静态方法中无法访问类或实例中的任何属性。 类方法只能访问类变量，不能访问实例变量。在定义方法前加上@classmethod标记，，可通过类的对象或类直接调用。 1234567891011121314151617class Person(object): name = "BBB" # 初始化方法对类方法的参数无效 def __init__(self, name="AAA"): self.name = name @classmethod def drink(self): print("&#123;&#125; is drinking".format(self.name)) p = Person()p.drink()Person.drink()# 执行结果BBB is drinkingBBB is drinking 属性方法会把一个方法变为一个静态属性，即不能作为一个函数（有括号的）。只能通过对象调用，不能直接类名调用。 123456789101112131415class Person(object): def __init__(self, name="AAA"): self.name = name @property def drink(self): print("&#123;&#125; is drinking".format(self.name)) p = Person()p.drink# 如果方法是带参数的，则这样调用会出错。 @property def drink(self, something): print("&#123;&#125; is drinking &#123;&#125;".format(self.name, self.something)) 解决方法：设置一个专门的设置属性值的函数setter，而原来的属性方法就不需要带参数了，而让setter方法进行设置参数值。setter方法就是类似java的setter方法 1234567891011121314151617 @property def drink(self): print("&#123;&#125; is drinking &#123;&#125;".format(self.name, self.something)) @drink.setter def setDrink(self, something): self.something = something print("set drink to : &#123;&#125;".format(self.something))p = Person()# 先调用setter方法设置属性值p.setDrink = "coffee"p.drink# 执行结果set drink to : coffeeAAA is drinking coffee 同理，删除对象属性的方法deleter也可定义。 1234567891011121314151617 @drink.deleter def deleteDrink(self): print("delete drink &#123;&#125;".format(self.something)) del self.somethingp = Person()p.drink = "coffee"del p.deleteDrinktry: print(p.something)except: print("p.something属性已被删除") # 执行结果set drink to : coffeedelete drink coffeep.something属性已被删除 错误、调试与测试进程与线程正则表达式网络编程数据库编程文本处理协程与异步IORedis编程RabbitMQ编程Web编程Tornado编程常见内建模块]]></content>
      <tags>
        <tag>Python</tag>
        <tag>lang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django使用Whoosh实现全文检索笔记]]></title>
    <url>%2F2019%2F02%2F01%2FDjango%E4%BD%BF%E7%94%A8Whoosh%E5%AE%9E%E7%8E%B0%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[在Django编写博客时添加简单的全文搜索的功能。使用到了haystack、whoosh和jieba三个项目 haystack是一个与whoosh交互的连接工具，属于一种全文检索的框架。官网 Whoosh是一个全文检索引擎，由python编写。官方文档 jieba是一个中文分词工具。github库 首先需要安装这三个库 1pip install django-heystack whoosh jieba 这三个库的版本 123django-haystack==2.8.1jieba==0.39Whoosh==2.7.4 简单实现然后在Django的项目settings.py中添加配置。首先将&#39;haystack&#39;添加到INSTALLED_APPS列表中 1234567INSTALLED_APPS = [ 'django.contrib.admin',...... 'blog', 'account', 'haystack',] 并添加一端配置 123456789101112# 用于haystack的连接HAYSTACK_CONNECTIONS = &#123; 'default': &#123; 'ENGINE': 'haystack.backends.whoosh_cn_backend.WhooshEngine', 'PATH': os.path.join(os.path.dirname(__file__), 'whoosh_index'), &#125;,&#125;# 注这里一定要将官方文档中的whoosh_backend改为whoosh_cn_backend# 因为是需要使用whoosh_cn_backend中的配置。否则无法检索中文# 用于自动生成索引HAYSTACK_SIGNAL_PROCESSOR = 'haystack.signals.RealtimeSignalProcessor' 官网配置文档 基本配置：https://django-haystack.readthedocs.io/en/v2.8.1/tutorial.html#configuration 所有设置字段：https://django-haystack.readthedocs.io/en/v2.8.1/settings.html# 在项目目录下的urls.py中添加url。 1234urlpatterns = [...... url(r&apos;^search/&apos;, include(&apos;haystack.urls&apos;)),] 在应用目录下创建search_indexes.py 1234567891011from haystack import indexesfrom .models import Articleclass ArticleIndex(indexes.SearchIndex, indexes.Indexable): text = indexes.CharField(document=True, use_template=True) def get_model(self): return Article def index_queryset(self, using=None): return self.get_model().objects.all() 在templates下创建search/indexes/应用名目录，并在该应用名目录下创建 模型类_text.txt文件。 123mkdir -p templates/search/indexes/blogtouch templates/search/indexes/blog/article_text.txt # txt文件的格式必须是： 要检索的模型类的小写_text.txt 在该txt文件中列出所有要检索的字段，是该模型类中定义的字段，一定要加上object 123&#123;&#123; object.title &#125;&#125;&#123;&#123; object.body &#125;&#125;# 对标题和文章内容进行检索 在search目录下创建一个search.html 12345678910111213141516171819&#123;% block content %&#125; &#123;% if query %&#125; &lt;h3&gt;搜索结果：&lt;/h3&gt; &#123;% for result in page.object_list %&#125; &lt;p&gt;&lt;a href=&quot;&#123;&#123; result.object.get_absolute_url &#125;&#125;&quot;&gt;&#123;&#123; result.object.title &#125;&#125;&lt;/a&gt;&lt;/p&gt; &#123;% empty %&#125; &lt;p&gt;未找到&lt;/p&gt; &#123;% endfor %&#125; &#123;% if page.has_previous or page.has_next %&#125; &lt;div&gt; &#123;% if page.has_previous %&#125;&lt;a href=&quot;?q=&#123;&#123; query &#125;&#125;&amp;amp;page=&#123;&#123; page.previous_page_number &#125;&#125;&quot;&gt;&#123;% endif %&#125;&amp;laquo; Previous&#123;% if page.has_previous %&#125;&lt;/a&gt;&#123;% endif %&#125; | &#123;% if page.has_next %&#125;&lt;a href=&quot;?q=&#123;&#123; query &#125;&#125;&amp;amp;page=&#123;&#123; page.next_page_number &#125;&#125;&quot;&gt;&#123;% endif %&#125;Next &amp;raquo;&#123;% if page.has_next %&#125;&lt;/a&gt;&#123;% endif %&#125; &lt;/div&gt; &#123;% endif %&#125; &#123;% endif %&#125;&#123;% endblock content %&#125; 在haystack安装的目录下中建立ChineseAnalyzer.py，路径例如：venv/lib/python3.7/site-packages/haystack/backends。不需要改，直接复制即可。 123456789101112131415161718192021import jiebafrom whoosh.analysis import Tokenizer, Tokenclass ChineseTokenizer(Tokenizer): def __call__(self, value, positions=False, chars=False, keeporiginal=False, removestops=True, start_pos=0, start_char=0, mode='', **kwargs): t = Token(positions, chars, removestops=removestops, mode=mode, **kwargs) seglist = jieba.cut(value, cut_all=True) for w in seglist: t.original = t.text = w t.boost = 1.0 if positions: t.pos = start_pos + value.find(w) if chars: t.startchar = start_char + value.find(w) t.endchar = start_char + value.find(w) + len(w) yield tdef ChineseAnalyzer(): return ChineseTokenizer() 将该目录中的whoosh_backend.py复制后改名为whoosh_cn_backend.py 并添加和修改以下内容 12from .ChineseAnalyzer import ChineseAnalyzer约164行的analyzer=StemmingAnalyzer() 修改为 analyzer=ChineseAnalyzer() 重建索引 12345678python3 manage.py rebuild_index # 会询问是否继续，y确认即可Removing all documents from your index because you said so.All documents removed.Indexing 11 articlesBuilding prefix dict from the default dictionary ...Loading model from cache /tmp/jieba.cacheLoading model cost 0.945 seconds.Prefix dict has been built succesfully. 会在项目目录下生成一个whoosh_index目录，以后的检索就是基于这个目录。 在应用目录下的urls中添加 1url(r&apos;^mysearch/$&apos;, views.mysearch) 这个名字可随便取，是普通的视图实现，即通过此url访问搜索表单。然后在views中添加实现方法 12def mysearch(request): return render(request, &apos;blog/mysearch.html&apos;) 在templates目录的应用目录下创一个mysearch.html 1234567&#123;% block content %&#125;&lt;form method=&quot;get&quot; action=&quot;/search&quot; target=&quot;_self&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;q&quot;&gt; # name必须是q &lt;input type=&quot;submit&quot;&gt;&lt;/form&gt;&#123;% endblock content %&#125; 运行项目，添加几篇文章，进行测试。通过/mysearch访问表单页面 先进行英文单词的检索 检索成功，跳转到结果页面。再进行中文单词检索 改进1不需要mysearch.html，不用在应用的urls中配置，不用配置views的mysearch方法。 注：使用的是MDUI前端UI 直接在网页中的搜索框中建立表单 123456789&lt;div class="mdui-col-xs-3"&gt; &lt;div class="mdui-textfield mdui-textfield-expandable mdui-float-right"&gt; &lt;button class="mdui-textfield-icon mdui-btn mdui-btn-icon"&gt;&lt;i class="mdui-icon material-icons"&gt;search&lt;/i&gt;&lt;/button&gt; &lt;form method="get" target="_self" action="/search"&gt; &lt;input name="q" class="mdui-textfield-input" type="text" placeholder="Search"/&gt; &lt;/form&gt; &lt;button class="mdui-textfield-close mdui-btn mdui-btn-icon"&gt;&lt;i class="mdui-icon material-icons"&gt;close&lt;/i&gt;&lt;/button&gt; &lt;/div&gt;&lt;/div&gt; 注：在简单实现中，搜索出的结果是无法进行超链接的。需要进行小的修改 对搜索结果界面进行美化，使用与首页一致的卡片 123456789101112131415161718192021&#123;% block content %&#125;&#123;% if query %&#125; &lt;div class=&quot;mdui-typo-headline-opacity&quot; style=&quot;margin-top: 20px;&quot;&gt;搜索结果：&lt;/div&gt; &lt;ul class=&quot;mdui-list mdui-center&quot;&gt; &#123;% for result in page.object_list %&#125; &lt;li class=&quot;mdui-card mdui-ripple mdui-shadow-2&quot; style=&quot;margin-bottom: 5px&quot;&gt; &lt;a href=&quot;/&#123;&#123; page.number &#125;&#125;/&#123;&#123; result.object.id &#125;&#125;&quot;&gt; &lt;div class=&quot;mdui-card-primary&quot;&gt; &lt;div class=&quot;mdui-card-primary-title&quot;&gt;&#123;&#123; result.object.title &#125;&#125;&lt;/div&gt; &lt;div class=&quot;mdui-card-primary-subtitle&quot;&gt;&#123;&#123; result.object.author &#125;&#125;&lt;/div&gt; &lt;div class=&quot;mdui-card-primary-subtitle&quot;&gt;&#123;&#123; result.object.publish &#125;&#125;&lt;/div&gt; &lt;/div&gt; &lt;/a&gt; &lt;/li&gt; &#123;% empty %&#125; &lt;div class=&quot;mdui-typo-headline-opacity&quot;&gt;未找到&lt;/div&gt; &#123;% endfor %&#125; &lt;/ul&gt;# 下面的内容不改......&#123;% endblock content %&#125; 参考文章： django-haystack(全文检索-jieba分词) Django—全文检索功能]]></content>
      <tags>
        <tag>Django</tag>
        <tag>Whoosh</tag>
        <tag>全文检索</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统安全笔记]]></title>
    <url>%2F2019%2F01%2F21%2FLinux%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Linux后门入侵检测 rootkit检测 Linux后门入侵检测rootkit检测rootkit是一种木马后门工具，主要通过替换系统文件达到入侵和隐蔽目的，攻击能力强，攻击者能隐蔽行迹并获取root权限。 rootkit分为两种： 文件级别：通过程序或系统漏洞进入系统后，修改系统文件隐蔽自己。通常会将程序替换为木马，例如login、ls、ps、ifconfig等。 内核级别：比文件级别更加高级，攻击者能获得系统底层的完全控制权，即可以修改内核。内核级rootkit主要依附在内核上，并不对系统文件做任何修改，一般检测工具无法检测。 可使用rkhunter工具检测rootkit威胁。官网下载。进入解压目录后 1./installer.sh --install rkhunter命令参数 1-c # 检测本地系统 服务器受到攻击后的处理 切断网络 查找攻击源：分析系统日志和用户登录日志、开放端口、进程服务 分析入侵原因和途径：可能是系统漏洞、程序漏洞 检查锁定可疑用户：通过w，或日志/var/log/secure查看异常登录 检查并关闭系统可疑进程：pidof命令、/proc/[pid]/fd|exe目录 检查文件系统完好性：rpm -Va命令 备份用户数据 重新安装系统 修复程序或系统漏洞 恢复数据和连接网络]]></content>
      <tags>
        <tag>运维</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins学习笔记]]></title>
    <url>%2F2019%2F01%2F21%2FJenkins%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[在Vultr上搭建Shadowsocks记录]]></title>
    <url>%2F2018%2F12%2F25%2F%E5%9C%A8Vultr%E4%B8%8A%E6%90%AD%E5%BB%BAShadowsock%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[使用的是Vultr的云服务器，选择的节点在日本，服务器是最便宜的3.5$每月的。 在服务器页面会有提示密码，先用ssh-copy-id拷贝一下密钥，方便以后登录。 登录服务器后，下载shadowsocks脚本，并增加执行权限，然后运行，最好记录日志 12345wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.shchmod +x shadowsocks.sh./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log 在安装过程中，会依次提示输入ss的密码 12345Please enter password for shadowsocks-python(Default password: teddysun.com):---------------------------password = XXXX--------------------------- 输入服务器端端口号 12345Please enter a port for shadowsocks-python [1-65535](Default port: 12305):---------------------------port = 12305--------------------------- 输入加密算法，为了使iphone能用，选第七个aes-256-cfb 123456789101112131415161718192021Please select stream cipher for shadowsocks-python:1) aes-256-gcm2) aes-192-gcm3) aes-128-gcm4) aes-256-ctr5) aes-192-ctr6) aes-128-ctr7) aes-256-cfb8) aes-192-cfb9) aes-128-cfb10) camellia-128-cfb11) camellia-192-cfb12) camellia-256-cfb13) chacha20-ietf-poly130514) chacha20-ietf15) chacha2016) rc4-md5Which cipher you&apos;d select(Default: aes-256-gcm):---------------------------cipher = aes-256-cfb--------------------------- 最后开始安装，安装完成后就会提示ss的信息 至此，服务器端配置完成。 在自己的主机上安装shadowsocks客户端 1apt-get install shadowsocks shadowsocks-client 然后配置ss服务器信息，修改配置文件/etc/shadowsocks/config.json 123456789101112&#123; &quot;server&quot;:&quot;XXX&quot;, # 服务器地址 &quot;server_port&quot;:12305, # 服务器端端口 &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, # 本地端口，用于建立vpn隧道 &quot;password&quot;:&quot;XXXX&quot;, # ss服务器的密码 &quot;timeout&quot;:300, &quot;method&quot;:&quot;aes-256-cfb&quot;, # 加密算法 &quot;fast_open&quot;: false, &quot;workers&quot;: 1, &quot;prefer_ipv6&quot;: false&#125; 最后使用命令启动shadowsocks-client 12345sshlocal -c /etc/shadowsocks/config.jsonINFO: loading config from /etc/shadowsocks/config.json2018-12-25 23:37:46 INFO loading libcrypto from libcrypto.so.1.12018-12-25 23:37:46 INFO starting local at 127.0.0.1:1080 在浏览器上设置代理，选自动检测代理设置。 然后安装插件switchyomega进行配置 代理协议一定要是sock5，因为ss只支持sock5，不支持HTTP。 代理服务器须是本地，因为是ss远端与本地建立隧道，指向的端口也是本地端口，就是ss本地的配置中指定的端口。 应用选项后即可访问外网。还可以使用BBR加速，BBR是谷歌开发的内核模块，可使用脚本一键安装，需要内核版本4.9以上。脚本会自动检测内核版本，并安装最新的内核（通过elrepo源）。注：此脚本是在服务器上执行，而不是在本主机上执行。 12wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.shchmod +x bbr.sh 安装完成后查看bbr模块是否已加载 12lsmod | grep bbrtcp_bbr 20480 9 至此所有配置完成，可直接上外网了。 参考文章 Vultr vps搭建属于自己的ss 代理 使用BBR一键脚本为你的CentOS/Debian/Ubuntu系统加速]]></content>
      <tags>
        <tag>Vultr</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centreon监控平台搭建笔记]]></title>
    <url>%2F2018%2F12%2F24%2FCentreon%E7%9B%91%E6%8E%A7%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Ganglia与Centreon概述 Centreon与Ganglia监控部署 Ganglia与Centreon概述Ganglia是一个为HPC（高性能计算）集群而设计的可扩展的分布式监控系统，它可以监视和显示集群中的节点的各种状态信息，它由运行在各个节点上的 gmond 守护进程来采集CPU 、内存、硬盘利用率、 I/O 负载、网络流量情况等方面的数据，然后汇总到 gmetad 守护进程下，使用 rrdtool 存储数据，最后将历史数据以曲线方式通过 PHP 页面呈现。Ganglia 监控系统有三部分组成，分别是 gmond、 gmetad、 webfrontend。 Ganglia的特点：具有良好的扩展性、负载开销低、支持高并发、支持各种操作系统与虚拟机 gmetad可周期性去多个gmond节点收集数据，并且可以去其他gmetad收集数据。 Centreon是一款开源的功能强大的分布式 IT 监控系统，它通过第三方组件可以实现对网络、操作系统和应用程序的监控。 它的底层采用 nagios 作为监控软件，同时 nagios 通过 ndoutil 模块将监控到的数据定时写入数据库中，而 Centreon 实时从数据库读取该数据并通过 Web 界面展现监控数据。可以通过 Centreon 管理和配置 nagios，或者说 Centreon 就是 nagios 的一个管理配置工具，通过Centreon 提供的 Web 配置界面，可以轻松完成 nagios 的各种繁琐配置。 Centreon由四部分组成：nagios、centstorage、centcore、ndoutils nagios是Centreon的底层监控引擎，完成监控报警的各项功能。Centreon也支持Centreon Engine或Icinga等监控引擎 centstorage是数据存储模块，用于将日志数据与rrdtool数据存储到数据库中 centcore是一个基于perl的守护进程，负责中心服务器（central server）和扩展节点（poller）间通信和数据同步，如远程对节点nagios的启动或关闭以及配置文件更新 ndoutils是连接nagios和数据库的工具，将nagios数据实时写入数据库 Centreon web、centstorage、centcore、ndo2db一般位于中心服务器，nagios和ndomod可位于一台独立扩展节点，也可位于中心服务器。 数据通信流程： Centreon web是Centreon的web配置管理界面，配置完成后会生成相应配置文件 Centcore会读取配置并结合nagios插件将数据发送到nagios引擎，并生成日志与rrds文件 这步也可以直接nagios获取数据，由centstorage存入数据库 也可以由ndomod进程将nagios的数据存入ndo2db，然后Centreon web定期读取数据库 centstorage模块收集这些日志和rrds数据存入数据库，供Centreon web调用 统一运维监控平台设计要以运行监控和故障报警为重点，通过消除管理软件的差别、数据采集手段的差别，对不同数据来源实现统一管理、规范等操作。 Centreon与Ganglia监控部署先安装ganglia。只要通过epel源就能安装。 在服务器端安装ganglia、ganglia-devel、ganglia-gmetad、ganglia-gmond、ganglia-web。客户端只要装ganglia-gmond即可。通过yum会自动安装依赖，如rrdtool等 服务器配置文件/etc/ganglia/gmetad.conf 12345678data_source &quot;cluster1&quot; localhost # 数据源，可添加多个客户端# 格式：data_source &quot;名称&quot; 拉取间隔（可选） 客户端IP:端口 客户端IP/域名 ....# 若端口号不写，默认为8249gridname &quot;MyGrid&quot; # 网格名称，一个网格由多个服务器集群构成，每个服务器集群由data_source定义setuid_username ganglia # 启动用户xml_port 8651 # 客户端的数据汇总端口，默认为8651rrd_rootdir &quot;/var/lib/ganglia/rrds&quot; # 数据存放位置interactive_port 8652 # gmetad回应请求的端口 客户端配置文件/etc/ganglia/gmond.conf 123456789101112131415161718192021222324252627282930globals &#123; daemonize = yes # 是否后台运行 setuid = yes # 是否设置运行用户 user = ganglia # 运行用户，默认为ganglia debug_level = 0 # 调试级别，默认为0（不输出任何日志） max_udp_msg_len = 1472 mute = no # 是否发送监控数据到其他节点 # no表示本节点将不再广播任何自己收集到的数据到网络上 deaf = no # 是否接收其他节点发来的数据，no表示不接收 allow_extra_data = yes # 是否发送扩展数据 host_dmax = 86400 # 是否删除超时节点。若为0表示永不删除。其他则为无响应时间，超时就清除节点信息 host_tmax = 20 cleanup_threshold = 300 # gmond清理过期数据的时间 gexec = no # 是否使用gexec告知主机是否可用 send_metadata_interval = 0 # 新添加的节点在多长时间内响应服务器（类似心跳） # 0为仅在gmond启动时通知&#125;cluster &#123; name = &quot;cluster1&quot; # 集群名，要与data_source中的一项一致 owner = &quot;unspecified&quot; # 节点管理员 latlong = &quot;unspecified&quot; # 节点坐标（一般不用设） url = &quot;unspecified&quot; # 节点url（一般不用设）&#125;udp_send_channel &#123; mcast_join = 239.2.11.71 # 指定发送的多播地址 port = 8649 # 监听端口 ttl = 1&#125; Ganglia web配置文件存放在/usr/share/ganglia/conf_default.php，需要改名为conf.php并存放在/etc/ganglia/下。 12345678910111213141516$conf[&apos;gweb_root&apos;] = dirname(__FILE__);$conf[&apos;gweb_confdir&apos;] = &quot;/var/lib/ganglia&quot;; # ganglia web根目录$conf[&apos;gmetad_root&apos;] = &quot;/var/lib/ganglia&quot;; # ganglia 程序安装目录$conf[&apos;rrds&apos;] = &quot;$&#123;conf[&apos;gmetad_root&apos;]&#125;/rrds&quot;; # ganglia web读取rrd数据库的路径# 该目录权限需要修改为777，使rrdtool能够修改：chmod -R 777 /var/lib/ganglia/rrds$conf[&apos;dwoo_compiled_dir&apos;] = &quot;$&#123;conf[&apos;gweb_confdir&apos;]&#125;/dwoo/compiled&quot;;$conf[&apos;dwoo_cache_dir&apos;] = &quot;$&#123;conf[&apos;gweb_confdir&apos;]&#125;/dwoo/cache&quot;;# 以上的两个路径需要设为777权限，否则ganglia web无法创建某些需要的文件# 即：chmod -R 777 /var/lib/ganglia/dwoo$conf[&apos;rrdtool&apos;] = &quot;/usr/bin/rrdtool&quot;; # rrdtool的路径$conf[&apos;graphdir&apos;]= $conf[&apos;gweb_root&apos;] . &apos;/graph.d&apos;; # 生成图形模板目录$conf[&apos;ganglia_ip&apos;] = &quot;127.0.0.1&quot;; # gmetad服务所在服务器地址$conf[&apos;ganglia_port&apos;] = 8652; # gmetad服务器的交互式提供监控数据发布端口 # 与gmetad.conf中的interactive_port一致 配置完成，在服务器端用systemctl start gmetad.sercive启动gmetad，并在客户端上直接gmond启动客户端。 需要确认PHP环境已搭建。配置httpd的虚拟主机，将路径设为/usr/share/ganglia，重启httpd后通过设置的域名访问 Ganglia优势与注意： 可监控上万台服务器，延时在10s以内 分布式架构，易于机房扩展 可与Centreon整合，实现监控报警一体化 需要高性能磁盘，数据存储可能成为瓶颈 部署Centreon。可以在官网下载iso直接类似虚拟机安装（包含了centos和Centreon），或者配置yum源下载 12345[centreon]name=centreon-el7-x86baseurl=&quot;http://yum.centreon.com/standard/18.10/el7/stable/x86_64/&quot;enabled=1gpgcheck=0 直接yum install centreon* 参考文章 高性能LINUX服务器构建实践：系统安全、故障排查、自动化运维与集群架构]]></content>
      <tags>
        <tag>Centreon</tag>
        <tag>Ganglia</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pacemaker笔记]]></title>
    <url>%2F2018%2F12%2F21%2FPacemaker%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Corosync笔记]]></title>
    <url>%2F2018%2F12%2F21%2FCorosync%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[OpenAIS概述 Corosync概述 OpenAIS概述]]></content>
      <tags>
        <tag>Corosync</tag>
        <tag>集群</tag>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MFS分布式文件系统笔记]]></title>
    <url>%2F2018%2F12%2F06%2FMFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[分布式文件系统 MFS概述 MFS简单部署 MFS高可用 分布式文件系统Distributed File System（DFS）分布式文件系统是开放软件基金会（OSF）的分布式计算环境（DCE）中的文件系统部分，指文件系统管理的物理存储资源不一定直接连接在本地节点上，具有以下特性： 只读共享：任何客户端只能访问文件，不能修改。 受控写操作：允许多个用户打开同一个文件，但只有一个用户能进行写操作，并且该用户的修改不能立刻在其他用户上体现。 并发写操作：允许多个用户同时读写一个文件，需要操作系统进行大量监控工作防止文件重写，并保证用户看到最新消息。 传统的DFS，如NFS，所有的数据和元数据存放在一起，通过单一的存储服务器提供服务，这种模式称为In-band Mode，随着客户端数量增加，服务器成为整个文件系统的瓶颈。 新型的DFS利用存储区域网络（SAN），将应用服务器直接与存储设备连接，提升了传输能力，应用服务器直接访问SAN中的数据，只有关于信息的元数据才经过元数据服务器处理，减少了数据传输的中间环节，减轻了元数据服务器的负载。这种模式称为Out-band Mode。 区分两种模式的依据：元数据操作的控制信息是否与文件数据一起通过服务器转发。In-band Mode需要服务器转发，Out-band Mode可直接访问。 MFS概述MooseFS是一个具备容错功能的高可用分布式网络文件系统，MFS将数据分散在多台服务器上，确保一份数据有多份备份，且备份分布在不同服务器上，而用户看到的只是一个资源，即对用户透明。MFS就类似一个unix的文件系统，包含层级结构、文件属性等。 分层目录树结构 存储支持POSIX标准的文件属性 支持特殊文件，如块设备、字符设备、管道、套接字、链接文件 支持基于IP地址和密码的方式访问文件系统 MFS特性： 高可靠性：一份数据多份副本 高可扩展性：轻松实现横向或纵向扩展 高可容错性：可实现回收站机制 高数据一致性：即使文件被写入或访问时，仍可以进行一致性快照 MFS应用场景： 大规模高并发的线上数据存储及访问 大规模数据处理，如日志分析。 尽量在文件系统服务器前架设缓存服务器，而不是一味地扩容 MFS组成： 管理服务器（managing servers）：也称master servers，管理整个文件系统的主机，存储每个文件的元数据（大小信息、属性、文件路径） 数据存储服务器（data servers）：也称chunk servers，存储文件并进行同步的服务器，如果确定的话，文件要做多于一份的备份。此服务器是真正的数据载体，最好组raid5或raid0或raid10。实际环境中应该至少有三台以上。 元数据备份服务器（metadata backup servers）：也称metalogger server，存储元数据修改日志并周期下载主元数据文件 客户端：使用mfsmount进程与管理服务器或数据存储服务器通信以获取与修改元数据信息的主机 MFS读过程 客户端向元数据服务器（master）发出读请求。 元数据服务器把所需数据的存放位置（chunk server IP和chunk编号）告知客户端 客户端向已知的chunk server发送请求 chunk server向客户端发送数据。 数据传输并不经过元数据服务器，减轻了元数据服务器的压力，也增大了整个系统的吞吐能力。 MFS写过程 客户端向元数据服务器发送写请求 元数据服务器与chunk server交互（只要当所需chunks存在才交互） a. 元数据服务器在某些服务器上创建chunks b. chunk server告知元数据服务器chunks创建成功 元数据服务器告知客户端可写的chunk server上的指定chunks 客户端向指定chunk server写数据 chunk server之间进行同步 chunk server互相通知同步成功 chunk server告知客户端写入成功 客户端告知元数据服务器写入成功 MFS简单部署实验环境： Master：192.168.60.134 MFS VIP：192.168.60.200 Backup：192.168.60.135 Chunk1：192.168.60.136 Chunk2：192.168.60.130 Client：192.168.60.131 先要配置官方源，官网配置，版本3.0 对Master：yum install moosefs-master moosefs-cgi moosefs-cgiserv moosefs-cli 对chunkserver：yum install moosefs-chunkserver 对metalogger：yum install moosefs-metalogger 对Client：yum install moosefs-client 启动masterMaster的配置文件目录/etc/mfs/ mfsexports.cfg：被挂载目录及权限控制文件 mfsmaster.cfg：master主配置文件 mfstopology.cfg： mfsmaster.cfg12345678910111213141516WORKING_USER = mfs # 运行master的用户WORKING_GROUP = mfs # 运行master的用户组SYSLOG_IDENT = mfsmaster # master在syslog中的标识LOCK_MEMORY = 0 # 执行mlockall()以避免mfsmaster进程溢出NICE_LEVEL = -19 # 运行优先级DATA_PATH = /var/lib/mfs # 数据存放路径EXPORTS_FILENAME = /etc/mfs/mfsexports.cfg # exports文件路径TOPOLOGY_FILENAME = /etc/mfs/mfstopology.cfg # BACK_LOGS = 50 # metalogger改变的log文件数量MATOML_LISTEN_HOST = * # metalogger监听IP地址MATOML_LISTEN_PORT = 9419 # metalogger监听端口MATOCS_LISTEN_HOST = * # chunkserver监听IPMATOCS_LISTEN_PORT = 9420 # chunkserver监听端口MATOCL_LISTEN_HOST = * # 客户端监听IPMATOCL_LISTEN_PORT = 9421 # 客户端监听端口REPLICATIONS_DELAY_INIT = 60 # 延迟复制的时间 mfsexports.cfg文件格式 1客户端IP地址（或范围） 挂载点 参数 其中挂载点路径有两个注意： /表示以MFS根为根目录 .表示以MFSMETA文件系统为根目录 参数可设置以下访问权限，逗号分隔多个参数： ro：只读 rw：读写 alldirs：允许挂载任何指定的子目录 maproot：映射为root password：指定客户端密码 启动操作先在master上配置VIP。ifconfig ens32:0 192.168.60.200/24 up。 在master上使用命令mfsmaster start即可启动主服务器。会开启三个端口 123master &lt;-&gt; metaloggers module: listen on *:9419master &lt;-&gt; chunkservers module: listen on *:9420main master server module: listen on *:9421 其中9419用于监听metalogger，9420监听chunkserver，9421监听master 12345678910111213mfsmaster -c 指定mfsmaster配置文件 -f 在前端运行 -i 忽略元数据结构错误 -a 自动从更改日志记录恢复元数据 -x 显示更多的日志信息，最高-xx start 启动mfsmaster stop 停止 reload 重载配置 restart 重启 info 打印mfsmaster信息 test 测试 kill 杀死 可以使用命令mfscgiserv start启动MFS的图形化web监控，通过9425端口访问，该图形化web是用python写的。 启动metalogger配置文件/etc/mfs/mfsmetalogger.cfg 1234MASTER_HOST = mfsmaster # 可配置master的主机名（需要在/etc/hosts中配置）、IP地址、域名等指定masterMASTER_PORT = 9419 # master监听端口MASTER_RECONNECTION_DELAY = 5 # 重连延迟MASTER_TIMEOUT = 10 # 连接超时时间 启动metalogger，mfsmetalogger start，查看端口可看到与master建立了长连接 1ESTAB 0 0 192.168.60.135:40476 192.168.60.200:9419 users:((&quot;mfsmetalogger&quot;,pid=7735,fd=8)) mfsmetalogger命令与mfsmaster类似。 启动chunkserver准备磁盘，分区、制作文件系统并挂载。 12mount /dev/sdb1 /var/mfsdatachown -R mfs:mfs /var/mfsdata # 一定要执行，否则启动失败 chunkserver挂载点配置文件/etc/mfs/mfshdd.cfg，只要将挂载点写入该文件即可。 1echo &quot;/var/mfsdata&quot; &gt;&gt; /etc/mfs/mfshdd.cfg 参数配置文件/etc/mfs/mfschunkserver.cfg 1234MASTER_HOST = mfsmaster # 同metalogger，要与hosts中一致MASTER_PORT = 9420 # master的连接端口CSSERV_LISTEN_HOST = * # 监听客户端IP，即指允许指定的客户端使用CSSERV_LISTEN_PORT = 9422 # 监听客户端的端口 命令mfschunkserver start启动chunkserver。 但通过web查看状态，发现已经使用了260M左右。 因为master向data服务器申请空间是按最少256M申请的，低于256M则不会再申请空间，因此用于MFS的磁盘空间一定要大于256M，并且空闲的空间一定要大于1G才能参与分配，即用于MFS磁盘的空间大小至少大于1G，应该从几个G开始。 启动clientMFS客户端的挂载依赖于fuse工具，需要先安装。默认系统已安装。但需要安装内核模块modprobe fuse。客户端上也要配置hosts文件添加mfsmaster。 创建mfs组与mfs用户，创建挂载目录 123groupadd mfsuseradd -g mfs mfs -s /sbin/nologinmkdir /mnt/mfsdata 使用mfsmount挂载mfs。mfsmount /mnt/mfsdata -H mfsmaster 挂载完成后，查看df可发现挂载成功。 客户端的/bin/中有许多mfs的工具，但都指向mfstools 在挂载目录中创建文件 12345678910111213# touch 1.conf# mfsfileinfo 1.conf # 只创建空文件并不会创建chunks1.conf: no chunks - empty file# dd if=/dev/zero of=/mnt/mfsdata/aaa count=200000# mfsfileinfo aaa # 查看文件信息，已经成功由MFS分配存储aaa: chunk 0: 0000000000000002_00000001 / (id:2 ver:1) copy 1: 192.168.60.130:9422 (status:VALID) copy 2: 192.168.60.136:9422 (status:VALID) chunk 1: 0000000000000003_00000001 / (id:3 ver:1) copy 1: 192.168.60.130:9422 (status:VALID) copy 2: 192.168.60.136:9422 (status:VALID) 在客户端的/mnt/mfsdata/中有以下目录 12# lsconf ini jpg md png 创建备份mfssetgoal -r 3 conf，备份三份conf目录。 12345# mfssetgoal -r 3 confconf: inodes with goal changed: 1001 inodes with goal not changed: 0 inodes with permission denied: 0 查看文件备份情况 12# mfsgetgoal confconf: 3 # 有三份备份 MFS数据存放在chunk中，类似block，数据是会分为多个chunk的，每个chunk的大小为64M，若一个文件大于64M，则会分为多个chunk。 12345678910111213141516# dd if=/dev/zero of=./aaa bs=1M count=63 # 63M的文件在一个chunk中# mfsfileinfo aaaaaa: chunk 0: 0000000000000008_00000001 / (id:8 ver:1) copy 1: 192.168.60.130:9422 (status:VALID) copy 2: 192.168.60.136:9422 (status:VALID)# dd if=/dev/zero of=./bbb bs=1M count=65 # 65M的文件分为了两个chunk存储# mfsfileinfo bbb bbb: chunk 0: 000000000000000B_00000001 / (id:11 ver:1) copy 1: 192.168.60.130:9422 (status:VALID) copy 2: 192.168.60.136:9422 (status:VALID) chunk 1: 000000000000000C_00000001 / (id:12 ver:1) copy 1: 192.168.60.130:9422 (status:VALID) copy 2: 192.168.60.136:9422 (status:VALID) 查看文件删除后会在回收站里的时间 12# mfsgettrashtime conf/1.conf conf/1.conf: 86400 # 86400s，即一天 设置文件删除后在回收站里的时间 123# mfssettrashtime -r 864000 conf/ # -r递归设置conf/: inodes with trashtime changed: 1001 挂载mfs回收站 123# mfsmount -H mfsmaster -m /mnt/mfs-trash# ls /mnt/mfs-trashsustained trash master宕机切换在master上/var/lib/mfs/中存放修改记录changelog.X.mfs和元数据记录metadata.mfs.back 在backup的/var/lib/mfs/中也存放着修改记录changelog_ml.X.mfs和元数据记录metadata_ml.mfs.back和metadata.mfs 若要在backup上恢复数据并身份转为master，可以通过命令mfsmaster -a直接恢复。 注：mfsmetarestore命令在1.7版本已被废除。 MFS集群内各角色的启动与停止规范的启动顺序： 启动Masters 启动所有chunk servers 启动metalogger 挂载客户端 规范的停止顺序： 客户端卸载挂载 停止所有chunk servers 停止metalogger 停止master MFS高可用有几个解决方法： 部署多个日志备份服务器（metalogger） 使用heartbeat或keepalived+DRBD实现master高可用 使用keepalived+inotify实现master高可用（不推荐） keepalived+DRBD实现高可用实验环境： Master：192.168.60.134 Backup：192.168.60.135 Chunk1：192.168.60.136 Chunk2：192.168.60.130 Client：192.168.60.131 在Master和Backup上设置DRBD分区，sdc大小2G，sdc1有400M做元数据存储，剩余sdc2做数据存储。 123 设备 Boot Start End Blocks Id System/dev/sdc1 2048 821247 409600 83 Linux/dev/sdc2 821248 4194303 1686528 83 Linux 在Master和Backup上都修改DRBD配置，创建mfs.res 123456789101112131415resource mfsdata &#123; protocol C; on host1 &#123; device /dev/drbd0; disk /dev/sdc2; address 192.168.80.128:7789; # 心跳线 meta-disk /dev/sdc1[0]; &#125; on host2 &#123; device /dev/drbd0; disk /dev/sdc2; address 192.168.80.129:7789; meta-disk /dev/sdc1[0]; &#125;&#125; 创建DRBD操作 12drbdadm create-md alldrbdadm up all 配置keepalived，在两台主机上配置 12345678910111213141516171819202122232425global_defs &#123; # 保持默认即可 notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.60.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0&#125;vrrp_instance VI_1 &#123; state MASTER interface ens32 virtual_router_id 51 priority 120 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.60.200 &#125;&#125;]]></content>
      <tags>
        <tag>存储</tag>
        <tag>MFS</tag>
        <tag>文件系统</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAProxy Starter Guide翻译]]></title>
    <url>%2F2018%2F12%2F02%2FHAProxy-Starter-Guide%E7%BF%BB%E8%AF%91%2F</url>
    <content type="text"><![CDATA[译者：serchaofan 翻译主要借助翻译工具，并进行校对。 根据官方18.14与18.15文档Starter Guide的翻译，并非完整翻译，且有的地方会有修改与删除。 快速介绍负载均衡和负载均衡器 HAProxy介绍 HAProxy是什么与不是什么 HAProxy如何工作 基础功能 代理 SSL 监控 高可用 负载均衡 粘性 采样与转换信息 映射 ACLS和条件 内容转换 绑定表 格式化字符串 HTTP重写与重定向 服务器保护 日志 统计 高级功能 管理 系统特定功能 脚本 调优 配套产品及替代产品 Apache Nginx Varnish 替代产品 快速介绍负载均衡和负载均衡器负载均衡包括聚合多个组件，以便在每个组件的单独流量上实现总处理能力，而无需客户端用户的任何干预并且是可扩展的。这导致组件在仅执行一个操作所花费的时间内同时执行更多操作。 但是，单个操作仍然会一次在单个组件上执行，并且不会比没有负载均衡时更快。 它始终需要至少与可用组件一样多的操作和有效的负载均衡机制来充分利用所有组件并从负载均衡中充分受益。一个很好的例子是高速公路上的车道数量，不增加车辆速度而允许尽可能多的车辆在同一时间段内通过。 负载均衡的示例： 多处理器系统中的进程调度 链路负载均衡（例如EtherChannel，Bonding） IP地址负载均衡（例如ECMP，DNS round-robin） 服务器负载均衡（通过负载均衡器） 执行负载均衡操作的机制或组件称为负载均衡器。 在Web环境中，这些组件称为“网络负载均衡器”，更常见的是“负载均衡器”，因为此说法是迄今为止负载均衡的最好示例。 负载均衡器可以起作用： 在链路级别：这称为链路负载均衡，它包括选择发送数据包的网络链路 在网络级别：这称为网络负载均衡，它包括选择一系列数据包将使用的路由 在服务器级别：这称为服务器负载均衡，它包括决定哪个服务器将处理连接或请求 存在两种不同的技术并满足不同的需求，但有一些重叠。在每种情况下，重要的是要记住，负载均衡包括将流量从其自然流转移，并且这样做总是需要最少的维护，以维持所有路由决策之间所需的一致性水平。 第一个技术作用于数据包级别并且或多或少地单独处理数据包。 输入和输出数据包之间存在一对一的关系，因此可以使用常规网络嗅探器跟踪负载均衡器两侧的流量。这项技术非常便宜且速度极快。 它通常以硬件（ASIC）实现，能够达到线速（line rate），例如执行ECMP的交换机。 通常是无状态的，它也可以是有状态的（考虑一个数据包所属的会话并称为layer4-LB或L4），如果数据包没有被修改，可以支持DSR（直接服务器返回，不再通过LB），但几乎不提供内容感知（content awareness）。 该技术非常适合网络级负载均衡，但有时用于高速的基本服务器负载均衡。 第二个技术作用于会话内容。 它要求输入流作为一个整体进行重组和处理。 可以修改内容，并且将输出流分段为新分组。出于这个原因，它通常由代理执行，它们通常被称为第7层负载均衡器或L7。这意味着每一侧有两个不同的连接，并且输入和输出数据包大小与计数之间没有关系。客户端和服务器不需要使用相同的协议（例如IPv4与IPv6，不加密与SSL）。 操作始终是有状态的，返回流量必须通过负载均衡器。 额外的处理带来了成本，因此并不总是能够实现线速，特别是对于小数据包。 另一方面，它提供了广泛的可能性，并且通常通过纯软件实现，即使嵌入到硬件设备中也是如此。 该技术非常适合服务器负载均衡。 基于数据包的负载均衡器通常以直通模式（cut-though mode）部署，因此它们安装在流量的正常路径上，并根据配置进行转移。 返回的流量不一定通过负载均衡器。 可以对网络目的地址进行一些修改，以便将流量引导到适当的目的地。 在这种情况下，返回流量必须通过负载均衡器。如果路由不能实现这一点，则负载均衡器也可以用自己的路由替换数据包的源地址，强制返回流量通过它。 基于代理的负载均衡器部署为具有自己的IP地址和端口的服务器，无需更改体系结构。有时，这需要对应用程序执行一些调整，以便客户端正确定向到负载均衡器的IP地址，而不是直接定向到服务器。某些负载均衡器可能必须调整某些服务器的响应才能实现这一点（例如HTTP重定向中使用的HTTP Location头字段）。某些基于代理的负载均衡器可能会拦截其不拥有的地址的流量，并在连接到服务器时欺骗客户端的地址。这使得它们可以像通常的路由器或防火墙一样进行部署，采用与基于数据包的负载均衡器非常相似的直通模式。对于结合了分组模式和代理模式的产品，这是特别受欢迎的。 在这种情况下，DSR显然仍然不可能，并且返回流量仍然必须路由回负载均衡器。 一种非常可扩展的分层方法将包括具有从多个负载均衡链路接收流量的前端路由器，并使用ECMP将该流量分配到多个有状态分组的负载均衡器（L4）的第一层。这些L4负载均衡器又将流量传递给更大数量的基于代理的负载均衡器（L7），这些负载均衡器必须解析内容以确定哪个服务器最终将接收流量。 流量的组件数量和可能的路径增加了失败的风险; 在非常大的环境中，永久性地将一些故障部件修复或替换是正常的。 在不了解整个堆栈的运行状况的情况下完成负载均衡会显着降低可用性。 出于这个原因，任何严谨的负载均衡器都将验证它打算提供流量的组件是否仍然存活且可访问，并且它将停止向故障流量提供流量。 这可以使用各种方法实现。 最常见的一种是定期发送探测包以确保组件仍可运行。 这些探测包称为“健康检查”。 它们必须代表要解决的失败类型。 例如，基于ping的检查不会检测到Web服务器已经崩溃并且不再监听端口，而与端口的连接将验证这一点，而更高级的请求甚至可以验证服务器是否仍然有效并且它依赖的数据库仍然可以访问。 健康检查通常需要进行一些重试以防止偶尔的监测错误。检查之间的时间间隔必须足够小，以确保在发生错误后故障组件的使用时间不会太长。 其他方法包括对发送到目的地的生产流量进行抽样，以观察是否正确处理，并去除返回不适当响应的组件。 然而，这需要牺牲一部分生产流量，这并不总是可以接受的。 这两种机制的组合提供了两全其美的优势，两者都用于检测故障，只有健康检查才能检测到故障的结束。 最后一种方法涉及集中报告：中央监控代理定期更新所有负载均衡器的所有组件的状态。 这为所有组件提供了基础架构的全局视图，但有时精度或响应性较低。 它最适合具有许多负载均衡器和许多服务器的环境。 第7层负载均衡器还面临另一个被称为粘性或持久性的挑战。 原则是它们通常必须将来自同一来源（例如最终用户）的多个后续请求或连接指向同一目标。 最着名的例子是在线商店的购物车。 如果每次点击都会导致新连接，则必须始终将用户发送到保存其购物车的服务器。 内容感知使得更容易发现请求中的某些元素以识别要将其传递到的服务器，但这并不总是足够的。 例如，如果把源地址用作选择服务器的指标，则可以确定将使用基于散列的算法，并且将始终按可用服务器的数量基于地址划分将给定的IP地址发送到同一服务器 。 但是如果一台服务器出现故障，结果会发生变化，所有用户都会突然被发送到另一台服务器并丢失购物车。 针对此问题的解决方案在于记录所选目标，以便每次看到相同的访问者时，无论可用服务器的数量如何，都会将其定向到同一服务器。 信息可以存储在负载均衡器的内存中，在这种情况下，如果不是单独的话，可能必须将其复制到其他负载均衡器，或者可以使用各种方法存储在客户端的内存中，前提是客户端能够随每个请求呈现该信息（cookie插入，重定向到子域等）。 这种机制提供了额外的好处，即不必依赖不稳定或分布不均匀的信息（例如源IP地址）。 事实上，这是采用第7层负载均衡器而不是第4层负载均衡器的最有力理由。 为了提取诸如cookie，主机头字段，URL或其他信息之类的信息，负载均衡器可能需要解密SSL/TLS流量，甚至可能在将其传递给服务器时对其进行重新加密。 这个复杂的任务解释了为什么在一些高流量的基础设施中，有时可能会有很多负载均衡器。由于第7层负载均衡器可以对流量执行许多复杂的操作（解密，解析，修改，匹配cookie，决定要发送到哪个服务器等），它肯定会造成一些麻烦，并且通常会为显露出很多麻烦而被指责。 通常会发现服务器不稳定并且周期性地停止重启，或者对于Web服务器，它们会传递带有一些硬编码链接的页面，迫使客户端直接连接到一个特定的服务器而不通过负载均衡器，或者他们需要很长时间才能在高负荷下做出反应，导致超时，这就是为什么日志记录是第7层负载均衡的一个极其重要的方面。一旦报告故障，重要的是要确定负载均衡器是否做出了错误的决定，如果是这样，如何才能不再发生这种情况。 HAProxy介绍HAProxy写作“HAProxy”来指定产品，而“haproxy”被指定为可执行程序，软件包或进程。 然而，两者通常用于两种目的，并且发音为H-A-Proxy。，很早以前，“haproxy”曾经代表“高可用性代理”，这个名字用两个单独的单词写成，但现在它只不过是“HAProxy”。 HAProxy是什么与不是什么HAProxy是： TCP代理：它可以接受来自侦听套接字的TCP连接，连接到服务器并将这些套接字连接在一起，允许流量在两个方向上流动 HTTP反向代理（在HTTP术语中称为“网关”）：它将自身表示为服务器，通过侦听TCP套接字上接受的连接接收HTTP请求，并使用不同的连接将请求从这些连接传递到服务器。 SSL终端/发起者/卸载程序（offloader）：SSL / TLS可用于来自客户端，到服务器的连接，甚至两个连接的连接。 TCP规范化程序（normalizer）：由于操作系统本地终止了连接，双方之间没有关系，因此无效数据包、标志组合、窗口通告（window advertisement）、序列号、不完整连接（SYN泛洪）等异常流量不会被传递到另一边。 这可以保护脆弱的TCP栈免受协议攻击，并且还允许与客户端优化连接参数，而无需修改服务器的TCP栈设置。 HTTP规范化程序：配置为处理HTTP流量时，仅传递有效的完整请求。 这可以防止许多基于协议的攻击。 另外，规范中存在容差的协议偏差是固定的，因此它们不会在服务器上引起问题（例如，多行头）。 HTTP修复工具：它可以修改/修复/添加/删除/重写URL或任何请求或响应头。 这有助于解决复杂环境中的互操作性（interoperability）问题。 基于内容的交换机：它可以根据请求中的任何元素来决定将请求或连接传递给哪个服务器。 因此，可以在同一端口上处理多个协议（例如，HTTP，HTTPS，SSH）。 服务器负载均衡器：它可以对TCP连接和HTTP请求进行负载均衡。 在TCP模式下，对整个连接采取负载均衡决策。 在HTTP模式下，根据请求做出决定。 流量调节器：它可以在不同点应用一些速率限制，保护服务器免受过载，根据内容调整流量优先级，甚至通过标记数据包将这些信息传递给较低层和外部网络组件。 防止DDoS和服务滥用（service abuse）：它可以维护每个IP地址，URL，cookie等的大量统计信息，并检测何时发生滥用，然后采取措施（减慢违规行为，阻止它们，将它们发送到过时的内容 等）。 网络故障排除的观察点：由于日志中报告的信息的精确性，它通常用于缩小网络相关问题的范围。 HTTP压缩卸载程序：它可以压缩未被服务器压缩的响应，从而减少连接不良或使用高延迟移动网络的客户端的页面加载时间。 HAProxy不是： 显式HTTP代理，即浏览器用于访问互联网的代理。 有专门用于此任务的优秀开源软件，例如Squid。 但是，HAProxy可以部署在这样的代理之前，以提供负载均衡和高可用性。 缓存代理：它将按原样返回从服务器收到的内容，不会干扰任何缓存策略。 有很好的开源软件可以完成这项任务，比如Varnish。 HAProxy可以部署在这样的缓存之前，通过智能负载均衡提供SSL卸载和可扩展性。 数据清理程序：它不会修改请求体和响应体。 Web服务器：在启动期间，它将自己隔离在chroot jail中并删除其权限，以便一旦启动它就不会执行任何单个文件系统访问。 因此，它无法转变为Web服务器。 有很好的开源软件，如Apache或Nginx，HAProxy可以部署在它们前端，以提供负载均衡和高可用性。 基于数据包的负载均衡器：它不会看到IP数据包也不会看到UDP数据包，也不会执行NAT甚至更少的DSR（动态源路由协议）。 这些是较低层的任务。 一些基于内核的组件（如IPVS（Linux虚拟服务器））已经很好地完成了这项工作并与HAProxy完美匹配。 HAProxy如何工作HAProxy是一个单线程，事件驱动的非阻塞引擎，它将非常快的I / O层与基于优先级的调度程序相结合。 由于它的设计考虑了数据转发目标，因此其架构经过优化，可以尽可能快地以尽可能少的操作移动数据。 因此，它实现了一个分层模型，在每个级别提供旁路机制（bypass mechanisms），确保数据不会达到更高级别，除非需要。 大多数处理都是在内核中执行的，HAProxy尽最大努力通过提供一些提示或者在猜测它们可以在以后分组时避免某些操作来尽可能快地帮助内核完成工作。 因此，典型数据显示，在TCP或HTTP关闭模式下，HAProxy中花费的处理时间占15％，而在内核占85％，在HTTP keep-alive模式下，HAProxy约占30％，而内核占70％。 单个进程可以运行许多代理实例。根据试验，单个进程中大到300000个不同代理的配置运行正常。 因此，通常不需要为所有实例启动多个进程。 可以使HAProxy在多个进程上运行，但它有一些限制。 一般来说，它在HTTP关闭或TCP模式下没有意义，因为内核端不能很好地扩展一些操作，如connect()。 它可以很好地扩展到HTTP的keep-alive模式，但是可以通过单个进程实现的性能通常比常见的需求高出一个数量级。 但是，当用作SSL卸载器（offloader）时，它确实有意义，并且在多进程模式中很好地支持此功能。 HAProxy只需要运行haproxy可执行文件和配置文件。 对于日志记录，强烈建议使用正确配置的syslog守护程序并记录日志轮换。 在启动之前解析配置文件，然后HAProxy尝试绑定所有侦听套接字，并在任何失败时拒绝启动。做到这一点，它就不会运行失败了。 这意味着没有运行时故障，如果它接受启动，它将一直有效，直到它停止。 一旦HAProxy被启动，它会做三件事： 处理传入的连接 定期检查服务器状态(称为健康检查) 与其他haproxy节点交换信息 处理传入连接是迄今为止最复杂的任务，因为它依赖于许多配置可能性，但它可以概括为以下9个步骤： 接受来自属于称为frontend的配置实体的侦听套接字的传入连接 ，引用一个或多个侦听地址 将特定于frontend的处理规则应用于这些可能导致阻塞它们，修改某些头或拦截它们以执行某些内部小程序（例如统计页面或CLI）的连接 将这些传入连接传递给另一个表示称为backend的服务器池的配置实体，该服务器场包含服务器列表和此服务器池的负载均衡策略 将特定于后端的处理规则应用于这些连接 根据负载均衡策略决定将连接转发到哪个服务器 将特定于后端的处理规则应用于响应数据 将特定于前端的处理规则应用于响应数据 发出日志详细报告发生的事情 在HTTP中，循环回第二步以等待新请求，否则关闭连接 前端和后端有时被认为是半代理，因为它们只看端到端连接的一侧。前端只关心客户端，而后端只关心服务器。 HAProxy还支持完全代理，它们正是前端和后端的联合。 当需要HTTP处理时，配置通常会分为前端和后端，因为它们会打开很多可能性，因为任何前端都可以将连接传递给任何后端。 对于仅使用TCP的代理，使用前端和后端很少提供好处，并且使用完整代理可以使配置更具可读性。 基础功能本节将列举HAProxy实现的许多功能，其中一些功能通常可以从任何现代负载均衡器中获得，其中一些功能是HAProxy架构的直接优势。 更多高级功能将在下一节中详细介绍。 代理代理是通过两个独立连接在客户端和服务器之间传输数据的操作。通过代理和连接管理，HAProxy具有以下基本特性： 为服务器提供干净的连接，以防止客户端出现任何客户端缺陷或攻击 监听多个IP地址或端口，甚至端口范围 透明：截取任何甚至不属于本地系统的任意IP地址的流量 服务器端口不需要与监听端口相关，甚至可以通过固定偏移量（对范围有用）进行转换 透明连接：连接服务器时，如果需要会欺骗客户端（或任何其他主机）的IP地址 为多站点LB中的服务器提供可靠的返回IP地址 借助缓冲区和可能短暂的连接来卸载服务器，以减少它们的并发连接数和内存占用量 优化TCP栈（例如SACK），拥塞控制和减少RTT影响 支持双方不同的协议系列（例如IPv4 / IPv6 / Unix） 超时强制执行：HAProxy支持多级别的超时，具体取决于连接的阶段，因此断开的客户端或服务器或攻击者不能长时间获得资源 协议验证：检查HTTP，SSL或有效负载，拒绝无效的协议元素，除非指示无论如何接受它们 策略执行：确保只转发允许的内容 传入和传出连接都可能仅限于某些网络命名空间（仅限Linux），因此可以轻松构建跨容器，多用户负载均衡器 PROXY协议将客户端的IP地址呈现给服务器，即使对于非HTTP流量也是如此。这是一个HAProxy扩展，现在被许多第三方产品采用，在撰写本文时至少有以下产品： 客户端：haproxy，stud，stunnel，exaproxy，ELB，squid 服务器：haproxy，stud，postfix，exim，nginx，squid，node.js，varnish SSLGoogle的工程师（http://istlsfastyet.com/）认为HAProxy的SSL栈是最具特色的功能之一。 使其相当完整的最常用特性是： 基于SNI的多主机，不限制站点数量并专注于性能。 至少有一个部署用于运行50000个域及其各自的证书 对通配符证书（wildcard certificates）的支持减少了对许多证书的需求 基于证书的客户端身份验证，如果无法提供有效证书，则使用可配置策略。例如，这允许不同的服务器池重新生成客户端证书 后端服务器的身份验证确保后端服务器是真正的后端服务器而不是中间人 使用后端服务器进行身份验证让后端服务器知道它实际上是连接到它的预期haproxy节点 TLS NPN和ALPN扩展使得可以可靠地卸载SPDY/HTTP2连接并以明文形式将它们传递给后端服务器 当客户端请求证书状态请求时，通过提供内联OCSP响应，OCSP装订（stapling）进一步减少了首页加载时间 动态记录大小调整可提供高性能和低延迟，并且当数据包仍处于运行状态时，允许浏览器开始获取新对象，从而显着缩短页面加载时间 永久访问所有相关的SSL/TLS层信息，用于日志记录、访问控制、报告等。这些元素可以嵌入到HTTP报头中，甚至可以作为代理协议扩展，这样卸载的服务器就可以获得如果它自己执行SSL终止时会有的所有信息 在易受攻击的SSL库上检测、记录和阻止某些已知攻击，例如影响OpenSSL某些版本的Heartbleed攻击 支持无状态会话恢复（RFC 5077 TLS故障单扩展）。可以从CLI更新TLS票证，通过频繁翻转（rotate）票证为他们提供实现Perfect Forward Secrecy的方法。 监控HAProxy非常关注可用性。 因此，它关心服务器状态，并将其自身状态报告给其他网络组件： 使用每台服务器的参数持续监控服务器的状态。 这确保了服务器的路径可用于常规流量 健康检查支持两个滞后（hysteresis）的上下转换，以防止状态振荡 可以将检查发送到不同的地址/端口/协议：这样可以轻松检查被视为代表多个服务的单个服务，例如HTTP + HTTPS服务器的HTTPS端口。 服务器可以跟踪其他服务器并同时关闭：这可确保托管多个服务的服务器可以原子方式失败，并且不会将任何人发送到部分故障的服务器 可以在服务器上部署代理以监视负载和运行状况：服务器可能有兴趣报告其负载，运行状态，管理状态，而不管运行状况检查可以看到什么。通过在服务器上运行一个简单的代理，除了验证整个路径的运行状况检查外，还可以考虑服务器对自身运行状况的看法 提供各种检查方法：TCP连接，HTTP请求，SMTP hello，SSL hello，LDAP，SQL，Redis，send /expect脚本，所有有/无SSL 状态更改在日志和统计信息页面中以失败原因通知（例如，在检测到故障时收到的HTTP响应）。在发生此类更改时，也可以将电子邮件发送到可配置的地址 服务器状态也在统计接口上报告，并且可用于做出路由决定，以便可以根据流量大小和/或健康状况（例如，丢失DC间链路）将流量发送到不同的服务器场。 HAProxy可以使用运行状况检查请求将信息传递给服务器，例如其名称，重量，服务器场中其他服务器的数量等，以便服务器可以根据这些知识调整其响应和决策（例如，推迟备份以保持更多CPU可用） 服务器可以使用健康检查报告更详细的状态，而不仅仅是打开/关闭（例如，我想停止，请停止发送新访问者） HAProxy本身可以将其状态报告给外部组件，例如路由器或其他负载均衡器，从而可以构建非常完整的多路径和多层基础架构。 高可用就像任何负载均衡器一样，HAProxy非常重视可用性，以确保最佳的全局服务持续性： 仅使用有效的服务器，其他的被自动从负载均衡服务器群中剔除，在某些条件下，仍有可能强制使用它们 支持优雅关闭，以便可以在不影响任何连接的情况下将服务器从服务器群中剔除 当活跃服务器关闭时自动使用备份服务器并替换它们，以便在可能的情况下不会丢失会话。 这还允许构建多个路径以到达相同的服务器（例如，多个接口） 当服务器过多时，能够返回服务器群的全局故障状态。 这与监视功能相结合，使上游组件可以为给定的服务选择不同的LB节点 无状态设计使构建集群变得容易：通过设计，HAProxy尽最大努力确保最高的服务持续性，而无需存储在发生故障时可能丢失的信息。 这确保了接管是最无缝的。 与标准VRRP守护程序保持良好集成：HAProxy告知keepalived其状态，并与浮动虚拟IP地址很好地对应。 注意：仅使用基于集群的解决方案（Heartbeat，…）的IP冗余协议（VRRP/CARP），因为它们是提供最快，最无缝和最可靠切换的解决方案。 负载均衡HAProxy提供了一套相当完整的负载均衡功能，其中大多数功能在许多其他负载均衡产品中是不支持的： 支持不少于9种负载均衡算法，其中一些适用于输入数据，以提供无限的可能性列表。 最常见的是round-robin（用于短连接，依次选择每个服务器），leastconn（用于长连接，选择最近最少使用的具有最低连接数的服务器），source（用于SSL服务器群或终端服务器群，服务器直接依赖于客户端的源地址），uri（对于HTTP缓存，服务器直接依赖于HTTP URI），hdr（服务器直接依赖于特定HTTP头字段的内容），first（对于短期虚拟机，所有连接都打包在最小的服务器子集上，以便可以关闭未使用的服务器） 以上所有算法都支持服务器权重，以便可以适应服务器群中不同的级别的服务器，或者将一小部分流量引导到特定服务器（调试模式，运行下一版本的软件等） 支持动态权重的轮询、最小控制和一致哈希，这允许从CLI动态修改服务器权重，甚至允许服务器上运行的代理修改服务器权重 只要支持动态权重，就支持慢启动，这允许服务器逐步获取流量。 这是脆弱的应用程序服务器的一个重要特性，它需要在运行时编译类以及需要在全速运行之前填满的冷缓存（cold caches） 散列可以应用于各种元素，如客户端的源地址，URL组件，查询字符串元素，报文头字段值，POST参数，RDP cookie 在服务器群中添加或删除服务器时，一致性哈希（consitent hashing）可保护服务器群免受大量重新分发的影响。 这在大型缓存群中非常重要，它允许使用慢启动来重新填充冷缓存 许多内部指标，例如每个服务器、每个后端的连接数，后端中可用连接插槽的数量等，可以构建非常先进的负载均衡策略。 粘性如果没有粘性（stickness），应用程序负载均衡将毫无用处。 HAProxy提供了一套相当全面的可能性，可以将访问者维持在同一台服务器上，甚至可以跨越各种事件，例如服务器添加/删除，下线/上线周期，并且某些方法可以克服多个负载均衡节点之间的距离并不需要任何复制： 如果需要，粘性信息可以单独匹配并从不同的地方学习。 例如，JSESSIONID cookie可以在cookie和URL中匹配。 可以同时学习多达8个并行源，每个源可以指向不同的绑定表（stick-table） 粘性信息可以来自请求或响应中可以看到的任何内容，包括源地址，TCP有效负载偏移和长度，HTTP查询字符串元素，报头字段值，cookie等 以多主方式在所有节点之间复制绑定表 常用的元素，如SSL-ID或RDP cookie（用于TSE群）可直接访问，以方便操作 所有粘性规则都可以由ACL动态调节 可以决定不绑定某些服务器，例如备份服务器。这样当名义上的（nominal）服务器返回集群时，它会自动恢复负载。 这通常用于多路径环境 在HTTP中，通常不会学习任何东西，而是操纵专用于粘性的cookie。 为此，可以检测，重写，插入或添加这样的cookie，让客户端记住分配了哪个服务器 服务器可以决定在注销时更改或清除粘性cookie，以便离开的访问者自动从服务器解除绑定 使用基于ACL的规则，无论服务器的状态如何，都可以选择性地忽略或强制粘性，结合高级健康检查，帮助管理员验证他们正在安装的服务器是否正常运行，再对外服务 在cookie上设置最大空闲时间（maximum idle time）和持续时间（duration）的机制可确保在永不关闭的设备（智能手机，电视，家用电器）上顺利停止粘性，而无需将其存储在持久存储上 多个服务器条目可以共享相同的粘性键，以便在一个路径发生故障时多路径环境中不会丢失粘性 软停止（soft-stop）确保只有具有粘性信息的用户才能继续访问他们已被分配到的服务器，但新用户不能被分配到那些服务器 采样与转换信息HAProxy支持使用大量“采样函数”进行信息采样。 原则是提取称为样本的信息，以便立即使用。 这用于粘性，构建条件，在日志中生成信息或丰富HTTP头。 可以从各种来源获取样本： 常量：整数，字符串，IP地址，二进制块 进程：日期，环境变量，服务器/前端/后端/进程状态，字节/连接计数/速率，队列长度，随机生成器，… 变量：每个会话，每个请求，每个响应变量 客户端连接：源和目标地址和端口，以及所有相关的统计计数器 SSL客户端会话：协议，版本，算法，密码，密钥大小，会话ID，所有客户端和服务器证书字段，证书序列，SNI，ALPN，NPN，某些扩展的客户端支持 请求和响应缓冲区内容：偏移/长度的任意有效载荷，数据长度，RDP cookie，SSL hello类型的解码，TLS SNI的解码 HTTP（请求和响应）：方法，URI，路径，查询字符串参数，状态代码，报头值，位置报头值，cookie，捕获，身份验证，正文元素 然后，样本可以通过许多称为“转换器”的运算符来实现一些转换。 转换器消耗样本并生成新样本，可能是完全不同的类型。 例如，转换器可以用于仅返回输入字符串的整数长度，或者可以将字符串转换为大写。 在最终使用之前，可以将任意数量的转换器串联应用于样品。 在所有可用的样本转换器中，以下是最常用的： 算术和逻辑运算符：它们可以对输入数据执行高级计算，例如计算比率，百分比或简单地从一个单元转换为另一个单元 当某些地址需要通过较大的网络进行分组时，IP地址掩码非常有用 数据表示：URL解码，base64，十六进制，JSON字符串，散列 字符串转换：提取固定位置的子串，固定长度，提取某些分隔符周围的特定字段，提取某些单词，更改大小写，应用基于正则表达式的替换 日期转换：转换为HTTP日期格式，将本地转换为UTC，反之，添加或删除偏移量 查找绑定表（stick table）中的条目以查找统计信息或分配的服务器 通过文件（主要用于定位）的基于映射的键值转换 映射映射是一种强大的转换器类型，包括在引导时将两列文件加载到内存中，然后查找第一列中的每个输入样本，并在找到条目时返回第二列上的相应模式，或者返回默认值。 输出信息也是一个样本，它可以反过来进行其他转换，包括其他映射查找。 映射最常用于将客户端的IP地址转换为AS号或国家/地区代码，因为它们支持网络地址的最长匹配，但它们还可用于各种其他目的。它们的部分优势来自于可以通过CLI或使用其他样本的某些操作进行快速更新，使它们能够在后续访问到来前完成存储和检索信息。 另一个优势来自基于二叉树的索引，即使它们包含数十万个条目，它们也非常快，使得位置定位非常方便且易于设置。 ACLS和条件HAProxy中的大多数操作都可以是有条件的。 通过使用逻辑运算符（AND，OR，NOT）组合多个ACL来构建条件。 每个ACL都是基于以下元素的一系列测试： 用于检索要测试的元素的示例获取方法 一系列可选的转换元件 要匹配的模式列表 一种匹配方法，用于指示如何将模式与样本进行比较 例如，可以从HTTP“主机”头部获取样本，然后可以将其转换为小写，然后使用正则表达式匹配方法与多个正则表达式模式进行匹配。 从技术上讲，ACL与映射构建在同一个核心上，它们共享完全相同的内部结构，模式匹配方法和性能。 唯一真正的区别是，ACL只返回“找到”或“未找到”，而不是返回样本。 在使用方面，ACL模式可以在配置文件中内联声明，并且不需要自己的文件。 可以命名ACL以便于使用或使配置易于理解。 命名ACL可以多次声明，它将依次评估所有定义，直到匹配为止。 提供了大约13种不同的模式匹配方法，其中包括IP地址掩码，整数范围，子串，正则表达式。 它们像函数一样工作，就像使用任何编程语言一样，只评估所需的内容，因此当涉及OR的条件已经为真时，不会评估下一个条件，并且当涉及AND的条件已经为假时，其余的条件则无需评估。 声明的ACL的数量没有实际限制，并且提供了少数常用的ACL。 但是经验表明，使用大量命名ACL的设置很难排除故障，并且有时使用内联匿名ACL更容易，因为它需要更少的分析范围之外的引用。 内容转换HAProxy实现了一种称为基于内容的转换机制。 原则是连接或请求到达前端，然后处理此请求或连接携带的信息，此时可以编写基于ACL的条件，利用这些信息来决定哪些后端处理请求。 因此，根据请求的内容将流量引导到一个后端或其他后端。 最常见的示例包括使用路径中的Host头和 / 或元素（子目录或文件扩展名）来确定HTTP请求是针对静态对象还是应用程序，以及将静态对象流量路由到后端快速轻量的服务器，以及所有剩余流量路由到更复杂的应用服务器，从而构成了一个细粒度的虚拟主机解决方案。 这可以方便地使多种技术作为更全面的解决方案共存。 内容交换的另一个用例包括根据各种标准使用不同的负载均衡算法。 缓存可以使用URI哈希，而应用程序将使用循环法（round-robin）。 最后，它允许多个客户通过强制执行每个后端（因此按客户连接限制）来使用一小部分公共资源。 内容转换规则可以很好地扩展，但其性能可能取决于所使用的ACL的数量和复杂性。 但是，也可以编写动态内容转换规则，其中样本值直接变为后端名称，而根本不使用ACL。 据报道，这种配置在生产中至少有300000个后端工作正常。 绑定表绑定表（stick table）通常用于存储粘性信息，即保持对某个访问者所指向的服务器的引用。 然后，密钥是与访问者关联的标识符（其源地址，连接的SSL ID，HTTP或RDP cookie，从URL或有效负载中提取的客户编号，…），然后存储的值为服务器的标识符。 绑定表可以使用3种不同类型的样本作为其键：整数，字符串和地址。 代理中只能引用一个绑定表，并且在任何地方都使用代理名称指定它。 最多可以并行跟踪8个键。 一旦密钥和服务器都已知，就在请求或响应处理期间提交服务器标识符。 绑定表内容可以在主主（active-active）模式下与其他HAProxy节点（称为“对等节点（peer）”）以及重新加载操作期间的新进程一起复制，以便如果客户机的请求分布在多个节点上，则所有负载均衡节点共享相同的信息并做出相同的路由决策。 由于绑定表是基于允许识别客户端的索引，因此它们通常还用于存储额外信息，例如每个客户端的统计信息。 额外的统计信息需要一些额外的空间，需要明确声明。 可以存储的统计类型包括输入和输出带宽，并发连接数，一段时间内的连接速率和计数，错误的数量和频率，一些特定的标签和计数器等。为了支持保持这些信息在不被强制绑定到给定服务器，它实现了一个特殊的“跟踪”特性，允许同时跟踪来自不同表的3个键，而不考虑粘性规则。 可以从CLI搜索，转储和清除每个存储的统计信息，并添加到实时故障排除功能。 虽然这种机制可以用来代表返回的访问者或根据好的或坏的行为来调整提供的服务质量，但它主要用于对抗服务滥用（service abuse），更常见的是DDoS，因为它允许构建复杂的模型，以高处理速度检测某些不良行为。 格式化字符串HAProxy需要处理字符串的许多地方，例如日志，重定向，添加报头等。 为了提供最大的灵活性，引入了格式化字符串的概念，最初用于记录目的，这解释了为什么它仍称为“日志格式”。 这些字符串包含转义字符，允许将各种动态数据（包括变量和样本提取表达式）引入字符串，甚至在结果转换为字符串时调整编码（例如，添加引号）。 这提供了一种构建报头内容或自定义日志行的强大方法。 此外，为了保持构建大多数常见字符串的简单性，提供了大约50个特殊标记作为日志中常用信息的捷径。 HTTP重写与重定向如果没有合适的工具，在从未为此设计的应用程序前面安装负载均衡器可能是一项具有挑战性的任务。 在这种情况下，最常请求的操作之一是调整请求和响应头，以使负载均衡器显示为源服务器并修复硬编码信息。 这需要更改请求中的路径（强烈建议不要这样做），修改主机头字段，修改重定向的位置响应头字段，修改cookie的路径和域属性等。 还有一些服务器有些冗长，往往会在响应中泄漏太多信息，使它们更容易受到针对性攻击。 虽然理论上讲负载均衡器并不能解决这个问题，但实际上它位于基础设施中最好的位置，以保证一切都被清理干净。 同样，有时负载均衡器必须拦截某些请求，并通过重定向到新的目标URL进行响应。 虽然有些人往往混淆重定向和重写，但这些是两个完全不同的概念，因为重写使客户端和服务器看到不同的东西（并且访问页面的位置不一致），而重定向则要求客户端访问新的URL，以便它看到与服务器相同的位置。 为此，HAProxy支持各种重写和重定向的可能性，其中包括： 请求和响应中基于正则表达式的URL和报头重写。 正则表达式是最常用的修改报头值的工具，因为它们易于操作和易于理解 也可以根据格式化字符串附加，删除或替换报头，以便传递信息（例如客户端TLS算法和密码） HTTP重定向可以使任何3xx代码重定向到相对，绝对或完全动态（格式化的字符串）的URI HTTP重定向还支持一些额外的选项，例如设置或清除特定cookie，删除查询字符串，如果缺少则附加斜杠等 所有操作都支持基于ACL的条件 服务器保护HAProxy可以最大限度地提高服务可用性，为此，需要付出巨大努力来保护服务器免受过载和攻击。 第一个也是最重要的一点是，只有完整有效的请求才会被转发到服务器， 最初的原因是HAProxy需要找到它与字节流保持同步所需的协议元素，第二个原因是在请求完成之前，无法知道某些元素是否会改变其语义。 这样做的直接好处是服务器不会暴露于无效或不完整的请求。 这是一种非常有效的防止慢速逃逸攻击（slowloris attacks）的保护措施，对HAProxy几乎没有任何影响。 另一个重要的点是，HAProxy包含用于存储请求和响应的缓冲区，并且仅在服务器完成时向服务器发送请求，并通过从本地网络快速读取整个响应，服务器端的连接只在短时间内被使用，这将尽可能地保留服务器资源。 对此的直接扩展是HAProxy可以人为地限制并发连接的数量或服务器未完成的请求，这保证了服务器永远不会过载，即使它在流量高峰期间不断以100％的容量运行。当一个插槽被释放时，所有多余的请求将被排队等待处理。 最后，这种巨大的资源节省通常可以确保更好的服务器响应时间，最终实际上比通过重载服务器更快。排队的请求可能被重新分配到其他服务器，甚至在客户端中止时在队列中中止，这也保护服务器免受“重新加载效应（reload effect）”的影响，即访问者在缓慢加载的页面上每次点击“重新加载”通常会导致新请求，使服务器维持在过载状态。 慢启动机制还可以在服务器仍在完成启动或编译某些类时保护服务器不受高流量水平的影响。 关于协议级保护，可以放宽HTTP解析器以接受非标准兼容但无害的请求或响应，甚至修复它们。这允许在开发修复程序时访问伪造应用程序。 同时，使用详细报告完全捕获有问题的消息，该报告可帮助开发人员发现应用程序中的问题。最危险的协议违规会被正确检测和处理并修复。 例如，如果值完全相同，则具有两个Content-length头的格式错误的请求或响应将被修复，或者如果它们不同则被拒绝，因为它会成为安全问题。 协议检查不仅限于HTTP，它也可用于其他协议，如TLS或RDP。 当检测到协议违规或攻击时，有多种选项可以响应用户，例如返回常见的“HTTP 400 bad request”，使用TCP重置关闭连接，或者在长时间延迟后伪造错误（“tarpit”）迷惑攻击者。 所有这些都有助于通过阻止违规客户端进行维护成本非常高的攻击来保护服务器。 HAProxy还提出了一些更高级的选项来防止意外数据泄漏和会话交叉（session crossing）。 它不仅可以记录可疑的服务器响应，还会记录并可选地阻止可能影响指定访问者机密性的响应。 一个这样的示例，可缓存的响应出现在可缓存的cookie中，可以导致中间缓存将其传递给另一个访问者，从而导致意外的会话共享。 日志对于负载均衡器来说，日志记录是一个非常重要的功能，首先是因为负载均衡器经常被错误地指责导致了它显现的问题，其次是因为它被放置在需要分析所有正常和异常活动的基础设施中的关键点并与其他组件相关联。 HAProxy提供非常详细的日志，具有毫秒精度，和可在防火墙日志中搜索的确切连接接受时间（例如，用于NAT关联）。 默认情况下，TCP和HTTP日志非常详细，包含故障排除所需的所有内容，例如源IP地址和端口，前端，后端，服务器，计时器（请求接收持续时间，队列持续时间，连接建立时间，响应报头时间，数据传输时间），全局进程状态，连接计数，队列状态，重试次数，详细的粘性操作和断开连接原因，带有安全输出编码的报头捕获（header captures）。然后可以扩展或替换此格式以包括任何采样数据，变量，捕获，从而产生非常详细的信息。 例如，可以记录客户端访问的累积请求数或不同URL。 可以使用标准ACL根据请求调整日志级别，因此可以自动静默一些脏日志，不会在一小部分流量发生某些异常行为时引发警告（例如，过多的URL或一个源地址的HTTP错误）。 管理日志也以其自己的级别发出，以通知服务器的丢失或恢复。 每个前端和后端可以使用多个独立的日志输出，这可以简化多租户。 日志优选地通过UDP发送，可能是JSON编码的，并且在可配置的线长度（line length）之后被截断以便保证传送。 统计HAProxy提供基于Web的统计报告界面，其中包含身份验证，安全级别和范围。 因此，可以为每个托管客户（hosted customer）提供他自己的页面，仅显示他自己的实例。 此页面可以位于常规网站的隐藏URL部分，因此不需要打开新端口。 此页面还可以报告其他HAProxy节点的可用性，以便一眼就能看出是否一切正常。 视图是合成的，可以访问许多详细信息（例如错误原因，上次访问和上次更改持续时间等），这些也可以作为CSV表访问，其他工具可以导入以绘制图形。 该页面可以自刷新以用作大显示器上的监视页面。 在管理模式下，该页面还允许更改服务器状态以简化维护操作。 高级功能管理HAProxy旨在在常规生产环境中保持极其稳定和安全的管理。它是作为一个单独的可执行文件提供的，不需要任何安装过程。 多个版本可以轻松共存，这意味着可以（并推荐）按重要性顺序逐步升级实例，而不是一次性迁移所有实例。配置文件很容易进行版本控制。配置检查是离线完成的，因此不需要重新启动可能失败的服务。在配置检查期间，可以检测到许多高级错误（例如隐藏另一个错误的规则，或者不起作用的粘性），并且提出详细的警告和配置提示来修复它们。向后配置文件的兼容性非常及时，版本1.5仍然完全支持13年前编写的1.1版本的配置，而1.6仅删除对几乎未使用的过时关键字的支持，这些关键字可以采用不同的方式。配置和软件升级机制平稳且无中断，因为它允许新旧进程在系统上共存，每个进程都处理自己的连接。 启动时会报告系统状态，构建选项和库兼容性。 一些高级功能允许应用程序管理员顺利停止服务器，检测服务器上何时没有活动，然后将其脱机，停止，升级并确保在升级时不会占用任何流量，然后再次通过正常路径对其进行测试并且不向外部开放服务，所有这一切都没有触及HAProxy。 这确保了在开放时间内可以利用所有可用的技术资源进行复杂的生产操作。 进程试图尽可能地节约资源，使用内存池来节省分配时间并限制内存碎片，一旦发送内容就释放有效负载缓冲区，并支持强制执行强内存限制，超过该限制，连接必须等待缓冲区变为可用，而不是分配更多内存。 该系统有助于保证在某些严格的环境中使用内存。 命令行界面（CLI）可用作UNIX或TCP套接字，以执行许多操作并检索故障排除信息。 在此套接字上完成的所有操作都不需要更改配置，因此它主要用于临时更改。 使用此接口可以更改服务器的地址、权重和状态，查询统计信息和清除计数器，转储和清除粘性表，可能有选择的关键标准，转储和终止客户端和服务器端连接，转储捕获的错误，详细分析错误的确切原因和位置，转储、添加和删除ACL和映射中的条目，更新TLS共享密钥，立即将连接限制和速率限制应用于任意前端（在共享托管环境中很有用），并禁用特定前端以释放监听端口（在禁止白天操作且仍需要修复时非常有用）。 对于必须使用SNMP的环境，至少存在两个代理，一个代理随HAProxy源提供，并依赖于Net-SNMP Perl模块。 另一个是商业包提供的，不需要Perl。 两者在覆盖范围方面大致相同。 通常建议在部署HAProxy的机器上安装4个实用程序： socat（为了连接到CLI，虽然netcat的某些分支也可以在一定程度上做到这一点） 来自最新HAProxy版本的halog：这是日志分析工具，它可以非常快速地解析本机TCP和HTTP日志（每秒1到2GB）并提取有用的信息和统计信息，例如每个URL的请求，每个源地址，已根据响应时间或错误率排序的URL ，终止代码等。它是为了在生产服务器上部署帮助解决问题，所以必须准备使用 tcpdump：强烈建议您使用所需的网络跟踪来解决日志中可见的问题。 有一段时间，应用程序和haproxy的分析会发生分歧，网络跟踪是判断谁对谁错的唯一方法。 由于tcpdump，在网络堆栈和管理程序中检测bug也相当常见。 strace：这是tcpdump的附件。 它将报告HAProxy真正看到的内容，并将帮助从HAProxy负责的问题中找出操作系统负责的问题。 当怀疑HAProxy中存在错误时，通常会要求Strace 系统特定功能根据部署的HAProxy操作系统，可能会提供或需要某些额外功能。 虽然它在许多平台上都受支持，但HAProxy主要是在Linux上开发的，这解释了为什么某些功能仅在此平台上可用。 透明绑定和连接功能，对绑定连接到特定网络接口的支持，以及将多个进程绑定到相同IP地址和端口的功能仅在Linux和BSD系统上可用，虽然只有Linux对可用进程之间的传入请求执行内核端负载均衡。 在Linux上，还有许多额外的功能和优化，包括支持网络命名空间（也称为“容器”），允许HAProxy成为所有容器之间的网关，能够在客户端连接上设置MSS，Netfilter标记和IP TOS字段，在监听端支持TCP FastOpen，TCP用户超时（user timeouts）让内核在检测到客户端在配置的超时时间之前消失时快速终止连接，TCP拼接（splicing）让内核在连接的两端之间转发数据，从而避免多个内存副本，启用“defer-accept”绑定选项的能力只有在内核缓冲区中数据可用时才会收到传入连接的通知，并且能够通过ACK确认连接发送请求（有时称为“背驮式（piggy-back）”），通过使用“tcp-smart-connect”选项启用。 在Linux上，HAProxy还非常注意操纵TCP延迟的ACK，以便在网络上保存尽可能多的数据包。 有些系统有一个不可靠的时钟，它在过去和将来会来回跳跃。这种情况曾经发生在一些NUMA系统中，其中多个处理器没有观察到完全相同的时间，并且最近它在虚拟化环境中变得更加普遍，其中虚拟时钟与真实时钟无关，导致巨大的时间跳跃（有时已观察到长达30秒）。这通常会导致很多关于超时执行的麻烦。 由于这些系统的缺陷，HAProxy保持其自己的单调时钟，该时钟基于系统的时钟，但是会测量和补偿时钟漂移。这确保即使系统时钟非常糟糕，定时器仍然保持相当准确，并且超时也可以继续工作。 请注意，此问题会影响在此类系统上运行的所有软件，并非特定于HAProxy。常见的影响是虚假超时（spurious timeouts）或应用冻结（application freezes）。 因此，如果在系统上检测到此行为，则必须修复此行为，而不管HAProxy是否保护自己不受其影响。 脚本HAProxy可以构建为支持Lua嵌入式语言，以实现请求或响应的复杂操作，路由决策，统计处理等相关的广泛的新功能。 使用Lua甚至可以与其他服务器建立并行连接以交换信息。 这样，例如使开发认证系统变得可能（尽管很复杂）。 有关如何使用Lua的更多信息，请参阅文档“doc/lua-api/index.rst”。 调优典型的CPU使用率数据显示，在TCP或HTTP关闭模式下，HAProxy中花费的处理时间占15％，而在内核占85％，在HTTP keep-alive模式下，HAProxy约占30％，而内核占70％。 这意味着操作系统及其调优对全局性能有很大影响。 用户之间的用途差异很大，一些用于带宽，另一些用于请求率，其他用于连接并发或用于SSL性能。 本节旨在提供一些帮助完成此任务的要素。 重要的是要记住，每个操作都带有开销，因此每个单独的操作都会增加其他操作的开销，这在某些情况下可以忽略不计，并且在其他情况下可能占主导地位。 在处理来自连接的请求时，我们可以这样说： 转发数据的开销低于解析请求或响应报头 解析请求或响应头的成本低于建立然后关闭与服务器的连接 建立关闭连接开销低于TLS恢复操作 TLS恢复操作的成本低于完整的需要密钥计算的TLS握手 空闲连接比缓冲区保存数据的连接消耗更少的CPU资源 TLS上下文比与数据连接的内存开销更高 因此在实践中，处理有效负载字节比头字节开销更少，因此使用大对象（每个卷单元的请求很少）比使用小对象（每个卷单元的请求很多）更容易实现高网络带宽。 这解释了为什么始终使用大对象测量最大带宽，而使用小对象测量请求率或连接速率。 某些操作可以在分布在多个CPU上的多个进程中很好地扩展，而其他操作不能扩展。网络带宽不会扩展到很远，因为CPU资源不足是大对象的瓶颈，到达网络接口的主要是网络带宽和数据总线。由于在处理本地端口表时系统中有一些锁，所以连接速率在多个处理器上不能很好地扩展。持久连接上的请求速率伸缩性非常好，因为它不涉及太多内存和网络带宽，也不需要访问锁定结构。TLS密钥计算非常好，因为它完全受CPU限制。TLS恢复规模适度，但在大约4个进程时达到其极限，其中访问共享表的开销抵消了从更大的功耗中获得的小收益。 人们可以从一个非常好的调优系统中得到的性能数字在以下范围内。重要的是将它们作为数量级，并根据处理器、IRQ设置、内存类型、网络接口类型、操作系统调优等预期任何方向都会发生显着变化。 在运行3.7 GHz的Core i7上发现了以下数字，配备了运行Linux内核3.10，HAProxy 1.6和OpenSSL 1.0.2的双端口10 Gbps网卡。 HAProxy在单个专用CPU内核上作为单个进程运行，另外两个内核专用于网络中断： 对于256kB或更高的对象，明文的20Gbps最大网络带宽；对于41kB或更高的对象，为10Gbps 使用带有大型对象的AES256-GCM密码的4.6 Gbps TLS流量 从客户端到服务器每秒83000个TCP连接 从客户端到服务器每秒82000个HTTP连接 服务器关闭（server-close）模式下每秒97000个HTTP请求（与客户端保持活跃状态，与服务器关闭） 端到端保持（end-to-end keep-alive）模式下每秒243000个HTTP请求 每秒300000个过滤的TCP连接（反DDoS） 在持久TLS连接上的keep-alive模式下每秒160000个HTTPS请求 使用TLS恢复连接，每秒13100个HTTPS请求 使用与RSA2048重新协商的TLS连接，每秒1300个HTTPS连接 每GB内存 20000个并发饱和连接，包括系统缓冲区所需的内存，通过仔细调整可以做得更好，但这很容易实现。 每GB内存大约8000个并发TLS连接（仅客户端），包括系统缓冲区所需的内存 每GB 内存大约5000个并发端到端TLS连接（双方），包括系统缓冲区所需的内存 因此，要记住的一个好的经验法则是请求率是TLS保持活动和TLS恢复之间数除以10，或TLS恢复和TLS重新协商之间的数除以10，或HTTP keepalive和HTTP close之间的值除以3。 另一个是，带有AES指令的高频核心可以为每个核心提供大约5 Gbps的AES-GCM。 拥有更多内核并不会有用（TLS除外），并且由于频率较低而甚至会适得其反。 通常，少量但高频的核心更好。 另一个好的经验法则是考虑在同一台服务器上，HAProxy将能够饱和： 大约5-10个静态文件服务器或缓存代理 约100个反病毒代理 大约100-1000个应用服务器，取决于所使用的技术 配套产品及替代产品HAProxy与下面列出的某些产品集成得相当好，这就是为什么在这里提到它们，即使它们与HAProxy没有直接关系。 ApacheApache是一个实际的标准HTTP服务器。 这是一个非常完整的模块化项目，支持文件服务和动态内容。 它可以作为某些应用程序服务器的前端， 甚至可以代理请求和缓存响应。 在所有这些使用案例中，通常需要前负载均衡器。 Apache可以在各种模式下工作，有些模式比其他模式更繁重。 某些模块仍然需要较繁重的预分叉（pre-forked）模型，并且会阻止Apache通过大量连接进行良好的扩展。 在这种情况下，HAProxy可以通过将每个服务器的连接限制强制设置为一个安全值来提供极大的帮助，并且可以显著提高服务器的速度，并保存应用程序可以更好地使用的资源。 Apache可以使用“mod_rpaf”扩展名从X-Forwarded-For报头中提取客户端的地址。 当在其配置中指定“option forwardfor”时，HAProxy将自动提供此报头。 当暴露于互联网时，HAProxy也可以为Apache提供良好的保护，它可以更好地抵御各种类型的DoS攻击。 NginxNGINX是第二个实际的标准HTTP服务器。 就像Apache一样，它涵盖了广泛的功能。 NGINX建立在与HAProxy类似的模型上，因此处理数以万计的并发连接没有问题。 当用作某些应用程序的网关时（例如使用内含的PHP FPM），设置一些前端连接限制以减少PHP应用程序的负载通常是有益的。 HAProxy作为常规负载均衡器和流量调节器显然都非常有用，可以通过解除拥塞来加速PHP。 此外，由于它们的事件驱动架构，两种产品都使用非常少的CPU，因此通常很容易在同一系统上安装它们。 NGINX实现了HAProxy的PROXY协议，因此HAProxy能很容易地将客户端的连接信息传递给NGINX，以便应用程序获取所有相关信息。 一些基准测试还表明，对于大型静态文件服务，在NGINX前面的HAProxy上实现一致的哈希可以通过优化操作系统的缓存命中率(基本上是乘服务器节点的数量)来实现。 VarnishVarnish是一种智能缓存反向代理，可能最好的描述是Web应用程序加速器。 Varnish没有实现SSL/TLS，并希望将其所有CPU周期专用于最佳功能。 Varnish还实现了HAProxy的PROXY协议，因此HAProxy可以很容易地作为SSL卸载程序和负载均衡器部署在Varnish前面，并将所有相关的客户端信息传递给它。此外，当服务器提供压缩对象时，Varnish自然支持从缓存中解压缩，但是不会压缩。 然后，当后端服务器不实现压缩时，可以使用HAProxy压缩传出数据，除非流量较小，否则在负载均衡器上压缩并不是一个好主意。 在跨多个节点构建大型缓存集群时，HAProxy可以使用一致的URL哈希来智能地将负载分配给缓存节点，避免缓存重复，从而得到一个总缓存大小，即所有缓存节点的总和。 替代产品Linux虚拟服务器（LVS或IPVS）是Linux内核中包含的第4层负载均衡器。 它在数据包级别工作并处理TCP和UDP。 在大多数情况下，它更多的是补充而不是替代，因为它根本没有第7层知识。 Pound是另一个著名的负载均衡器。它比HAProxy简单得多，功能也少得多，但对于许多非常基本的设置，都可以使用这两种方法。它的作者总是首先关注代码的可审计性，并希望保持少量的特性。它的基于线程的体系结构在连接计数高的情况下伸缩性较差，但它是一个很好的产品。 Pen是一款非常轻的负载均衡器。它支持SSL，使用客户机IP地址的固定大小表维护持久性。它支持面向包的模式，允许它在一定程度上支持直接服务器返回和UDP。它适用于小负载（持久性表只有2048个条目）。 NGINX可以在某种程度上进行一些负载均衡，尽管它显然不是它的主要功能。 生产流量用于检测服务器故障，负载均衡算法更受限制，并且粘性非常有限。 但是在它已经存在的一些简单部署场景中它是有意义的。 好处是，由于它与HAProxy的集成非常好，因此在达到其限制后添加HAProxy没有任何问题。 Varnish还对其后台服务器进行了一些负载均衡，并支持真正的健康检查。但是它并没有实现粘性，所以就像NGINX一样，只要不需要粘性，这就足够了。同样，由于HAProxy和Varnish集成得非常好，所以很容易在以后将其混用以补充功能集。]]></content>
      <tags>
        <tag>HAProxy</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Linux-HA User's Guide翻译]]></title>
    <url>%2F2018%2F11%2F27%2FThe-Linux-HA-User-s-Guide%E7%BF%BB%E8%AF%91%2F</url>
    <content type="text"><![CDATA[翻译自The Linux-HA User’s Guide 只翻译了有用部分，未翻译获取帮助部分。不确定的地方会保留原文，且并非完全参照原文，会有改动。 前言 Heartbeat介绍 Heartbeat作为集群信息层 组件 通讯模块 集群共识成员资格 集群管道库 IPC库 非阻塞日志守护进程 安装Heartbeat 源码构建安装 源码构建安装Cluster Glue Cluster Glue构建的先决条件 下载Cluster Glue源码 构建Cluster Glue 构建包 源码构建安装Heartbeat Heartbeat构建的先决条件 下载Heartbeat源码 构建Heartbeat 构建包 安装预建包 Debian与Ubuntu Fedora，RHEL与CentOS OpenSUSE与SLES 管理任务 创建初始Heartbeat配置 ha.cf文件 authkeys文件 将群集配置传播到群集节点 启动Heartbeat服务 Heartbeat的更多搭配 升级Heartbeat版本 不使用CRM从Heartbeat2.1版本升级 停止Heartbeat服务 升级软件 使能Heartbeat集群使用Pacemaker 重启Heartbeat 从开启了CRM的Heartbeat2.1集群升级 将集群放置在非托管模式 备份CIB 停止Heartbeat服务 删除CRM的相关文件 重置CIB 升级软件 重启Heartbeat服务 将集群再置为托管模式 升级CIB架构 前言本指南旨在成为Heartbeat集群消息传递层（messaging layer）、Linux-HA集群资源代理（resource agents）以及Linux-HA项目维护的其他集群构建块的用户的权威参考指南。 Heartbeat介绍Heartbeat作为集群信息层Heartbeat是一个守护程序，为其客户端提供集群基础结构（通信和成员资格）服务。这允许客户端了解其他计算机上对等（peer）进程的存在（或消失），并轻松地与它们交换消息。 为了对用户有用，Heartbeat守护程序需要与集群资源管理器（CRM）结合使用，该集群资源管理器的任务是启动和停止集群中将要配置高可用的服务（IP地址，Web服务器等）。通常与Heartbeat关联的规范集群资源管理器是Pacemaker，这是一种高度可扩展且功能丰富的实现，支持Heartbeat和Corosync集群消息传递层。 直到Heartbeat发布2.1.3版本，Pacemaker与Heartbeat共同开发，作为Linux-HA总体项目的一部分。在此版本发布之后，Pacemaker项目作为一个单独的项目分离出来并继续开发，同时保持对Heartbeat集群消息传递的完全支持。 组件通信模块Heartbeat通信模块能基本上在任何媒介（无论是否基于IP）上提供强认证的、本地有序的多播消息传递功能。 Heartbeat支持通过以下网络类型进行群集通信： 单播UDP over IPv4 广播UDP over IPv4 多播UDP over IPv4 串行链路通信 请考虑一些关于串行链路连接的重要注意事项（参见ha.cf手册页，man ha.cf）。作为一般规则：如有疑问，应避免串行链接。 Heartbeat可以在不到半秒的时间内可靠地检测到节点故障。如果配置为执行此操作，它将向系统监视程序计时器（watchdog timer）注册。 心跳层（heartbeat layer）有一个API，提供以下服务类： 集群内通信 - 向集群节点发送和接收数据包 配置查询 连接信息（当前节点可以监听数据包的人） - 用于查询和状态更改通知 基本的团体成员（group membership）服务 集群共识成员资格CCM（Cluster Consensus Membership集群共识成员资格）提供强大连接的集群共识成员资格服务。它确保计算成员资格中的每个节点都可以与具有相同成员资格的其他任意节点进行通信。 CCM实现OCF（Open Connectivity Foundation开放连接基金会）的draft membership API和SAF AIS membership API。通常，它会在亚秒级时间内计算成员资格。 集群管道库集群管道库（Cluster Plumbing Library）是一组非常有用的函数，它们提供了许多主要组件使用的各种服务。该库提供的一些主要对象包括： 压缩API（带有底层压缩插件） 非阻塞日志记录API 面向持续运行服务的内存管理 分层名称 - 值对消息传递工具，提升可移植性和版本升级兼容性（还提供可选的消息压缩功能） 信号统一（Signal Unification） - 允许信号显示为主循环事件（mainloop events） 核心备份（core dump）管理实体 - 在所有情况下以统一的方式促进核心备份的完成 定时器（类似glib mainloop定时器 - 但它们即使在时钟跳转时也可以工作） 子进程管理 - 子进程的死亡导致进程对象的调用，具有可配置的死亡子进程（death-of-child）消息 触发器（由软件触发的任意事件） 实时管理 - 设置和取消设置高优先级，并锁定到进程的内存属性 64位HZ粒度（64-bit HZ-granularity）时间操作（longclock_t） 出于安全目的的用户标识管理，用于一些需要root权限的进程 IPC、普通文件描述符、信号等的mainloop集成。这意味着所有这些不同的事件源都被一致地管理和分配 IPC库所有进程间通信都使用非常通用的IPC库执行，该库使用灵活的队列策略提供对IPC的非阻塞访问，并包括集成流控制。此IPC API不需要套接字，但当前可用的实现使用了UNIX（本地）域套接字。 此API还包括内置的对等进程身份验证和授权，并且可以移植到大多数类似POSIX的操作系统。虽然不需要在这些API中使用Glib主循环（mainloop），但Heartbeat提供了与mainloop的简单方便的集成。 非阻塞日志守护进程logd是Heartbeat的日志记录守护程序，能够记录到syslog守护程序、文件或两者。 logd永远不会阻塞，相反，它会删除时间过久的消息。 一旦它能够再次输出消息，logd就会打印删除的消息计数。队列大小可以在整体上进行控制，也可以在每个应用程序上进行控制。 安装Heartbeat源码构建安装构建和安装Heartbeat集群消息传递层以需要构建以下包： heartbeat 包含Heartbeat本地资源管理器（LRM）和STONITH插件的cluster-glue包 由于Heartbeat对cluster-glue具有构建依赖性，因此在构建和安装heartbeat之前，必须先构建和安装cluster-glue。 源码构建安装Cluster GlueCluster Glue构建的先决条件构建Cluster Glue需要在构建系统上存在以下工具和库： C编译器（通常是gcc）和相关的C开发库 flex扫描器生成器和bison解析编译器 net-snmp开发库，用于启用SNMP相关功能 OpenIPMI开发库，用于启用IPMI相关功能 Python 此列表适用于默认软件配置。如果使用非标准选项配置源，则可能适用其他依赖项。 下载Cluster Glue源码有几个选项可用于检索Cluster Glue源代码，以便在目标系统上本地构建。 下载发布的tar包 下载已发布的Heartbeat版本的压缩tar包就相当于从Mercurial源代码存储库中获取标记的快照。发布标签遵循glue-x.y.z格式，其中x.y.z是您要下载的Cluster Glue的发布版本。 例如，如果想要下载1.0.1版本，那么正确的命令是： 12# wget http://hg.linux-ha.org/glue/archive/glue-1.0.1.tar.bz2# tar -vxjf glue-1.0.1.tar.bz2 下载最新的Mercurial快照 最新的开发代码始终在Mercurial存储库中作为最新修订版提供。 要下载自动生成的tarball，请使用以下命令： 12# wget http://hg.linux-ha.org/glue/archive/tip.tar.bz2# tar -vxjf tip.tar.bz2 检查Mercurial源 如果您在本地安装了Mercurial实体程序，则可以使用以下方法。通过克隆检查源码： 12345678$ hg clone http://hg.linux-ha.org/glue cluster-gluerequesting all changesadding changesetsadding manifestsadding file changesadded 12491 changesets with 34830 changes to 2632 filesupdating working directory356 files updated, 0 files merged, 0 files removed, 0 files unresolved 构建Cluster Glue构建Cluster Glue是一个广泛使用GNU Autotools的自动化过程。在同一台机器上构建和安装时，通常只需要以下命令： 1234$ ./autogen.sh$ ./configure$ make$ sudo make install autogen.sh脚本是automake，autoheader，autoconf和libtool的安装脚本 支持许多配置选项，您可以调整其中一些以优化系统的Heartbeat。要检索配置选项列表，可以使用--help选项调用configure。因此，定制构建可以包括以下步骤： 12345$ ./autogen.sh$ ./configure --help$ ./configure configuration-options$ make$ sudo make install 您可能希望设置的一些典型配置选项是--prefix， - -sysconfdir和--localstatedir，如下例所示： 12345$ ./autogen.sh$ ./configure --help$ ./configure --prefix=/usr --sysconfdir=/etc --localstatedir=/var$ make$ sudo make install 构建包RPM包 SuSE和红帽发行版都在CLuster Glue的源码包中提供了RPM规范文件： cluster-glue-suse.spec应该用于OpenSUSE和SLES安装 cluster-glue-fedora.spec适用于Fedora，RHEL和CentOS Debian包 Cluster Glue的Debian包保存在alioth.debian.org上的Mercurial存储库中。因此，不是从上游Mercurial存储库克隆或下载，而是使用在alioth上托管的存储库。 从alioth存储库中解压缩源码包后，只需从源码目录（source tree）的顶部（根目录）调用dpkg-buildpackage - 就像使用任何其他Debian软件包一样。 源码构建安装HeartbeatHeartbeat构建的先决条件构建Heartbeat需要存在以下的工具和库： C编译器（通常是gcc）和相关的C开发库 flex扫描器生成器和bison解析编译器 net-snmp开发库，用于启用SNMP相关功能 OpenIPMI开发库，用于启用IPMI相关功能 Python cluster-glue开发头 下载Heartbeat源码下载发行tar包 下载一个Heartbeat的发行版本的压缩tar包就相当于从Mercurial源代码存储库中获取标记的快照。发布标签遵循STABLE-x.y.z格式，其中x.y.z是您要下载的Heartbeat的发布版本。 例如，如果项下载3.0.4的发布版本，可以执行以下语句： 12# wget http://hg.linux-ha.org/dev/archive/STABLE-3.0.4.tar.bz2# tar -vxjf STABLE-3.0.4.tar.bz2 下载最新Mercurial快照 最新开发代码能在Mercurial库中获取。 从tip自动获取tar包，可执行： 12# wget http://hg.linux-ha.org/dev/archive/tip.tar.bz2# tar -vxjf tip.tar.bz2 检查Mercurial源 如果您在本地安装了Mercurial实体程序，则可以使用以下方法。通过克隆检查源码： 12345678$ hg clone http://hg.linux-ha.org/dev heartbeat-devrequesting all changesadding changesetsadding manifestsadding file changesadded 12491 changesets with 34830 changes to 2632 filesupdating working directory356 files updated, 0 files merged, 0 files removed, 0 files unresolved 构建Heartbeat构建Heartbeat是一个广泛使用GNU Autotools的自动化过程。在同一台机器上构建和安装时，通常只需要以下命令： 1234$ ./bootstrap$ ./configure$ make$ sudo make install 支持大量的配置选项,你可能调整其中的一些优化系统的Heartbeat。检索配置选项的列表,您可以调用配置--help选项。因此,一个定制的构建可能包含以下步骤: 12345$ ./bootstrap$ ./configure --help$ ./configure &lt;configuration-options&gt;$ make$ sudo make install 一些典型的配置选项,您可能希望设置--prefix,--sysconfdir和--localstatedir,如本例所示: 12345$ ./bootstrap$ ./configure --help$ ./configure --prefix=/usr --sysconfdir=/etc --localstatedir=/var$ make$ sudo make install 构建包RPM包 SuSE和红帽发行版都在CLuster Glue的源码包中提供了RPM规范文件： heartbeat-suse.spec应该用于OpenSUSE和SLES安装 heartbeat-fedora.spec适用于Fedora，RHEL和CentOS Debian包 Heartbeat的Debian包保存在alioth.debian.org上的Mercurial存储库中。因此，不是从上游Mercurial存储库克隆或下载，而是使用在alioth上托管的存储库。 从alioth存储库中解压缩源码包后，只需从源码目录（source tree）的顶部（根目录）调用dpkg-buildpackage - 就像使用任何其他Debian软件包一样。 安装预建包Cluster Glue和Heartbeat可在许多平台上作为预构建的二进制包提供，包括： Debian（完全包含在squeeze和向上，后端包可用于lenny） Ubuntu（自lucid） Fedora（自版本12） OpenSUSE（自版本11） 本节介绍在这些平台上安装二进制包所需的步骤。 Debian与Ubuntu在Debian和Ubuntu上安装cluster-glue和heartbeat包是一个简单的过程。 假设您为APT配置了正确的软件包源，请使用以下命令安装这两个软件包： 1aptitude install heartbeat cluster-glue 由于您很可能还希望安装Pacemaker（超出本手册的范围），因此也可以通过发出以下命令来执行此操作： 1aptitude install cluster-agents pacemaker Fedora，RHEL与CentOS在Red Hat平台上，您可以使用YUM包管理器安装cluster-glue和heartbeat包。 假设您在/etc/yum.repos.d/中配置了正确的软件包源，请使用以下命令安装这两个软件包： 1yum install heartbeat cluster-glue 由于您很可能还希望安装Pacemaker（超出本手册的范围），因此也可以通过发出以下命令来执行此操作： 1yum install resource-agents pacemaker OpenSUSE与SLES在SUSE平台上，使用Zypper软件包管理器安装cluster-glue和heartbeat软件包。 假设您已配置正确的软件包存储库，请使用以下命令安装这两个软件包： 1zypper install heartbeat cluster-glue 由于您很可能还希望安装Pacemaker（超出本手册的范围），因此也可以通过发出以下命令来执行此操作： 1zypper install resource-agents pacemaker 管理任务创建初始Heartbeat配置对于任何Heartbeat群集，必须提供以下配置文件： /etc/ha.d/ha.cf：全局群集配置文件 /etc/ha.d/authkeys ：包含用于相互节点身份验证的密钥的文件 ha.cf文件以下示例是一个小而简单的ha.cf文件： 12345678910autojoin nonemcast bond0 239.0.0.43 694 1 0bcast eth2warntime 5deadtime 15initdead 60keepalive 2node alicenode bobpacemaker respawn 将autojoin设置为none将禁用集群节点自动发现，并要求使用节点选项显式列出群集节点。 这加速了具有固定少量节点的集群的启动。 此示例假定bond0是集群与共享网络的接口，并且eth2是专用于两个节点之间的DRBD复制的接口。 因此，bond0可以用于多播心跳，而在eth2广播上是可行的，因为eth2不是共享网络。 下一个选项配置节点故障检测。它们设置的时间是Heartbeat发出警告表示不再可用的对等节点可能已死（warntime），Heartbeat认为节点已确认死亡（deadtime）的时间，以及等待其他节点在集群启动时加入的最长时间（initdead）。keepalive设置发送Heartbeat keep-alive数据包的时间间隔。所有这些选项单位都是秒。 节点选项标识集群成员。此处列出的选项值必须与uname -n给出的集群节点的确切主机名匹配。 pacemaker respawn启用Pacemaker集群管理器，并确保在发生故障时自动重启Pacemaker。 在Heartbeat 3.0.4版之前，pacemaker关键字被命名为crm。 较新版本仍将旧名称保留为兼容性别名，但pacemaker是首选写法。 authkeys文件/etc/ha.d/authkeys包含用于相互集群节点身份验证的预共享机密。 它应该只能由root读取并遵循以下格式： 12auth &lt;num&gt;&lt;num&gt; &lt;algorithm&gt; &lt;secret&gt; num是一个简单的键索引，从1开始。通常，您的authkeys文件中只有一个键。 algorithm是使用的签名算法。 你可以使用md5或sha1; 不推荐使用crc（简单的循环冗余校验，不安全）。 secret是实际的身份验证密钥。 您可以通过以下shell，使用生成的密钥创建一个authkeys文件： 1234( echo -ne &quot;auth 1\n1 sha1 &quot;; \ dd if=/dev/urandom bs=512 count=1 | openssl md5 ) \ &gt; /etc/ha.d/authkeyschmod 0600 /etc/ha.d/authkeys 将群集配置传播到群集节点为了传播ha.cf和authkeys配置文件的内容，您可以使用ha_propagate命令，您可以使用该命令调用 1/usr/lib/heartbeat/ha_propagate 或 1/usr/lib64/heartbeat/ha_propagate 此程序将使用scp将配置文件复制到/etc/ha.d/ha.cf中列出的任何节点。 之后它还将使用ssh连接到节点并发出chkconfig heartbeat on，以便在系统启动时启用Heartbeat服务。 启动Heartbeat服务Heartbeat服务的启动方式与计算机上的任何其他系统服务一样。 您可能正在使用以下命令之一，具体取决于您的系统平台： 12345/etc/init.d/heartbeat startservice heartbeat startrcheartbeat start 通过ha.cf中的pacemaker输入，Heartbeat现在将启动Pacemaker守护程序（由于历史原因而命名为crmd）以及其余服务。 几秒钟后，您应该能够检测进程表中的Heartbeat进程： 123456789101112131415# ps -AHfww | grep heartbeatroot 2772 1639 0 14:27 pts/0 00:00:00 grep heartbeatroot 4175 1 0 Nov08 ? 00:37:57 heartbeat: master control processroot 4224 4175 0 Nov08 ? 00:01:13 heartbeat: FIFO readerroot 4227 4175 0 Nov08 ? 00:01:28 heartbeat: write: bcast eth2root 4228 4175 0 Nov08 ? 00:01:29 heartbeat: read: bcast eth2root 4229 4175 0 Nov08 ? 00:01:35 heartbeat: write: mcast bond0root 4230 4175 0 Nov08 ? 00:01:32 heartbeat: read: mcast bond0102 4233 4175 0 Nov08 ? 00:03:37 /usr/lib/heartbeat/ccm102 4234 4175 0 Nov08 ? 00:15:02 /usr/lib/heartbeat/cibroot 4235 4175 0 Nov08 ? 00:17:14 /usr/lib/heartbeat/lrmd -rroot 4236 4175 0 Nov08 ? 00:02:48 /usr/lib/heartbeat/stonithd102 4237 4175 0 Nov08 ? 00:00:54 /usr/lib/heartbeat/attrd102 4238 4175 0 Nov08 ? 00:08:32 /usr/lib/heartbeat/crmd102 5724 4238 0 Nov08 ? 00:04:47 /usr/lib/heartbeat/pengine 最后，您还应该能够通过Pacemaker的crm_mon命令确认群集正在运行： 1234567891011# crm_mon -1============Last updated: Mon Dec 13 14:29:36 2010Stack: HeartbeatCurrent DC: alice (083146b9-6e26-4ac8-a705-317095d0ba57) - partition with quorumVersion: 1.0.9-74392a28b7f31d7ddc86689598bd23114f58978b2 Nodes configured, unknown expected votes24 Resources configured.============Online: [ alice bob ] Heartbeat的更多搭配现在您已经有了可用的Heartbeat配置，您将需要继续配置Pacemaker并添加群集资源。 以下文件供您阅读： Clusters From Scratch是配置Pacemaker集群的绝佳指南。 该文档主要涵盖了Corosync上的Pacemaker，但从其“使用Pacemaker工具”一章开始，同样适用于Heartbeat集群。 DRBD用户指南有一章专门介绍DRBD与Pacemaker集群的集成。 LINBIT网站提供了几个涵盖各种应用的Heartbeat / Pacemaker集群的技术指南。 升级Heartbeat版本不使用CRM从Heartbeat2.1版本升级对于不使用CRM的Heartbeat 2.1集群（即，使用haresources文件配置的集群），升级到3.0涉及将当前配置转换为适合Pacemaker的配置。 注：此升级过程确实会导致应用程序停机。 但是，在正确规划，测试和执行升级时，此停机时间为几分钟，甚至几秒（取决于配置）。 停止Heartbeat服务您应该在当前备用节点上开始升级过程，即当前未运行任何资源的群集节点。 如果您的群集正在使用主动-主动（active-active）配置（两个节点都在运行资源），请选择其中一个主机，并发出以下命令将所有资源传输到对等节点： 1# hb_standby 然后，仅在该节点上，停止Heartbeat服务： 1# /etc/init.d/heartbeat stop 升级软件在升级时，重要的是要记住单个的Heartbeat 2.1树已经分成模块化部分。 因此，您将用三个独立的软件替换Heartbeat：Cluster Glue，Pacemaker和Heartbeat 3，它只包含群集消息传递层。 从源代码升级：在您安装Heartbeat 2.1的解压缩归档文件中，运行make uninstall。 然后，安装Cluster Glue和Heartbeat。 使用本地构建的软件包升级：手动安装软件包时，首先卸载heartbeat软件包。 然后安装cluster-glue，heartbeat3，resource-agents和pacemaker。 使用软件包存储库升级：使用APT，YUM或Zypper存储库进行升级时，您应该只能运行heartbeat版本3和pacemaker的install命令，并且将自动解析依赖项。 此时不要重新启动Heartbeat服务。 使能Heartbeat集群使用Pacemaker现在必须指示群集消息传递层在群集启动时启动Pacemaker。 为此，请添加： crm respawn到您的ha.cf配置文件。 完成ha.cf修改后，将文件复制到对等节点。 重启Heartbeat您的群集现在可以在启用Pacemaker的模式下重新启动。 为此： 运行/etc/init.d/heartbeat停止在仍处于活动状态的节点上。 这将关闭您的群集资源。 在备用节点（创建CIB的节点）上运行/etc/init.d/heartbeat。 这将启动本地Heartbeat实例和Pacemaker，并等待其他群集节点加入。 在另一个节点上运行/etc/init.d/heartbeat start。 这将启动本地Heartbeat实例和Pacemaker，自动获取CIB并启动应用程序。 从开启了CRM的Heartbeat2.1集群升级本节概述了将启用了内置CRM的Heartbeat 2.1群集升级到带有Pacemaker的Heartbeat 3.0所需的步骤。 注：如果计划和执行得当，升级过程可以在几分钟内完成，无需停机。 强烈建议在尝试生产集群升级之前阅读并理解本节中概述的步骤。必须以root身份运行本节中说明的所有命令。 不要在所有群集节点上并行执行各个步骤。 而是在继续下一个节点之前完成每个节点上的过程。 将集群放置在非托管模式通过此步骤，群集暂时放弃对其资源的控制。 这意味着群集在升级期间不再监视其节点或资源，并且在此期间不会纠正应用程序或节点故障。 但是，当前正在运行的资源将继续运行。 1# crm_attribute -t crm_config -n is_managed_default -v false 在大多数配置中，单个资源不单独设置is_managed属性，因此群集范围的属性is_managed_default适用于所有这些属性。 如果在您的特定配置中您确实拥有设置了此属性的资源，则应将其删除以确保默认值适用： 1# crm_resource -t primitive -r &lt;resource-id&gt; -p is_managed -D 备份CIB此时，保存群集信息库（CIB）的副本非常重要。 要保存的CIB存储在名为cib.xml的文件中，该文件通常位于/var/lib/heartbeat/crm中。 1# cp /var/lib/heartbeat/crm/cib.xml ~ 您只需在当前连接到群集的一个节点上执行此步骤。 不要删除此文件，以后会恢复。 停止Heartbeat服务您现在可以使用/etc/init.d/heartbeat stop或首选命令停止Heartbeat以停止分发上的系统服务（service heartbeat stop，rcheartbeat stop等）。 如果您运行受关闭错误影响的旧版Heartbeat，则优雅关闭crmd将无法在非托管模式下正常运行。 在这种情况下，使用上述命令启动正常服务关闭后，请手动终止crmd进程： 使用ps -AHfww检索crmd的进程ID; 用TERM信号杀死crmd。 删除CRM的相关文件 注：在继续本节之前，请验证是否已在其中一个群集节点上创建了CIB的备份副本 您现在应该从节点擦除本地CRM相关文件。 为此，请从CRM存储CIB信息的目录中删除所有文件，通常为/var/lib/heartbeat/crm。 1# rm /var/lib/heartbeat/crm/* 重置CIB 注：如果Heartbeat仍在所有群集节点上停止，并且所有群集节点都已擦除其CIB内容，则只应执行此步骤。 如果仍有剩余节点具有剩余CIB配置，按“删除CRM的相关文件”中所述进行操作。 恢复CIB意味着将“备份CIB”中描述的CIB备份复制到/var/lib/heartbeat/crm目录。 123# cp ~/cib.xml /var/lib/heartbeat/crm/cib.xml# chown hacluster:haclient /var/lib/heartbeat/crm/cib.xml# chmod 0600 /var/lib/heartbeat/crm/cib.xml 您必须仅在一个节点上执行此步骤，即您要在其上升级群集软件的第一个节点。 在所有其他节点上，/var/lib/heartbeat/crm目录必须保持为空——Pacemaker会自动分发CIB。 升级软件在升级时，重要的是要记住单个的Heartbeat 2.1树已经分成模块化部分。 因此，您将用三个独立的软件替换Heartbeat：Cluster Glue，Pacemaker和Heartbeat 3，它只包含群集消息传递层。 从源代码升级：在您安装Heartbeat 2.1的解压缩归档文件中，运行make uninstall。 然后，安装Cluster Glue和Heartbeat。 使用本地构建的软件包升级：手动安装软件包时，首先卸载heartbeat软件包。 然后安装cluster-glue，heartbeat3的包，resource-agents和pacemaker。 使用软件包存储库升级：使用APT，YUM或Zypper存储库进行升级时，您应该只能运行heartbeat3和pacemaker的install命令，并且将自动解析依赖项。 如果这是集群中要升级的最后一个节点，并且软件包升级后软件包管理系统未重新启动Heartbeat服务，则现在应继续“重新启动Heartbeat服务”。 否则，您应移至下一个节点，然后按“停止Heartbeat服务”和“升级软件”中所述进行操作。 重启Heartbeat服务 注：如果您的软件包管理系统在安装后自动重新启动Heartbeat服务，则可以省略此步骤。 首先，使用/etc/init.d/heartbeat start在恢复CIB的节点上重新启动Heartbeat（请参见“重置CIB”）。 然后，在剩余的群集节点上重复此命令。 此时， 群集仍处于非托管模式（意味着它不会启动，停止或监视任何资源） 集群在其节点之间重新分配旧CIB 群集仍在使用升级前的CIB架构 将集群再置为托管模式升级群集软件后，建议将群集恢复为托管模式： 1# crm_attribute -t crm_config -n is_managed_default -v true 升级CIB架构虽然升级后的集群理论上可以无限期地在升级前的CIB模式上运行，但强烈建议将CIB升级到当前模式。 为此，请在重新建立所有节点之间的集群通信后运行以下命令： 1# cibadmin --upgrade --force]]></content>
      <tags>
        <tag>集群</tag>
        <tag>高可用</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS高可用笔记]]></title>
    <url>%2F2018%2F11%2F27%2FNFS%E9%AB%98%E5%8F%AF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[NFS高可用概述 NFS+Keepalived+DRBD搭建 NFS高可用概述NFS的物理磁盘往往做RAID10或RAID0，再通过DRBD同步NFS，以及设置VIP进行主从热备。若主NFS宕机后，默认情况在几秒内，新的主NFS就可以启动同步程序自动把数据同步到所有从NFS中。 NFS+Keepalived+DRBD搭建实验环境： host1：NFS-Master ens32：192.168.60.134 ens34：192.168.70.128（Heartbeat线网卡） ens35：192.168.80.128（DRBD线网卡） sdb：2G（NFS存数据） host2：NFS-Backup ens32：192.168.60.135 ens34：192.168.70.129（Heartbeat线网卡） ens35：192.168.80.129（DRBD线网卡） sdb：2G（NFS存数据） host3：NFS-Slave ens32：192.168.60.136 首先在host1和host2上安装Cluster Glue，cluster-glue下载 解压后，进入目录，执行autogen.sh，生成configure文件 安装可能需要的依赖： 1yum install -y glib2-devel libxml2-devel bzip2-devel flex-devel bison-devel OpenIPMI-devel net-snmp-devel ipmitool ipmiutil ipmiutil-devel asciidoc 编译安装 12./configure --prefix=/usr/local/glue \ LIBS=&apos;/lib64/libuuid.so.1&apos; # 一定要指定否则会报错 然后make &amp;&amp; make install 下载heartbeat源码包，下载地址，解压进入目录执行./bootstrap生成configure文件，开始构建 12./configure --prefix=/usr/local/heartbeat \ CFLAGS=-l/usr/local/heartbeat/include -L/usr/local/heartbeat/lib 编译安装keepalived。先检查依赖libnl-devel与libnl3-devel 1234./configure --prefix=/usr/local/keepalived \ --bindir=/usr/bin \ --sbindir=/usr/sbin \ --sysconfdir=/etc 首先配置分区一个是400M，用于存放元数据，一个是1.6G，用于存放业务数据。 安装DRBD，可通过yum安装，但要先安装elrepo源，下载地址，安装完成后，查看该repo文件，将enabled设为1。 安装DRBD，先yum search 查看要安装的版本，安装9的版本需要安装drbd90-utils和kmod-drbd90。 导入drbd内核modprobe drbd，再查看lsmod | grep drbd 123# lsmod | grep drbddrbd 541356 0 libcrc32c 12644 2 xfs,drbd drbd模块导入成功。 编辑/etc/drbd.d/nfs.res配置，两台主机上要一致。 123456789101112131415resource data &#123; protocol C; on host1 &#123; device /dev/drbd1; disk /dev/sdb2; address 192.168.80.128:7789; # 心跳线 meta-disk /dev/sdb1[0]; &#125; on host2 &#123; device /dev/drbd1; disk /dev/sdb2; address 192.168.80.129:7789; meta-disk /dev/sdb1[0]; &#125;&#125; 创建drbd磁盘drbdadm create-md data并启动drbdadm up data，两台都要执行。 查看是否正常启动，以下为drbd9的显示，与8版本不同。 1234# cat /proc/drbd version: 9.0.14-1 (api:2/proto:86-113)GIT-hash: 62f906cf44ef02a30ce0c148fec223b40c51c533 build by mockbuild@, 2018-05-04 03:32:42Transports (api:16): tcp (9.0.14-1) 使host1变为角色变为primary。drbdadm primary data --force 在host1上挂载mount /dev/drbd1 /var/drbd1，并在其中创建文件。 一定要在设置了primary角色后才挂载，否则挂载不上。 然后host1卸载挂载，并角色转为secondary 12umount /var/drbd1drbdadm secondary data 在host2上转变角色为primary，并挂载 12drbdadm primary datamount /dev/drbd1 /var/drbd1 进入目录后查看，能看到在host1上创建的文件，同步实现。实验完后切换回来，仍然是host1为primary，host2为secondary。 安装NFS服务，在两台主机上yum install nfs-utils rpcbind systemctl start nfs-server.service rpcbind.service应该是先启动rpcbind、再启动nfs-server。 在两台host上修改nfs配置文件/etc/exports 1/var/drbd1 192.168.60.*(rw,sync) 命令exportfs -r重新导入/etc/exports中的目录。 使用showmount -e 192.168.60.134查看是否配置成功 123# showmount -e 192.168.60.134Export list for 192.168.60.134:/var/drbd1 192.168.60.* 开启一台同网段客户端验证。先安装nfs-utils和rpcbind 执行mount -t nfs 192.168.60.134:/var/drbd1 /var/drbd1 查看该目录，里面有创建的文件，NFS获取成功。 错误解决参考文章： http://doc.okbase.net/zhangjie830621/archive/79242.html https://www.linuxidc.com/Linux/2012-11/73620.htm http://www.bubuko.com/infodetail-1848309.html]]></content>
      <tags>
        <tag>高可用</tag>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LDAP学习笔记]]></title>
    <url>%2F2018%2F11%2F24%2FLDAP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[LDAP概述 LDAP简单部署 LDAP概述目录服务目录是一类为了浏览和搜索数据而设计的特殊数据库，按照树状形式存储信息，目的包含基于属性的描述性信息，支持高级过滤功能。 目录不支持大多数事务型数据库支持的高吞吐量和复杂更新操作。目录服务适合的业务应用于大量查询与搜索操作，而不是大量写入操作。目录服务器还能提供主从服务器同步目录数据功能。 DNS就是一个典型的大范围分布式目录服务 目录服务器功能： 按照网络管理员指令，强制实施安全策略，保证目录信息安全 目录数据库可分布在一个网络的多台计算机上，提高响应速度 复制目录，使更多用户可使用目录，提高可靠性和稳定性 将目录划分为多个数据源（存储区），以存储大量对象 X.500X.500是构成全球分布式的名录服务系统的协议，描述了用户信息的存储和访问方式，X.500不是一个协议，而是一个协议族，包括从X.501到X.525等一系列完整的目录服务协议。X.500采用层次结构（类似DNS）。 X.500相关协议或机制： DAP目录访问协议：控制服务器和客户端之间的通信 DSA目录系统代理：用于存储目录信息的数据库，采用分层格式，提供快速高效的搜索功能，与目录信息树DIT连接。DSA之间通过链操作实现分布式访问。 DUA目录用户代理：用于访问一个或多个DSA的用户接口程序 DSP目录系统协议：控制两个或多个DSA间、DUA与DSA间的交互 DISP目录信息映像协议：定义了如何将选定的信息在服务器间进行复制 DOP目录操作绑定协议：定义了服务器间自动协商连接配置的机制 X.501：模型定义，定义目录服务的基本模型和概念 X.509：认证框架，定义如何处理目录服务中客户和服务器的认证 X.511：抽象服务定义，定义X.500提供的服务原语 X.518：分布式操作过程定义，定义如何跨平台处理目录服务 X.520：定义属性类型和数据元素 X.521：定义了对象类 X.525：定义在多个服务器间的复制操作 X.530：定义目录管理系统的使用 X.500的OSI模型： 独立的目录信息树DIT，采用层级化节点结构，每个节点都有一个唯一名称标识DN（也称唯一辨别名），唯一名称由相对唯一名称RDN（也称相对辨别名）标识和父节点标识组成。 X.500特征： 分散维护：运行X.500的每个站点只负责本地目录，可立刻进行更新和维护 搜索性能：X.500有强大的搜索功能，支持用户建立复杂查询 单一全局命名空间：为用户提供单一同性命名空间（Single Homogeneous Namespace），类似DNS，但比DNS灵活且可扩展。 结构化信息结构：目录中定义了信息结构，允许本地扩展 基于标准的目录服务：请求应用目录信息的应用（邮件、资源分配器等）能访问重要且有价值的信息 基于OSI协议，需要在会话层和表示层进行许多连接的建立和包处理 LDAPLDAP就是活动目录在Linux上的一个实现。 LDAP（Lightweight Directory Access Protocol）轻量目录访问协议，基于X.500标准，支持TCP/IP。 LDAP支持一主多从、多主多从以及分布式。 DAP是一个重量级的协议，在整个OSI协议栈上操作，需要占用大量计算资源，而LDAP设计在TCP/IP上，以小得多的资源消耗实现了大多数DAP功能。LDAP 服务器可当做网关访问X.500服务器，但基本都是在X.500服务器上直接实现LDAP。 单独的LDAP守护程序slapd，可看做是轻量级X.500服务器。LDAP就是轻量级的DAP。 LDAP与X.500的相同点： 都实现了通用的平台结构 信息模型上，都使用了项、对象类、属性等概念描述信息 命名空间上，都使用了目录信息树结构和层次命名模型 功能模型上，都使用了相似操作命令 认证框架上，都实现了用户名密码、安全加密认证 灵活性上，目录规模都可大可小 分布性上，目录信息都可分布在多个目录服务器上，服务器由各组织管理，保证目录信息总体结构一致 LDAP常用名词： dc：Domain Component，域名部分，会将完整域名分成几部分。如example.com会分为dc=example,dc=com uid：User id，用户ID。最常见的uid是从/etc/passwd中转来的条目。 ou：Organization Unit，组织单位，类似文件系统的子目录，是一个容器对象，可包含其他各种对象。 cn：Common Name，公共名称。最常见的cn是从/etc/group中转来的条目 sn：Surname，姓 dn：Distinguished Name，唯一辨别名，类似文件系统的绝对路径，每个对象都有一个唯一名称。 rdn：Relative dn：相对辨别名，类似文件系统的相对路径，是与目录树结构无关的部分。 c：Country，国家。如CN、US o：Organization，组织。如Inc LDAP目录结构与信息： 目录数据库以目录信息树DIT为存储方式的。 DIT由条目（Entry）构成，条目相当于关系数据库中的表的记录。 条目又由DN的键值对（Attribute-Value）组成 LDAP允许通过objectClass来控制哪些属性是条目必须的，objectClass的值是条目必须遵从的方案schema定义的。 LDAP目录的根称为BaseDN ou下是真正的用户条目 LDAP数据导入导出的格式是LDIF，LDIF是LDAP数据库信息的一种文本格式。 LDAP特点总结： 跨平台 树型结构，无需SQL语句维护 静态数据快速查询 使用基于推拉的复制信息技术 支持多种安全协议（SASL、SSL、TLS）和多种访问控制 支持异类数据存储（存储文件可以是文本或图片） C/S模型 LDAP常见应用： 数字证书管理、授权管理、单点登录 分布式计算环境DCE、统一描述发现与集成协议UDDI MAIL、DNS、网络用户管理、电话号码簿 内网组织信息服务、电子政务目录、人口基础库 LDAP目录数据文件： LDIF（LDAP Data Interchange Format，轻量级目录交换格式）是一种ASCII文件格式，能够向目录导入与修改信息。 LDIF文件注意点： 空行分割一个条目或定义 注释 属性: 属性值 属性可被重复赋值 每行结尾不能有空格 每条记录必须有至少一个objectClass属性 LDAP的配置模式 基本的目录查询服务：slapd仅为本地域提供目录服务，不会以任何方式与别的目录服务器交互。 目录查询代理服务：带有指针（Refferals），类似DNS，若本地的LDAP无法处理，则会返回一个指针，指向更高级的服务器地址。 异机复制数据，即主从同步：LDAP的slurpd守护进程是用于将slapd上的改变传播到一个或多个从的slapd上。可以通过inotify+rsync方案实现简单的同步。 LDAP简单部署实验环境： Master：192.168.60.134 Slave：192.168.60.135 要安装的软件：安装的ldap版本2.4 openldap：ldap库 openldap-servers：ldap服务器 openldap-clients：ldap客户端 openldap-devel：ldap开发库与头文件 nss：网络安全服务，类似Openssl，是底层密码库 OpenLDAP的配置目录：/etc/openldap/ 1234567/etc/openldap/├── certs├── check_password.conf├── ldap.conf # ldap默认的全局配置├── schema # 存放LDAP的schema└── slapd.d # 存放ldap的配置文件老版本还有slapd.conf，作为主配置文件，记录根域信息、管理员信息等。2.3以后已不再使用，但目前仍然支持。 OpenLDAP 2.3及更高版本已转换为使用动态运行时配置引擎slapd-config 完全启用LDAP 使用标准LDAP操作进行管理 将其配置数据存储在LDIF数据库中，通常位于/etc/openldap/slapd.d目录中。 允许所有slapd的配置选项在运行中进行更改，通常无需重新启动服务器即可使更改生效。 OpenLDAP监听的端口： 389：默认监听端口，是传输明文数据的 636：加密监听端口，默认启动时不开启，是传输密文数据的 OpenLDAP的配置文件目录结构：/etc/openldap/slapd.d 123slapd.d/└── cn=config └── cn=schema slapd-config配置树具有非常特定的结构。 树的根名为cn = config并包含全局配置设置。cn = config中包含的指令通常适用于整个服务器。 其中大多数是面向系统或连接，而不是数据库相关。 此条目必须具有olcGlobal的objectClass。 参考资料 Linux服务器架设指南 Linux就该这么学 Linux企业应用案例精解 Linux系统管理大全 百度百科——X.500 百度百科——LDAP]]></content>
      <tags>
        <tag>LDAP</tag>
        <tag>验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SaltStack学习笔记]]></title>
    <url>%2F2018%2F11%2F16%2FSaltStack%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Salt概述 SaltStack安装部署 Master迁移 returner event 分组 常用模块 配置管理 grains pillar syndic Job Schedule Salt SSH Salt概述Salt是一个配置管理系统，能够维护预定义状态的远程节点，是一个分布式远程执行系统，用来在远程节点上执行命令和查询数据。Salt基于Python开发，提供大量python接口。底层使用ZeroMQ消息队列pub/sub方式通信。采用RSA key认证身份。 Salt的核心功能 使命令发送到远程系统是并行的而不是串行的 使用安全加密的协议 使用最小最快的网络载荷 提供简单的编程接口 Salt同样引入了更加细致化的领域控制系统来远程执行，使得系统成为目标不止可以通过主机名，还可以通过系统属性。 SaltStack是围绕Salt开发的一系列技术栈，具有三大功能： 远程管理（Remote Execution） 配置管理（Config Management） 云管理（Cloud Management） SaltStack架构SaltStack基于C/S架构，服务器端称为Master，客户端称为Minion。中间件使用的是ZeroMQ。 Salt的三种运行方式：1. Local本地 2. Master/Minion（C/S架构） 3. Salt SSH（无客户端） SaltStack安装部署先去saltstack官网下载源，选系统以及python版本对应的源，安装后再安装salt的所有部件 1234567salt # salt主程序salt-api # salt的REST APIsalt-cloud # salt云配置器salt-minion # salt的客户端部件salt-master # salt的管理部件salt-ssh # salt的无客户端版本，使用的是ssh通信salt-syndic # salt的master-of-master组件 安装完成后，使用systemctl start salt-master启动salt服务器端，同时会自动开启两个端口4505和4506。 4505：salt的消息发布专用端口 4506：服务器与客户端通信的端口 可以通过salt-master命令管理salt-master。 12345678-c # 指定配置文件--saltfile # 指定saltfile路径，若不指定，会在当前目录查找-u # 指定运行用户-d # 后台运行--pid-file # 指定pid文件--log-level # 指定日志等级（控制台）--log-file # 指定日志文件--log-file-level # 指定日志等级（日志文件） 在客户端上，只要安装salt-minion即可。安装完成后启动systemctl start salt-minion即可。 启动进程后，无论是salt的哪个部件，都会在/var/log/salt/中创建一个日志文件，名字就是组件名，如master、minion。 日志的默认级别为warning，可通过master配置文件的log_level参数配置 在客户端配置文件中，找到参数master，配置的是服务器端的主机标识，默认叫salt，于是修改/etc/hosts，添加服务器端IP和标识salt。 注意：客户端和服务器的防火墙一定要方形4505和4506端口，否则公钥无法传递。 在服务端查看日志，说明已经开始进行认证了，但此时认证没有通过。 1234[salt.transport.mixins.auth][INFO ][32699] Authentication request from s4[salt.transport.mixins.auth][INFO ][32699] New public key for s4 placed in pending[salt.transport.mixins.auth][INFO ][32708] Authentication request from s3[salt.transport.mixins.auth][INFO ][32708] New public key for s3 placed in pending 在服务端上salt-key -L查看公钥 1234567# salt-key -LAccepted Keys:Denied Keys:Unaccepted Keys:s3s4Rejected Keys: 添加这两个密钥即可salt-key -a s3和salt-key -a s4即可 在添加前，两个未认证的密钥是存放在/etc/salt/pki/master/minions_pre目录下的，在认证后，就会转移到minions目录下，并且客户端的/etc/salt/pki/minion目录中会生成master公钥minion_master.pub。 salt-key命令 1234567-L # 列出所有公钥-a # 允许指定的公钥-A # 允许所有公钥-r # 拒绝指定公钥-R # 拒绝所有公钥-d # 删除指定公钥-D # 删除所有公钥 注：当客户端启动salt-minion时，会自动将主机名写入到/etc/salt/minion_id中，并且还会生成/etc/salt/pki/中的密钥等参数，如果修改了主机名，一定要将该minion_id和pki目录都删除，然后重启salt-minion。而且还要在master上删除该主机原来的key，重新接受新的key，再重启服务。一旦服务端与客户端的key不一致，客户端会自动停止minion进程。 测试是否与客户端正常通信 12345# salt &quot;*&quot; test.ping # &apos;*&apos;是正则表达式，匹配所有通过认证的客户端s4: Trues3: True 可以通过salt &#39;*&#39; sys.doc查看可用函数，或通过网页查看 salt命令匹配主机的常用参数 12345678-E # 正则匹配-L # 以主机id为列表匹配-G # 根据主机的grains信息匹配-I # 根据主机的pillar信息匹配-N # 根据master的配置文件中分组匹配-C # 根据条件运算符or\not\and匹配-S # 根据主机IP或子网匹配-b # 设置操作的minion的个数，可设置数字，或百分比（对于所有minion） master配置文件常用配置参数 12345678910interface: 0.0.0.0 # 网卡绑定的地址，一般保持默认即可publish_port: 4505 # 发布端口，默认4505user: root # 启动用户ret_port: 4506 # 接收消息的端口，默认4506max_open_files: 100000 # 最大同时打开文件数，尽量设大些worker_threads: 5 # 启动的线程数，不得小于3cachedir: /var/cache/salt/master # 存储任务和缓存的目录keep_jobs: 24 # 执行命令结果的缓存时间timeout: 5 # salt命令或API的连接超时时间job_cache: True # master是否缓存任务执行结果，若管理主机超过5000台，最好换其他方式存储。 minion配置文件常用配置参数 12345master: salt # 设置master，可以是fqdn，或IP地址retry_dns: 30 # 使用dns解析域名前等待的时间master_port: 4506 # 向master发送结果信息的端口cache_jobs: False # 是否在本地缓存执行结果，默认不缓存，因为结果都发往masterbackup_mode: minion # 当文件改变时会对该文件备份 Master迁移首先在原先的Master上将/etc/salt/pki目录打包tar -cf pki.tar /etc/salt/pki 将该tar包传到新的Master上的/etc/salt/中，然后解压。 在原Master上执行操作，更改minion客户端上的hosts文件。先查看一下客户端上原配置，然后修改为新的MasterIP地址。 123456789101112131415# salt &quot;*&quot; cmd.run &apos;grep salt /etc/hosts&apos;s3: 172.16.246.131 salts4: 172.16.246.131 salt # salt &apos;*&apos; cmd.run &quot;sed -i &apos;s/172.16.246.131/172.16.246.133/g&apos; /etc/hosts&quot;s4:s3:# salt &apos;*&apos; cmd.run &quot;grep salt /etc/hosts&quot;s4: 172.16.246.133 salts3: 172.16.246.133 salt 然后仍在原master上执行命令，重启客户端的salt-minion 12345# salt &apos;*&apos; service.restart salt-minions3: Trues4: True 执行完成后，原Master已经无法对客户端操作了，在新的Master上测试。确保新Master上将两台主机的密钥接受了。使用salt &#39;*&#39; test.ping，操作成功，Master迁移完成。 returnersalt客户端通过returner接口，向服务器端返回数据。在服务器端的salt命令可以添加参数--return决定将返回的数据存储在哪。returner列表 syslog将数据返回到主机操作系统的syslog工具。必需的python模块：syslog，json syslog returner只是重用操作系统的syslog工具来记录返回数据。 salt &#39;*&#39; network.interfaces --return syslog 在客户端上查看/var/log/messages，可看到信息返回为json格式。 1s4 /salt-minion: &#123;&quot;return&quot;: &#123;&quot;ens33&quot;: &#123;&quot;up&quot;: true, &quot;hwaddr&quot;: &quot;00:0c:29:15:5f:47&quot;, &quot;inet6&quot;: [&#123;&quot;scope&quot;: &quot;link&quot;, &quot;address&quot;: &quot;fe80::905f:45b9:8486:c538&quot;, &quot;prefixlen&quot;: &quot;64&quot;&#125;], &quot;inet&quot;: [&#123;&quot;label&quot;: &quot;ens33&quot;, &quot;netmask&quot;: &quot;255.255.255.0&quot;, &quot;address&quot;: &quot;172.16.246.136&quot;, &quot;broadcast&quot;: &quot;172.16.246.255&quot;&#125;]&#125;, &quot;lo&quot;: &#123;&quot;up&quot;: true, &quot;hwaddr&quot;: &quot;00:00:00:00:00:00&quot;, &quot;inet6&quot;: [&#123;&quot;scope&quot;: &quot;host&quot;, &quot;address&quot;: &quot;::1&quot;, &quot;prefixlen&quot;: &quot;128&quot;&#125;], &quot;inet&quot;: [&#123;&quot;label&quot;: &quot;lo&quot;, &quot;netmask&quot;: &quot;255.0.0.0&quot;, &quot;address&quot;: &quot;127.0.0.1&quot;, &quot;broadcast&quot;: null&#125;]&#125;&#125;, &quot;jid&quot;: &quot;20181117111540048278&quot;, &quot;success&quot;: true, &quot;id&quot;: &quot;s4&quot;, &quot;fun&quot;: &quot;network.interfaces&quot;, &quot;retcode&quot;: 0, &quot;fun_args&quot;: []&#125; mysql将数据返回到mysql中。需要服务器端有pymysql模块，客户端有python的mysql客户端模块。 master和minion中有关于returner的配置，默认包含mysql，但要启用仍然要配置。在minion的配置文件取消return: mysql注释，并添加以下参数 12345mysql.host: &apos;172.16.246.133&apos;mysql.user: &apos;salt&apos;mysql.pass: &apos;salt&apos;mysql.db: &apos;salt&apos;mysql.port: &apos;3306&apos; 由于每台服务器都要和mysql连接，会使得mysql服务器的压力很大，在实际环境中不会这样调用。 eventSalt Event System是一个本地的ZeroMQ pub interface，用于触发事件，使第三方应用程序或外部进程能够对Salt内的行为做出反应，发送信息通知salt或其他操作系统。 事件系统由两个主要组件组成： 发布事件的事件套接字（event sockets）。 事件库（event library）可以监听事件并将事件发送到salt系统。 每个event都有一个标签，事件标签允许快速置顶过滤事件，且每个event都有一个数据结构，是一个dict类型，包含事件的信息。 分组master配置文件中nodegroups块用于设置分组。也可以在master.d/中创建独立的nodegroups配置文件。 12345678#nodegroups:# group1: 'L@foo.domain.com,bar.domain.com,baz.domain.com or bl*.domain.com'# group2: 'G@os:Debian and foo.domain.com'# group3: 'G@os:Debian and N@group1'# group4: # 列表写法，等同于 G@foo:bar or G@foo: baz# - 'G@foo:bar'# - 'or'# - 'G@foo:baz' 分组可设置的匹配规则 Letter 含义 例 G Grains glob匹配 G@os: Ubuntu E PCRE minion id匹配 `E@web\d+.(dev qa prod).loc` P Grains PCRE匹配 `P@os: (RedHat Fedora CentOS)` L minions列表 L@minion1, minion2 I Pillar glob匹配 I@pdata: foobar S 子网/IP匹配 S@192.168.1.0/24 or S@192.168.1.100 R Range Cluster匹配 R@foo.bar D Minion Data匹配 D@key: value C Compound匹配（可匹配多种上面的匹配规则，称为混搭匹配） G@os: Ubuntu and I@pdata: foobar or web* 常用模块可使用sys.list_modules列出所有可用模块，可使用sys.doc查看指定模块的用法 archive gunzip：解压gzip gzip：gzip压缩 rar：rar压缩 unrar：rar解压 unzip：zip解压 zip：zip压缩 tar：打包 12salt &apos;*&apos; archive.gzip /tmp/file.gz /root/a.ymlsalt &apos;*&apos; archive.gunzip /tmp/file.gz /root/ cmd run：运行命令 1salt &apos;*&apos; cmd.run &apos;free -m&apos; script：执行脚本 cp get_dir： cache_file： cache_files： cache_local_file： cache_master： get_file： get_file_str： get_url： crondnsutilfilenetworkpkg主机程序安装管理，能根据主机的系统使用不同的包管理工具。 install：安装软件 remove：卸载软件 upgrade：升级软件 refresh_db：检查repos service主机服务管理 enable：开机自启 disable：开机不自启 reload：重载配置 restart：重启 start：启动 stop：停止 status：状态 statussaltutilstateuser `` grouppartitionsystempillarnginxtest配置管理配置管理（Configuration Management），也称组态管理，是一个建立系统工程的过程，用来建立和维持一个产品，使该产品的效能、功能及物理特性在生命周期中都保持稳定和一致性。Salt的配置描述文件称为sls文件（Salt State）。 State结构： Top文件，配置管理的入口文件，默认为top.sls。 sls的模块使用点分割。如salt://apache/install.sls或salt://apache/install/init.sls都可用apache.install表示。 在top.sls中若指定了apache，则在执行时会查找state根目录下apache目录中的init.sls，若找不到则找根目录下的apache.sls sls文件间可用include或extend引用或扩展。 sls中ID必须唯一，ID为state的名称。 states模块列表 在master上查看配置文件/etc/salt/master中file_roots参数配置 123456789file_roots: base: # 基础版，一般只要base版就行 - /srv/salt/ # 指定salt文件的根目录，需要先手动创建 dev: # 开发版 - /srv/salt/dev/services - /srv/salt/dev/states prod: # 生产版 - /srv/salt/prod/services - /srv/salt/prod/states 在配置中还有一个state_top参数，Salt在执行自定义sls配置时会根据该参数指定的sls文件（默认为top.sls）中的定义查找要执行的文件 首先在/srv/salt/中创建一个sls文件top.sls 123base: # 使用base版 &apos;*&apos;: # 目标所有主机 - apache # 执行的sls文件名 然后创建apache.sls文件 12345apache-service: # 功能块ID service.running: # states模块 - name: httpd # 指定服务 - enable: True # 设置服务开机自启 - reload: True # 设置服务重载 执行salt -L &#39;s3&#39; state.highstate或salt -L &#39;s3&#39; state.highstate salt://apache或salt -L &#39;s3&#39; state.highstate apache 12345678910111213141516171819202122# salt -L &apos;s3&apos; state.highstates3:---------- ID: apache-service Function: service.running Name: httpd Result: True Comment: Service httpd is already enabled, and is running Started: 09:36:45.596459 Duration: 143.647 ms Changes: ---------- httpd: TrueSummary for s3------------Succeeded: 1 (changed=1)Failed: 0------------Total states run: 1Total run time: 143.647 ms 如果sls文件中的操作有依赖或先后关系，还可以在sls文件中指定以下参数： require：本state执行前需要先执行哪些state require_in： watch：除了require外，也监测依赖的state状态，若状态发生变化，则做出反应 watch_in： prereq：通过test=True检查所依赖的state状态，若状态发生变化，则执行 prereq_in： 123456789101112131415apache: # statesID pkg.installed: - name: httpd file.managed: - name: /etc/httpd/conf/httpd.conf # 目标文件 - source: salt://httpd.conf # 源文件 - require: - pkg: apache # 需要httpd已安装，apache为statesID service.running: - name: httpd - enable: True - reload: True - watch: # 需要file和pkg同时满足要求 - pkg: apache - file: apache 使用模板修改/srv/salt/的配置文件httpd.conf。 12Listen &#123;&#123; http_port &#125;&#125;ServerName &#123;&#123; server_name &#125;&#125; 修改apache.sls的file.managed。 123456789file.managed: - name: /etc/httpd/conf/httpd.conf - source: salt://httpd.conf - require: - pkg: apache - template: jinja # 指定模板的格式 - context: http_port: 8080 server_name: s3.example.com 然后执行，可看到修改信息 123456789101112131415161718Changes: ---------- diff: --- +++ @@ -1,10 +1,10 @@ ServerRoot &quot;/etc/httpd&quot; -Listen 81 +Listen 8080 # 替换了端口号 Include conf.modules.d/*.conf User apache Group apache ServerAdmin root@localhost -ServerName www.example.com:80 +ServerName s3.example.com # 替换了主机域名 &lt;Directory /&gt; AllowOverride none Require all denied 若有多台主机需要配置，则可以使用Jinja的if判断结合grains 12345678- context: &#123;% if grains[&apos;id&apos;] == &apos;s3&apos; %&#125; http_port: 81 server_name: s3.example.com &#123;% elif grains[&apos;id&apos;] == &apos;s4&apos; %&#125; http_port: 82 server_name: s4.example.com &#123;% endif %&#125; 或者结合pillar。先在/srv/pillar/httpd.sls中配置 12345678apache: &#123;% if grains.id == &apos;s3&apos; %&#125; http_port: 81 server_name: s3.example.com &#123;% elif grains.id == &apos;s4&apos; %&#125; http_port: 82 server_name: s4.example.com &#123;% endif %&#125; 然后刷新salt &#39;*&#39; saltutil.refresh_pillar，并查看是否能获取 12345678910111213# salt &apos;*&apos; pillar.get apaches4: ---------- http_port: 82 server_name: s4.example.coms3: ---------- http_port: 81 server_name: s3.example.com 然后修改/srv/salt/apache.sls 1234- context: http_port: &#123;&#123; salt[&apos;pillar.get&apos;](&apos;apache:http_port&apos;, 80) &#125;&#125; # 若该项存在就使用该项的值，否则就用括号中另一个值 server_name: &#123;&#123; salt[&apos;pillar.get&apos;](&apos;apache:server_name&apos;, &apos;www.example.com&apos;) &#125;&#125; grainsgrains是Salt的重要组件之一，用于收集客户端的信息，包括CPU、内核、系统等。在minion上配置Grains。 可在master上通过grains获取minion的信息。可用salt &#39;*&#39; grains.ls查看可选项 grains.items查看所有项与对应值，grains.item ITEM查看指定项的值 12345# salt -L &apos;s3&apos; grains.item oss3: ---------- os: CentOS 客户端自定义项与值，可以在minion的/etc/salt/minion配置文件中添加，也可以在/etc/salt/minion.d/中创建独立文件。修改完需要重启minion服务。 1234grains: roles: # 自定义项 - web # 项的值 - proxy 然后在master上查看roles项的值 123456# salt -L &apos;s3&apos; grains.item roless3: ---------- roles: - web - proxy 还可以通过grains.get直接获取指定项的值 1234# salt -L &apos;s3&apos; grains.get roless3: - web - proxy pillarPillar在Master上定义，功能类似Grains，但比Grains更加灵活，能给特定的minion定义需要的数据。在master配置文件中的pillar_roots块。 123#pillar_roots: # pillar的根目录# base:# - /srv/pillar # 需要手动创建 在/srv/pillar中创建top.sls 123base: &apos;*&apos;: - httpd 然后创建httpd.sls 1234httpd: function: state.sls args: - &apos;httpd&apos; 使用命令salt &#39;*&#39; saltutil.refresh_pillar刷新pillar，无须重启服务。 123456789# salt -L &apos;s3&apos; pillar.datas3: ---------- httpd: ---------- args: - httpd function: state.sls Grains和Pillar的区别： 用途不同：Grains用于存储Minion的基本数据信息，Pillar用于存储Master分配给Minion的数据信息 存储区域不同：Grains元数据存储在Minion端，Pillar元数据存储在Master端 更新方式不同：Grains在Minion启动时更新或通过saltutil.sync_grains刷新，Pillar元数据存储在Master端，可用saltutil.refresh_pillar刷新，更加灵活。 syndicsyndic是一个允许建立salt命令拓扑结构的工具，当两台master上都运行了syndic，则高一级的master可以管理到另一台下的所有minion，Master的Master也称为Master of Master，syndic常用于代理proxy。 加入一台新的salt主机，IP地址为172.16.246.134，安装salt-syndic，然后在现master（172.16.246.158）的master配置文件中找到syndic_master参数并修改。 123syndic_master: 172.16.246.134 # 更高一级的Master的IP地址syndic_log_file: /var/log/salt/syndic # 日志文件路径，可不改order_masters: True # 更高一级的master能管理低等级的master的syndic接口，默认为False master和更高级别的master都要开启salt-syndic服务。在新salt主机上添加master的密钥，重启服务，然后测试。 1234567# salt &apos;*&apos; service.restart httpd # &apos;*&apos;能包含master所管理的minion和master本身。sys1.example.com: Trues4: Trues3: True JobSalt的任务管理job。当Master下发指令时，会附带产生的jid（job id，格式%Y%m%d%H%M%S%f），Minion在接收到指令后开始执行时，会在本地cachedir（默认/var/cache/salt/minion下的proc目录）产生以该jid命名的文件，用于在执行完毕将结果传给Master，并删除该临时文件。Master会将结果存放在/var/cache/salt/master/jobs目录，默认缓存24小时，可通过master配置的keep_jobs修改。 可在salt命令后添加-v显示当前命令的jid。在master上通过命令salt-run jobs.list_jobs查看已缓存的job saltutil中job的管理方法 running：查看minion正在运行的Jobs find_job &lt;jid&gt;：查看指定jid的job signal_job &lt;jid&gt; &lt;signal&gt;：给指定jid进程发送信号 term_job &lt;jid&gt;：终止指定jid进程，信号为15 kill_job &lt;jid&gt;：终止指定jid进程，信号为9 也可通过命令salt-run查看job salt-run jobs.active：查看所有Minion当前正在运行的jobs，即在所有Minion上运行saltutil.running salt-run jobs.lookup_jid &lt;jid&gt;：查看指定jid进程的运行结果 salt-run jobs.list_jobs：列出当前master的jobs cache中的所有jobs Schedule用于在Master或Minion定期执行Schedule中配置的任务。Master配置Schedule运行runner，Minion端配置Schedule为远程执行。可以在配置文件中或pillar中配置Schedule。 在/srv/pillar/中创建schedule文件schedule.sls，并在top.sls中添加该文件，然后编写Schedule。然后刷新pillar。 123456schedule: job1: function: cmd.run args: - "date &gt;&gt; /tmp/test.log" minutes: 1 可通过salt-run jobs.list_jobs查看所有jobs。 Salt SSHSalt ssh基于ssh，无需Zeromq和agent。salt也为ssh构建了一个系统结构Roster，为salt ssh提供需要连接的主机及权限信息。 Roster的配置文件：/etc/salt/roster 12345678salt ID: # 配置target的ID host: # 目标主机IP地址或域名 user: # 登录用户 passwd: # 用户密码 sudo: # 是否通过sudo执行，可选 port: # 连接目标的ssh端口 priv: # ssh私钥 timeout: # 等待回应的超时时间 参考文章 Saltstack 自动化运维工具详细介绍 SaltStack学习 saltstack快速入门 Saltstack-部署]]></content>
      <tags>
        <tag>运维</tag>
        <tag>自动化</tag>
        <tag>SaltStack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Swarm学习笔记]]></title>
    <url>%2F2018%2F11%2F06%2FDocker-Swarm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Docker Swarm概述 swarm操作 实战一-LNMP搭建 Docker Swarm概述Docker Swarm用于跨主机部署管理docker集群。从1.12版本开始就集成在docker engine中，并称为swarm mode。swarm已内置kv存储功能，不再需要外置的etcd，内置Overlay网络，服务发现，负载均衡。 当 Docker Engine 初始化了一个 swarm 或者加入到一个存在的 swarm 时，它就启动了 swarm mode。没启动 swarm mode 时，Docker 执行的是容器命令；运行 swarm mode 后，Docker 增加了编排 service 的能力。Docker 允许在同一个 Docker 主机上既运行 swarm service，又运行单独的容器。 Swarm特点 Docker Engine集成了swarm 去中心化设计：Swarm角色分为Manager和Worker，Manager的故障不会影响应用使用 扩容缩容：可声明每个服务运行的容器数量，会自动添加或删除容器数，以调整到期望的状态 期望状态协调：Manager节点监控集群状态，自动调整当前状态与期望状态之间的差异。 多主机网络：可为服务指定Overlay网络，党初始化或更新应用程序时，Manager会自动为Overlay网络上的容器分配IP地址 服务发现：Manager为集群的每个服务分配唯一的DNS记录和负载均衡VIP，可通过Swarm内置的DNS服务器查询集群中每个运行的容器 安全传输：Swarm中每个节点使用TLS互相验证和加密，确保节点间安全通信 滚动更新：升级时，逐步将应用服务更新到节点，若出现问题，可以将任务回滚到先前版本 Swarm术语 node：swarm中每个docker engine都是一个node，有两种类型：manager和worker manager node负责执行编排和集群管理工作，保持并维护 swarm 处于期望的状态。manager node会将部署任务拆解并分配给一个或多个worker node完成部署。Manager节点默认也作为worker节点，不过可以将其配置成 manager-only node，让其专职负责编排和集群管理工作。 swarm 中如果有多个 manager node，它们会自动协商并选举出一个 leader 执行编排任务。 worker node 接收并执行管理节点分配的任务，并会定期向 manager node 报告自己的状态和它正在执行的任务的状态 service与task：定义了 worker node 上要执行的任务。swarm 的主要编排任务就是保证 service 处于期望的状态下。 任务Task是swarm中的最小原子调度单位。Services是一组task的集合，service定义了这些task的属性。 swarm的工作流程： Client发送请求给Swarm Swarm处理并发送给相应docker node docker node执行操作并返回结果 services有两种模式： replicated services：按照一定规则在各个worker node上运行指定个数的tasks，和k8s的replicate、marathon中的instance概念一样。 global services：每个woker node上运行一个此task Swarm调度模块 filter：使用过滤器挑出符合条件的节点，并从中选出最优节点。有以下过滤器： Constraints： Affinity： Dependency： Health filter： Ports filter： strategy：使用策略挑出最优节点。有以下策略： Binpack： Spread： Random： 服务发现：分为三种场景 Ingress： Ingress+Link： 自定义网络： 负载均衡swarm manager使用入口负载均衡（Ingress load balance）来发布向集群外部提供的服务。swarm manager可以自动为已发布的端口（published port）分配服务，也可以为服务配置发布端口（Published Port）。可以指定任何未使用的端口，如果未指定端口，则swarm manager会为服务分配30000-32767范围内的端口。 外部组件（例如云负载平衡器）可以访问集群中任何节点的发布端口上的服务，无论该节点当前是否正在运行该服务的任务。集群中的所有节点都将入口连接到正在运行的任务实例。 Swarm模式有一个内部DNS组件，可以自动为swarm中的每个服务分配一个DNS条目。swarm manager使用内部负载均衡（Internal load balance）来根据服务的DNS名称在集群内的服务之间分发请求。 swarm操作实验环境： Manager：本机192.168.43.106 Worker：atom-1 172.16.246.138 Worker：atom-2 172.16.246.139 创建与查看服务初始化一个swarm，docker swarm init --advertise-addr IP地址，指定发布的地址。 1234&gt; docker swarm init --advertise-addr 192.168.43.106Swarm initialized: current node (w4wogxb10dhxtcvh3ljx5ltqh) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token XXXXXX 192.168.43.106:2377 在atom-1、atom-2上执行提示的docker swarm join命令。然后在Manager上执行docker node ls查看节点，集群已创建成功。 如果docker swarm join的命令忘记了，则可以在Manager上执行docker swarm join-token worker查看 12345&gt; docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION7r0pg83uetbwp1jc2ysgkitj5 atom-1 Ready Active 1.13.1e3fnuzkgzjhxqg748us07pb48 atom-2 Ready Active 1.13.1w4wogxb10dhxtcvh3ljx5ltqh * gutianyi-PC Ready Active Leader 18.06.1-ce docker node命令。专门对swarm节点操作 12345678docker node COMMAND demote 降级一个或多个节点（从Manager降为Worker） inspect 显示一个或多个节点的详细信息。输出为Json格式，或者添加--pretty会重新排版，便于查看 ls 显示所有节点 promote 提升一个或多个节点（从Worker升为Manager） ps 列出在一个或多个节点上运行的任务（tasks），默认为当前节点 rm 从集群中删除指定节点（通过ID） update 更新一个节点 docker service命令。管理docker 服务。 12345678910docker service COMMAND create 创建一个服务 inspect 显示一个或多个服务的详细信息 logs 获取一个服务或任务的日志 ls 显示所有服务 ps 显示指定服务的任务 rm 删除一个或多个服务 rollback 回滚一个服务的配置 scale 扩展一个或多个复制的服务 update 更新一个服务 在Manager上创建服务docker service create --replicas 2 --name busybox busybox /bin/ping &quot;baidu.com&quot;。其中--replicas表示期望状态的实例个数，由于busybox一定要参数任务，否则服务无法正常启动，所以在后面加上了ping的任务。 1234&gt; docker service lsID NAME MODE REPLICAS IMAGE PORTSp519w5pjai5y busybox replicated 2/2 busybox:latest # MODE为replicated说明会根据调度算法动态调度节点 若暂时未添加参数，未能成功启动：docker service create --replicas 2 --name busybox_1 busybox，也可以通过docker service update对服务添加参数 123456&gt; docker service update busybox_1 --args &quot;/bin/ping baidu.com&quot;busybox_1overall progress: 2 out of 2 tasks 1/2: running 2/2: running verify: Service converged 可以通过docker service ps SERVICE查看服务的任务，可以查看到该服务在哪个节点NODE上运行。 12345&gt; docker service ps busyboxID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSr9eogiyc0xkl busybox.1 busybox:latest gutianyi-PC Running Running 20 minutes ago 5z2rfa8xiuvq \_ busybox.1 busybox:latest gutianyi-PC Shutdown Failed 20 minutes ago &quot;task: non-zero exit (1)&quot; txz74rterci8 \_ busybox.1 busybox:latest gutianyi-PC Shutdown Failed 21 minutes ago &quot;task: non-zero exit (1)&quot; 还可以通过-f指定满足条件的条目 1234&gt; docker service ps busybox -f &quot;desired-state=running&quot; #只查看正在运行的任务ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSr9eogiyc0xkl busybox.1 busybox:latest gutianyi-PC Running Running 22 minutes ago axvqvs5wuvw4 busybox.2 busybox:latest gutianyi-PC Running Running about an hour ago 扩缩容可通过docker service scale SERVICE=REPLICAS进行扩容或缩容 1234567891011&gt; docker service scale busybox=3 # 将busybox的replicas扩容到3台busybox scaled to 3overall progress: 3 out of 3 tasks 1/3: running [==================================================&gt;] 2/3: running [==================================================&gt;] 3/3: running [==================================================&gt;] verify: Service converged &gt; docker service lsID NAME MODE REPLICAS IMAGE PORTSp519w5pjai5y busybox replicated 3/3 busybox:latest 更新与回滚创建web服务，设置定时更新策略 123456789101112docker service create \ --name web \ --replicas 3 \ --update-delay 2s \ # 任务升级间的间隔 --update-parallelism 2 \ # 同时更新的最大任务数 nginx:1.12 # 使用nginx:1.12镜像docker service ps web ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSp1w8ee6fhrt8 web.1 nginx:1.12 gutianyi-PC Running Running 13 minutes ago gv5jm09qsvq7 web.2 nginx:1.12 atom-2 Running Running 13 hours ago 600wh1qru5f5 web.3 nginx:1.12 atom-1 Running Running 13 hours ago 然后执行docker service update命令升级镜像 12345678docker service update --image nginx:1.13 web# 查看任务，确认镜像已全部升级到nginx:1.13docker service ps web -f &quot;desired-state=running&quot;ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSe8t755h66a32 web.1 nginx:1.13 atom-3 Running Running 13 hours ago lkf51u3brkun web.2 nginx:1.13 gutianyi-PC Running Running about a minute ago u240xfs3q023 web.3 nginx:1.13 atom-1 Running Running 13 hours ago 手动回滚镜像版本到nginx:1.12 12345678docker service update --rollback web# 已回滚完成，版本又变为nginx:1.12docker service ps web -f &quot;desired-state=running&quot;ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSyuj9ry8uipy4 web.1 nginx:1.12 atom-2 Running Running 13 hours ago szfnmk3o7wgv web.2 nginx:1.12 atom-3 Running Running 13 hours ago jjsutat7tc65 web.3 nginx:1.12 atom-1 Running Running 13 hours ago docker service update与更新回滚相关的参数 1234567891011121314--rollback # 回滚到上一个版本--rollback-delay duration # 回滚时间间隔，单位(ns|us|ms|s|m|h)--rollback-failure-action string # 回滚失败执行的动作(&quot;pause&quot;|&quot;continue&quot;)--rollback-max-failure-ratio float # 能够容忍的回滚错误率--rollback-monitor duration # 每次任务回滚后等待的时间，以监视是否回滚失败 (ns|us|ms|s|m|h)--rollback-order string # 回滚指令(&quot;start-first&quot;|&quot;stop-first&quot;)--rollback-parallelism uint # 同时回滚的最大任务数，若为0则同时回滚所有任务--update-delay duration #更新时间间隔(ns|us|ms|s|m|h)--update-failure-action string #更新失败执行的动作(&quot;pause&quot;|&quot;continue&quot;|&quot;rollback&quot;)--update-max-failure-ratio float # 能够容忍的更新失败率--update-monitor duration # 每次更新后等待的时间，以监视是否更新失败(ns|us|ms|s|m|h)--update-order string # 更新指令(&quot;start-first&quot;|&quot;stop-first&quot;)--update-parallelism uint # 同时更新的最大任务数，若为0则同时更新所有任务 DRAIN可用性有时，例如计划的维护时间，需要将节点设置为DRAIN可用性。DRAIN可用性会阻止节点从swarm manager接收新任务。这也就意味着manager会停止在该节点上运行的任务，并在具有ACTIVE可用性的节点上启动副本任务。 将节点设置为DRAIN不会从该节点中删除独立容器，例如使用docker run，docker-compose up或Docker Engine API创建的容器。节点的状态（包括DRAIN）仅影响节点调度swarm服务工作负载的能力。 12345678910111213141516171819202122232425262728293031# 最初每个worker上都有一个任务&gt; docker service ps web -f &quot;desired-state=running&quot;ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTStffbqbf4v2ah web.1 nginx:1.12 atom-1 Running Running 17 hours ago n0bk8a7nva7m web.2 nginx:1.12 atom-2 Running Running 17 hours ago ugw21hq29jt3 web.3 nginx:1.12 atom-3 Running Running 17 hours ago exvdophp0rc6 web.4 nginx:1.12 gutianyi-PC Running Running about a minute ago # 将atom-1的可用性设为drain&gt; docker node update --availability drain atom-1# 查看atom-1，可看到可用性已变为drain&gt; docker node inspect atom-1 --pretty ID: 845ol5bc51p68esmt14w1r7k8Hostname: atom-1Joined at: 2018-11-06 12:33:43.750433367 +0000 utcStatus: State: Ready Availability: Drain Address: 192.168.43.106......# 查看服务，atom-1已不再接受任务，并且任务由另一个节点接替（此处为manager节点）&gt; docker service ps web -f &quot;desired-state=running&quot;ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSkid3lp31jvz0 web.1 nginx:1.12 gutianyi-PC Running Running about a minute ago n0bk8a7nva7m web.2 nginx:1.12 atom-2 Running Running 17 hours ago ugw21hq29jt3 web.3 nginx:1.12 atom-3 Running Running 17 hours ago exvdophp0rc6 web.4 nginx:1.12 gutianyi-PC Running Running 5 minutes ago # 可再通过将可用性设回active使该节点重新开始接受任务 数据持久化 volume bind 创建服务使用volume数据卷 12345678910111213&gt; docker service create --name web-1 --mount src=test,dst=/data nginx:1.12&gt; docker inspect web-1 -f &quot;&#123;&#123;json .Spec.TaskTemplate.ContainerSpec.Mounts&#125;&#125;&quot;[&#123;&quot;Type&quot;:&quot;volume&quot;,&quot;Source&quot;:&quot;test&quot;,&quot;Target&quot;:&quot;/data&quot;&#125;]# src必须是volume的名字，不能是绝对路径# 还可指定type，默认不指定就是volume通过docker volume ls也可查看到test的volume&gt; docker exec -it web-1.1.uowomv72xjti9l5373erxskra /bin/bash# 在容器内部的data目录中创建一个文件# touch 1.txt在volume的目录中就能看到该文件&gt; ls /var/lib/docker/volumes/test/_data1.txt 创建服务使用bind挂载 12345678&gt; docker service create --mount type=bind,src=/home/gutianyi/test,dst=/data --name web1 nginx:1.12 # 使用bind的话，src必须是绝对路径&gt; docker inspect web1 -f &quot;&#123;&#123;json .Spec.TaskTemplate.ContainerSpec.Mounts&#125;&#125;&quot;[&#123;&quot;Type&quot;:&quot;bind&quot;,&quot;Source&quot;:&quot;/home/gutianyi/test&quot;,&quot;Target&quot;:&quot;/data&quot;&#125;]# 若要挂载只读权限，可以在--mount中添加readonly&gt; docker service create --mount type=bind,src=/home/gutianyi/test,dst=/data,readonly --name web1 nginx:1.12 路由网格（routing mesh）Docker Engine的swarm模式可以轻松发布服务端口，使其可用于群组外的资源。所有节点都参与入口路由网格（ingress routing mesh）。路由网格允许群集中的每个节点接受已发布端口上的连接，以便在群集中运行的任何服务，即使节点上没有任何任务正在运行。路由网格将所有请求路由到可用节点上的已发布端口的活动容器。 要在群集中使用入口网络，需要在启用swarm模式之前在集群节点之间打开以下端口： 端口7946 TCP / UDP用于容器网络发现。 端口4789 UDP用于容器入口网络。 并且还必须打开集群节点与需要访问端口的任何外部资源（如外部负载平衡器）之间的已发布端口。 使用--publish在创建服务时发布端口。 target用于指定容器内的端口，published用于指定要在路由网格上绑定的端口。如果不使用已发布的端口，则会为每个服务任务绑定一个随机端口（30000-32767）。默认发布的是TCP端口，若要设置协议可在--publish中添加protocol=tcp|udp指定 123456789&gt; docker service create --name web \ --replicas 5 \ --update-delay 5s \ --update-parallelism 2 \ --publish published=8080,target=80 \ nginx:1.12 &gt; docker service inspect web -f &quot;&#123;&#123;json .Endpoint.Ports&#125;&#125;&quot;[&#123;&quot;Protocol&quot;:&quot;tcp&quot;,&quot;TargetPort&quot;:80,&quot;PublishedPort&quot;:8080,&quot;PublishMode&quot;:&quot;ingress&quot;&#125;] 该服务的每个容器都能作为一个负载均衡器，如下图（docker文档的图） docker service update --published-add published=XX,target=XX SERVICE能够添加发布的端口（不是替换） 123456&gt; docker service create --name web-1 --publish published=8081,target=80 nginx:1.12 &gt; docker service update --publish-add published=8082,target=80 web-1&gt; docker service inspect web-1 -f &quot;&#123;&#123;json .Endpoint.Ports&#125;&#125;&quot;[&#123;&quot;Protocol&quot;:&quot;tcp&quot;,&quot;TargetPort&quot;:80,&quot;PublishedPort&quot;:8081,&quot;PublishMode&quot;:&quot;ingress&quot;&#125;,&#123;&quot;Protocol&quot;:&quot;tcp&quot;,&quot;TargetPort&quot;:80,&quot;PublishedPort&quot;:8082,&quot;PublishMode&quot;:&quot;ingress&quot;&#125;] 可以绕过路由网格，在访问给定节点上的绑定端口时，始终访问在该节点上运行的服务实例，这称为主机模式（host）。在--publish后加上mode=host 服务发现与负载均衡swarm模式内置DNS组件，可自动为集群中每个服务分配DNS记录，swarm manager使用内部负载均衡，根据服务的DNS名在集群内的服务间分发请求。swarm manager使用ingress load balancing暴露服务。ingress network是特殊的overlay网络，便于服务的节点直接负载均衡，当任何swarm节点在已发布的端口上接受请求时，会将请求转发到IPVS模块，IPVS追踪该服务的所有容器IP地址，选择其中一个并将请求路由给它。 官网的图，只看原理 需要创建overlay网络docker network create -d overlay --subnet 192.1.1.0/24 --myoverlay 注：若没有指定--subnet，一定要注意查看创建的网络的子网，有可能会创建子网为10.0.0.0/16的网络，这会与docker的默认子网冲突，导致后续的DNS解析出错，因此最好指定子网。 创建一个Nginx web集群 1234&gt; docker service create --replicas 3 --network myoverlay --name web nginx:1.12&gt; docker inspect web -f &quot;&#123;&#123;json .Endpoint.VirtualIPs&#125;&#125;&quot;[&#123;&quot;NetworkID&quot;:&quot;ne9ejireolrulkw9072gstiaq&quot;,&quot;Addr&quot;:&quot;192.1.1.22/24&quot;&#125;] 创建一个busybox服务，使用与web集群相同的网络 123456789101112131415&gt; docker service create --network myoverlay --name busy busybox&gt; docker inspect busy -f &quot;&#123;&#123;json .Endpoint.VirtualIPs&#125;&#125;&quot;[&#123;&quot;NetworkID&quot;:&quot;ne9ejireolrulkw9072gstiaq&quot;,&quot;Addr&quot;:&quot;192.1.1.26/24&quot;&#125;]# 进入busy服务的容器&gt; docker exec -it busy.1.a8mzyt0vlb7ic68aehmlzrmik sh# 使用nslookup解析服务# nslookup webServer: 127.0.0.11Address: 127.0.0.11:53Non-authoritative answer:Name: webAddress: 192.1.1.22# 得到负载均衡器的IP 高可用为了使swarm具有容错功能（高可用），一般使集群中的节点个数为奇数个数。当leader故障时自动选举新的leader。 注：若添加多个Manager，则需要保持一半以上的Manager正常工作。 可在manager上提升一个节点，使其成为备用manager节点。 docker node promote指定要提升的节点。 123456&gt; docker node promote ubuntu-s1Node ubuntu-s1 promoted to a manager in the swarm.&gt; docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONlgq8c78rd2ajx9mf05x8qgrdp * gutianyi-PC Ready Active Leader 18.06.1-cejd81rx6tdzf9uak63b4iefqi2 ubuntu-s1 Ready Active Reachable 18.06.1-ce 节点的manager状态变为Reachable。 或者也可以使节点在加入swarm时就成为Manager节点，在当前的Manager上执行docker swarm join-token manager，再复制到节点上执行。 配置文件存储使用命令docker config管理配置文件。需要该节点是集群的Manager。 12345docker config COMMAND create 创建配置文件 inspect 查看配置文件信息 ls 列出所有配置文件 rm 删除配置文件 在Manager上创建一个配置文件web1.conf 123456789101112server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / &#123; root /usr/share/nginx/html; index index.html index.htm; &#125;&#125; 创建docker配置docker config create web1.conf web1.conf 创建服务，应用该配置 12345docker service create --name web \ --replicas 3 \ --config source=web1.conf,target=/etc/nginx/conf.d/web1.conf \ -p 8080:80 \ nginx 实战一-LNMP搭建 创建overlay网络lnmp 1docker network create -d overlay --subnet 192.168.1.0/24 lnmp 下载discuz包，解压后进入。创建Dockerfile。 123456.├── Dockerfile├── readme├── README.md├── upload└── utility 1234FROM phpCOPY upload /usr/src/discuzWORKDIR /usr/src/discuzCMD [&apos;php&apos;, &apos;./index.php&apos;] 构建镜像docker build -t discuz-php . 创建一个php服务 123456docker service create \ --name discuz-php \ --replicas 3 \ --network lnmp \ --mount type=volume,source=www,destination=/usr/local/nginx/html \ discuz-php 创建mysql服务 123456789docker service create \ --name discuz-mysql \ --network lnmp \ --mount type=volume,source=dbdata,destination=/var/lib/mysql \ -e MYSQL_ROOT_PASSWORD=123456 \ -e MYSQL_USER=discuz \ -e MYSQL_PASSWORD=123456 \ -e MYSQL_DATABASE=discuz \ mysql 创建nginx服务 123456docker service create --name nginx \ --replicas 3 \ --network lnmp \ -p 8080:80 \ --mount type=volume,source=www,destination=/usr/local/nginx/html \ nginx]]></content>
      <tags>
        <tag>集群</tag>
        <tag>docker</tag>
        <tag>云计算</tag>
        <tag>容器编排</tag>
        <tag>docker swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Memcached笔记]]></title>
    <url>%2F2018%2F11%2F05%2FMemcached%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Memcached概述 Memcached简单部署 Memcached概述Memcached是一个高性能、支持高并发的分布式内存缓存系统，由C语言编写，是基于存储键值对的hashmap，用于动态web应用，减轻后端服务器和数据库的负载。采用C/S架构，服务器端的程序叫Memcached，客户端程序叫Memcache。 Memcached通过事先规划好的系统内存空间中临时缓存数据库中的各类数据，达到减少前端业务服务对数据库的直接高并发访问。原理与缓存服务器一致。 Memcached特点： 协议简单：采用基于文本行的协议，可通过telnet等命令直接操作数据 支持epoll/kqueue异步I/O模型，使用libevent作为事件处理通知机制 全内存缓存，效率高。无持久化存储设计 支持分布式集群 多线程处理时采用pthread线程模式 应用场景： 作为数据库的查询数据缓存 作为集群节点的session会话共享存储 Memcached内存管理机制： 采用slab内存分配机制：slab分配器是基于对象（内核中的数据结构）进行管理的，每当要申请这样一个对象时，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，从而避免内部碎片。slab分配器并不丢弃已经分配的对象，而是释放并把它们保存在内存中。slab分配对象时，会使用最近释放的对象的内存块，因此其驻留在cpu高速缓存中的概率会大大提高。 采用LRU对象清除机制：Least Recent Used，淘汰最不常使用的，即缓存中最长时间没有被访问的会被淘汰。 采用hash机制快速检索item：对item做hash，建立hash表 Slab内存管理机制：全称Slab Allocation。会提前将大内存分为若干1M的slab，每个小对象称为chunk，把相同尺寸的内存块分为组chunks slab class，可重复利用。当新增数据对象时，会根据空闲chunk的表进行分配。存储在chunk中的数据项称为item。 Memcached预热：当需要大规模重启Memcached时，要先在前端控制网站入口的访问流量，然后重启Memcached集群进行数据预热，再逐步放开前端的流量控制。 Memcached检测过期与删除机制：Memcached不会主动检测item对象是否过期，而是在进行get操作时检查时间戳，这种策略称为懒惰检测对象过期策略，这种策略不会在过期数据上浪费CPU资源。在删除item时，不会自动释放内存空间，而是做删除标记，将指针放入slot回收槽，下次分配时直接使用。在分配内存时，会优先使用已过期的键值对空间，并采用LRU算法进行淘汰。 Memcached简单部署安装Memcached前确保libevent和libevent-devel已安装。然后可通过yum或源码包安装。推荐使用yum安装，虽然版本会老一点。 源码包安装，进入解压目录。 1234./configure --prefix=/usr/local/memcached \ --bindir=/usr/bin \ --sbindir=/usr/sbin \ --sysconfdir=/etc 然后make &amp;&amp; make install 服务器端memcached命令参数： 12345678910111213memcached -p # TCP端口，默认为11211 -U # UDP端口，默认0（未开启） -d # 后台运行 -u # 指定验证用户 -m # 内存限制，默认64MB -c # 连接限制，默认1024 -v # 显示详细信息 -t # 使用的线程数，默认4 -R # 每个event最大请求数，默认20 -C # 禁用CAS -M # 不使用LRU清除数据 -L # 启用大内存页，可降低内存浪费 启动Memcached实例 12memcached -m 128m -d -u root -c 8192# 如果要使用root用户启动，必须要加-u 可使用telnet进入Memcached进行操作。telnet 127.0.0.1 11211 memcached命令格式 123&lt;command&gt; &lt;key&gt; &lt;flags&gt; &lt;exptime&gt; &lt;bytes&gt; # 命令&lt;datablock&gt; # 填数据&lt;status&gt; # 返回的状态 命令 说明 command set\get\add\replace\append\prepend\cas key 键名 flags 客户端用来标识数据格式的数值，如json、xml等 exptime 存活时间，0为永远，单位秒（小于30天），unix时间戳（大于30天） bytes 字符个数，不包含\r\n datablock 文本行，以\r\n结尾 status 命令返回状态，STORED\NOT_STORED\NOT_FOUND\EXISTS\ERROR\CLIENT_ERROR\SERVER_ERROR 常用操作 插入数据 123set key1 0 0 5abcdeSTORED 查询数据 1234get key1VALUE key1 0 5abcdeEND]]></content>
      <tags>
        <tag>Memcached</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB基础笔记]]></title>
    <url>%2F2018%2F10%2F29%2FMongoDB%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于MongoDB 4.0.3 MongoDB概述 CRUD 索引 权限 MongoDB概述MongoDB是一个跨平台的基于分布式文件存储的面向文档的数据库，提供高性能，高可用性和易于扩展。由 C++ 语言编写，旨在为 WEB 应用提供可扩展的高性能数据存储解决方案。 MongoDB中的记录是一个文档，由键值对组成。 MongoDB文档类似于JSON对象。字段的值可以包括其他文档，数组和文档数组。 MongoDB特点： 提供高性能数据持久性：对嵌入式数据模型的支持减少了数据库系统的I / O活动。索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键。 丰富的查询语言 高可用性：MongoDB的复制工具称为副本集（replica set），它提供自动故障转移和数据冗余。 副本集是一组MongoDB服务器，它们维护相同的数据集，提供冗余并提高数据可用性。 水平扩展（Horizontal Scalability）：分片将数据分配到集群的不同机器上。支持基于分片键（shard key）创建数据区域（zones of data） 支持主从复制。主服务器可以执行读写操作，从服务器从主机复制数据，只能用于读取或备份 MongoDB能够实现负载均衡 支持多个存储引擎（WiredTiger、In-Memory、MMAPv1） 提供可插拔存储引擎API，允许第三方为MongoDB开发存储引擎 可以将不同结构的文档存储在同一个数据库中 可对任何属性创建索引 支持二进制数据和大型对象 MongoDB结构： database：数据库 collection：集合，对应了SQL的table document：文档，对应了SQL的row，即值 field：域，对应SQL的column字段 index：索引 primary key：主键，MongoDB自动将_id字段设置为主键 安装MongoDB需要安装mongodb-org、mongodb-org-mongos、mongodb-server、mongodb-org-shell、mongodb-org-tools MongoDB默认端口27017，配置文件/etc/mongod.conf。 常见命令： db：显示当前数据库名 show dbs：显示所有数据库，默认有四个，admin、config、local、test use 数据库名：切换数据库，若不存在就会自动创建 db.dropDatabase()：删除数据库，删除前一定要切换到该数据库 show collections：显示当前库中的所有集合 db.collection.drop()：删除指定集合 show users：显示当前数据库的所有用户 MongoDB的数据类型： ObjectID：文档ID，12字节，十六进制数。由以下信息构成： 前4个字节为创建时的时间戳 接下来3个字节为机器ID 接下来2个字节为MongoDB的服务进程ID 最后3个字节为简单的增量值 例：5bd6b780 ba51d7 f829 d135e9 String：字符串，必须是有效的UTF-8 Boolean：布尔值 Integer：整型 Double：浮点型 Arrays：数组或列表 Object：用于嵌入式文档，一个值就是一个文档 Null：Null值 Timestamp：时间戳 Date：当前日期或时间，unix格式 CRUD db.createCollection(name, options)：创建集合。options是一个文档，用于指定集合配置。 db.collection.insertOne()：插入单个文档，若集合不存在，会自动创建 db.collection.insertMany()：插入多个文档 db.collection.insert()：既可以插入单个文档，也可插入多个文档 1234567891011121314151617181920212223db.users.insertOne( &#123; name: &quot;zhangsan&quot;, age: 22, hobby: [&quot;climbing&quot;, &quot;swimming&quot;, &quot;game&quot;] &#125;)db.users.insertMany([ &#123; name: &quot;lisi&quot;, age: 23, hobby: [&quot;swimming&quot;, &quot;game&quot;] &#125;, &#123; name: &quot;wangwu&quot;, age: 25, hobby: [&quot;tennis&quot;, &quot;swimming&quot;] &#125;, &#123; name: &quot;zhaoliu&quot;, age: 21, hobby: [&quot;game&quot;] &#125;]) 在MongoDB中，存储在集合中的每个文档都需要一个唯一的_id字段作为主键。如果插入的文档省略了_id字段，MongoDB驱动程序会自动为_id字段生成ObjectId。 MongoDB中的所有写入操作都是单个文档级别的原子操作。 db.collection.find()：从集合中检索文档 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162db.users.find( &#123;&#125; ) # 显示所有记录&#123; &lt;field1&gt;: &lt;value1&gt;, ... &#125; 直接指定键值查询db.users.find( &#123; name: &quot;zhaoliu&quot; &#125; # name为zhaoliu)&#123; &lt;field1&gt;: &#123; &lt;operator1&gt;: &lt;value1&gt; &#125;, ... &#125; 使用查询运算符指定条件db.users.find( &#123; age: &#123;$gt: 23&#125;, # age大于23 hobby: &quot;climbing&quot; # 且hobby中有climbing &#125;)db.users.find( &#123; $or: [ # or关系 &#123; age: &#123;$gt: 23&#125; &#125;, # 要么age大于23 &#123; hobby: &quot;climbing&quot; &#125; # 要么hobby中有climbing ] &#125;)db.users.find( &#123; age: &#123;$gt: 23&#125;, # age大于23 $or: [ # 下面的为或关系 &#123; hobby: &quot;climbing&quot; &#125;, # 要么hobby中有climbing &#123; hobby: &quot;game&quot; &#125; # 要么hobby中有game ] &#125;)相当于SQL：select * from users where age &gt; 23 and (hobby=&quot;climbing&quot; or hobby=&quot;game&quot;)db.users.find( &#123; age: &#123; $in: [23, 24] &#125; &#125; # 查询age在[23, 24]中的文档)db.users.find( &#123; hobby: [ &quot;swimming&quot;, &quot;game&quot; ] &#125; # hobby必须包含该列表（包括列表中顺序也要一致）)db.users.find( &#123; hobby: &#123; $all: [ &quot;game&quot;, &quot;swimming&quot; ] &#125;&#125; # hobby必须包含该列表（顺序不用一致）)$elemMatch运算符匹配包含数组字段的文档，其中至少有一个元素匹配所有指定的查询条件。例：&#123; _id: 1, results: [ 82, 85, 88 ] &#125;,&#123; _id: 2, results: [ 75, 88, 89 ] &#125;db.scores.find( &#123; results: &#123; $elemMatch: &#123; $gte: 80, $lt: 85 &#125; &#125; &#125;)返回结果为_id为1的文档若包含数组（列表），可通过指定列表的下标进行匹配db.users.find( &#123; &quot;hobby.1&quot;: &quot;climbing&quot; # 查找hobby列表的下标为1的值为climbing的文档，一定要加引号 &#125;)在匹配数组中的文档时，该字典的字段顺序必须完全一致匹配列表中的文章，只要有一项满足就会被匹配例：&#123;&quot;item&quot; : &quot;paper&quot;, &quot;instock&quot; : [ &#123; &quot;warehouse&quot; : &quot;A&quot;, &quot;qty&quot; : 60 &#125;, &#123; &quot;warehouse&quot; : &quot;B&quot;, &quot;qty&quot; : 15 &#125; ] &#125;则db.inventory.find( &#123; &apos;instock.qty&apos;: &#123; $lte: 20 &#125; &#125; )也能匹配到该条文档 db.collection.updateOne()：更新单个文档 db.collection.updateMany()：更新多个文档 db.collection.update()：更新一个或多个文档 db.collection.replaceOne()：替换除_id字段之外的文档的整个内容 db.collection.save()：更新现有文档或插入新文档，用法与update()或insert()一致 12345678910111213141516171819db.users.update( &#123; name: &quot;zhangsan&quot; &#125;, # 指定要改的满足条件的文档 &#123; $set: # 指定$set进行修改 &#123; &quot;hobby.1&quot;: &quot;tennis&quot; &#125; &#125;)db.users.replaceOne( &#123; name: &quot;zhangsan&quot; &#125;, &#123; name: &quot;zhangsan&quot;, age: 24, hobby: [&quot;swimming&quot;, &quot;basketball&quot;, &quot;football&quot;] &#125;)替换文档必须仅包含字段/值对，即不包括更新运算符表达式。_id字段始终是文档中的第一个字段。字段名称的更新（包括重命名）可能会导致文档中字段的重新排序。 db.collection.deleteOne()：删除一个文档 db.collection.deleteMany()：删除多个文档 db.collection.remove()：删除单个文档或与指定过滤器匹配的所有文档。 12345db.users.deleteOne( &#123; name: &quot;zhangsan&quot; &#125;) 索引先创建200000条数据做测试 12345for(i = 0; i &lt; 200000;i++)&#123; db.test.insert( &#123; name: &quot;test&quot;+i &#125; )&#125; 查询指定数据 123456db.test.find( &#123; name: &quot;test10000&quot; &#125;).explain(&apos;executionStats&apos;)# explain(&apos;executionStats&apos;)用于显示查询过程信息 返回结果 1234567&quot;executionStats&quot; : &#123; &quot;executionSuccess&quot; : true, &quot;nReturned&quot; : 1, &quot;executionTimeMillis&quot; : 93, # 花费93毫秒 &quot;totalKeysExamined&quot; : 0, &quot;totalDocsExamined&quot; : 210000,... 创建索引：db.collection.ensureIndex() 12db.test.ensureIndex(&#123; name: 1 &#125;)对name创建索引，1表示升序，-1表示降序 再次执行查询语句，得到以下结果 1234567&quot;executionStats&quot; : &#123; &quot;executionSuccess&quot; : true, &quot;nReturned&quot; : 1, &quot;executionTimeMillis&quot; : 0, # 创建索引后，基本不消耗时间 &quot;totalKeysExamined&quot; : 1, &quot;totalDocsExamined&quot; : 1,... 唯一索引：db.collection.ensureIndex({ name: 1 }, { unique: true }) 联合索引：db.collection.ensureIndex({ name: 1, XXX: 1 })设置多个字段 查看当前集合的所有索引：db.collection.getIndexes() 123456789101112131415161718[ &#123; &quot;v&quot; : 2, &quot;key&quot; : &#123; &quot;_id&quot; : 1 # _id为主键，也是默认的索引 &#125;, &quot;name&quot; : &quot;_id_&quot;, &quot;ns&quot; : &quot;test.test&quot; &#125;, &#123; &quot;v&quot; : 2, &quot;key&quot; : &#123; &quot;name&quot; : 1 # 添加的索引name &#125;, &quot;name&quot; : &quot;name_1&quot;, &quot;ns&quot; : &quot;test.test&quot; &#125;] 删除指定索引：db.collection.dropIndexes(&#39;索引名&#39;) 权限MongoDB采用角色-用户-数据库的管理模式 常见的系统角色： root：只能在admin数据库中可用，是超级用户，具有超级权限 read：允许用户读取指定数据库 readWrite：允许用户读写指定数据库 创建超级管理员 先切换到admin数据库，然后创建 12345678910db.createUser( &#123; user: &apos;admin&apos;, pwd: &apos;123123&apos;, roles: [&#123; role: &apos;root&apos;, db: &apos;admin&apos; &#125;] &#125;) 然后修改MongoDB的配置文件/etc/mongod.conf 找到security配置，删除注释，并添加内容 12security: authorization: enabled 然后重启MongoDB，systemctl restart mongod，再重进mongo 执行show dbs，出现报错，说明授权起作用了 1234567[js] Error: listDatabases failed:&#123; &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;command listDatabases requires authentication&quot;, &quot;code&quot; : 13, &quot;codeName&quot; : &quot;Unauthorized&quot;&#125; :...... 需要指定用户名和密码以及参数--authenticationDatabase admin mongo -u username -p password --authenticationDatabase admin，登录后可以正常操作数据库 为单独的应用创建用户，专门用于该数据库的读写。 首先切换到测试数据库test，创建用户testuser 12 退出MongoDB，重新使用该用户登录 mongo -u testuser -p 123123 --authenticationDatabase test 能查看到的数据库就只有test了，切换到别的数据库也无法查看任何数据]]></content>
      <tags>
        <tag>MongoDB</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重学Docker笔记]]></title>
    <url>%2F2018%2F10%2F12%2F%E9%87%8D%E5%AD%A6Docker%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[重新学习Docker整理，docker版本18.06 Docker安装注意事项 Docker基础命令集 Docker核心原理 Docker镜像管理 Dockerfile Docker监控与安全 Docker安装注意事项官方安装说明页面 若要使普通用户也能有直接操作Docker命令的权限（不需要sudo），可将该用户添加到docker组内。先要确保/var/run/docker.sock所属组为docker。 DaoCloud加速 之后systemctl daemon-reload以及重启docker Docker基础命令集环境信息： docker info：显示docker配置信息 docker version：显示docker版本号 容器生命周期管理： docker create：创建容器 docker exec：对运行的容器执行一条命令 docker kill：杀死容器 docker pause：停止指定容器的所有进程 docker restart：重启容器 docker rm：删除容器 docker run：创建并运行容器。run就是create和start的组合 docker start：启动一个或多个停止的容器 docker stop：停止一个或多个容器 docker unpause：恢复指定容器的所有进程继续运行 镜像仓库管理： docker login：登录到Docker仓库 docker logout：登出Docker仓库 docker pull：拉取镜像 docker push：上传镜像 docker search：搜索镜像 镜像管理： docker build：用Dockerfile构建一个镜像 docker images：查看镜像 docker import： docker load： docker rmi： docker save： docker tag： docker commit：因为容器的变化而构建一个新的镜像 容器运维管理： docker attach：连接进入一个容器 docker export： docker inspect： docker port： docker ps：列出容器 docker rename：重命名一个容器 docker stats： docker top： docker wait： docker cp： docker diff： docker update： 容器资源管理： docker volume：管理数据卷 docker network：管理网络 系统日志信息： docker events：获取一个容器的实时信息 docker history：显示一个镜像的构建历史信息 docker logs：获取一个容器的日志 常用命令调用过程： Docker核心原理namespaceLinux内核虚拟化容器技术（LXC Kernel Namespace），将某个特定的全局系统资源通过抽象方法使得namespace中的进程看起来拥有自己的隔离的全局系统资源实例。LXC提供以下六种隔离的系统调用。 namespace 隔离的资源 UTS 主机名和域名 IPC 进程间通信资源（信号量、消息队列、共享内存） PID 进程编号 Network 网络相关资源（网络设备、网络栈、端口等） Mount 挂载点（文件系统） User 用户与用户组 详细实现原理笔记 cgroupscgroups全称control groups，是Linux内核的一种机制，可根据需求把一系列系统任务及子任务整合到按资源划分等级的不同组内，从而为系统资源管理提供一个统一的框架。即cgroups可以限制、记录任务组所使用的物理资源。 本质上，cgroups是内核附加在程序上的一系列钩子hook，通过程序运行时对资源的调度，触发相应的hook函数，以达到资源追踪和限制的目的。 cgroups特点： cgroups的API以一个伪文件系统实现，用户态的程序可以通过文件操作实现cgroups的组织管理 cgroups的组织操作单元的细粒度可达到线程级别，用户可创建销毁cgroups，实现资源再分配和管理 所有资源管理功能都以子系统方式实现，接口统一 子任务创建之初与父任务处于同一个cgroups控制组 cgroups功能： 资源限制：对任务使用的资源总额进行限制。一旦超出配额就发出OOM（out of memory）的警告 优先级分配：通过分配的CPU时间片数量及磁盘IO带宽大小，实际上就相当于控制了任务运行的优先级 资源统计：统计系统的资源使用量，适合于计费 任务控制：可对任务执行挂起、恢复等操作 cgroups术语： task：任务，表示系统的一个进程或线程 cgroup：控制组，cgroups中资源控制都是以cgroup为单位，表示按某种资源控制标准划分而成的任务组，包含一个或多个子系统。任务可在cgroup间迁移 subsystem：子系统，是一个资源调度控制器 hierarchy：层级，由一系列cgroup以一个树状结构排列，每个层级通过绑定对应的子系统进行资源控制，并且子节点能继承父节点挂载的子系统。 层级规则 规则1：同一个层级可附加一个或多个子系统。事例如图，CPU和Memory子系统附加到一个层级上 规则2：一个子系统可附加到多个层级上（仅当目标层级只有唯一一个子系统时），一个已经附加在某个层级上的子系统不能附加到其他含有别的子系统的层级上。 规则3：每新建一个层级时，该系统上所有任务默认加入这个新建层级的初始化cgroup，称为root cgroup。一个任务不能存在于同一个层级的不同cgroup，但可以存在于不同层级的多个cgroup中。若将一个任务添加到同一层级的另一个cgroup，则会自动将其从第一个cgroup中移除。 规则4：任务在fork/clone自身时创建的子任务默认与原任务在同一个cgroup，但完成后，父子任务间在cgroup方面互不影响。 子系统子系统是cgroups的资源控制系统，每种子系统独立控制一种资源。Docker有以下子系统： blkio：限制块设备输入输出 cpu：控制对CPU的使用 cpuacct：对CPU资源使用情况的报告 cpuset：分配独立的CPU和内存 devices：开启/关闭任务对设备的访问 freezer：挂起/恢复任务 memory：限定任务的内存使用量，并生成内存资源使用报告 perf_event：可进行统一的性能测试 net_cls：控制网络流量，识别数据包 Linux中cgroup表现为一个文件系统，需要mount才能使用。 123456789101112# mount -t cgroupcgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_prio,net_cls)cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct,cpu) 子系统文件都存放在/sys/fs/cgroup目录中。Docker daemon会在每个子系统的控制组目录中创建一个docker控制组，并在其中为每个容器创建一个以容器ID（长ID）为名称的容器控制组，该容器中所有任务的TID（进程或线程的ID）都会写入该控制组的tasks文件。 12345678910111213# tree /sys/fs/cgroup/cpu/docker//sys/fs/cgroup/cpu/docker/├── c146b9740725896dca61d96788acecd80c3bb7f80aedd22359cd78adbfda4fdc│ ├── cgroup.clone_children│ ├── cgroup.procs│ ├── cpuacct.stat| |......│ └── tasks├── cgroup.clone_children├── cgroup.procs├── cpuacct.stat......└── tasks cgroups实现原理cgroups如何判断资源超限并做出措施对于不同系统资源，cgroups提供了统一的接口对资源进行控制和统计。会有描述子系统资源状态的结构体记录所属cgroup，当进程申请更多资源时，会触发cgroup用量检测，若超出限额，则拒绝，否则就给予相应资源并记录在统计信息中，不仅要考虑资源的分配和回收，还要考虑不同类型的资源等。 在超出限额后，会根据信号（如果设置的话）（如内存的OOM信号）决定进程是否挂起或继续执行。 cgroup与任务之间的关联关系cgroup与任务间是多对多关系，并不直接关联，而是通过一个中间结构将双向的关联信息记录。每个任务结构体能通过指针查询对应group的情况，也能查询各个子系统的情况，结构体把子系统状态指针包含进来，并由内核通过container_of宏定义获取对应结构体，关联到任务，实现资源限制。 使用注意Docker需要挂载cgroup文件系统新建一个层级结构，挂载时指定要绑定的系统。除cgroup文件系统外，内核没有为cgroups的访问和操作添加任何系统调用。 无法将一个新的子系统绑定到一个已激活的层级，或从一个层级解除某个子系统的绑定。 只有递归卸载层级中的所有cgroup，该层级才会被真正删除，否则即使上层的层级删除了，后代的cgroup中的配置也会依然生效。 在容器目录下，会有以下固定文件，描述cgroup相应信息。 tasks：在该cgroup中任务的进程或线程ID（无序），意味着把这个任务加入这个cgroup。 cgroup.procs：记录所有在cgroup的TGID（线程组ID，是线程组中第一个进程的ID），意味着将与其相关的线程都加到这个cgroup中。 notify_on_release：是否在cgroup中最后一个任务退出时通知运行release agent，默认为0，不运行。若为1则表示运行 Docker架构采用C/S架构，用户通过Docker client与Docker daemon建立通信。 docker daemon是docker的核心后台进程，响应client的请求，然后调度给容器操作。 docker client向daemon发送请求，可以是命令docker，也可以是使用了docker API的应用。 image management：docker通过distribution、registry、layer、image、reference等模块实现docker镜像管理。 distribution：与docker registry交互，上传下载镜像及存储registry的元数据 registry：与docker registry有关的身份验证、镜像查找、镜像验证等操作 image：与镜像元数据相关的存储、查找、镜像层索引、镜像tar包导入导出的交互操作 reference：存储本地所有镜像的repository和tag名，维护与镜像ID间的映射关系 layer：与镜像层、容器层元数据有关的增删改查，将镜像层操作映射到实际存储镜像层文件系统的graphdriver模块 docker daemon包含的三个主要模块：execdriver（容器执行驱动）、volumedriver（volume存储驱动）、graphdriver（镜像存储驱动） execdriver：是对namespaces、cgroups、selinux等系统操作的二次封装，比LXC功能更全面。默认实现是官方的libcontainer库 volumedriver：是volume存储操作的执行者，负责volume增删改查。默认实现是local，默认将文件存放在docker根目录下volume目录 graphdriver：是所有与容器镜像相关操作的执行者，会在docker工作目录下维护一组与镜像层对应的目录，存放镜像层关系和元数据。主要支持的graphdriver：aufs、btrfs、zfs、devicemapper、overlay、vfs libnetwork：抽象出了容器网络模型（Container Network Model），提供统一接口。抽象除了sandbox、endpoint、network对象，由具体网络驱动操作对象，通过网络控制器的统一接口供调用者管理网络。主要实现：创建网络、创建network namespace、虚拟网卡和所有网络相关配置等 镜像管理Docker镜像的文件内容以及一些运行Docker容器的配置文件组成了Docker容器的静态文件系统运行环境——rootfs。 rootfs是Docker容器在启动时内部进程可见的文件系统，即Docker容器的根目录。docker daemon为Docker容器挂载rootfs时，先将rootfs设为只读（read-only），在挂载完毕后，利用联合挂载（union mount）在rootfs上再挂载一个读写层，使得读写层位于Docker容器文件系统的最顶层，下面是多个只读层。 Docker镜像的特点： 分层 写时复制（copy-on-write）：在多个容器间共享镜像，只有Docker容器运行时文件系统变化时，才会把变化的文件写到可读写层。写时复制减少了镜像对磁盘空间的占用和容器启动时间。 内容寻址存储（content-addressable storage）：该机制根据文件内容索引镜像和镜像层。会对镜像层生成内容哈希值，作为镜像层唯一标识。提高了镜像安全性，并能检测数据完整性。 联合挂载：可以在一个挂载点同时挂载多个文件系统，将挂载点的原目录与被挂载内容进行整合。实现联合挂载的文件系统称为联合文件系统（union filesystem）。 存储管理数据卷网络管理容器安全参考资料 《Docker开发指南》 《Docker容器与容器云》 Docker官方文档 版本18.03]]></content>
      <tags>
        <tag>docker</tag>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laogu-Monitor开发日志]]></title>
    <url>%2F2018%2F10%2F09%2FLaogu-Monitor%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[记录我的个人项目Laogu-Monitor监控系统的开发过程。 2018.10.9开始学习监控系统的开发，基于Django框架。以下是需要考虑的问题： 监控的东西 网络层面：网络流量、延迟、存活状态 系统层面：CPU、内存、磁盘分区、负载 应用层面：mysql、tomcat、nginx、django、HAProxy、Squid等 业务层面：PV、UV 硬件层面：磁盘、温度 监控的模式 主动监控：监控服务器主动向客户端索取数据 好处：不需要安装客户端，简单 坏处：当客户端过多则会出现性能瓶颈，不能灵活定制监控插件 被动监控：客户单主动向监控服务器汇报数据 好处：对服务器端的压力小，能灵活定制监控插件，延迟小 坏处：需要安装客户端（若通过自动化软件可轻松实现，也不能算坏处） 监控需求： 一台主机监控多个不同服务、不同服务间隔可不同 同一服务在不同主机上监控间隔、报警阈值可不同 可批量给主机添加、删除、修改服务 根据不同的服务以及服务的重要程度设置不同的告警级别并通知特定的用户，并且能实现告警升级 监控数据的存储和优化。实现用最少的空间存储最多的有效数据。在一秒内取出一台主机所有服务的5年记录 监控服务器的水平扩展 采用的C/S架构：HTTP 原因： 借口设计简单 容易水平扩展做分布式 Socket稳定成熟、省去较多的通信维护精力 监控数据存储：Redis 暂时列出以下几项规划： 主机监控： 系统状态 网络状态 服务监控： web服务 LB服务（暂不在计划） HA服务（暂不在计划） HPC服务（暂不在计划） 容器监控： docker容器 docker镜像 docker-swarm服务（暂不在计划） kubernetes服务（暂不在计划） 数据库监控： 数据库状态 日志管理： 日志收集 日志分析 自动化运维： 集成ansible功能（暂不在计划） 告警功能 服务发现 网络拓扑 数据存储 用户管理： 权限管理 告警升级（暂不在计划） 访问统计]]></content>
      <tags>
        <tag>运维</tag>
        <tag>监控</tag>
        <tag>自动化</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[信息安全学习笔记（软考）]]></title>
    <url>%2F2018%2F10%2F03%2F%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E8%BD%AF%E8%80%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[软考信息安全工程师的重要知识点整理，不做扩展 目录： 密码学基础 网络安全基础 信息系统安全基础 应用系统安全基础 密码学基础网络安全基础信息系统安全基础应用系统安全基础]]></content>
      <tags>
        <tag>信息安全</tag>
        <tag>软考</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KVM学习笔记]]></title>
    <url>%2F2018%2F10%2F03%2FKVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[虚拟化概述 KVM概述 KVM操作 虚拟化概述KVM概述KVM（Kernel-based Virtual Machine）基于内核的虚拟机，是一个Linux内核模块，使得Linux变成一个Hypervisor（一个虚拟化的管理程序）。 KVM环境首先要查看本机是否支持KVM，KVM基于x86虚拟化扩展技术（Intel VT或AMD-V）。 可通过cat /proc/cpuinfo | egrep &quot;vmx|svm&quot;查看，若有返回，则说明支持。其中vmx是对应Intel的处理器，svm是对应AMD的处理器，根据本机情况查找关键字。 或者可通过lsmod | grep kvm查看，若有该模块也可说明支持。 若用VMware虚拟机，需要在虚拟机的settings中开启虚拟化选项 确保已关闭selinux。 安装kvm相关包（并非都要装） qemu-kvm 主要的KVM程序包 virt-manager GUI虚拟机管理工具（需要桌面环境） virt-top 虚拟机统计命令 virt-viewer GUI连接程序，连接到已配置好的虚拟机 libvirt C语言工具包，提供libvirt服务 libvirt-client 为虚拟客户机提供的C语言工具包 virt-install 基于libvirt服务的虚拟机创建命令 bridge-utils 创建和管理桥接设备的工具 libvirt是KVM的管理工具，包含守护进程程序libvirtd，API库和命令行工具virsh dnf install qemu-kvm libvirt virt-install bridge-utils，这是命令行操作kvm需要的软件。开启KVM服务systemctl start libvirtd，并设置开机启动。 在启动以后，会自动创建一张虚拟网卡 123virbr0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt; mtu 1500 inet 192.168.122.1 netmask 255.255.255.0 broadcast 192.168.122.255 ether 52:54:00:b0:61:8a txqueuelen 1000 (Ethernet) 并且还会启动dnsmasq服务 12nobody 6320 1 0 18:39 ? 00:00:00 /sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/libexec/libvirt_leaseshelperroot 6323 6320 0 18:39 ? 00:00:00 /sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/libexec/libvirt_leaseshelper 网卡的配置存放在/etc/libvirt/qemu/networks/default.xml中。 KVM操作创建一个硬盘qemu-img create -f raw /opt/kvm.raw 10G，这里创建的硬盘虽然还没使用，但会直接占用硬盘空间，需要有一定的大小，因为要装系统。 12# ll -h /opt/kvm.raw -rw-r--r-- 1 root root 1.0G 11月 12 18:49 /opt/kvm.raw 可通过qemu-img info /opt/kvm.raw查看该硬盘的信息 1234image: /opt/kvm.rawfile format: rawvirtual size: 1.0G (1073741824 bytes)disk size: 0` 若硬盘空间不够，就添加虚拟硬盘。注意，需要在虚拟机里有安装的镜像，所以要在虚拟机设置中把镜像设置连接。 然后创建镜像，把/dev/cdrom复制到一个容量足够的目录中。dd if=/dev/cdrom of=/disk/sdb1/fedora25.iso 创建一个虚拟机 123456789101112131415virt-install --virt-type kvm \ --name kvm-fedora \ --ram 512 \ --cdrom=/disk/sdb1/fedora27.iso \ --network network=default \ --noautoconsole \ --os-type=linux \ --os-variant=fedora25 \ --graphics vnc,listen=0.0.0.0 \ --disk path=/opt/kvm.raw 提示开始安装，使用ss -anpt查看端口变化State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 1 *:5900 *:* 开始监听5900端口 此时查看创建的KVM虚拟机，如果没有，可能是没有启动，可通过加上--all显示所有虚拟机 1234# virsh list Id 名称 状态---------------------------------------------------- 1 kvm-fedora running 也可查看本机信息 123456# virsh nodeinfo CPU 型号： x86_64CPU： 4CPU 频率： 2399 MHz.....内存大小： 4027656 KiB 并且，会在/etc/libvirt/qemu/下创建了一个kvm-fedora.xml配置文件。 若没有启动，可通过virsh start kvm-fedora启动虚拟机。 virsh destroy停止指定虚拟机，还能通过virsh list --all查看到 virsh undefine删除标记，即彻底删除该虚拟机 参考资料 KVM —介绍 KVM虚拟化 CentOS7安装KVM虚拟机详解 KVM Cloudman-KVM]]></content>
      <tags>
        <tag>KVM</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenVPN学习笔记]]></title>
    <url>%2F2018%2F10%2F03%2FOpenVPN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <tags>
        <tag>网络</tag>
        <tag>VPN</tag>
        <tag>OpenVPN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集群概念及应用笔记]]></title>
    <url>%2F2018%2F10%2F01%2F%E9%9B%86%E7%BE%A4%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%BA%94%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[集群概念 集群搭建实验集合 集群概念几种服务器性能增强方式： Scale on：向上扩展。也称垂直扩展，在服务器硬件上扩展 Scale out：向外扩展。也称水平扩展，在服务器数量上扩展 LB集群与HA集群的着眼点： LB集群是为了增加请求的并发处理能力，而HA集群是为了增加服务的可用性 RAID阵列与NFS的区别： NFS是文件系统服务器，前端web对数据的请求是文件级别的。属于NAS NAS具有锁机制，因为NAS是服务器，是有操作系统的，这样就不会造成数据的不一致了。 RAID阵列是磁盘，前端web对数据的请求是块级别的。属于DAS DAS就是磁盘，无法设置磁盘锁，因为读写操作是在内存中执行的，读取的数据都是在web服务器中执行操作，不同的web服务器读取同一段数据会造成数据的不一致 但是DAS的速度远高于NAS 一个文件包含多个数据块 资源粘性：资源更倾向于运行在哪个节点 节点间通过Messaging Layer传递资源粘性值，但Messaging Layer并不进行比较，而是在CRM（Cluster Resource Manager集群资源管理器）上比较，指定资源应该运行在哪个节点上。 资源约束：Constraint ​ 排列约束 ​ 位置约束（location） Session共享： 基于Cookie的Session共享： 将全站用户的Session信息加密并序列化后以Cookie的方式统一存放在根域名下，当浏览器访问该根域名下的所有二级域名时，会将域名相对应的所有Cookie内容传递给子服务器，实现用户的Cookie化Session在多个服务器间共享。 优点：无需额外服务器资源。 缺点：受HTTP协议头长度限制，仅存储小部分用户信息。 基于数据库的Session共享： 实用性强，但比较复杂，Session的逻辑淘汰也需要自己实现，并且Session的并发读写能力取决于数据库的性能。 Session复制： 将用户的Session复制到每个要访问的服务器，Tomcat和Weblogic都带有这种机制，但随机器增加，网络负担会成指数上升。 基于Memcached或Redis的Session共享： Memcached和Redis适合用于存放Session，Memcached和Redis中的Hash表具有Expires数据淘汰机制，符合Session的要求。并且这两款数据存储系统的性能都很强，能够应对高并发场景。 会话保持： 会话保持不是Session共享。网站中有时一次操作需要与服务器进行多次交互，并且这几次的交互都是紧密联系的，这要求相关操作都要在一台服务器上完成，不能被负载到其他服务器上。 会话保持就是指在负载均衡器上的机制，可识别客户和服务器间交互的关联性，在做负载均衡的同时，还能保持一系列相关的访问都分配到同一台服务器上。 负载均衡器的会话保存机制： 基于源IP的持续性保持：主要用于四层负载均衡，如Nginx的ip_hash、HAProxy的source算法。 基于Cookie的持续性保持：主要用于七层负载均衡，同一会话的被分配到同一台服务器上。 根据应答报文中是否带有Set_Cookie字段，可分为Cookie插入保持和Cookie截取保持。 基于HTTP报文头的持续性保持：主要用于七层负载均衡，负载均衡器首次收到客户端的请求时，会建立该客户端的表项，记录为该客户端分配服务器的情况。在会话表项生存期内，后续具有相同HTTP报文头的连接都发往同一服务器。]]></content>
      <tags>
        <tag>server</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Puppet自动化工具笔记]]></title>
    <url>%2F2018%2F10%2F01%2FPuppet%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Puppet概述 Puppet概述Puppet是一个基于Ruby开发的主机配置管理工具，采用C/S结构，服务器端称为Puppet Master或Puppet Server，客户端称为Puppet Agent。 Puppet有自己的语言，可管理配置文件、用户、cron任务、软件包、服务等，这些紫铜实体称为资源。 Puppet工作流程 客户端向Master发送认证请求 Master通过认证返回确认信息 客户端调用facter探测主机的变量，如主机名、内存大小、IP地址，然后通过SSL发送给Master Master检测主机名，找到对应node配置，解析内容，只解析facter发来信息与node有关的代码。解析分为：语法检查、生成伪代码catalog，然后发送给客户端 客户端接收伪代码并执行 客户端在执行时判断是否有file文件，若有就向文件服务器发送请求 客户端判断是否有配置report，若有配置，则将结果发送给Master。Master将结果写入日志。 Puppet采用的拉取模式：Agent定期（默认30分钟）向Master发送自身状态。 Puppet服务器和客户端之间通信采用的协议是XMLRPC over HTTPS。 Puppet安装部署首先确保时间同步。然后搭建ruby环境，或者直接安装puppet，也会自动解决依赖。 yum install ruby。ruby版本2.4。puppet到http://yum.puppetlabs.com/ 下载安装官方源。rpm -ivh http://yum.puppetlabs.com/puppetlabs-release-el-7.noarch.rpm以及http://yum.puppetlabs.com/puppet6/puppet-release-el-7.noarch.rpm。 然后用过yum安装puppet-agent和puppet-server，版本为6.0.2。 安装完后，会自动创建用户与用户组puppet。设置/etc/hosts文件，添加客户端。 puppet的配置目录/etc/puppet 12345678puppet/├── auth.conf # 认证配置├── fileserver.conf # 文件服务器配置├── hiera.yaml # ├── manifests # 存放init.pp和其他配置的目录├── modules # 存放模块的目录├── puppet.conf # 主配置文件└── ssl # 存放SSL认证相关的文件，如密钥、证书等 启动puppetmaster服务systemctl start puppetmaster，也可通过命令puppet master --verbose --no-daemonize启动，会显示详细的启动过程。 puppetmaster会开启一个端口8140 在客户端只要安装ruby和 puppet。]]></content>
      <tags>
        <tag>运维</tag>
        <tag>自动化</tag>
        <tag>Puppet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL高可用笔记]]></title>
    <url>%2F2018%2F10%2F01%2FMySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[MySQL高可用概述 MySQL主从复制 MySQL读写分离 MySQL常用调优策略 MySQL高可用概述MySQL主从复制MySQL提供了灵活的主从复制机制，可实现一主一从、一主多从、多主一从、主主复制、联级复制。 MySQL复制原理：MySQL使用二进制日志（默认未启用），二进制日志会记录所有修改数据库的SQL语句。 主服务器上执行了SQL操作后，会记录到二进制日志binlog 从服务器生成两个线程，一个是I/O线程，一个是SQL线程，I/O线程请求主数据库的binlog，将得到的binlog写入中继日志relay log 从数据库的SQL进程读取relay log，并开启事务执行最新的一条SQL指令，实现主从一致 MySQL常用调优策略硬件层优化修改服务器BIOS设置 选择DAPC模式，发挥CPU的最大性能 Memory Frequency（内存频率）选择Maximum Performance 内存设置中启用Node Interleaving，避免NUMA问题 磁盘I/O优化 使用SSD 使用磁盘阵列，并使用阵列卡，同时配备CACHE及BBU模块 RAID尽量选择RAID10，而不是RAID5 文件系统层优化 使用deadline或noop这两种I/O调度器，不要用cfq 使用xfs文件系统，不要用ext3，尽量不用ext4 文件系统挂载mount参数中添加noatime，nobarrier选项 内核参数优化 修改vm.swappiness参数，降低swap使用率，尽量设为5到10，最好不要设为0，防止OOM故障 调整vm.dirty_background_ratio和vm.dirty_ratio参数，确保能持续将脏数据刷新到磁盘，避免瞬时I/O写 调整net.ipv4.tcp_tw_recycle和net.ipv4.tcp_tw_reuse都为1，减少TIME_WAIT，调高TCP效率]]></content>
      <tags>
        <tag>高可用</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DRBD数据同步笔记]]></title>
    <url>%2F2018%2F09%2F30%2Fdrbd%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[DRBD概述 DRBD基础搭建 DRBD概述Distributed Replicated Block Device 分布式复制块设备是一种基于软件的，无共享，复制的存储解决方案。可以实现在网络中的两台服务器之间基于块设备级别的实时或异步镜像或同步复制，类似于rsync+inotify，是基于TCP/IP网络的RAID1。DRBD是基于文件系统底层的，即block层级同步，效率较rsync更快。块设备可以是磁盘分区、LVM逻辑卷、磁盘等。 DRBD工作在文件系统的层级以下，比文件系统更加靠近操作系统内核以及I/O。当DRBD使用在两台HA服务器上，一旦数据写入其中一台的本地磁盘，则该数据会被实时发送到另一台主机，以相同形式记录在文件系统中，实现主备数据同步。 DRBD镜像的特点： 实时：应用程序修改设备上的数据时，会不断进行复制。 透明：应用程序无需知道数据存储在多个主机上。 同步或异步。使用同步镜像，在所有主机上执行写入后，应用程序会收到写入完成的通知。使用异步镜像，当写入在本地完成时，应用程序会收到写入完成的通知，这通常是在数据传播到其他主机之前。 DRBD的核心功能是通过Linux内核模块实现的。具体而言，DRBD构成虚拟块设备的驱动程序，因此DRBD位于系统I / O堆栈的底部附近。因为DRBD的定义以及Linux内核体系结构强制要求，DRBD不依赖于它上面的层，也就无法管理上一层（即文件系统层），例如DRBD无法自动检测文件系统损坏。 其中，File system为API向外输出的接口，Buffer cache用来缓存数据与元数据的，Disk Scheduler是用来排序内存中即将要写入磁盘的数据合并读请求。 DRBD的两种同步模式： 实时同步：当数据写入到本地磁盘和远端所有服务器磁盘都成功后才返回成功写入信息，可以防止本地和远端数据丢失或不一致，在生产环境中最常用。 异步同步：当数据写入到本地服务器成功后就直接返回成功写入信息，不管远端服务器是否写入成功。 DRBD功能两种工作模式： 单主模式（Single-primary mode）：资源在任何给定时间仅在一个集群节点上的主要角色（primary role）中。由于保证只有一个集群节点可以随时处理数据，因此该模式可以与任何传统文件系统（ext3，ext4，XFS等）一起使用。在单主模式下部署DRBD是高可用性（具有故障切换功能）集群的规范方法。 双主模式（Dual-primary mode）：资源在任何给定时间都在集群节点上的主要角色中。由于可以同时访问数据，因此该模式需要使用利用分布式锁管理器的共享集群文件系统，如GFS和OCFS2。在双主模式下部署DRBD是负载均衡集群的首选方法，这些集群需要从两个节点进行并发数据访问。默认禁用此模式，必须在DRBD的配置文件中显式启用。 复制模型（Replication modes）：DRBD支持三种不同的复制模式，允许三种复制同步性。 Protocol A：异步复制协议。一旦本地磁盘写入完成，则认为主节点上的本地写入操作已完成，并且复制数据包已放置在本地TCP发送缓冲区中。在强制故障转移的情况下，可能会发生数据丢失。故障转移后备用节点上的数据是一致的，但是崩溃之前执行的最新更新可能会丢失。协议A最常用于远程复制方案。与DRBDProxy结合使用时，它可以提供有效的灾难恢复解决方案。 Protocol B：内存同步（半同步）复制协议。一旦发生本地磁盘写入，并且复制数据包已到达对端节点，则认为主节点上的本地写入操作已完成。通常，在强制故障转移的情况下不会丢失写入。但是，如果两个节点同时出现电源故障并且主要数据存储的并发，出现不可逆转的破坏，则在主节点上完成的最近写入可能会丢失。 Protocol C：同步复制协议。只有在确认了本地和远程磁盘写入后，才认为主节点上的本地写操作已完成。因此，单个节点的宕机不会导致任何数据丢失。但是如果两个节点（或其存储子系统）同时被不可逆转地销毁，数据丢失也是不可避免的。 生产环境最常用的就是协议C 复制协议的选择会影响部署的两个要素：保护（protection）和延迟（latency）。吞吐量（thoughput）很大程度上与所选的复制协议无关。 脑裂与自动修复 DRBD脑裂：节点间由于网络故障或集群软件错误导致DRBD两个节点都切换为主节点而断开连接。在8版本后，DRBD实现了脑裂的自动修复以及脑裂通知。DRBD提供以下的修复策略： 丢弃较新的主节点的修改，即因脑裂升为主节点的节点。 丢弃老的主节点的修改 丢弃修改较少的主节点的修改。会先比较两个节点的数据，再丢弃修改较少的节点的数据 一个节点数据没有发生变化的情况下完美修复脑裂 DRBD基础搭建准备实验继续沿用heartbeat的实验环境： Ubuntu18.04，heartbeat3.0 ubuntu-s1：172.16.246.155（ens33） heartbeat（ens37）：192.168.60.100 ubuntu-s2：172.16.246.156（ens33） heartbeat（ens37）：192.168.60.101 heartbeat配置沿用实验的。 123456789101112131415161718192021# ha.cf的配置node ubuntu-s1node ubuntu-s2auto_failback onmcast ens33 225.0.0.1 694 1 0bcast ens37 debugfile /var/log/ha-debuglogfile /var/log/heartbeat.loglogfacility local2keepalive 2deadtime 30warntime 10initdead 120# authkeys的配置auth 11 sha1 3c767c41afb12ada140190ed82db3fd930e2efa3# haresources的配置ubuntu-s1 IPaddr::172.16.246.200/24/ens33ubuntu-s2 IPaddr::172.16.246.201/24/ens33 重启heartbeat服务，查看两台主机的IP地址 123456# ubuntu-s1inet 172.16.246.155/24 brd 172.16.246.255 scope global dynamic ens33inet 172.16.246.200/24 brd 172.16.246.255 scope global secondary ens33:6# ubuntu-s2inet 172.16.246.156/24 brd 172.16.246.255 scope global dynamic ens33inet 172.16.246.201/24 brd 172.16.246.255 scope global secondary ens33:6 并且一定要做到时间同步。两台虚拟机都加上一块硬盘，大小设为1G。并且对新加磁盘sdb分区。分两个主分区，一个约800M，一个约200M。800M的作为存储实际业务数据的分区，200M的作为meta data分区，存储drbd同步的状态信息。 123Device Boot Start End Sectors Size Id Type/dev/sdb1 2048 1640447 1638400 800M 83 Linux/dev/sdb2 1640448 2097151 456704 223M 83 Linux 在生产环境中，meta data分区一般给1-2G大小。 分区完后，meta data分区不要格式化建文件系统，且暂时都不要挂载。在sdb1上建文件系统。mkfs.ext4 /dev/sdb1 注：如果数据大小超过2T，则需要用parted命令分区，不能用fdisk了。 安装DRBD，在ubuntu18.04的库中软件叫做drbd-utils，安装即可，版本为8.9，两台都要装。 安装完成后，查看drbd模块是否加载 1234# lsmod | grep drbddrbd 360448 0lru_cache 16384 1 drbdlibcrc32c 16384 4 nf_conntrack,nf_nat,drbd,raid456 源码编译安装drbd驱动，版本为9.0.16。下载源码包，进入解压目录。 直接make &amp;&amp; make install，然后要modprobe drbd。在查看是否加载成功 123# lsmod | grep drbddrbd 550058 0 libcrc32c 12644 4 xfs,drbd,nf_nat,nf_conntrack 还是该网站下载drbd-utils，版本需要看编译驱动后的说明。 12Again: to manage DRBD 9 kernel modules and above,you want drbd-utils &gt;= 9.3 from above url. 这里下载了drbd-utils-9.6的包，进入解压目录 123./configure --prefix=/usr/local/drbd9 \ --with-heartbeat \ 允许heartbeat的haresources脚本 --sysconfdir=/etc/ 设置配置文件目录 然后make &amp;&amp; make install即可。 可能会报错make[1]: *** [drbdsetup.8] 错误 4，需要安装依赖docbook-style-xsl 搭建drbd的配置文件为/etc/drbd.conf和/etc/drbd.d/中的global_common.conf以及所有.res结尾文件，.res结尾的文件是专门用来配置资源的。用于配置drbd参数的文件是global_common.conf，有模板文件/usr/share/doc/drbd-utils/examples/drbd.conf.example.gz参考。 123456789101112global &#123; # 全局配置 usage-count no; # 不允许网站统计开源软件的安装量&#125;common &#123; handlers &#123; &#125; startup &#123; &#125; options &#123; &#125; disk &#123; &#125; net &#123; protocol C; &#125;&#125; 创建资源配置文件heartbeat.res 1234567891011121314151617181920resource data &#123; # 资源名，随便起 protocol C; # 采用协议C disk &#123; # 磁盘配置，可不配 on-io-error detach; &#125; on ubuntu-s1 &#123; # 服务器配置 device /dev/drbd1; # drbd会用专门的设备写数据 disk /dev/sdb1; # 数据存放磁盘 address 192.168.60.200:7789; # 主机的心跳线IP地址，后面的端口不用改 meta-disk /dev/sdb2[0]; # 存放meta data的分区 &#125; on ubuntu-s2 &#123; device /dev/drbd1; disk /dev/sdb1; address 192.168.60.201:7789; meta-disk /dev/sdb2[0]; &#125;&#125; 初始化DRBD的meta data，创建DRBD记录信息的meta data分区元数据。 drbdadm create-md data，其中data就是在res文件中配置的资源名 初始化启动DRBDdrbdadm up data，没报错说明启动成功。查看进程 1234567# ps -ef | grep drbdroot 507 2 0 17:25 ? 00:00:00 [drbd-reissue]root 2682 2 0 20:15 ? 00:00:00 [drbd1_submit]root 2689 2 0 20:15 ? 00:00:00 [drbd_w_data]root 2877 2 0 21:06 ? 00:00:00 [drbd_r_data]root 2902 2 0 21:11 ? 00:00:00 [drbd_a_data]root 2903 2 0 21:11 ? 00:00:00 [drbd_as_data] 如果报错，可能是磁盘分区的问题，或者drbd的meta data创建的问题。 可以通过cat /proc/drbd查看DRBD的状态。以下是初始时的状态。 12345version: 8.4.10 (api:1/proto:86-101)srcversion: 17A0C3A0AF9492ED4B9A418 1: cs:WFConnection ro:Secondary/Unknown ds:Inconsistent/DUnknown C r----- ns:0 nr:0 dw:0 dr:0 al:8 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:818944 如果ro为Secondary/Unknown，说明DRBD没有连通，是网络的问题，检查网卡、路由。修复后再查看。 121: cs:Connected ro:Secondary/Secondary ds:Inconsistent/Inconsistent C r----- ns:0 nr:0 dw:0 dr:0 al:8 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:818944 两台drbd都是Secondary/Secondary则成功。ds为Inconsistent表示两端的数据还不一致。 在ubuntu-s1上使自身成为primary节点，drbdadm primary data，如果报错，可以加--force强制执行。 11: State change failed: (-2) Need access to UpToDate data 再查看两台主机的/proc/drbd，两台主机的ro是相反的。并且已完成了同步 1234567891011# ubuntu-s1 1: cs:SyncSource ro:Primary/Secondary ds:UpToDate/Inconsistent C r----- ns:16976 nr:0 dw:0 dr:17616 al:0 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:802224 [&gt;....................] sync&apos;ed: 3.0% (802224/819200)K finish: 0:04:39 speed: 2,828 (2,828) K/sec# ubuntu-s21: cs:SyncTarget ro:Secondary/Primary ds:Inconsistent/UpToDate C r----- ns:0 nr:41984 dw:41984 dr:0 al:0 bm:0 lo:1 pe:1 ua:0 ap:0 ep:1 wo:f oos:777216 [&gt;...................] sync&apos;ed: 6.0% (777216/819200)K finish: 0:03:05 speed: 4,196 (4,196) want: 8,120 K/sec 如果状态为Secondary/Unknown，还有可能是出现了脑裂。可以在备节点上操作 12drbdadm secondary datadrbdadm connect --discard-my-data data 然后在主节点操作drbdadm connect data，再查看是否解决。 在主节点挂载DRBD设备mount /dev/drbd1 /data，备节点是不能挂载的。 在主节点上测试dd if=/dev/zero of=/data/zero count=1000000，然后在备节点上查看/proc/drbd 121: cs:Connected ro:Secondary/Primary ds:UpToDate/UpToDate C r----- ns:0 nr:575700 dw:575700 dr:0 al:0 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0 容量也同步为500多M，说明数据同步成功。 参考文章 DRBD工作原理及安装配置详解 DRBD原理知识 DRBD官方文档 【高可用HA】HA之DRBD详解（基于CentOS7.0）]]></content>
      <tags>
        <tag>集群</tag>
        <tag>高可用</tag>
        <tag>同步</tag>
        <tag>DRBD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Heartbeat笔记]]></title>
    <url>%2F2018%2F09%2F30%2FHeartbeat%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Heartbeat概念 Heartbeat配置 Heartbeat概念Heartbeat 项目是 Linux-HA 工程的一个组成部分，它实现了一个高可用集群系统。可以将资源（IP及程序服务等资源）从一台故障计算机快速转移到另一台运转正常的机器继续提供服务。 通过修改heartbeat的配置文件，可以指定一台heartbeat服务器作为主服务器，另一台自动成为热备服务器。在热备服务器上面配置heartbeat守护程序来监听来自主服务器的心跳信息。如果在规定时间内，无法监听到心跳信息，那么就启动故障转移，取得主服务器上的相关资源的所有权，接替主服务器继续不间断的提供服务，从而达到资源以及服务高可用的目的。而heartbeat还支持主主模式，即两台服务器互为主备，互相监听，发送心跳报文。 注：heartbeat的业务切换时间大概在5到20秒，所谓的业务不间断其实是保障业务一致，不会造成数据错误。heartbeat的高可用是服务器级别的，而不是服务级别的。 业务切换的常见条件为： 服务器宕机 心跳线故障 heartheat服务本身故障 heartbeat服务器间通信的方法： 串口线缆。线缆专门进行心跳通信，稳定，且不用配IP地址。缺点：服务器距离不能远。 两台服务器网卡通过以太网线直连。推荐使用 两台服务器网卡通过以太网设备连接。不稳定 heartbeat应用场景： 主要用于双机场景，如：web服务器、数据库、文件服务器、负载均衡器、代理服务器 而如果负载均衡采用了LVS，则最好不要使用heartbeat，而是使用keepalived，因为heartbeat没有对下面节点RS的健康状态检查。 heartbeat适合更多机器的连接，keepalived在多机（超过两台）上可能会出问题 需要数据同步的业务最好使用heartbeat，如：mysql双主多从、NFS/MFS等。也可配合drbd服务同步。如果使用inotify+rsync解决了同步问题，也可以用keepalived。 脑裂两台正常运行的高可用服务器在心跳超时内无法监听到对方心跳报文，于是各自启动了故障转移，获取了资源的所有权，两台服务器都拥有同一个VIP地址，数据会出现不一致或丢失，这种情况称为脑裂（split brain）。 发生脑裂的原因： 高可用服务器对之间的心跳链路故障，导致无法正常通信 心跳线故障 网卡或相关驱动故障 IP配置冲突 心跳线间连接的设备故障，如交换机 仲裁机器故障 高可用服务器上开启了防火墙，过滤掉了心跳报文 心跳配置不一致，如心跳方式、心跳广播冲突，以及软件BUG等 防止脑裂的方法： 同时使用串口线缆和一台线缆，组成两条心跳线 检测到脑裂时强行关闭一个节点，若备节点认为主节点故障，则会自动向主节点发送关机命令（此功能需要特殊设备支持，如STONITH、fencing） 对脑裂的告警，及时采取措施 启用磁盘锁，正在提供服务的一方锁住共享磁盘，即使发生脑裂也不会出现数据不一致或丢失情况。 增加仲裁机制。例如设置参考IP地址，若能ping通的服务器则接管服务，ping不通的服务器主动放弃竞争。 STONITH：Shoot-The-Other-Node-In-The-Head，是heartbeat的一个组件，能够保护数据使其不会因为节点异常或者同时访问而遭到损坏。用于集群服务无法停下的情况，在这种情况下，集群可以使用STONITH来强制整个节点离线，并让服务在其它节点上安全启用。 heartbeat消息类型三种heartbeat消息类型： 心跳消息：控制心跳频率和出现故障后进行故障转换的等待时间。可以单播广播和组播，约150字节。 集群转换消息：ip-request和ip-request-resp 当主服务器恢复后，使用ip-request消息要求备机将服务的提供权交还给主服务器。备服务器将服务提供权释放后，通过ip-request-resp通知主服务器，主节点收到后开始正常提供服务 重传消息：rexmit-request控制重传心跳请求 heartbeat IP地址接管及故障转移heartbeat通过IP地址接管和ARP广播进行故障转移。为防止ARP老化时间内，客户端仍请求已故障的服务器，备服务器会进行强制所有客户端进行ARP表项刷新。 VIP为对外提供服务的IP地址，因此需要在DNS上配置将网站的域名解析到这个VIP。有两种手工配置VIP的方法： ifconfig eth0:1 [IP地址] netmask [掩码] up ip addr add [IP地址/掩码] broadcast [该网段广播地址] dev eth1 注：ip addr能看到网卡别名和VIP，而ifconfig无法看到。 Heartbeat配置在红帽系的库（包括epel）中已经没有heartbeat了，在ubuntu的库中还有，所以用ubuntu做实验。ubuntu版本18.04，heartbeat版本3.0.6。 heartbeat的默认配置文件目录为/etc/ha.d，主要的配置文件存放在/usr/share/doc/heartbeat中。 ha.cf.gz，是被gz压缩的，解压后得到ha.cf。是heartbeat的参数配置文件 authkeys，是heartbeat认证文件 haresources.gz，也是gz压缩，解压得到haresources，是heartbeat资源配置文件 将这三个文件复制到/etc/ha.d中 heartbeat的资源目录为/etc/ha.d/resources.d/，可以将开发的程序直接放在该目录中，然后在haresources中调用。 实验环境： 两台ubuntu作为负载均衡器，要有双网卡，一个提供服务，一个做心跳线 负载均衡器1（master）：172.16.246.155（网卡ens33） heartbeat网卡：192.168.60.100（网卡ens37） 负载均衡器2（backup）：172.16.246.156（网卡ens33） heartbeat网卡：192.168.60.101（网卡ens37） 设置好/etc/hosts，使能通过主机名访问，主机名要和uname -n的结果一致。 配置文件参数列举的是常用参数，并没有修改为实验用的值 ha.cf123456789101112debugfile /var/log/ha-debug # 调试日志位置logfile /var/log/ha-log # 日志位置logfacility local0 # 日志设备keepalive 2 # 心跳间隔 deadtime 30 # 认为主节点宕机的超时时间warntime 10 # 心跳延迟时间，备份节点无法接收主节点的心跳时就会往日志写入一个警告日志initdead 120 # heartbeat在首次运行后，需等待120秒才能启动主服务器的资源。取值至少为deadtime的两倍udpport 694 # UDP端口，默认为694mcast eth0 225.0.0.1 694 1 0 # 多播端口auto_failback on # 是否开启自动故障恢复。因故障而切换的资源是否要在主节点恢复后再切回主节点bcast eth0 # 广播端口node XXX # 节点名，先定义的是主节点，后定义的都是备用节点 authkeys12345# 可用的加密算法：crc、sha1、md5。crc不需要密码。官方推荐sha1和md5。crc没有安全性auth 11 crc2 sha1 HI!3 md5 Hello! 注：authkeys文件的权限必须是600，否则无法启动heartbeat haresources只要添加heartbeat的两台主机即可，指定VIP，无须手动创建 123ubuntu-s1 IPaddr::172.16.246.200/24/ens33ubuntu-s2 IPaddr::172.16.246.201/24/ens33# 其中的IPaddr是/etc/ha.d/resources.d/中的IPaddr脚本 实际配置ha.cf配置，两台都要配 123456789101112debugfile /var/log/ha-debuglogfile /var/log/heartbeat.loglogfacility local2keepalive 2deadtime 30warntime 10initdead 120mcast ens33 225.0.0.1 694 1 0bcast ens37 auto_failback onnode ubuntu-s1node ubuntu-s2 authkeys配置，先用命令sha1sum -t输入密码生成密钥。然后复制到文件中，只保留sha1。 12auth 11 sha1 3c767c41afb12ada140190ed82db3fd930e2efa3 修改haresources，配置的是VIP，不需要手动创建 12ubuntu-s1 IPaddr::172.16.246.200/24/ens33ubuntu-s2 IPaddr::172.16.246.201/24/ens33 这三个文件都要做到两端一致（除了日志的设定可以不一致）。然后启动heartbeat，systemctl start hearthbeat 等待initdead的时间后，查看网卡，可以发现VIP的网卡已自动创建 123ens33:1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.16.246.200 netmask 255.255.255.0 broadcast 172.16.246.255 ether 00:0c:29:93:da:9b txqueuelen 1000 (Ethernet) 模拟一台宕机，关闭ubuntu-s1的heartbeat，查看ubuntu-s2。发现成功迁移。 1234567ens33:1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.16.246.201 netmask 255.255.255.0 broadcast 172.16.246.255 ether 00:0c:29:e5:d5:55 txqueuelen 1000 (Ethernet)ens33:2: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.16.246.200 netmask 255.255.255.0 broadcast 172.16.246.255 ether 00:0c:29:e5:d5:55 txqueuelen 1000 (Ethernet) 重启ubuntu-s1的heartbeat，再查看ubuntu-s2的网卡，已经迁移回去，因为开启了auto_failback 123ens33:1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.16.246.201 netmask 255.255.255.0 broadcast 172.16.246.255 ether 00:0c:29:e5:d5:55 txqueuelen 1000 (Ethernet) 将apache交给heartbeat管理将命令apachectl复制到/etc/ha.d/resource.d/中，然后修改haresources文件，在一个主机的最后加上apachectl 1ubuntu-s1 IPaddr::172.16.246.200/24/ens33 apachectl 注意： 脚本要放在/etc/ha.d/resource.d/中 脚本的执行要有start和stop两个参数 脚本要有可执行权限 haresources文件中的脚本名一定是resource.d中的指定脚本 关闭apache和heartbeat，然后只启动heartbeat，但是apache也被启动了。可看到日志中 1ResourceManager(default)[8373]: info: Running /etc/ha.d/resource.d/apachectl start heartbeat两种方法实现高可用： 仅控制VIP资源转移，而不负责资源的启动与关闭。一般用于web服务 既控制VIP资源转移，又负责资源的启动与关闭。一般用于数据库、存储服务，为了控制数据一致性，防止两台都在写。 故障排查若主节点出现故障，可以使用命令hb_standby将业务推到备节点，再对主节点配置进行检查。该脚本存放在/usr/share/heartbeat/中。 将故障排除后，还可执行脚本/usr/share/heartbeat/hb_takeover再次接管业务。 参考文章 Heartbeat介绍 Heartbeat高可用解决方案 heartbeat单独提供高可用服务]]></content>
      <tags>
        <tag>server</tag>
        <tag>集群</tag>
        <tag>高可用</tag>
        <tag>heartbeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sed与Awk笔记]]></title>
    <url>%2F2018%2F09%2F29%2FSed%E4%B8%8EAwk%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Sed Awk Sedsed是一个面向字符流的编辑器，对文本进行过滤和替换操作，sed一次仅读取一行进行操作，适合处理大数据文件。可在一个或多个文件上自动实现编辑，简化对多个文件执行相同的编辑处理工作。 sed默认不修改源文件，仅仅修改输出信息，sed先将从文件读入的内容放入缓冲区，称为模式空间，在模式空间中对文件的副本操作，再输出到屏幕。 12345678910sed [选项]... [输入文件]... -n, --quiet, --silent 静默模式，结果不显示到屏幕 -e 脚本 添加脚本指令，可添加多个 -f 脚本文件 添加脚本文件 --follow-symlinks 直接修改文件时跟随软链接 -i[SUFFIX] 直接修改源文件，若指定SUFFIX前缀，则进行对源文件的备份 -l N 指定l命令（输出非打印字符）可输出的行长度 --posix 关闭所有 GNU 扩展 -s, --separate 默认sed将输入的多个文件名当做一个长的输入流，而GNU sed允许看做单独的文件 -u, --unbuffered 从输入文件读取最少的数据，即最低限度的缓存输入和输出 sed的指令：[地址]指令 内容，在sed中/称为定界符，也可用其他的符号作为定界符，如:或|等。 a：append追加，若不指定行数，则会在每一行后都添加一行内容 1234例：sed &apos;2a XXXXX&apos; 文件 在文件的第二行后添加一行内容XXXXX sed &apos;/XXX/a XXXXX&apos; 文件 在所有包含XXX的行后添加一行XXXXX sed &apos;1,4a XXXXX&apos; 在第1到4行后添加一行XXXXX sed &apos;$a XXXXX&apos; 在最后一行后添加一行，$表示最后一行 i：insert插入，是在行前添加一行内容，若不指定行数，则在每一行前添加 12例：sed &apos;2i XXXXX&apos; 文件 在第二行前添加一行XXXXX sed &apos;/XXX/i XXXXX&apos; 在包含XXX的行前添加一行XXXXX d：delete删除 1234例：sed &apos;2d&apos; 删除第二行 sed &apos;/^$/d&apos; 删除空白行 sed &apos;1~2d&apos; ~用于指定从第几行开始的指定步长行的内容 1~2用于指定第1行开始的两行，即第1,2行 s：substitution替换 123例：sed &apos;s/XXX/XXXX/&apos; 将XXX替换为XXXX，会替换第一个匹配的 sed &apos;s/XXX/XXXX/n&apos; 只替换第n个匹配的XXX，n的范围是1-512 sed &apos;s/XXX/XXXX/g&apos; 对模式空间的所有匹配都更改 c：替换 1例：sed &apos;/XXX/c XXXXX&apos; 将包含XXX的一行替换为XXXXX p：打印 12例：sed &apos;s/XXX/XXXX/p&apos; 替换后，打印替换后的句子（会重复打印）以及其他未替换的内容 若和-n一起使用，则只打印进行处理的行 n：一遇到匹配的行就立刻移动到下一行 若要执行多个指令，则指令间用逗号分隔，或通过-e 指令1 -e 指令2...指定，最好通过文件添加指令，然后通过-f指定指令文件。 还可使用/XXX/ {指令/内容}替换：匹配的语句支持正则表达式 123456例：&lt;body&gt;hello&lt;body&gt; sed &apos;s/body/\/body/2&apos; 将第二个body换为/body，还可用&#123;&#125;实现 sed &apos;/body/ &#123;s//\/body/2&#125;&apos; 就是s/后的要替换的内容提前到前面 还可以用&amp;替换要替换的部分 sed &apos;/body/ &#123;s//\/&amp;/2&#125;&apos; 正则表达式\w\+匹配每一个单词，例：将每个单词都添加一个[] sed &#39;s/\w\+/[&amp;]&#39; \n匹配子串，n表示第n个子串，用\(XXX\) 匹配子串，会将XXX作为主串，将XXX后的字符串作为子串，例：将abcdefg中的efg替换为fff：sed &#39;s/\(abcd\)efg/\1fff&#39; 可通过在匹配的行间添加逗号选定行范围：sed &#39;/efg/,/abc/&#39; 将指定的内容添加到匹配的行下面：使用a\指令，sed &#39;/abc/a\test&#39;，将test字符串插入到匹配包含abc的行的下面。同理，i\将指定内容添加到匹配的行上面 打印奇数行：sed -n &#39;p;n&#39;或sed -n &#39;1~2p&#39;打印偶数行：sed -n &#39;n;p&#39;或sed -n &#39;2~2p&#39; AwkAwk是一种模式匹配的程序设计语言，用于对文本和数据进行扫描和处理，常用操作是将数据转换为格式化的报表。常见的awk编译器版本有awk，gawk，gawk与awk一致。 awk先逐行扫描文件，寻找匹配特定模式的行，并进行操作。因此，awk基本结构就是由模式匹配和处理动作组成。]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>sed</tag>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix搭建笔记]]></title>
    <url>%2F2018%2F09%2F28%2Fzabbix%E6%90%AD%E5%BB%BA%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[zabbix概述 zabbix搭建 zabbix操作 zabbix概述Zabbix是一个企业级开源的分布式监控套件，可以监控网络和服务的监控状况。 zabbix组成：zabbix server和zabbix agent Zabbix Server可通过SNMP、Zabbix_agent、ping、端口扫描等方法提供对远程服务器的监视 Zabbix Agent安装在需要被监控的目录服务器上收集信息。监听端口10050 zabbix核心组件： zabbix server：收集agent的监控信息，对数据统计操作，设置配置。zabbix server可单独监控，也可与agent结合。可轮询agent主动接收监控数据，也可被动接收。监听端口10051 zabbix databases：存储所有配置信息，以及监控数据。一般可以是：mysql，oracle，sqlite zabbix web GUI：通常与server运行在同一主机上（可在不同主机），用于可视化操作 zabbix可选组件： proxy：代理服务器，用于分布式监控环境，代理server接收agent的监控数据，汇总后统一发往server agent：被监控主机，收集本地数据 zabbix也可用于监控java应用，可基于JMX组件监控JVM zabbix服务进程： zabbix_agentd：zabbix agent的守护进程 zabbix_server：zabbix server的守护进程 zabbix_get：zabbix的一个工具，用于拉取远端客户端的信息，通常用于排错。需要安装zabbix-get zabbix_sender：zabbix的一个工具，用于主动推送数据给server或proxy，通常用于耗时较长的检查或大量主机监控的场景。需要安装zabbix-sender zabbix_proxy：zabbix proxy的守护进程。需要安装zabbix-proxy-mysql|pgsql|sqlite3 zabbix_java_gateway：java网关，用于监控java应用环境，类似agentd。只能主动推送数据。 常用术语： 监控项item：一个特定的监控指标的数据，监控项是zabbix数据收集的核心 触发器trigger：一个表达式，用于评估某监控对象的某特定item内所接收的数据是否在合理范围内，即阈值。当数据量大于阈值时，触发器状态从ok变为problem 事件event：发生的事情，如触发器状态的变化，新的agent或agent重新注册 动作action：指对特定事件事先定义的处理方法，包含操作与条件 报警升级escalation：发送警报或执行远程命令的自定义方案 媒介media：发送通知的手段或通道，如Email，jabber，SMS 通知notification：通过选定的媒介向用户发送的有关某事件的信息 远程命令：预定义的命令，可在被监控主机处于某特定条件下自动执行 模板template：用于快速定义被监控主机的预设条目集合，包含item，trigger，graph，screen（多个graph），application，low-level discovery rule。模板可以直接链接到单个主机 应用程序application：一组item的集合 web场景web scennaria：用于检测web站点可用性的一个或多个http请求 Zabbix特点： 配置简单：可使用模板，直接添加监控设备、可配置组监控、可对模板继承，进行精细设定 实时绘图，自定义监控图表（面板），支持网络拓扑图 灵活的告警机制：可自定义告警升级（escalation）、接受者和告警方式，还可通过远程命令实现自动化动作action 可进行不同类型数据的收集：性能、SNMP、IPMI、JMX，可自定义收集数据的间隔 数据存储：可将数据存放在数据库中，并内置数据清理机制 网络自动发现机制：自动发现网络设备、文件系统、网卡等，agent自动注册 zabbix由C开发，高性能，内存消耗低。web前段由php编写 提供丰富的API 可进行权限认证，并进行访问控制 zabbix搭建搭建zabbix监控服务器端 zabbix需要LAMP或LNMP的环境，先安装以下环境gcc gcc-c++ autoconf automake zlib zlib-devel openssl openssl-devel pcre-devel 安装php环境：yum install php php-fpm 安装mysql/mariadb环境：yum install mariadb* LNMP/LAMP环境搭建Zabbix可通过yum安装nginx，但版本不是最新的。通过源码安装nginx版本为1.14。 首先创建nginx用户及用户组。然后下载源码包并解压，进入目录 1234567891011121314151617181920./configure --prefix=/usr/local/nginx \ --sbin-path=/usr/sbin/nginx \ --conf-path=/etc/nginx/nginx.conf \ --error-log-path=/var/log/nginx/error.log \ --pid-path=/var/run/nginx/nginx.pid \ --lock-path=/var/lock/nginx.lock \ --user=nginx \ --group=nginx \ --http-log-path=/var/log/nginx/access.log \ --http-client-body-temp-path=/var/tmp/nginx/client \ --with-http_ssl_module \ --with-http_stub_status_module \ --with-http_gzip_static_module \ --with-http_dav_module \ --with-http_stub_status_module \ --with-http_addition_module \ --with-http_flv_module \ --with-http_mp4_module \ --with-http_sub_module \ --with-debug 进入/etc/nginx/nginx.conf添加一行user nginx nginx 安装zabbix，首先去官网选择主机环境版本下载页，安装zabbix的repo源。 1rpm -i https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm 然后安装zabbix-server-mysql zabbix-web-mysql zabbix-agent zabbix-web 若是客户端，不需要搭建LAMP或LNMP环境，只需要安装repo源和zabbix-agent和zabbix-sender，并且zabbix-sender也不是必须安装，若要主动向zabbix服务器发送监控数据时才需要安装。 zabbix的几个目录： /etc/zabbix：zabbix配置目录 /var/log/zabbix：zabbix日志目录 /var/run/zabbix：zabbix运行目录 /usr/lib/zabbix：zabbix库文件目录 /usr/share/zabbix：zabbix的web文件目录 修改nginx配置文件，找到下面配置，修改fastcgi_param后的路径为/usr/share/zabbix 1234567location ~ \.php$ &#123; root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/share/zabbix$fastcgi_script_name; include fastcgi_params;&#125; 在mysql创建zabbix库，和管理数据库的用户zabbix 123create database zabbixdb;grant all on zabbixdb.* to zabbix@127.0.0.1 identified by &apos;zabbix&apos;;flush privileges; 导入zabbix的sql文件，sql文件存放在/usr/share/doc/zabbix-server-mysql-3.4.14/create.sql.gz中，用gunzip create.sql.gz解压，然后导入mysql -u root -p zabbixdb &lt; create.sql 修改/etc/zabbix/zabbix_server.conf 1234DBHost=localhostDBName=zabbixdbDBUser=zabbixDBPassword=zabbix 安装zabbix后，会自动创建系统用户zabbix，但这个用户是设置了无法登录，而zabbix不允许。需要重新创建 zabbix命令 1234567891011121314zabbix_server -c 指定配置文件，默认/etc/zabbix/zabbix_server.conf -f 在前台运行zabbix_server -R 执行运行时管理功能，功能如下 config_cache_reload 重新读取配置缓存 housekeeper_execute 执行housekeeper log_level_increase=target 提升日志等级，若不指定target则影响zabbix所有进程 log_level_decrease=target 降低日志等级，同上 #target可以是PID，进程类型zabbix_agentd 与zabbix_server参数一致，并多了下面的配置 -p 显示已知的items -t 测试指定的item 启动zabbix_server服务systemctl start zabbix-server.service或zabbix_server启动 在apache或nginx配置文件中创建虚拟主机后，通过浏览器访问 1234567891011121314151617181920212223242526# apache虚拟主机配置&lt;VirtualHost *:80&gt; ServerName &quot;zabbix.monitor1.com&quot; DocumentRoot &quot;/usr/share/zabbix&quot; &lt;Directory &quot;/usr/share/zabbix&quot;&gt; Require all granted AllowOverride None &lt;/Directory&gt;&lt;/VirtualHost&gt;# nginx虚拟主机配置server &#123; listen 80; server_name zabbix.monitor1.com; location / &#123; root /usr/share/zabbix; index index.php index.html; &#125; location ~ \.php$ &#123; root /usr/share/zabbix; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/share/zabbix$fastcgi_script_name; include fastcgi_params; &#125;&#125; 根据网页提示，修改php配置文件/etc/php.ini 12# 时区错误date.timezone = Asia/Shanghai 全部修改完成后重启php-fpm和httpd。再次访问安装界面，完成安装。默认登录用户为admin，默认登录密码zabbix 在监控主机上需要修改配置文件/etc/zabbix/zabbix_agentd.conf 12最基本就只需要修改一项Server = 监控服务器的IP地址 并且默认不能以root身份运行zabbix_agentd，可以修改配置文件 123AllowRoot=1 # 是否允许root运行agentd，1为允许，0为不允许或修改User=zabbix # 运行agentd的用户，需要取消注释 使用zabbix_get工具检查是否能获取数据 12# zabbix_get -s 192.168.80.128 -p 10050 -k &quot;system.uptime&quot;198526 zabbix操作 监控一台主机 详细配置操作 监控一台主机配置用户 Administration —&gt; Users 创建一个用户 设置用户媒介（如何通知） 官方文档详细配置说明 配置主机 Configuration —&gt; Hosts 默认已存在一个主机Zabbix server，监控本机。在Create host添加新主机。 注：如果是虚拟机主机，则需要在同一个网段 添加监控项 Configuration —&gt; Hosts —&gt; Items —&gt; create items 有几个需要填写的项： Name：监控项名 Key：监控项技术上的名称，即要获取的信息 Type of information：信息类型，即数据格式，有Numeric（无符号/浮点）、character、log、text 其他选项详情 第一次获得的监控项值最多需要60秒才能到达。然后，默认30秒更新一次，可通过Update interval修改 然后在Monitoring的Lateset data中添加显示的主机或主机组。然后在下面添加项的右侧Graph查看图像。 新建触发器 Configuration —&gt; Hosts —&gt; Triggers —&gt; Create trigger 触发器表达式可直接Add选择，也可手动编写，触发器表达式语法 可在Monitroing的Problems中添加问题报告的主机和触发器。 触发器表达式格式： 1234567&#123;&lt;server&gt;:&lt;key&gt;.&lt;function&gt;(&lt;parameter&gt;)&#125;&lt;operator&gt;&lt;constant&gt;# server：主机名# key：监控项的键# function：触发器函数# parameter：触发器函数的参数（如果有的话）# operator：判断符号。有：&gt;、&lt;、&lt;&gt;、&gt;=、&lt;=、=# constant：常数值，即判断的数值 常见触发器函数 diff：返回值若为1表示最近的值与之前不同，0为无变化 last：获取最近的值。需要指定参数#num，为最近的第num个值。例：last(#2) avg：返回一段时间的平均值。例：avg(5)为最近5秒的平均值，avg(#5)为最近五次的平均值，avg(3600,86400)为一天前的一个小时的平均值 change：返回最近获得值与之前获得值的差值，返回字符串0表示相等，1表示不等。 nodata：是否能接收到数据，返回1表示指定的间隔内未收到数据，0表示正常接收数据 count：返回指定时间间隔内数值的统计 sum：返回指定时间间隔中收集的值的总和。例：sum(600)表示600s内接收到所有值的和，sum(#5)表示最后5个值的和 设置通知 Administration —&gt; Media Types zabbix中提供的几种媒介（Media）类型： Email：电子邮件 SMS：手机短信，通过连接至zabbix服务器GSM Modem发送通知 Jabber：jabber消息。Jabber是一个开放的基于XML的协议，能实现基于Internet的即时通讯服务 自定义脚本通知：调用位于配置文件的AlertScriptsPath变量定义的脚本目录中的脚本 Email的配置。 一个媒体类型必须通过发送地址来关联用户，否则它将无法生效。 发送通知是Zabbix中动作（actions）执行的操作之一，因此为了建立一个通知，需要创建动作。 Configuration —&gt; Actions —&gt; Create action 新建模板 Configuration —&gt; Templates —&gt; Create template 在Configuration的Hosts中选择一个主机的item，并点击Copy进行复制，在复制界面选择目的模板 通过此法向模板中添加监控项。 在Host的主机配置表中，选择Templates，然后添加模板，先点select选模板，然后add添加。 新建图表 Configuration —&gt; Hosts —&gt; Graphs —&gt; Create graph show legend：是否显示图例 percentile line：是否显示百分位线，用作参考 Graph type：有四种图表 Normal：普通线图 Stacked：堆图 Pie：饼图 Exploded：爆炸图（分裂的饼图） 详细配置操作主机资产管理 Configuration —&gt; Hosts —&gt; Host inventory 有三种设置模式：disabled（关闭）、manual（手动）、automatic（自动） 手动模式需要输入设备类型、序列号等信息。自动模式会自动填充，需要在监控项中添加一些项才能实现。 1234567system.hw.chassis[full|type|vendor|model|serial] - 默认是 [full], 需要root权限system.hw.cpu[all|cpunum,full|maxfreq|vendor|model|curfreq] - 默认是[all,full]system.hw.devices[pci|usb] - 默认是 [pci]system.hw.macaddr[interface,short|full] - 默认是 [all,full], interface支持正则表达式system.sw.archsystem.sw.os[name|short|full] - 默认是 [name]system.sw.packages[package,manager,short|full] - 默认是 [all,all,full], package支持正则表达式 可在Inventory中的Hosts查看配置的主机现有资产数据。 批量更新一次更改多个主机的某些属性。 Configuration —&gt; Hosts 选中多个主机，点下方的Mass update。 Host选项卡： Replace host groups：从任何现有主机组中删除主机，并替换为该字段中指定的主机 Add new or existing host groups：从现有主机组指定其他主机组 Remove host groups：从主机中删除特定主机组 Templates选项卡： Link Templates：指定模板，可选择替换或添加。Clear when unlinking选项将不仅可以取消链接任何以前链接的模板，还可以删除所有继承自它们的元素（监控项、触发器等）。 Zabbix事件事件是基于时间戳进行标记的，是采取动作的基础，来源于三个途径： 触发器事件：每次触发器状态改变就会生成相应事件 发现（discovery）事件：zabbix会周期性扫描网络发现规则中的指定IP范围，一旦发现主机或服务，就会生成发现事件 有8类发现事件：Service Up，Service Down，Host Up，Host Down，Service Discovered，Service Lost，Host Discovered，Host Lost 主动agent自动发现事件：也称自动注册事件，当一个此前状态未知的主动agent发起检测请求时会生成该类事件 因此，Zabbix的通知机制也称为基于事件的通知机制。 触发器当每次采集的数据超出了设置的触发器阈值，则触发器状态会变为Problem，若数据在范围之内，则触发器状态变为OK。 事件成功迭代（OK event generation）设置，用于控制如何生成正常事件（OK event） 表达式（Expression）：当表达式结果为FALSE，Problem会生成一个OK事件 恢复表达式（Recovery expression）：当表达式结果为FALSE，且恢复表达式结果为TRUE，Problem状态会变为OK事件。如果触发器的恢复条件和问题标准不同，则可以使用此设置。 无（None）：正常事件从来不生成。可以和多重问题事件生成一起结合使用，以便在某事件发生时可以更简单的发送通知。 事件成功关闭（OK event closes）设置，用来控制哪些问题事件（Problem events）被关闭 所有问题（All problems）：正常事件（OK event）将关闭触发器创建的所有打开的问题 所有问题如果标记的值匹配（All problems if tag values match）：正常事件（OK event）将关闭触发器创建的打开的问题，并且至少有一个匹配的标记值。 触发器的严重性： 未分类（Not classified）：未知严重性（灰） 信息（Information）：提示（浅蓝） 警告（Warning）：警告（黄） 一般严重（Average）：一般问题（橙） 严重（High）：发生重要的事（浅红） 灾难（Disaster）：灾难，财务损失（红） 触发器提示颜色可在Adminstration —&gt; General —&gt; Trigger severities中修改 事件关联是一种设置自定义事件关闭（导致正常事件生成）的规则，该规则定义了新的问题事件如何与现有的问题事件配对，并通过生成相应的正常事件来关闭新的事件或匹配事件。 action参考文章 zabbix官方中文手册 51cto专栏——无监控 不运维 朱双印个人日志-zabbix]]></content>
      <tags>
        <tag>运维</tag>
        <tag>监控</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lucene与Solr笔记]]></title>
    <url>%2F2018%2F09%2F26%2FLucene%E4%B8%8ESolr%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[ELK与EFK详细笔记]]></title>
    <url>%2F2018%2F09%2F24%2FELK%E4%B8%8EEFK%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容： ELK Elasticsearch Logstash Kibana Beats ELK架构 EFK Fluentd EFK架构 Elasticsearch Elasticsearch是基于Lucene的搜索框架，使用Java编写，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口，上手容易，拓展节点方便，可用于存储和检索海量数据，接近实时搜索，海量数据量增加，搜索响应性能几乎不受影响。 Apache Lucene：目前存在的拥有最先进，高性能和全功能搜索引擎功能的库。但仅仅是一个库，Elasticsearch则是提供了Lucene库的RESTful API接口，将所有的功能打包成一个单独的服务，做到”开箱即用“。 Elasticsearch主要特点： 全文检索，结构化检索 数据统计、分析，接近实时处理 分布式搜索（可部署数百台服务器） 自动发现节点 副本机制 处理PB级别的结构化或者非结构化数据 保障可用性 搜索纠错，自动完成 与各种语言基础，与Hadoop、Spark等大数据分析平台集成 使用场景：日志搜索，数据聚合，数据监控，报表统计分析 使用Elasticsearch的大企业：维基百科、卫报、StackOverflow、Github、ebay Elasticsearch安装 因为Lucene和Elasticsearch都是Java写的，所以首先搭建JDK环境，下载JDK1.8，设置环境变量，并source /etc/profile应用 123echo &quot;export JAVA_HOME=/usr/local/jdk1.8&quot;&gt;&gt;/etc/profileecho &quot;export CLASSPATH=$JAVA_HOME/lib&quot;&gt;&gt;/etc/profileecho &quot;export PATH=$JAVA_HOME/bin:$PATH&quot;&gt;&gt;/etc/profile 下载Elasticsearch，目前版本为6.4.1，解压到/usr/local/elasticsearch-6.4 不能使用root运行elasticsearch，需要创建一个用户 12useradd elasticchown -R elastic:elastic /usr/local/elasticsearch-6.4 切换到该用户，并执行elasticsearch。等待一段时间启动，然后执行curl localhost:9200查看。若看到json对象信息则说明成功。 12345678910111213curl localhost:9200&#123; &quot;name&quot; : &quot;3dcAoxl&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;GNdmHFuXTsK-6B-swVNQag&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.4.1&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;,...... &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 运行报错 12bootstrap checks failed #bootstrap检查失败max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] #最大虚拟内存太低 解决： 临时解决： sysctl -w vm.max_map_count=262144 永久解决：修改/etc/sysctl.conf文件，添加 vm.max_map_count设置，并执行sysctl -p 1max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 解决：修改unix最大同时打开文件数，ulimit -n 65536 1234567elasticsearch -E &lt;键值对&gt; 设置参数 -d, --daemonize 后台启动 -p, --pidfile &lt;Path&gt; 设置PID文件 -q, --quiet 静默启动 -s, --silent 显示最少的输出 -v, --verbose 显示详细输出 Elasticsearch配置文件ES核心配置文件config/elasticsearch.yml 12345cluster.name: my-application #集群名称，若相同，且是同一网段会自动加入node.name: node-1 #当前节点名称node.attr.rack: r1 #network.host: 127.0.0.1 #默认情况下，Elastic只允许本机访问 #若要远程访问，取消注释并修改值为0.0.0.0 JVM配置文件jvm.option，最好不要调。 12345678-Xms1g #最小堆内存-Xmx1g #最大堆内存#两个值最好一致，且为机器物理内存的一半到2/3，也不能太小-XX:+UseConcMarkSweepGC-XX:CMSInitiatingOccupancyFraction=75-XX:+UseCMSInitiatingOccupancyOnly#垃圾回收算法，官方已经优化过了，不用调整 Elasticsearch概念Elasticsearch 是 面向文档 的，意味着它存储整个对象或文档。且Elasticsearch不仅存储文档，而且索引每个文档的内容使之可以被检索。在Elasticsearch 中，是对文档进行索引、检索、排序和过滤，而不是对行列数据。这就是ES能支持复杂的全文搜索的原因。 Elasticsearch使用JSON作为文档的序列化格式。存储数据到 Elasticsearch 的行为叫做索引（动词，索引一个文档就是存储一个文档到索引），一个 Elasticsearch 集群可以包含多个索引 ，相应的每个索引可以包含多个类型 。这些不同的类型存储着多个文档 ，每个文档又有多个字段 。Elasticsearch和Lucene使用倒排索引（也称反向索引）结构达到较高的检索速度。倒排索引就是关系型数据库通过增加一个索引到指定列上以提高搜索速度。 RESTRepresentational State Transfer表述性状态传递，是一种软件架构风格，提供的是一组设计原则和约束条件，主要用于客户端与服务器交互的软件，使得软件更简洁、有层次，更利于实现缓存等机制。 REST提供的与资源交互的方法：类似于HTTP，但REST的方法仅仅面向资源，无法对web应用操作。 GET：列出URI以及资源中详细信息 PUT：将给定的一组资源替换当前资源 POST：在指定资源中创建、追加一个新资源 DELETE：删除资源 HEAD：获取头信息 12345678PUT /megacorp/employee/1&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125; megacorp为索引名，employee为类型名，1为雇员ID。Elasticsearch仅需要找到雇员ID文件，就能知道该雇员的所有信息。 若要与关系型数据库对照，索引（indice或index）对应库，类型（type）对应表，文档（document）对应行，字段（field）对应列 Elasticsearch通过将数据分片（shards）存储以解决数据量大时不能直接存储在一块硬盘中，且无法一次性搜索超大的数据量的情况。创建索引时，只需定义所需的分片数即可。每个分片本身都是一个功能齐全且独立的“索引”，可以托管在集群中的任何节点上。 每个Elasticsearch分片都是Lucene索引。每个Lucene可包含的最大文件数量为Integer.MAX_VALUE - 128个文件可以使用/_cat/shards监视分片大小。 并通过创建分片的副本（replicas），当主分片不可用时，副本就充当主分片使用。Elasticsearch为每个索引分配5个主分片和1个副本，若集群中有两个节点，该索引的分片数会翻倍，即10个分片。 集群原理一个运行的Elasticsearch实例为一个节点，集群是由一个或多个拥有相同cluster.name的节点构成的，当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。 cluster.name默认为elasticsearch 主节点：负责管理集群范围内的所有变更（增删索引和节点等），任何节点都可以成为主节点。主节点并不需要涉及到文档级别的变更和搜索等操作，因此流量的增加它也不会成为瓶颈。 每个节点都知道任意文档所处的位置，并且能够将请求直接转发到存储客户所需文档的节点。 集群健康可通过curl localhost:9200/_cluster/health或使用telnet 127.0.0.1 9200并输入GET /_cluster/health HTTP/1.1获取集群的健康状况，或通过curl 127.0.0.1 9200/_cat/health?v查看。 123456&#123; &quot;cluster_name&quot;: &quot;elasticsearch&quot;, &quot;status&quot;: &quot;green&quot;, &quot;timed_out&quot;: false,......&#125; 其中健康状况就是字段status，有三个可能值： green：所有的主分片和副本分片都正常运行 yellow：所有的主分片都正常运行，但不是所有的副本分片都正常运行 red：有主分片没能正常运行，数据可能丢失，需要紧急修复 水平扩容读操作、搜索和返回数据都可以同时被主分片或副本分片所处理，所以拥有越多的副本分片时，也将拥有越高的吞吐量。在运行中的集群上是可以动态调整副本分片数目的 ，可以按需伸缩集群。 1234curl -H &quot;Content-Type: application/json&quot; -X PUT localhost:9200/blogs/_settings -d &apos;&#123; &quot;number_of_replicas&quot;: 2&#125;&apos; 如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少，需要增加更多的硬件资源来提升吞吐量，但是更多的副本分片数提高了数据冗余量。 添加索引可通过curl添加索引 12345678curl -H &quot;Content-Type: application/json&quot; -X PUT localhost:9200/blogs/article/1 -d &apos;&#123; &quot;title&quot;: &quot;article1&quot;, &quot;content&quot;: &quot;article1&quot;&#125;&apos;# -H设置内容类型，要设为JSON格式# -X设置请求类型，设为PUT# -d设置请求数据 若添加成功就会返回以下信息： 1234567891011121314&#123; &quot;_index&quot;: &quot;blogs&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;:&#123; &quot;total&quot;: 2, #目前总共的分片数 &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;_seq_no&quot;: 0, &quot;_primary_term&quot;: 1&#125; 对已存在的记录再进行PUT操作就会更新该记录，同时，该字段的_version和_result都会改变，_version会+1，_result会变为updated。 再通过curl localhost:9200/blogs/article/1，获取该文章的元数据，以及_source属性，存储的就是文章中定义的内容。 1234567891011&#123; &quot;_index&quot;: &quot;blogs&quot;, &quot;_type&quot;: &quot;article&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;article1&quot;, &quot;content&quot;: &quot;article1&quot; &#125;&#125; 可通过curl localhost:9200/_cat/indices?v获取当前节点的索引信息 若要删除某个索引或类型或文档，都可通过curl -X DELETE localhost:9200/要删的资源删除。 简单搜索curl localhost:9200/_search?pretty获取本节点的所有文档信息，并且返回结果不仅告知匹配了哪些文档，还包含了整个文档本身：显示搜索结果给最终用户所需的全部信息。?pretty会将json重新排版显示。 1234567891011121314151617181920&#123; ...... &quot;hits&quot; : &#123; &quot;total&quot; : 2, &quot;max_score&quot; : 1.0, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;blogs&quot;, &quot;_type&quot; : &quot;article&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;article2&quot;, &quot;content&quot; : &quot;article2&quot; &#125; &#125;, ...... ] &#125;&#125; 可通过_all字段进行指定文档或类型中的搜索，例如/_all/employee/_search?进行指定类型中搜索（所有索引的中的employee（如果存在）） ?q=字段:值进行查询字符串（Query-string）搜索 1234567curl localhost:9200/_search?q=title:article2&#123; ...... &quot;hits&quot;:&#123;&quot;total&quot;:1,&quot;max_score&quot;:0.2876821,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;blogs&quot;,&quot;_type&quot;:&quot;article&quot;,&quot;_id&quot;:&quot;2&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123; &quot;title&quot;: &quot;article2&quot;, &quot;content&quot;: &quot;article2&quot; &#125;&#125;]&#125;&#125; 查询表达式搜索使用的是Elasticsearch开发的DSL（领域特定语言），基于JSON定义查询，能够构造复杂的查询语句。 不使用Query-string查询，而是通过请求体查询，请求会通过Json构造。 12345678curl localhost:9200/_search -X GET -H &quot;Content-Type: application/json&quot; -d &apos;&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; #使用了match类型查询 &quot;title&quot;: &quot;article1&quot; &#125; &#125;&#125;&apos; 常用请求体搜索规则： &quot;query&quot;:{}表示开始查询，其中定义许多查询规则，会计算评分数量（相关度）_score &quot;bool&quot;：进行布尔匹配 &quot;must&quot;：包含 &quot;must_not&quot;：不包含 &quot;match&quot;：普通匹配，若用空格隔开多个关键字，则es认为是或的关系，如果要同时满足多个关键词，即与关系，必须用bool查询 &quot;match_phrase&quot;：短语精确匹配 &quot;filter&quot;：过滤器，不会计算评分数量 &quot;range&quot;：匹配范围，例如：&quot;range&quot;:{age&quot;:{&quot;gt&quot;:30}}匹配age大于30 &quot;size&quot;：设置一次返回的结果数量，默认为10条。 &quot;from&quot;：设置移位，默认从位置0开始 12345678910111213141516171819202122# 已经alias curl_lo_g=&apos;curl -X GET -H &apos;Content-Type:application/json&apos;&apos;# export LO_ES=&apos;localhost:9200&apos;curl_lo_g $&#123;LO_ES&#125;/_all/employee/_search -d &apos;&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;age&quot;: &#123; &quot;gt&quot;: &quot;30&quot; #要加上双引号 &#125; &#125; &#125;, #这里有逗号 &quot;must&quot;: &#123; &quot;match&quot;: &#123; &quot;hobby&quot;: &quot;swimming&quot; &#125; &#125; &#125; &#125; &#125;&apos; 对于filter和query的区别： 大部分filter的速度快于query的速度 filter不会计算相关度得分，且结果会有缓存，效率高 全文搜索、评分排序，使用query 是非过滤，精确匹配，使用filter 高亮搜索能将搜索结果的要搜索的字符串高亮显示， 12345678910111213141516171819202122232425262728curl_lo_g $&#123;LO_ES&#125;/_all/employee/_search -d &apos;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;hobby&quot;: &quot;climbing&quot; &#125; &#125;, &quot;highlight&quot;: &#123; #只需要添加highlight搜索即可 &quot;fields&quot;: &#123; #fields指定高亮的字段 &quot;hobby&quot;: &#123;&#125; #需要高亮搜索的字段 &#125; &#125;&#125;&apos;......&#123;&quot;_index&quot;:&quot;tech&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;3&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123; &quot;name&quot;: &quot;wangwu&quot;, &quot;age&quot;: &quot;26&quot;, &quot;address&quot;: &quot;yangzhou&quot;, &quot;hobby&quot;: [&quot;swimming&quot;, &quot;climbing&quot;]&#125;,&quot;highlight&quot;:&#123; #标出高亮部分 &quot;hobby&quot;:[ &quot;&lt;em&gt;climbing&lt;/em&gt;&quot; #高亮部分由HTML标签&lt;em&gt;封装 #告诉浏览器把其中的文本表示为强调的内容 #通常为斜体 ]&#125;&#125;]&#125;&#125; 聚合聚合aggregations用于生成基于数据的精细分析结果，类似SQL的group by。 LogstashLogstash是一个开源的服务器端数据处理管道（Pipeline），它可以同时从多个源中提取数据，对其进行转换，然后将其发送到数据存储（如Elasticsearch）。支持丰富的 Input 和 Output 类型，能够处理各种应用的日志。 Logstash对于每一行数据（称为event）按流水线三个部分进行操作： input：负责产生事件（即数据），即数据源，如syslog、数据库日志、web日志、文件系统日志、java的log4j、网络日志、防火墙等各类日志，kafka、RabbitMQ等消息队列，移动设备、智能家居、传感器、联网汽车等IoT数据，以及Beats能获取的数据。是必须配置 filter：负责数据处理与转换，包括过滤，分类等操作。不是必须配置。 output：负责数据的输出，可输出到数据分析或存储的软件，如Elasticsearch，nagios，kibana等数据处理软件。是必须配置 Logstash开箱即用，包含许多聚合（aggregation）和突变（mutation），以及模式匹配（pattern matching），地理映射（geo mapping）和动态查找（dynamic lookup）功能。 Logstash安装 下载Logstash包，版本为6.4.1，解压到/usr/local/logstash6.4 进入logstash的bin目录执行./logstash -e &#39;input{stdin{}} output{stdout{codec=&gt;rubydebug}}&#39;，需要等待一段时间，期间会有信息，直到出现Successfully started Logstash API endpoint {:port=&gt;9600}，然后输入hello world即可看到以下信息。若要退出，按Ctrl+D。 1234567hello world&#123; &quot;message&quot; =&gt; &quot;hello world&quot;, &quot;host&quot; =&gt; &quot;VM_0_7_centos&quot;, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;@timestamp&quot; =&gt; 2018-09-26T11:09:10.781Z&#125; docker下载Logstash：直接docker pull logstash即可。 docker下启动Logstash：首先要确保本地存放pipeline配置文件的目录存在。通过在该目录添加配置文件。或者直接-v ~/config:/usr/share/logstash/config可直接修改所有配置 docker run -it -v ~/pipeline:/usr/share/logstash/pipeline logstash Logstash配置文件： logstash.yml：主配置文件 pipelines.yml：管道的配置，包括input，filter，output jvm.options：JVM配置文件 log4j2.properties：log4j2的配置 startup.options：启动脚本选项文件，包含Logstash的变量。若要让Logstash按修改后的配置运行，需要重新用root运行bin/system-install导入参数。 自定义的Logstash配置文件，一般以.conf结尾，同样存放在配置文件目录中。 logstash命令 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081logstash -n NAME 指定logstash的node.name，若不指定默认是当前的主机名 -f CONFIG_PATH 从特定文件或目录加载logstash配置 -e CONFIG_STRING 使用给定的字符串作为配置数据（与配置文件的语法相同） 默认输入：“input &#123;stdin &#123;type =&gt; stdin&#125;&#125;” 默认输出：“output &#123;stdout &#123;codec =&gt; rubydebug&#125;&#125;“ 若直接使用默认，则-e &quot;&quot; 即可（不能什么都不加） --field-reference-parser MODE 在解析字段引用时使用的模式 字段引用解析器用于扩展管道配置中的字段引用，能更好地处理非法和模糊输入 可用的MODE值：1. LEGACY：LEGACY解析器，不发出警告 2. COMPAT：COMPAT解析器，对每个不同的模糊或非法语法输入警告一次（默认使用） 3.STRICT：STRICT解析器，模糊或非法语法输入会引发插件运行时异常 --modules MODULES 加载logstash模块，不能与&apos;-e&apos;或&apos;-f&apos;一起使用 因为会覆盖在logstash.yml中加载的模块 两种写法：--modules module1 --modules module2 ... --modules=module1,module2 -M MODULES_VARIABLE Load variables for module template. Multiple instances of &apos;-M&apos; or &apos;--modules.variable&apos; are supported. Ignored if &apos;--modules&apos; flag is not used. Should be in the format of &apos;-M &quot;MODULE_NAME.var.PLUGIN_TYPE.PLUGIN_NAME.VARIABLE_NAME=VALUE&quot;&apos; as in &apos;-M &quot;example.var.filter.mutate.fieldname=fieldvalue&quot;&apos; --setup Load index template into Elasticsearch, and saved searches, index-pattern, visualizations, and dashboards into Kibana when running modules. (default: false) --cloud.id CLOUD_ID Sets the elasticsearch and kibana host settings for module connections in Elastic Cloud. Your Elastic Cloud User interface or the Cloud support team should provide this. Add an optional label prefix &apos;&lt;label&gt;:&apos; to help you identify multiple cloud.ids. e.g. &apos;staging:dXMtZWFzdC0xLmF3cy5mb3VuZC5pbyRub3RhcmVhbCRpZGVudGlmaWVy&apos; --cloud.auth CLOUD_AUTH Sets the elasticsearch and kibana username and password for module connections in Elastic Cloud e.g. &apos;username:&lt;password&gt;&apos; --pipeline.id ID Sets the ID of the pipeline. (default: &quot;main&quot;) -w COUNT 指定pipeline worker数量（即线程数），默认1 --experimental-java-execution (Experimental) Use new Java execution engine. (default: false) -b, --pipeline.batch.size SIZE Size of batches the pipeline is to work in. (default: 125) -u, --pipeline.batch.delay DELAY_IN_MS When creating pipeline batches, how long to wait while polling for the next event. (default: 50) --pipeline.unsafe_shutdown Force logstash to exit during shutdown even if there are still inflight events in memory. By default, logstash will refuse to quit until all received events have been pushed to the outputs. (default: false) --path.data PATH 数据存储目录。插件需要能访问该目录，默认安装目录下的data/ -p, --path.plugins PATH 插件目录，可指定多个Plugins are expected to be in a specific directory hierarchy: &apos;PATH/logstash/TYPE/NAME.rb&apos; where TYPE is &apos;inputs&apos; &apos;filters&apos;, &apos;outputs&apos; or &apos;codecs&apos; and NAME is the name of the plugin. (default: []) -l PATH 指定Logstash的日志目录，默认安装目录下的logs/ --log.level LEVEL 设置日志等级（fatal/error/warn/info/debug/trace），默认info --config.debug Print the compiled config ruby code out as a debug log (you must also have --log.level=debug enabled). WARNING: This will include any &apos;password&apos; options passed to plugin configs as plaintext, and may result in plaintext passwords appearing in your logs! (default: false) -i, --interactive SHELL Drop to shell instead of running as normal. Valid shells are &quot;irb&quot; and &quot;pry&quot; -t 检查logstash配置文件语法是否正常 -r 自动检测配置文件是否变动，若变动自动重载 --config.reload.interval RELOAD_INTERVAL How frequently to poll the configuration location for changes, in seconds. (default: 3000000000) --http.host HTTP_HOST Web API binding host (default: &quot;127.0.0.1&quot;) --http.port HTTP_PORT Web API http port (default: 9600..9700) --log.format FORMAT Specify if Logstash should write its own logs in JSON form (one event per line) or in plain text (using Ruby&apos;s Object#inspect) (default: &quot;plain&quot;) --path.settings SETTINGS_DIR 包含logstash.yml的目录，可通过LS_SETTINGS_DIR环境变量配置 默认&quot;/usr/local/logstash6.4/config&quot; --verbose 相当于设置日志等级为info --debug 相当于设置日志等级为debug --quiet 相当于设置日志等级为info Logstash如何工作关闭Logstash可通过systemctl stop logstash或直接kill关闭。Logstash有自己关闭过程，以达到安全地关闭： 首先停止所有的input、filter、output插件 处理完所有管道中的事件 最后关闭Logstash进程 在处理过程中，以下的状况会影响关闭过程： input插件以很慢的速度接收数据 速度慢的filter，如执行sleep(10000)的Ruby filter或执行非常繁重的查询的Elasticsearch过滤器。 一个断开连接的output插件，等待重新连接以刷新正在进行的事件。 Logstash有一个停顿检测机制（stall detection），可以在关闭过程中分析管道和插件的行为。此机制会对内部队列中的飞行事件（in-flight events）数量和繁忙的worker线程列表定期生成信息报告。 若要在Logstash关闭阶段直接强行关闭，可在主配置文件中设置pipeline.unsafe_shutdown值为true，但这样可能造成数据丢失，不安全。 Logstash配置文件logstash.yml因为配置文件的语法是YAML，所以有两种写法： 1234567pipeline: batch: size: 125 delay: 50#等同于pipeline.batch.size: 125pipeline.batch.delay: 50 配置文件也支持${}引用变量 如果使用命令的--modules指定模块，则配置文件中所有配置的模块都会被忽略。 模块的配置： 123modules: - name: 模块名 var.插件类型.插件名.键: 值 所有配置参数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253node.name #节点名，默认为主机名#path参数path.data #数据存放目录，默认为安装目录的data/path.config #logstash.yml路径path.plugins #插件的路径#插件应该位于特定的目录层次结构中：PATH/logstash/TYPE/NAME.rb#其中TYPE的值可以是inputs，filters，outputs或codecs，NAME是插件的名称#http参数http.port #监听的http主机端口，默认为9600http.host #监听的http主机IP，默认为127.0.0.1#日志log参数log.level #日志等级（fatal/error/warn/info/debug/trace），默认infolog.format #日志格式，默认为plain格式path.logs #日志的路径，默认安装目录的logs/#pipeline参数（关于pipeline的配置可专门存放在一个配置文件中，如pipeline.yml）pipeline.id #pipeline的ID，默认为mainpipeline.workers #管道的worker数量，默认为CPU的核数pipeline.batch.size #单个工作线程将从输入收集的最大事件数，默认125。增大此值会加大内存开销，还需调整JVM堆内存参数pipeline.batch.delay #event被调度到worker前等待的时间，单位毫秒，默认50pipeline.unsafe_shutdown #在关闭时立刻退出，会导致数据丢失。 #默认为false，完全退出前会将数据处理好并输出到屏幕再退出#config参数config.string #pipeline配置config.test_and_exit #检查配置是否有效，然后退出。默认为false不检查config.reload.automatic #定期检查配置是否已更改，并在配置发生更改时重新加载配置。默认false不检查config.reload.interval #检查配置是否变动的时间间隔，需要上一条开启。默认3sconfig.debug #是否开启调试日志消息。若开启还需要将log.level的值设为debug。默认false #注：日志消息可能会包含明文密码config.support_escapes #是否开启转义字符，即启用\转义。默认falsemodules #设置模块#queue参数queue.type #用于事件缓冲的队列模型（model to use for event buffering），有以下两种，默认memory。 memory：传统基于内存的队列 persisted：基于磁盘的响应队列（disk-based ACKed queueing）path.queue #启用持久队列（即上一项值为persisted）时存储数据文件的目录。默认data/queuequeue.pagt_capacity #启用持久队列时使用的页面数据文件的大小。默认64MBqueue.max_events #启用持久队列时队列中未读事件的最大数量。默认0，不限制queue.max_bytes #队列的总容量，以字节数表示。确保磁盘容量大于此值。默认1G#若与上一项同时配置，则Logstash会加载先配置的一项queue.checkpoint.acks #启用持久队列时强制检查点之前的最大ACK响应事件数。默认1024，若设为0则不限制queue.checkpoint.writes #在启用持久队列时强制检查点之前写入事件的最大数量。默认1024，若设为0则不限制queue.drain #启用后，Logstash将等待直到持久队列耗尽，然后才能关闭。默认false#dead_letter_queue参数dead_letter_queue.enable #是否启用dead_letter_queue，简称DLQ功能。默认false不启用dead_letter_queue.max_bytes #每个DLQ的最大大小。超出就会删除条目，默认1Gpath.dead_letter_queue #DLQ目录的位置，默认为安装目录的data/dead_letter_queue 自定义Logstash配置文件自定义的配置文件主要用于指定input、filter、output插件等管道参数。 配置文件支持的值类型： 列表Lists：[ ]中包含多个值。如path =&gt; [&#39;XXX&#39;,&#39;XXX&#39;] 布尔值Boolean：指定true或false 字节Bytes：是字符串字段，表示有效的字节单位。支持SI（k M G T P E Z Y）和二进制（binary）（Ki Mi Gi Ti Pi Ei Zi Yi）单位。二进制单位基数为1024，SI单位基数为1000。此字段不区分大小写，并接受值和单位之间的空格。 编解码器codec：表示数据的Logstash编解码器的名称。编解码器可用于输入和输出。例：codec =&gt; json 输入编解码器提供了一种在数据进入输入之前对其进行解码的便捷方式。 输出编解码器提供了一种在数据离开输出之前对数据进行编码的便捷方式。 使用输入或输出编解码器无需在Logstash管道中使用单独的过滤器。 哈希Hash：键值对集合，多条键值对间使用空格间隔，而不是逗号 数字Number：数字必须为浮点型或整型 密码Password：密码必须是一个字符串，且该字符串应未被记录或打印 URI：可以是完整的URL，也可以是类似邮件地址，如user:pass@XXX.net，如果URI包含密码，则不会记录或打印URI的密码部分 路径Path：表示有效操作系统路径的字符串 字符串String：必须用引号括住，可以是单引号或双引号 转义序列Escape Sequences：默认不启用转义序列。如果要在字符串中使用转义字符，需要在logstash.yml中设置config.support_escapes：true。 Logstash日志Logstash的日志存放在LS_HOME/logs中，默认日志等级为INFO， Logstash的日志框架基于Log4j 2框架，其大部分功能直接暴露给用户。 在调试问题时，尤其是插件问题时，一般将日志记录级别增加到DEBUG以获取更详细的消息。从5.0版本开始，可以在Logstash中配置特定日志子系统的日志记录。 Logstash提供一个带有开箱即用设置的log4j2.properties文件，可以更改轮换策略，类型和其他log4j2配置。需要重启Logstash以应用该配置。 慢日志（Slowlog）用于报告在通过管道（pipeline）时花费不正常时间的事件的日志消息。慢日志同样存放在LS_HOME/logs中。可在主配置文件中添加slowlog的配置，如下： 1234slowlog.threshold.warn: 2sslowlog.threshold.info: 1sslowlog.threshold.debug: 500msslowlog.threshold.trace: 100ms 以上配置指定了触发慢日志的条件。在过滤器中处理超过100ms的事件会在慢日志中记录为trace等级的事件，超过2秒的事件会记录为等级为warn的事件 可通过curl -X GET localhost:9600/_node/logging?pretty获取关于日志的信息 12345678910111213curl localhost:9600/_node/logging?pretty&#123; "host" : "VM_0_7_centos", "version" : "6.4.1", "http_address" : "127.0.0.1:9600", "id" : "07b4b966-d732-4263-bc16-1efc6e927e1c", "name" : "VM_0_7_centos", "loggers" : &#123; #显示的是日志子系统以及日志等级 "logstash.agent" : "INFO", "logstash.api.service" : "INFO", "logstash.codecs.line" : "INFO", "logstash.codecs.rubydebug" : "INFO",...... 可通过curl -X PUT localhost:9600/_node/logging?pretty -H &#39;Content-Type: application/json&#39; -d &#39;{...}&#39;动态设置指定日志子系统的日志等级。例如： 1234curl -XPUT &apos;localhost:9600/_node/logging?pretty&apos; -H &apos;Content-Type: application/json&apos; -d &apos;&#123; &quot;logger.logstash.outputs.elasticsearch&quot; : &quot;DEBUG&quot;&#125;&apos; 则会在log4j2.properties配置中自动添加上该指定配置。若要重置已通过日志记录API动态更改的任何日志记录级别，需要通过将PUT请求发送到_node/logging/reset将所有日志记录级别都恢复为log4j2.properties文件中指定的值 curl -X PUT localhost:9600/_node/logging/reset?pretty 将其他任意日志导入Logstash的操作：编写一个pipeline配置文件test.conf，或直接在pipeline.yml添加 123456789input &#123; #设置input参数 file &#123; #通过列表添加两个日志 path =&gt; [&apos;/var/log/httpd/access_log&apos;,&apos;/var/log/squid/access.log&apos;] &#125;&#125;output &#123; #标准输出，一定要加，否则无法输出到屏幕 stdout &#123;&#125;&#125; 启动Logstash，bin/logstash -f config/test.conf。会不断获取httpd和squid的日志消息 1234567891011121314&#123; &quot;path&quot; =&gt; &quot;/var/log/httpd/access_log&quot;, &quot;message&quot; =&gt; &quot;127.0.0.1 - - [02/Oct/2018:16:11:16 +0800] \&quot;GET / HTTP/1.0\&quot; 200 10 \&quot;-\&quot; \&quot;ApacheBench/2.3\&quot;&quot;, &quot;@timestamp&quot; =&gt; 2018-10-02T08:11:20.344Z, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;VM_0_7_centos&quot;&#125;&#123; &quot;path&quot; =&gt; &quot;/var/log/squid/access.log&quot;, &quot;message&quot; =&gt; &quot;1538467887.306 656 180.126.242.119 TCP_TUNNEL/200 33103 CONNECT xui.ptlogin2.qq.com:443 - HIER_DIRECT/xui.ptlogin2.qq.com -&quot;, &quot;@timestamp&quot; =&gt; 2018-10-02T08:11:27.355Z, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;VM_0_7_centos&quot;&#125; 若要将elasticsearch的日志都再导入elasticsearch，可进行以下配置： 12345678910111213141516input &#123; file &#123; path =&gt; &apos;/usr/local/es-6.4/logs/elasticsearch.log&apos; type =&gt; &apos;elasticsearch&apos; start_position =&gt; &apos;beginning&apos; #从日志的头开始读 &#125;&#125;output &#123; elasticsearch &#123; #使用elasticsearch插件 hosts =&gt; &apos;127.0.0.1:9200&apos; #指定elasticsearch源 index =&gt; &apos;es_message-%&#123;+YYYY.MM.dd&#125;&apos; #指定index &#125; stdout&#123; codec =&gt; rubydebug &#125;&#125; 启动Logstash就会显示已导入elasticsearch的日志 12345678&#123; &quot;type&quot; =&gt; &quot;elasticsearch&quot;, &quot;message&quot; =&gt; &quot;[2018-10-03T16:06:50,392][INFO ][o.e.c.m.MetaDataMappingService] [system135] [.kibana/PnIK501cQUydUEIVp0icjw] update_mapping [doc]&quot;, &quot;@timestamp&quot; =&gt; 2018-10-03T08:06:50.560Z, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;system5.example.com&quot;, &quot;path&quot; =&gt; &quot;/usr/local/es-6.4/logs/elasticsearch.log&quot;&#125; Logstash常用插件默认的Logstash安装包括Beats输入插件。 Beats输入插件使Logstash能够从Elastic Beats框架接收事件，任何与Beats框架一起使用的Beat（如Packetbeat和Metricbeat），也可以将事件数据发送到Logstash。 Grok：是Logstash过滤器的基础，用于从非结构化数据中获取结构，具有丰富的集成模式，能快速处理Web，系统，网络和其他类型的事件格式。 Codecs：通常用于简化对JSON和多行事件等常见事件结构的处理。 KibanaKibana是一个开源分析和可视化平台，旨在与Elasticsearch协同工作。可使用Kibana搜索，查看以及与存储在Elasticsearch索引中的数据进行交互，可以轻松地执行高级数据分析，并在各种图表（charts），表格（tables）和地图（maps）中可视化数据。 Kibana是基于JS的WEB界面，在Node.js上运行，而官方在Kibana包中包含了必要的Node.js二进制文件，并且不支持针对单独维护的Node.js版本运行Kibana，因此不需要单独搭建Nodejs环境。 应将Kibana配置为针对相同版本的Elasticsearch节点运行，即版本要一致。 注：从V6.0.0开始，Kibana仅支持64位操作系统。 Kibana安装下载Kibana包，版本为6.4.1，解压到/usr/local/kibana6.4 kibana需要elasticsearch的开启才能正常使用，否则启动kibana会不断报错，进入Kibana后也会提示status为red，无法正常使用，因此需要先启动elasticsearch。开启后，进入kibana目录下bin执行kibana命令。需要等待一段时间直到出现信息[info][listening][server][http] Server running at http://localhost:5601。通过浏览器localhost:5601访问kibana。 注：内存或CPU不足会将Elasticsearch杀死，Kibana也就无法启动 Kibana的文件结构：除了bin、config、data、plugins，kibana还有以下目录： node： node_modules optimize：存放透明的源代码。某些管理操作（例如，插件安装）导致源代码在运行中被重新传输。 src webpackShims 可在浏览器访问localhost:5601/status查看kibana是否启动正常，插件是否加载正常，以及kibana的当前信息。 启动时Kibana信息处理warning消息 123[warning][security] Generating a random key for xpack.security.encryptionKey. To prevent sessions from being invalidated on restart, please set xpack.security.encryptionKey in kibana.yml 1[warning][security] Session cookies will be transmitted over insecure connections. This is not recommended. Kibana配置Kibana只有一个配置文件KIBANA_HOME/config/kibana.yml。默认运行在localhost的5601端口。 常见配置： 123456789101112131415161718server.port: 5601 #Kibana服务端口server.host: &quot;localhost&quot; #向哪些主机开放端口，若要所有主机都能访问，即客户端能远程访问，需要设为0.0.0.0server.name: &quot;your-hostname&quot; #Kibana实例名，一般为主机名server.basePath: &quot;&quot; #server.maxPayloadBytes: 1048576server.rewriteBasePath: falseelasticsearch.url: &quot;http://localhost:9200&quot; #Elasticsearch的地址，需要设置正确elasticsearch.preserveHost: truekibana.index: &quot;.kibana&quot;kibana.defaultAppId: &quot;home&quot;#elasticsearch.username: &quot;user&quot; #设置es授权用户名#elasticsearch.password: &quot;pass&quot; #设置es授权用户密码#server.ssl.enabled: false #是否开启ssl#server.ssl.certificate: /path/to/your/server.crt#server.ssl.key: /path/to/your/server.key#elasticsearch.ssl.certificate: /path/to/your/client.crt#elasticsearch.ssl.key: /path/to/your/client.key Kibana基本功能添加index的管理首先要在elasticsearch添加index数据 1234567curl -X PUT -H &quot;Content-Type: application/json&quot; localhost:9200/tech/employee/1 -d &apos;&#123; &quot;name&quot;: &quot;zhangsan&quot;, &quot;age&quot;: &quot;25&quot;, &quot;address&quot;: &quot;nanjing&quot;, &quot;hobby&quot;: [ &quot;football&quot;, &quot;tennis&quot;, &quot;game&quot; ]&#125;&apos; 然后刷新kibana，进入Management中的Kibana，选Index pattern，并创建。 创建完成后，进入Discover菜单，可查看插入的数据 使用kibana提供的数据进行分析从kibana文档中下载数据，可选择银行账户数据account.json，下载以后使用curl -H &#39;Content-Type: application/x-ndjson&#39; -XPOST &#39;localhost:9200/bank/account/_bulk?pretty&#39; --data-binary @accounts.json导入elasticsearch。开启kibana，进入Management添加index pattern，然后进入Discover菜单，选择bank，添加要看的字段。 为数据创建报表，进入Visualize菜单，可根据需要选择报表形式，此处选Pie饼图，然后再选择bank即可进入定制界面。 选择split slices，然后在聚合（aggregation）中选择range，然后进行自定义数据范围 ELK架构若环境的内存少，就在es配置文件添加以下配置 bootstrap.memory_lock: false 为避免内存与磁盘间的swap，会损耗大量性能 bootstrap.system_call_filter: false 参考文章 全文搜索引擎 Elasticsearch 入门教程 每天5分中玩转docker容器技术 Elasticsearch: 权威指南 Elasticsearch官方文档 Logstash简单介绍 ELK 之 Logstash Logstash官方文档 ES之五：ElasticSearch聚合]]></content>
      <tags>
        <tag>运维</tag>
        <tag>监控</tag>
        <tag>Elasticsearch</tag>
        <tag>ELK</tag>
        <tag>EFK</tag>
        <tag>Kibana</tag>
        <tag>Logstash</tag>
        <tag>搜索</tag>
        <tag>日志</tag>
        <tag>Fluentd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重学数据结构与算法笔记]]></title>
    <url>%2F2018%2F09%2F15%2F%E9%87%8D%E5%AD%A6%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[使用C与python实现。 学习资源： 中国大学mooc：数据结构与算法—电子科技大学—戴波、林劼、刘震 学习目录： 数据结构与算法分析概念 线性表 堆栈与队列 数组与字符串 树与二叉树 集合与搜索 搜索树 图 排序 题目整理 数据结构与算法分析概念数据：是对客观事物的符号表示，是可被计算机识别并加工处理的对象。 数据对象：是性质相同的数据元素的集合。 数据元素：是数据的基本单位，在程序中通常作为一个整体进行处理。 数据项：是组成数据元素的不可分割的最小单位。 以上四个术语的关系：数据（包含）数据对象（包含）数据元素（包含）数据项 数据结构是相互之间存在一种或多种特定关系的数据元素的集合。 数据元素相互之间的关系称为结构，有以下几种结构：集合、线性结构（一对一）、树形结构（一对多）、图状结构/网状结构（多对多），其中除线性结构外的其他结构，也属于非线性结构。 数据结构是一个二元组：Data_Structure = (D, S)，其中D是数据元素的有限集，S是D上关系的有限集。 数据结构由四部分组成：数据元素、数据元素之间的逻辑关系、逻辑关系在计算机中的存储表示、所规定的操作 数据的存储表示和运算算法的描述构成了数据结构的实现。 数据结构在计算机中的表示称为存储结构。有两种存储结构： 顺序存储结构：将逻辑上相关的数据元素一次存储在地址连续的存储空间内。特点：借助元素在存储器中的相对位置来表示数据元素间的逻辑关系。 链式存储结构：数据元素可以存储在任意的存储空间中，可以是连续的存储空间，可以是不连续的存储空间。元素的存储位置不能体现逻辑关系，而是需要通过指示元素存储地址的指针表示数据元素之间的逻辑关系。 数据类型是性质相同的值的集合以及定义在该值集上的运算操作的集合。 抽象数据类型（ADT）是指一个数学模型以及定义在该模型上的一组操作。不论内部结构如何变化，只要数学特性不变，就不影响其外部使用。ADT有两个特征： 数据封装：把数据和操纵数据的运算组合在一起的机制 信息隐蔽：数据的使用者只需知道运算的定义便可访问数据，无需了解数据的存储和实现细节 抽象数据类型可以用三元组表示：(D, S, P)。其中D表示数据对象、S表示D上的关系集、P表示对D的基本操作集 算法是对特定问题求解步骤的描述，有5个特性：输入、输出、可行性、确定性、有穷性 好的算法需要具备的特性：正确性、可读性、健壮性、高效性 算法复杂性是算法运行所需要的计算机资源的量，其中时间资源的量称为时间复杂度，空间资源的量称为空间复杂度。 复杂度与问题的规模、算法的输入、算法本身的函数有关，其中最主要因素是问题规模。 一个算法的时间花销与算法中语句的执行次数成正比。一个算法中语句执行次数为语句频度，记为T(n)，其中n为问题规模大小。若有一个函数f(n)，则算法渐进时间复杂度记为T(n) = O(f(n)) 渐进表示法： 渐进上界记号$O(g(n)) = \{ f(n)|存在正常数c和n_0，使得对所有n \geq n_0有：0 \leq f(n) \leq cg(n) \}$ 渐进下界记号$\Omega(g(n)) = \{ f(n)|存在正常数c和n_0，使得对所有n \geq n_0有：0 \leq cg(n) \leq f(n) \}$ 紧渐近界记号$\Theta(g(n)) = \{ f(n)|存在正常数c_1,c_2和n_0，使得对所有n \geq n_0有：c_1g(n) \leq f(n) \leq c_2g(n) \}$ 常见的渐进时间复杂度（从小到大）: $O(1)&lt;O(\log_2n)&lt;O(n)&lt;O(n\log_2n)&lt;O(n^2)&lt;O(n^3)&lt;O(2^n)$]]></content>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neural-style试玩环境搭建]]></title>
    <url>%2F2018%2F09%2F15%2FNeural-style%E8%AF%95%E7%8E%A9%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Cacti监控学习]]></title>
    <url>%2F2018%2F09%2F15%2FCacti%E7%9B%91%E6%8E%A7%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[本篇笔记包含以下内容： Cacti原理与安装 Cacti常用操作 Cacti原理与安装Cacti是一套基于PHP，MySQL，SNMP及RRDTool开发的网络流量监测图形分析工具。使用SNMP服务获取数据，用rrdtool存储和更新数据，并可以使用rrdtool生成图表。因此SNMP和RRDtool是Cacti的关键。注意，Cacti仅仅是一个展示工具，是一个PHP网页，真正实现数据收集以及绘图的是SNMP和RRDtool。 MySQL与PHP用来存储一些变量数据并对变量进行调用，如主机名、主机IP、Snmp团体名、端口号、模板信息等，Snmp抓取的数据并不存放在MySQL中，而是存放在rrdtool生成的RRD文件中，rrdtool对数据的更新和存储就是对RRD文件的处理，RRD文件是大小固定的档案文件，能存储的数据量在创建时就被定义好了。 Cacti特点： 提供图形化页面操作实现rrdtool create命令 周期性执行能取得数据的命令，并将取回的数据存储在rrd文件中 通过rrdtool绘图并展示 强大的用户管理机制 丰富的插件库，如thold，并提供插件框架允许自定义模板 Cacti模板分为三类： 图形模板：定义图形的绘制 数据模板：定义如何获得数据，如何保存数据 主机模板：就是分好类的图形模板和数据模板，可直接应用于一个或一类主机 SNMP简介 Simple Network Management Protocol简单网络管理协议，由一组网络管理的标准组成，包含一个应用层协议、数据库模型（database schema）和一组资源对象。该协议能够支持网络管理系统，用以监测连接到网络上的设备是否有任何引起管理上关注的情况。 SNMP管理的网络主要由三部分组成： 被管理的设备 SNMP代理（Agent） 网络管理系统（NMS） 三部分之间的关系： 网络中被管理的每一个设备都存在一个管理信息库（MIB）用于收集并储存管理信息。通过SNMP协议，NMS能获取这些信息。被管理设备，又称为网络单元或网络节点，可以是支持SNMP协议的路由器、交换机、服务器或者主机等等。 SNMP代理是被管理设备上的一个网络管理软件模块，拥有本地设备的相关管理信息，并用于将它们转换成与SNMP兼容的格式，传递给NMS。 NMS运行应用程序来实现监控被管理设备的功能。另外，NMS还为网络管理提供大量的处理程序及必须的储存资源。 上述资料引用自百度百科snmp RRDtool简介 Round Robin Database Tool轮询式数据库工具，是一个强大的绘图的引擎。其中，Round Robin是一种存储数据的方式，使用固定大小的空间来存储数据，并有一个指针指向最新的数据的位置。RRDtool针对处理的是时序型数据(time-series data)，比如网络带宽，温度，CPU负载等等这些和时间相关联的数据或者说指标。 上述资料引用自百度百科rrdtool和RRDtool入门详解 Cacti安装首先需要搭建LAMP环境yum install httpd php php-devel php-gd gd gd-devel gcc glibc openssl* mariadb* zlib* php-xml libxml libjpeg libpng freetype cairo-devel pango-devel cairo是一个2D图形库 Pango是一个用于布局和呈现文本的库 gd也是一个图形库，用于动态生成图片 12345yum install net-snmp \ net-snmp-devel \ net-snmp-utils \ lm_sensors \ rrdtool* 安装snmp主程序及相关监控工具。net-snmp会提供两个命令snmpwalk和snmpget lm_sensors：是一款基于linux系统的硬件监控的软件。可以监控主板，CPU的工作电压，温度等数据。 开启snmpd和snmptrapd服务systemctl start snmpd snmptrapd 修改snmp配置文件/etc/snmp/snmpd.conf，找到com2sec notConfigUser default public一行，复制到下一行并修改 12com2sec myuser 127.0.0.1 mycommunity# 127.0.0.1可配置为要监控的主机或网段 找到下面的group配置，同样复制一行并修改 1group mygroup v2c myuser 再下面，找到view配置，添加一行 1view all included .1 保存并重启snmpd服务。执行snmpwalk -c mycommunity 127.0.0.1 -v2c可看到大量信息。 注：如果是被监控主机，只需要安装net-snmp和lm_sensors即可。 cacti安装完成后，会在/etc/httpd/conf.d/中生成一个cacti.conf配置文件，可以不用改动，文件中指定的网页存储位置为/usr/share/cacti/，该目录中存放着所有php网页。 cacti的sql数据存放在/usr/share/doc/cacti/cacti.sql需要导入数据库。首先要进入mariadb，创建数据库cactidb，退出后，mysql -u root -p cactidb &lt; /usr/share/doc/cacti/cacti.sql导入数据库。 在数据库中创建用户管理cactidb，进入数据库grant all on cactidb.* to cactiadmin@localhost identified by &quot;cactiadmin&quot;;并flush privileges; 设置httpd虚拟主机，使用户通过cacti.example.com直接访问 1234567891011&lt;VirtualHost *:80&gt; ServerName cacti.example.com DocumentRoot &quot;/usr/share/cacti&quot; ErrorLog &quot;log/cacti-access.log&quot; CustomLog &quot;log/cacti-error.log&quot; common&lt;/VirtualHost&gt;&lt;Directory &quot;/usr/share/cacti&quot;&gt; Require all granted Options Indexes AllowOverride None&lt;/Directory&gt; 修改管理Cacti的配置文件/usr/share/cacti/include/config.php，修改以下内容： 1234$database_default = &apos;cactidb&apos;; 设置数据库名$database_username = &apos;cactiadmin&apos;; 设置数据库中cacti用户名$database_password = &apos;cactiadmin&apos;; 设置数据库中cacti用户密码$url_path = &apos;/&apos;; 网页访问的路径，可改可不改，若不改就是通过http://localhost/cacti访问 创建普通用户用于周期性执行获取数据的php脚本，因为为了安全性，不能让管理员执行。useradd cactiuser，并且将cacti目录中log和rra目录的所属人和所属组都改为cactiuser，chown -R cactiuser:cactiuser /usr/share/cacti/log /usr/share/cacti/rra 至此，安装配置完毕，重启Apache，浏览器输入cacti.example.com访问，开始网页配置。 若遇到以下报错： 说明cacti数据库管理员cactiadmin没有对mysql.time_zone_name表的select权限，需要授权。 12grant select on mysql.time_zone_name to cactiadmin@localhost;flush privileges; 并且要修改/etc/my.cnf配置，在[mysqld]下添加： 1default-time-zone = &apos;+8:00&apos; 重启并进入mysql，使用命令验证 1234567show variables like &apos;%time_zone%&apos;; +------------------+--------+| Variable_name | Value |+------------------+--------+| system_time_zone | CST || time_zone | +08:00 |+------------------+--------+ 退出MySQL，使用命令mysql_tzinfo_to_sql tz_file tz_name | mysql -u root -p mysql tz_file指timezone文件，存放在/usr/share/zoneinfo中 执行mysql_tzinfo_to_sql /usr/share/zoneinfo/Asia/Shanghai Shanghai | mysql -u root -p mysql 说明php的timezone没设置，修改/etc/php.ini，把;date.timezone =注释去除，设置为date.timezone = Asia/Shanghai。支持的时区表 网页下拉还有类似的问题，需要修改mysql表中相应参数。修改/etc/my.cnf文件，在[mysqld]下添加报错项，只要满足即可。 12345678max_heap_table_size=2048Mtmp_table_size=2048Mjoin_buffer_size=2048Minnodb_buffer_pool_size=2048Minnodb_doublewrite=offinnodb_flush_log_at_timeout=10innodb_read_io_threads=32innodb_write_io_threads=16 修改完后重启php和mysql 12systemctl restart mariadb.service systemctl restart php-fpm.service 重新访问cacti.example.com。进入安装选项页面： 有两种选项： 12New Primary Server：若是主节点就选这项New Remote Poller：若是用于收集主节点无法访问的服务器的信息，就选这项 Cacti的各个路径已自动设置好。由于Spine还没有安装，所以会提示错误，但不影响安装。 安装模板，若为Linux或unix主机，必选Local Linux Machine，若为Windows主机，必选Windows Device。 用户登录界面，初始的管理员用户名和密码都是admin，登陆后会强制要求更改。 密码设置有几个条件必须满足： 大于8位 含有字母大小写 至少包含一个数字 至少包含一个特殊字符 若想绕过这些规则，可直接进入mysql的cactidb库，执行update user_auth set password = md5(&quot;密码&quot;) where username=&quot;admin&quot;; 然后就进入了cacti主界面。 查看Graph页面，出现以下报错： 是因为没有运行/usr/share/cacti/poller.php，这个是cacti自带的脚本，用于收集数据，并生成图表。默认cacti每5分钟收集一次信息，所以要设置定时，每五分钟运行该脚本。而cacti安装后已生成一个文件/etc/cron.d/cacti，内容如下：若带有注释，就将注释去除，并要修改用户名。需要确定crond服务是否启动。 1*/5 * * * * cactiuser /usr/bin/php /usr/share/cacti/poller.php &gt; /dev/null 2&gt;&amp;1 最好通过crontab -e -u cactiuser输入*/5 * * * * /usr/bin/php /usr/share/cacti/poller.php &gt; /dev/null 2&gt;&amp;1设置cron。 先手动执行一次php /usr/share/cacti/poller.php &gt; /dev/null 2&gt;&amp;1，可通过查看/var/log/cacti/cacti.log确认是否能获取数据。然后查看/usr/share/cacti/rra/是否有rrd文件。然后重启httpd，访问cacti的Graph。 有可能没有启动的原因是系统时间和BIOS时间不符，通过hwclock -s同步。 参考文章 Cacti实战 Linux运维之道（第二版） 高性能网站构建实战 Cacti完全使用手册 ( 让你快速个性化使用Cacti ) 服务器监控系统cacti cacti安装与配置 使用 SNMP 和 Cacti 监控 Linux 服务器]]></content>
      <tags>
        <tag>运维</tag>
        <tag>监控</tag>
        <tag>server</tag>
        <tag>Cacti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLite学习笔记]]></title>
    <url>%2F2018%2F09%2F07%2FSQLite%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容： SQLite介绍与安装 []]]></content>
      <tags>
        <tag>数据库</tag>
        <tag>SQLite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cuda环境搭建]]></title>
    <url>%2F2018%2F08%2F16%2FCuda%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[CUDA为 CUDA搭建CUDA环境搭建大致需要以下步骤： Nvidia显卡驱动安装 CUDA安装 cuDNN安装 Nvidia驱动安装首先卸载现有的驱动（如果不是最新的话） sudo apt-get remove nvidia* 自动安装Nvidia最新驱动 sudo apt-get install bumblebee-nvidia nvidia-driver nvidia-settings 其中：nvidia-driver对应了最新的Nvidia驱动，bumblebee-nvidia为Nvidia的大黄蜂模式驱动，用于双显卡智能切换。 安装Nvidia的系统管理界面Nvidia-smi sudo apt-get install nvidia-smi 使用nvidia-smi查看显卡详细信息 12]]></content>
      <tags>
        <tag>CUDA</tag>
        <tag>Nvidia</tag>
        <tag>人工智能</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IS-IS学习笔记]]></title>
    <url>%2F2018%2F08%2F05%2FIS-IS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于华三网络学习笔记 本篇主要包含以下内容： OSI地址 IS-IS概述 IS-IS实现 OSI地址在OSI协议体系中，OSI地址标识了一台支持OSI协议的设备。IS-IS的报文封装在数据链路层，采用OSI报文格式，包含OSI地址。IS-IS协议将ISO网络层地址称NSAP。IS-IS用OSI地址标识不同IS，并构建网络拓扑数据库，计算到达各节点的最短路径树。 OSI地址使用的是NASP（Network Service Access Point网络服务接入点）地址格式，是IP地址和上层协议号的组合，用于标识设备和设备启用的服务。 NASP由IDP（Initial Domian Part初始域部分）和DSP（Domain Specific Part域指定部分），IDP表示IP地址的主网络号，DSP表示IP地址的子网号和主机地址。IDP和DSP长度是可变的，但NASP的总长最多为20字节，最少8字节。 在IS-IS中，NASP地址被分为3部分：可变长区域地址，System ID，NSEL。 System ID用于在区域中唯一表示主机或服务器，一般会由Router ID转换得出。 转换方法：Router ID的每部分都扩展为3位数字，不足则在前补零，将扩展后的地址重新划分为3部分，每部分4个数字，得到System ID NSEL类似于协议标识符，当协议为IP时，NSEL均为00。 路由器只需配置一个区域地址，但最多可以配置3个，同一区域中所有节点的区域地址都相同。 NET（Network Entity Title网络实体名称）指示的是IS本身的网络层信息，不包括传输层信息，可看做NSEL为0的特殊的NASP。一台路由器只需配置一个NET，最多3个，若配置多个NET，则必须保证System ID相同。NET除了可以通过Router ID转换变得，也可通过MAC地址转换变得，但MAC地址由于具有全局性，一个区域内的路由器的MAC没有规律，管理不方便，所以一般还是用Router ID映射。 IS-IS概述IS-IS（Intermediate System-to-Intermediate System，中间系统到中间系统）是ISO为CLNP（Connection Less Network Protocol，无连接网络协议）设计的一种动态路由协议。IS-IS能够同时应用在TCP/IP和OSI环境中，形成了集成化IS-IS。采用TLV架构，易于扩展。 IS-IS属于内部网关路由协议，用于自治系统内部。IS-IS是一种链路状态协议，与TCP/IP网络中的OSPF协议非常相似，使用最短路径优先算法SPF进行路由计算。 IS-IS常见术语：区域（Area）：路由域的细分单元，IS-IS允许将整个路由域分为多个区域 路由域（Routing Domain）：较大的区域，可包含多个区域 中间系统Intermediate System（IS）：即路由器 终端系统End System（ES）：即主机 ES-IS：主机和路由器之间运行的协议 IS-IS：路由器与路由器之间运行的协议，就是用来提供路由域内或一个区域内的路由 IS-IS路由器有三种角色： Level-1：负责区域内的路由，只与属于同一区域的Level-1和Level-1-2路由器形成邻居关系，维护一个Level-1的链路状态数据库，该链路状态数据库包含本区域的路由信息，到区域外的报文转发给最近的Level-1-2路由器。 Level-2：负责区域间的路由，可以与同一区域或者其它区域的Level-2和Level-1-2路由器形成邻居关系，维护一个Level-2的链路状态数据库，该链路状态数据库包含区域间的路由信息。所有Level-2路由器和Level-1-2路由器组成路由域的骨干网，负责在不同区域间通信，路由域中的Level-2路由器必须是物理连续的，以保证骨干网的连续性。 Level-1-2：同时属于Level-1和Level-2的路由器，可以与同一区域的Level-1和Level-1-2路由器形成Level-1邻居关系，也可以与同一区域或者其他区域的Level-2和Level-1-2路由器形成Level-2的邻居关系。Level-1路由器必须通过Level-1-2路由器才能连接至其他区域。Level-1-2路由器维护两个链路状态数据库，Level-1的链路状态数据库用于区域内路由，Level-2的链路状态数据库用于区域间路由。 每台路由器只能属于一个区域，区域边界在链路上。 IS-IS协议报文IS-IS使用协议数据单元PDU进行通讯。PDU有以下类型： IS-IS Hello PDU：简称IIH，负责路由间的邻居关系建立和维护 链路状态PDU：简称LSP，描述路由器中的所有链路状态信息 时序报文SNP：用于确认邻居间最新接收的LSP，类似于确认报文。包括两种报文：CSNP和PSNP 全时序报文CSNP：包含网络中每个LSP的摘要信息。当路由器收到一个CSNP时，它会将该CSNP与其链路状态数据库LSDB进行比较，如果该路由器丢失了一个在CSNP中存在的LSP时， 它会发送一个组播PSNP，向网络中其它路由器索要其需要的LSP。 部分时序报文PSNP：在点对点链路中用于确认接收的LSP和请求最新或者丢失的LSP；在广播链路中仅用于请求最新或者丢失的LSP。 IS-IS报文直接封装在链路层数据中。报头包含通用报头Common Header和专用报头Specific Header。 IS-IS网络类型点对点：主要用于PPP、HDLC 广播：主要用于以太网 IS-IS实现邻接关系 邻居关系建立 若在点对点网络，只要IS能接收到对端的P2P IIH报文，则邻居能建立，状态变为UP 若在广播网络，邻居建立需要三次握手。 邻接关系建立 若在点对点网络： 若在同一区域Area，L1间只建立L1邻接关系，L1和L1/2只建立L1邻接关系，L1/2间建立L1和L2邻接关系。 若在不同区域，L1间不建立邻接关系（邻居关系都不是），L2间建立L2邻接关系，L1/2间建立L2邻接关系。 若在广播网络：会选举DIS（Desginated IS，指定IS），类似DR，相同角色的IS间会选举一个，例如L1的路由器间选出一个，与L2间选出的并不冲突。 DIS的作用： 一旦一个设备选举为DIS以后，DIS发送HELLO数据包的时间间隔是普通路由器的1/3，这样可以保证DIS失效的时候可以被快速检测到。 DIS的选举是抢占的, 不能不参加选举，IS-IS中不存在备份DIS,当一个DIS不能工作的时候，直接选举另外一个。 在广播子网中创建并向所有的路由器通告伪节点LSP(Link State Protocol Data unit 链路状态数据单元). 在LAN中通过每10s周期性发送CSNP（完全数据库描述）来泛洪LSP(Link State Protocol Data unit 链路状态数据单元). DIS的选举过程： 比较接口优先级，高的优 具有最大的(SNPA子网接入点)的路由器将当选DIS。广播网络中SNPA是指MAC地址 点到点 广播 Hello报文 P2P IIH Level-1/2 LAN IIH Hello报文形式 单播 组播 Hello定时器 10s 10s，DIS为3.3s 邻接关系数量 1 多个 LSDB同步同步相关报文： LSP报文：用于描述链路状态信息 Level-1 LSP仅在区域内传播，Level-2 LSP在骨干网传播 SNP报文：用于描述LSDB中LSP摘要，并对邻居之间最新接收的LSP进行确认 CSNP报文：包含所有LSP的摘要信息，在广播网络中周期发送，在点对点网络中只在第一次发送 PSNP报文：列举最近收到的一个或多个LSP序号，用于LSP确认 在广播网络中： 所有同类路由器向DIS发送自己的所有LSP DIS周期发送LSP摘要信息 IS向DIS发送PSNP响应 DIS回复LSP_K 参考资料 百度百科IS-IS]]></content>
      <tags>
        <tag>网络</tag>
        <tag>IS-IS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件系统学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2F%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Postfix邮件服务器学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2FPostfix%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[邮件服务概述 常见邮件服务或协议 Postfix服务器搭建 邮件服务概述Mail与DNS的相关性mail server需要有一个合法的域名存在于DNS服务器上（不是一定要自己架设DNS服务器），可以找ISP或DNS服务商等注册。 只要有主机名称对应到IP ，即是有A ( Address )这个DNS的标志后，那么就可以架设mail server了。 MX（Mail Exchanger）这个DNS设定中的标志，主要就是要给mail server用的，可以让Internet上面的信件马上找寻到Mail主机的位置，并且MX后面可以接数字，一个domain或者是一个主机可以有多个MX标志。当主要的mail server挂点时，由于有MX标号，信件不会直接退回，而是跑到下一个MX设定的主机去，并且暂存在该处，等到主要的mail server起来之后，这个MX设定的主机就会将信件传送到目的地。当有了MX标志之后，要传送mail的时候，可以直接依据DNS的MX标志直接将信件传送到该设定的MX邮件主机，而不需要去寻问到底邮件要寄到哪里去，实现邮件路由。 邮件传送流程MUA（Mail User Agent）：邮件用户代理，即邮件客户端，用于收发邮件 MTA（Mail Transfer Agent）：邮件传送代理，即邮件服务，具有收受邮件和转递邮件的功能 MDA（Mail Delivery Agent）：邮件递送代理，是MTA下的一个程序。用于分析MTA收到的新建表头或内容等资料，决定这封邮件的去向，即MTA的转递功能是由MDA完成的。且MDA能过滤垃圾邮件、自动回复 Mailbox：邮件信箱，即某个用户专用的邮件存放点，Linux默认的信箱目录为/var/spool/mail step0：获取本地MTA的使用权限，即向MTA注册邮箱账号密码 step1：编写邮件，传送到MTA。邮件包含：标头（收寄件人邮箱，标题）、内容 step2.1：若该邮件的目的是本地端MTA账号，会通过MDA发往本地的mailbox step2.2：若该邮件的目的是远端MTA，则开始转递，向下一跳MTA的25端口发送 step3：对方MTA接收邮件，等待远端用户读取 MRA（Mail Retrieval Agent）：邮件恢复代理。当用户端收受信件时，使用的是MRA的POP3, IMAP等通讯协定，并非MTA的SMTP。 常见邮件服务或协议SMTPSMTP（Send Mail Transfer Protocol）：是一种发送邮件的协议，使用TCP的25端口。在建立一个TCP连接后，在这个连接上进行控制、应答与数据发送。客户端以文本发送请求，服务器端回复3个数字的应答。 客户端常见指令 指令 说明 HELO \ 开始通信 EHLO \ 开始通信（扩展HELO） MAIL FROM: \ 发送人 RCPT TO: \ 接收人 DATA 发送电子邮件的正文 RSET 初始化 VERY \ 确认用户名 EXPN \ 将邮件组扩展为邮件地址列表 NOOP 请求应答 QUIT 关闭 每个指令和应答最后必须追加换行指令CR、LF 由于SMTP不具备验证发送者的功能，因此无法避免垃圾邮件，但也可通过POP before SMTP或SMTP认证对发送者认证。并且，邮件收发双方必须同时在线，否则邮件会发送失败。 使用SMTP协议发送邮件首先检查本机的25号端口是否开启。在root用户上向本地用户tom发送邮件。 123456789101112131415161718192021[root@s1 ~]# telnet 127.0.0.1 25 # 使用telnet连接本地25端口Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is &apos;^]&apos;.220 s1.localdomain ESMTP Postfixhelo s1 # 开始通信，跟上主机名250 s1.localdomainmail from:root # 发送方250 2.1.0 Okrcpt to:tom # 接收方250 2.1.5 Okdata # 开始正文354 End data with &lt;CR&gt;&lt;LF&gt;.&lt;CR&gt;&lt;LF&gt;hellohellohello. # 单独换一行，并打. ，再换行结束正文250 2.0.0 Ok: queued as E4B5D20E4560quit # 退出221 2.0.0 ByeConnection closed by foreign host. 切换到tom用户 1234567891011121314151617[tom@s1 ~]$ mailHeirloom Mail version 12.5 7/5/10. Type ? for help.&quot;/var/spool/mail/tom&quot;: 1 message 1 new&gt;N 1 root@s1.localdomain Thu Jan 24 05:18 15/432 &amp; 1 # 查看第一封邮件Message 1:From root@s1.localdomain Thu Jan 24 05:18:01 2019Return-Path: &lt;root@s1.localdomain&gt;X-Original-To: tomDelivered-To: tom@s1.localdomainDate: Thu, 24 Jan 2019 05:17:05 +0800 (CST)From: root@s1.localdomainStatus: Rhellohellohello POP为了解决SMTP的弊端，引入了POP（Post Office Protocol）协议，这是一种用于接收邮件的协议，TCP端口110，发送端的邮件根据SMTP协议被转发到一直处于插电状态的POP服务器，客户端再根据POP协议从POP服务器接收对方发来的邮件，该过程中支持身份验证，邮件客户端会从邮件服务器上获取所有发给自己的新邮件，然后关闭连接，在关闭连接后，邮件服务器会删除所有被标记为已接收的邮件。当前POP的版本为3，写作POP3。 客户端的应答只有两种：正常的”+OK”，错误的”-ERR”。 POP3的收信方式： MUA 透过POP3连接到MRA 的110端口， 并且输入帐号与密码来取得正确的认证与授权 MRA 确认该使用者帐号/密码没有问题后，会前往该使用者的Mailbox (/var/spool/mail/使用者帐号) 取得使用者的信件并传送给使用者的MUA上 当所有的信件传送完毕后，使用者的mailbox内的资料将会被删除 POP3与SSL结合称为POP3S，实现邮件加密， IMAPIMAP（Internet Message Access Protocol）因特网消息访问协议，与POP类似，是接收邮件的协议。在POP中，邮件有客户端进行管理，IMAP中邮件由服务器进行管理。不必从邮件服务器上下载所有邮件也可以阅读，并且会对已读和未读进行分类管理。当前版本为4，写作IMAP4。 可以将mailbox的资料转存到主机上的家目录，不但可以建立邮件档案，也可以针对信件分类管理。 Postfix服务器搭建直接yum安装postfix。若安装了postfix，就要停止sendmail的所有相关服务。 postfix的相关配置文件： /etc/postfix/main.cf：主配置文件 /etc/postfix/master.cf：postfix运行参数，一般不用修改 /etc/postfix/access：访问控制 /etc/aliases：邮件别名，或设置邮件群组 postfix命令 12345postfix check #检查配置文件或权限等 start #启动postfix stop #关闭postfix flush #强制将目前邮件队列中的邮件寄出 reload #重载配置文件 postfix服务的配置文件/etc/postfix/main.cf 12345678inet_interfaces = localhost # 接收本地的请求。# all为所有请求，localhost-only为仅接收本地请求myhostname = host.domain.tld # 系统主机名（FQDN）mydomain = domain.tld # 系统域名myorigin = $myhostname # 发信源mydestination = $myhostname # 指定发给本地邮件的域名relayhost = $mydomain # 中继服务器域名mynetworks = 127.0.0.0/8 # 信任的客户端 可以直接使用命令postconf -e修改配置项。 12345postconf -e &quot;inet_interfaces=all&quot;postconf -e &quot;myhostname=s1.example.com&quot;postconf -e &quot;mydomain=example.com&quot;postconf -e &quot;myorigin=example.com&quot;postconf -e &quot;inet_protocols=ipv4&quot; 参考文章 鸟哥的Linux私房菜 图解TCP/IP]]></content>
      <tags>
        <tag>Postfix</tag>
        <tag>邮件服务</tag>
        <tag>sendmail</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2FTomcat%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于tomcat9.0.13，jdk1.8 Tomcat概述 Tomcat环境搭建 Tomcat概述Tomcat是Apache基金会下的一个核心项目，是一个轻量级的web应用服务器，主要用于作为JSP应用与Servlet的后端服务器。最早项目名叫catalina，后改名为tomcat。 Tomcat注重于servlet引擎，对静态页面的加载不如apache，因此常常tomcat与apache组网，apache用于静态页面生成，动态请求会转发给tomcat处理。 Tomcat环境搭建搭建Tomcat，首先要配置JAVA环境，下载jdk，解压/usr/local/jdk8。然后在/etc/profile配置环境变量 123export JAVA_HOME=/usr/local/jdk8export CLASSPATH=$JAVA_HOME/libexport PATH=$JAVA_HOME/bin:$PATH 使用java -version和javac -version检查是否安装及配置成功 Tomcat目录结构123456789# tree -d -L 1.├── bin # 存放启动和关闭Tomcat的脚本文件├── conf # 存放配置文件├── lib # 存放服务器支撑jar包├── logs # 存放日志文件├── temp # 存放临时文件├── webapps # web应用目录└── work # Tomcat工作目录 bin目录 1234567891011├── catalina.sh # Tomcat的核心脚本文件，用于启动、停止tomcat等操作├── ciphers.sh├── configtest.sh├── daemon.sh├── digest.sh├── makebase.sh├── setclasspath.sh├── shutdown.sh # Tomcat停止脚本├── startup.sh # Tomcat启动脚本，相当于catalina.sh run，而且是后台运行├── tool-wrapper.sh└── version.sh # 显示Tomcat版本信息 conf目录 12 配置WEB应用使用catalina.sh run或start.sh启动Tomcat。tomcat默认会监听三个端口8005、8009、8080。 有五种方法配置web应用 在conf目录中context.xml中配置，配置会被所有web应用加载 在conf目录中引擎目录(catalina)的主机目录(localhost)下新建server.xml.default配置，会被主机的所有web应用加载 在conf目录中catalina的localhost目录中创建任意一个.xml文件，在文件中添加上下文，而文件名会被用作web应用的名称（虚拟站点名）。一个web应用可以映射多个虚拟目录。 在主机目录下META-INF/中context.xml 在conf目录下server.xml中在&lt;Host&gt;中添加上下文（就是web应用路径）]]></content>
      <tags>
        <tag>server</tag>
        <tag>Tomcat</tag>
        <tag>web</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH与SSL协议学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2FSSH%E4%B8%8ESSL%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[SSL/TLS概念 OpenSSL简介 SSH协议 SSL/TLS概念SSL（Secure Socket Layer，安全套接字层）是一种标准安全协议，由美国网景（Netscape）开发，用于在在线通信中建立Web服务器和浏览器之间的加密链接。SSL技术的使用确保了Web服务器和浏览器之间传输的所有数据都保持加密状态。TLS（transport Layer Security，安全传输层协议）是SSL标准化后的版本，与SSL基本没有区别。 SSL/TLS的主要功能： 认证用户与服务器，确保数据发送到正确的客户端和服务器，即可靠性 加密数据，即机密性 维护数据的完整性 SSL协议架构SSL基于TCP，且分为两个子层：握手层和记录层，其中握手层负责建立SSL连接，记录层负责对报文的加解密。 握手层： 协商加密能力 协商密钥参数 验证对方身份 建立并维护SSL会话 握手层协议报文格式： 消息类型Type 消息长度Length 消息相关参数Content SSL提供三种握手过程，分别为： 无客户端身份认证的全握手 客户端向服务器发送以下信息：支持的SSL最高版本、加密套件列表、压缩算法列表、客户端随机数（32位）、会话ID 服务器端回应客户端以下信息：服务器同意的SSL版本、加密套件、压缩算法、会话ID、服务器端随机数。并且还会发送服务器的证书、服务器端密钥交换的信息，最后通知对端握手信息已发完 客户端再向服务器端发送密钥参数和握手过程的验证报文，并通知对端开始启用加密参数 服务器再向客户端发送自己的握手过程验证报文，并通知对端开始启用加密参数 有客户端身份认证的全握手 与上面类似，但在第2步后，服务器端还会向客户端请求客户端的证书，然后客户端回应自己的证书，并会附加上数字签名 会话恢复 当SSL连接因某些原因不正常断开后，可在超时时间内进行会话恢复。 客户端向服务器发送的消息与第1条一致，其中会话ID为上一次SSL连接的会话ID。其余过程也基本一致。 记录层： 保护传输数据的机密性，对数据进行加密和解密 验证传输数据的完整性，计算报文摘要 对报文压缩 保证数据传输的可靠有序 记录层对数据包的三个操作：分片、压缩、加密 记录层协议报文格式： 报文类型：1个字节，密钥改变协议（20）、告警协议（21）、握手协议（22）、应用层数据（23） 版本：2字节，TLS1.0（3,1）、SSL3.0（3,0） 长度：2字节记录层报文的长度，包括加密数据和MAC值 MAC：消息验证码 SSL会话与连接 SSL会话是指客户端与服务器间的关联关系，通过握手协议创建。而SSL连接是用于点对点数据的传输，连接的维持时间比较短暂，且一定与一个会话关联。 一次会话过程通常会发起多个SSL连接来完成任务，这些连接共享会话定义的安全参数，这样可以避免为每个SSL连接单独进行安全参数的协商，而只需在会话建立时进行一次协商，提高了效率。 HTTPS与HTTP连接的建立耗时也因为SSL层而出现3倍的差距。可通过curl -w &quot;TCP handshake: %{time_connect}, SSL handshake: %{time_appconnect}&quot; -so /dev/null 网址测试。 OpenSSL概念OpenSSL是一个SSL的密码库，是对SSL协议的实现，包含了主要的密码算法，常用的密钥和证书封装管理功能。 OpenSSL提供八种对称加密算法（DES、AES、Blowfish、CAST、IDEA、RC2、RC5），支持四种非对称加密算法（DH、RSA、DSA、椭圆曲线EC），实现五种信息摘要算法（MD2、MD5、MDC2、SHA（SHA+SHA1）、RIPEMD） Heartblood漏洞简介 心脏出血漏洞，于2014年被公开。受害者的内存内容就会以每次64KB的速度进行泄露，通过读取网络服务器内存，攻击者可以访问敏感数据，从而危及服务器及用户的安全。 SSH协议Secure Shell安全壳协议，是建立在TCP上的安全协议，端口号22。可以防止中间人攻击、DNS和IP欺骗，并可加快数据的传输速度，且通过ssh传输的数据都是经过压缩的。 目前SSH有两个版本SSH1和SSH2，这两个版本互不兼容。SSH有以下特点： 支持DES、3DES加密 支持公钥（密钥）验证方式、密码（口令）验证方式、不验证 支持RSA认证 SSH连接建立过程： 版本号协商：客户端与服务器协商出双方使用的SSH版本 密钥与算法协商：客户端与服务器交换算法协商报文，协商出使用的算法，并且生成会话密钥和ID 认证：客户端向服务器发送认证请求，服务器端对客户端认证 会话请求：客户端向服务器发送会话请求，服务器等待并处理客户端请求 交互会话：数据加密传输 sshd服务通过openssh软件实现sshd服务，sshd正是使用ssh协议进行远程访问或传输文件的服务。 sshd主要要有三个软件： openssh：包含openssh服务器与客户端需要的核心文件 openssh-clients：openssh客户端软件 openssh-server：openssh服务器软件 Openssh的配置文件 /etc/ssh/ssh_config：客户端配置文件 /etc/ssh/sshd_config：服务器端配置文件 ssh命令常见选项： 123456ssh [username@]host [options] [command] -p 指定连接的远程主机端口，默认22 -v 显示详细信息，一般用于拍错 -C 压缩所有数据 可直接通过ssh在远端执行命令 -l 指定登录用户名 sshd_config配置1234567891011121314151617181920212223242526272829Port 22 #端口号#为安全起见，在实际生产环境中，最好将端口改为非22，减小ssh暴露的危险Protocol 2 #SSH版本，默认2，SSH1已淘汰AddressFamily #ListenAddress 0.0.0.0 #设置sshd服务器监听的本地IP地址。0.0.0.0表示监听本地所有IP地址（如果有多个）HostKey /etc/ssh/ssh_host_rsa_key #服务器秘钥文件的路径（还有dsa等密钥）Compression yes #是否可使用压缩指令KeyRegenerationInterval 1h #服务器重新生成密钥的周期ServerKeyBits 1024 #服务器密钥的长度LogLevel INFO #日志等级LoginGraceTime 2m #输入密码后，若2分钟内未连接成功，则断开PermitRootLogin yes #是否允许使用root登录远程主机，若为生产环境需要设为noStrictModes yes #ssh在接收登录请求之前是否检查用户根目录和rhosts文件的权限和所有权，默认开启SyslogFacility AUTHPRIV #日志类型PubkeyAuthentication yes #是否开启公钥验证，如果使用公钥验证的方式登录时，则设置为yesAuthorizedKeysFile .ssh/authorized_keys #公钥验证文件的路径PasswordAuthentication yes #是否开启密码验证PermitEmptyPasswords no #是否允许空密码登录PrintMotd yes #登录后是否打印信息（上次登录时间和地点等），信息内容可在/etc/motd中编辑PrintLastLog yes #显示上次登录的信息，默认允许UsePrivilegeSeparation sandbox #是否允许权限较低的程序一共用户操作，会让sshd在远程用户登入后产生一个属于该用户的sshd程序，使系统较安全UseDNS yes #为了判断客户端是否合法，会使用DNS反查客户端主机名。 #若是内网，则no可以让连接更快。MaxAuthTries 6 #最多密码尝试次数MaxSessions 10 #最多终端数ClientAliveInterval 0 #向客户端发送keepalive报文的间隔ClientAliveCountMax 3 #若三次收不到keepalive消息，则认为连接断开TCPKeepAlive #是否持续连接，设置yes可以防止死连接#SSH Server会传送KeepAlive的讯息给Client端，以确保两者的联机正常 最好将ssh的日志文件/var/log/secure的路径改掉，减小入侵后ssh日志文件被删除的风险。可修改/etc/rsyslog.conf的authpriv参数，包括特权信息如用户名在内的认证活动。 默认：authpriv.* /var/log/secure ，修改此项即可改变ssh日志路径 密钥分发命令ssh-keygen用于生成密钥对。 参考文章 百度百科-ssl 百度百科-ssh]]></content>
      <tags>
        <tag>server</tag>
        <tag>OpenSSL</tag>
        <tag>SSL</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Xinted学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2FXinted%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[无人值守学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2F%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇主要包含以下内容： PXE概述 Kickstart 网络安装试验 Kickstart配置 Cobbler PXE概述Preboot Execution Environment远程预启动执行环境，就是使计算机通过网络启动。 要达成PXE必须要有两个环节： 客户端的网卡必须要支持PXE用户端功能，并且开机时选择从网卡启动，这样系统才会以网卡进入PXE客户端的程序 PXE服务器必须要提供至少含有DHCP以及TFTP的服务 DHCP服务必须要能够提供客户端的网络参数，还要告知客户端TFTP所在的位置； TFTP则提供客户端的boot loader及kernel file下载路径。 可选的其他服务：NFS、FTP、HTTP等 完整的PXE交互过程： Client向DHCP发送IP地址请求消息，DHCP检测Client是否合法（主要是检测Client的网卡MAC地址），如果合法则返回Client的IP地址，同时将启动文件pxelinux.0的位置信息一并传送给Client Client向TFTP发送获取pxelinux.0请求消息，TFTP接收到消息之后再向Client发送pxelinux.0大小信息，试探Client是否满意，当TFTP收到Client发回的同意大小信息之后，正式向Client发送pxelinux.0，Client接收并执行pxelinux.0文件 Client向TFTP Server发送获取针对本机的配置信息文件的请求（在TFTP服务的pxelinux.cfg目录下，这是系统菜单文件，格式和isolinux.cfg格式一样，功能也是类似），TFTP将配置文件发回Client，继而Client根据配置文件执行后续操作。 Client向TFTP发送Linux内核请求信息，TFTP接收到消息之后将内核文件发送给Client Client向TFTP发送根文件请求信息，TFTP接收到消息之后返回Linux根文件系统Client启动Linux内核 Client从FTP或HTTP下载安装源文件，读取自动化安装脚本 引用自Cobbler原理解析 KickstartKickstart概述Kickstart是通过自动应答文件，将安装系统过程中手动设置的语言、密码、网络等参数自动设置。 Kickstart文件有三种生成方式： 手动书写 system-config-kickstart图形化配置 红帽系系统自带的Anaconda生成 Kickstart准备服务分工介绍： DHCP：为安装的新主机分配IP地址 TFTP：仅仅提供引导文件 VSFTP|HTTP|NFS：提供系统镜像中所有文件，然后会根据Kickstart文件自动选择要安装的软件，并配置 防止访问出现错误，先将selinux设为Permissive。setenforce 0 DHCP配置首先配置DHCP服务。yum install dhcp修改配置文件/etc/dhcp/dhcpd.conf12345678910111213141516171819# 日志级别log-facility local7;# DNS服务器域名option domain-name-servers system1.example.com;# 网关option routers 192.168.10.2;# 默认分配时间default-lease-time 600;# 最大分配时间max-lease-time 7200;subnet 192.168.10.0 netmask 255.255.255.0 &#123; # 地址分配范围 range 192.168.10.101 192.168.10.110; # TFTP服务器（重要） next-server 192.168.10.100; # TFTP服务器上的共享启动文件名（重要） filename &quot;pxelinux.0&quot;;&#125; 重新加载并设置开机自启systemctl restart dhcpdsystemctl enable dhcpd若开启了防火墙应该放行服务123firewall-cmd --permanent --add-service=dhcpfirewall-cmd --permanent --add-port=67/tcp --add-port=67/udpfirewall-cmd --reload TFTP配置配置TFTP服务，首先需要安装xinetd服务，因为TFTP是被Xinetd动态管理的服务。yum install xinetd tftp-server修改配置文件/etc/xinetd.d/tftp123456789101112131415service tftp&#123; socket_type = dgram protocol = udp wait = yes user = root server = /usr/sbin/in.tftpd # server_args指定共享目录路径 server_args = -s /tftpboot disable = no per_source = 11 cps = 100 2 flags = IPv4&#125;disable的值默认为yes，表示禁用tftp，因此要改为no，开启tftp 重启Xinted服务systemctl restart xinetd.service123通过查看服务是否开启# ss -aupt | grep xinetdudp UNCONN 0 0 *:tftp *:* users:((&quot;xinetd&quot;,pid=3490,fd=5)) 若开启了防火墙，需要放行服务和端口123firewall-cmd --permanent --add-service=tftpfirewall-cmd --permanent --add-port=69/udpfirewall-cmd --reload 使用VSFTP搭建镜像源安装VSFTPD服务yum install vsftpdsystemctl start vsftpdsystemctl enable vsftpd 将光盘镜像挂载在/var/ftp/pub中。mount /dev/cdrom /var/ftp/pub 若开启了防火墙，应该放行端口和服务123firewall-cmd --permanent --add-port=20/tcp --add-port=21/tcpfirewall-cmd --permanent --add-service=ftpfirewall-cmd --reload 在浏览器中输入ftp://192.168.10.100访问成功。 使用HTTP搭建镜像源安装HTTPD服务yum install httpdsystemctl start httpdsystemctl enable httpd 将光盘镜像挂载在/var/www/html/centos7上。mount /dev/cdrom /var/www/html/centos7 若开启了防火墙，应该放行端口和服务123firewall-cmd --permanent --add-port=80/tcpfirewall-cmd --permanent --add-service=httpfirewall-cmd --reload 在浏览器中输入192.168.10.100/centos7访问成功。 Syslinux配置安装syslinux服务syslinux是一个功能强大的引导加载程序，用于获取引导文件。yum install syslinux将引导文件复制到TFTP主目录cp /usr/share/syslinux/pxelinux.0 /tftpboot若要图形化菜单功能（仅仅是可以上下键切换，最好一起复制了），可将/usr/share/syslinux中的menu.32或vesamenu.c32复制到/tftpboot。这里就复制vesamenu.c32，比menu.32更好。并在/tftpboot中创建目录pxelinux.cfg用于存放默认开机选项，并在该目录中创建default文件 创建存放CentOS7内核文件的目录mkdir /tftpboot/centos7，并将挂载镜像目录/var/ftp/pub/isolinux/中vmlinuz和initrd.img两个内核文件复制到该目录中。cp /var/ftp/pub/isolinux/{vmlinuz,initrd.img} /tftpboot/centos7/最好将isolinux目录下的isolinux.cfg也复制过去，该文件提供了开机选项，可以以它作为修改开机选项和菜单的模板。可以直接将内容拷贝过去，cat /var/ftp/pub/isolinux/isolinux.cfg &gt; /tftpboot/pxelinux.cfg/default。 default即isolinux.cfg简单解析123456789101112131415161718192021222324252627282930default vesamenu.c32 # 必须指定，填/tftpboot中复制的图形化文件timeout 10 # 在选择界面停留的时间（若未操作）display boot.msg # 选项的说明文件菜单的一些显示设置，不用改menu clearmenu background splash.pngmenu title CentOS 7 # 引导是显示的标题menu vshift 8menu rows 18menu margin 8#menu hiddenmenu helpmsgrow 15menu tabmsgrow 13.....在引导界面上显示的选项label linux menu label ^Install CentOS 7 kernel ./centos7/vmlinuz # vmlinuz是可引导的、压缩的内核，路径要设为相对路径（相对于tftp根目录） append initrd=./centos7/initrd.img ks=ftp://192.168.10.100/ks_config/ks.cfg quiet # 设置内核文件，要设置initrd.img的相对路径 # initrd.img全称boot loader initialized RAM disk， boot loader初始化的内存盘。在linux内核启动前，boot loader会将存储介质中的initrd文件加载到内存，内核启动时会在访问真正的根文件系统前先访问该内存中的initrd文件系统 # 后面跟着ks=ks.cfg文件的路径，http或ftp都行 # 后面还可以跟上ksdevice=eth0，当客户端有多块网卡时，此项就会让系统不提示要选择哪块网卡label check menu label Test this ^media &amp; install CentOS 7 menu default # 默认光标停留在此标签（选项）上 kernel ./centos7/vmlinuz append initrd=./centos7/initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 rd.live.check quiet 整个/tftpboot的目录结构如下12345678/tftpboot/├── centos7│ ├── initrd.img│ └── vmlinuz├── pxelinux.0├── pxelinux.cfg│ └── default└── vesamenu.c32 网络安装试验做这个实验时，要先修改/tftpboot/pxelinux.cfg/default1234567891011找到以下内容label linux menu label ^Install CentOS 7 menu default kernel ./centos7/vmlinuz append initrd=./centos7/initrd.img inst.stage2=ftp://192.168.10.100/pub quietnet.ifnames=0 biosdevname=0inst.stage2设置FTP镜像源在quiet后再加上net.ifnames=0 biosdevname=0让网卡名称为ethN，而不是默认的eno16777728这样的随机名称 创建一个新的虚拟机，不指定镜像。进入虚拟机的BIOS设置进入Boot菜单，通过-或+改变启动顺序，将Network boot from Intel E1000移到最上面。保存退出，会自动启动主机，通过网络读取FTP镜像源。最后进入图形化安装界面 Kickstart配置手动配置首先创建ks.cfg，存放在/var/ftp/ks_config（FTP源）或/var/www/html/centos/ks_config（HTTP源）。修改/tftpboot/pxelinux.cfg/default12345678仍然找到这段内容，修改initrid后的内容删除原来的inst.stage2，改为ks=fs.cfg路径，HTTP同理label linux menu label ^Install CentOS 7 menu default kernel ./centos7/vmlinuz append initrd=./centos7/initrd.img ks=ftp://192.168.10.100/ks_config/ks.cfg quietnet.ifnames=0 biosdevname=0 在主目录中有系统自动创建的anaconda-ks.cfg，可以此为模板。在图像化配置安装时就是向该文件中添加配置，直到点击安装时，安装程序就会根据该配置文件安装。 anaconda-ks.cfg简单解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142分为三个部分：1. 选项指令段，用于图形化安装时除包选择外的所有手动操作2. %packages段，用于选择软件包3. 脚本段，可选。分为两种： %pre：预安装脚本段，在安装系统之前就执行的脚本。很少使用 %post：后安装脚本段，在系统安装完成后执行的脚本。必选选项：# auth验证选项auth --enableshadow --passalgo=sha512 --enableshadow|--useshadow 开启shadow文件验证 --passalgo 指定密码加密算法# bootloader指定如何安装引导程序bootloader --append=&quot;crashkernel=auto&quot; --location=mbr --boot-drive=sda --append 指定内核参数 --location 指定引导程序的位置，默认为MBR --boot-drive 指定grub安装的分区# keyboard键盘类型keyboard --vckeymap=us --xlayouts=&apos;us&apos; --vckeymap指定键盘分布，默认为us美式# lang指定语言lang en_US.UTF-8# rootpw指定root密码rootpw --iscrypted $6$D2fmDfXJI30ZbG0x$lenXfD98spplf7jHTmfiJ0m7CgQqJM.ddQ5hu07qiU3A5fJcRhSQA5KZolrWoSfGm2oIwJUglnRwoXth9rDGc0 --iscrypted 使用加密密码可选选项：install 表示是安装系统，若为install还需指定安装方式： cdrom 表示从光盘安装 harddrive 硬盘安装，硬盘必须是VFAT或EXT文件系统 --dir 指定从包含安装树（install-tree）的目录安装 --partition 指定从哪个分区安装 nfs --server 指定NFS服务器主机名或IP地址 --dir 指定安装树目录 --opts 指定NFS的挂载选项 url --url 后面跟上地址update 表示是升级系统graphical 表示图形模式下执行kickstart安装，默认text 文本模式下根据kickstart执行安装（手动创建一定是text）firstboot 安装后第一次启动默认会有需要手动配置的界面，应该禁用 --enable|--disable 启用|禁用ignoredisk 指定忽略的磁盘 --only-use=sdanetwork 配置网络 --bootproto 地址协议，dhcp或static。若为static需要配置IP、掩码、网关、DNS --device=ens33 设置网卡名 --onboot=off 是否在引导系统时启用设备 --ipv6=auto 开启IPv6 --no-activate --hostname=localhost.localdomain 主机名若协议为static，则需要以下选项： --ip= --netmask= --gateway= --nameserver=repo 设置repo源 --name= --baseurl=services 设置服务是否启用 --disabled= --enabled=timezone Asia/Shanghai --isUtc --nontp 指定时区selinux 设置selinux --enforcing --permissive --disabledfirewall 是否开启防火墙 --disable|--enablexconfig --startxonbootautostep 交互式，和interactive类似interactive 使用kickstart文件指定的参数交互式安装，但仍会给出每一步的选择项，如果直接下一步就使用kickstart参数cmdline 在完全非交互的命令行模式下进行安装driverdisk 指定驱动程序所在位置 --source=autopart 自动分区 --type=lvmzerombr 清除磁盘的MBRclearpart 在安装系统前清除分区 --all 清除所有分区 --initlabel 创建标签，对于没有MBR或者GPT的新硬盘，该选项是必须的 --drives=sda 清除指定的分区 --Linux 清除Linux分区 --none 不清除分区 常用cleanpart --all --initlabelpart [分区] 创建分区 --fstype 文件系统类型 --asprimary 强制为主分区 --size 设置大小（单位Mb） --grow 使用所有可用空间，即为其分配所有剩余空间。 对于根分区至少需要3G空间（即使是--grow，也还是需要指定--size）user 在系统中生成一个新用户 --name 指定用户名 --groups 指定辅助组，非默认组 --homedir 用户家目录，如果不指定则默认为/home/&lt;username&gt; --password 该用户的密码，如果不指定或省略则创建后该用户处于锁定状态 --shell 用户的shell，不指定则默认 --uid 用户UID，不指定则自动分配一个非系统用户的UIDloggin 指定安装过程中的错误日志位置 --host 指定日志将发送到那台主机上 --port 如果远程主机的rsyslog使用非默认端口，则应该指定该端口选项 --level 指定日志级别halt|reboot 安装完成后操作，halt为关机，reboot为重启，默认是halt# 软件包或软件包组# @表示包组，@base和@core默认包含%packages@^graphical-server-environment@base@core@desktop-debugging@dial-up@fonts@gnome-desktop@guest-agents@guest-desktop-agents@hardware-monitoring@input-methods@internet-browser@multimedia@print-client@x11kexec-tools%end%addon com_redhat_kdump --enable --reserve-mb=&apos;auto&apos;%end%anacondapwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notemptypwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyokpwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty%end 注：%addon、%anaconda、%packages、%onerror、%pre、%post必须以%end结尾 官方并不建议手工创建kickstart文件，因为太过复杂，且容易出错。因此，可通过system-config-kickstart图形化工具快速生成kickstart文件。 system-config-kickstart配置需要安装该工具yum install system-config-kickstart打开工具后，按照以下界面配置即可。 若需要修改，则直接打开修改即可。若图形化无法添加安装软件包，就在生成的ks.cfg中添加。最终修改后的ks.cfg文件如下12345678910111213141516171819202122232425262728293031installkeyboard &apos;us&apos;rootpw --iscrypted $1$8.DdzSgf$UIjrFmFh/4Mavb/4q7z8U.url --url=&quot;ftp://192.168.10.100/pub&quot;lang en_USfirewall --disabledauth --useshadow --passalgo=sha512graphicalselinux --disabledskipxnetwork --bootproto=dhcp --device=eth0network --hostname=system10.example.comreboottimezone Asia/Shanghaibootloader --location=mbrzerombrclearpart --all --initlabelpart /boot --fstype=&quot;xfs&quot; --size=200part / --fstype=&quot;xfs&quot; --size=5part /var --fstype=&quot;xfs&quot; --size=10services --enabled=httpd%packages@base@coretreenmapwgethttpd%end 再次进行安装，进入下面画面时，发现配置已根据kickstart文件填写完成。 CobblerCobbler与Kickstart类似，是一个Linux服务器快速网络安装的服务，可以通过PXE快速安装、重装物理服务器和虚拟机。基于Python开发，支持命令行管理、web界面管理、提供API接口。可以管理DHCP，DNS，TFTP、RSYNC以及yum仓库、构造系统ISO镜像。 Cobbler会在请求内核文件后，再请求Kickstart文件（即ks.cfg）和OS镜像。然后Cobbler加载Kickstart文件并接收安装OS镜像。 Cobbler常见术语： distro：发行版，相当于一个操作系统镜像，包含内核和initrd信息以及软件包等 repository：保存一个yum或rsync存储库的镜像信息 profile：配置文件，包含distro、kickstart文件和repository等信息，作用为了修改/tftpboot/pxelinux.cfg/default文件，每生成或修改一次profile，都会在default文件中修改或追加对应的label system：目标系统，即要安装的主机，包含配置文件或镜像，IP地址等信息 image：系统镜像 system、image、repository用的很少，主要用distro和profile。 Cobbler安装仍然使用之前Kickstart的环境。必须关闭selinux。首先安装epel-release，因为Cobbler位于epel源中。然后安装Cobbler及其他工具程序yum install cobbler cobbler-web pykickstart其中cobbler-web是cobbler的网页端配置工具，可不用安装。pykickstart是用于检查kickstart文件语法的工具cobbler的运行依赖于dhcp、tftp、rsync及dns服务，因此在现有环境下还要安装rsync。yum install rsyncsystemctl enable rsyncdsystemctl start rsyncdsystemctl enable cobblerd.servicesystemctl start cobblerd.service 使用命令cobbler check进行检查，对查出的错误一一解决。12345671 : The &apos;server&apos; field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it.2 : For PXE to be functional, the &apos;next_server&apos; field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network. 这两个问题需要设置/etc/cobbler/settings，修改以下内容：123# 将127.0.0.1修改为本机的IP地址next_server: 192.168.10.100server: 192.168.10.100 13 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run &apos;cobbler get-loaders&apos; to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The &apos;cobbler get-loaders&apos; command is the easiest way to resolve these requirements. 问题是需要获取bootloaders文件，执行cobbler get-loaders自动下载，但要求联网。也可复制，但需要的文件很多，有的不好找，最好直接执行命令。 14 : debmirror package is not installed, it will be required to manage debian deployments and repositories 安装debmirror软件包并将/etc/debmirror.conf中的dists和arches注释。12#@dists=&quot;sid&quot;;#@arches=&quot;i386&quot;; 15 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to &apos;cobbler&apos; and should be changed, try: &quot;openssl passwd -1 -salt &apos;random-phrase-here&apos; &apos;your-password-here&apos;&quot; to generate new one 需要使用openssl生成加密密码来取代默认的密码。123456openssl passwd -1 -salt &apos;cobbler&apos; &apos;123456&apos; passwd 表示生成密码 -1 表示使用MD5加密 -salt 表示使用后面提供的参数生成，后面跟上用户名和密码会生成一个加密密码，将这串字符替换掉原来的默认密码default_password_crypted: &quot;$1$cobbler$52QDrGSqGlT9d5qbjg7QY/&quot; 16 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them 安装cman和fence-agents，cman可能会找不到这个包，但只安装fence-agents就够了。 最后使用命令cobbler sync应用调整的参数或重启cobblerd服务，再执行一次cobbler check检查，若还有错就继续排错，若没有错误就会显示No configuration problems found. All systems go. Cobbler默认管理tftp服务，默认不管理dhcp，因此tftp的根目录变为/var/lib/tftpboot。如果让Cobbler管理DHCP，则Cobbler管理DHCP的模板文件/etc/cobbler/dhcp.template会覆盖/etc/dhcp/dhcpd.conf。 将光盘挂载到本地，mount /dev/cdrom /mnt/mirror，然后执行cobbler import --name=CentOS7 --path=/mnt/mirror生成distro，从本地导入的过程实际上是将系统镜像中的文件复制到/var/www/cobbler/ks_mirror/CentOS7中。在/var/www/cobbler/images中也会生成一个CentOS7-x86_64的目录，其中存放了initrd.img和vmlinuz文件。 然后，需要提供kickstart文件，这里继续使用Kickstart实验用的ks.cfg文件，将文件移动到/var/lib/cobbler/kickstarts中，并改名为CentOS7.ks，需要修改以下内容。 123#如果存在ignoredisk设置，一定要注释掉，cobbler编译时不支持此语法修改镜像安装源url --url=&quot;http://http://192.168.10.100/cobbler/ks_mirror/CentOS7/&quot; 在导入镜像生成distro的过程中，会自动生成一个profile。使用cobbler profile list查看。使用cobbler profile report --name=CentOS7-x86_64查看profile信息。 123# cobbler profile report --name=CentOS7-x86_64其中profile默认使用的kickstart文件有误Kickstart : /var/lib/cobbler/kickstarts/sample_end.ks 需要通过cobbler profile edit --name=CentOS7-x86_64 --kickstart=/var/lib/cobbler/kickstarts/CentOS7.ks修改。 最好再修改内核启动参数net.ifnames和biosdevname使网卡名为ethN系列而不是用enoXXXXXX随机名。cobbler profile edit --name=CentOS7-x86_64 --kopts=&quot;net.ifnames=0 biosdevname=0&quot; 若要手动添加一个profile，可使用cobbler profile add --name=XXX --distro=distro名 --kickstart=ks文件路径。每添加一个profile，就是在/var/lib/tftpboot/pxelinux.cfg/default中添加一个label，一个label就是开机启动时的引导选项。 12345LABEL CentOS7-x86_64 kernel /images/CentOS7-x86_64/vmlinuz MENU LABEL CentOS7-x86_64 append initrd=/images/CentOS7-x86_64/initrd.img ksdevice=bootif lang= text net.ifnames=0 biosdevname=0 kssendmac ks=http://192.168.10.100/cblr/svc/op/ks/profile/CentOS7-x86_64 ipappend 2 在配置完成后，执行cobbler sync同步设置。 通过浏览器访问default文件中ks参数指定的ks文件路径，看是否能访问，若能显示文件内容，则配置没有问题。 重启xinetd、cobblerd、dhcpd服务，以防配置未刷新。 仍然使用一台裸机进行安装，会自动进入安装界面。 使用cobbler-web图形化配置如果开启了防火墙，需要放行443端口和https服务，因为Cobbler在CentOS7只支持https。 在浏览器访问https://IP地址/cobbler_web即可，输入账号密码，均为cobbler。 首先进行镜像的导入，左侧菜单的Import DVD选项配置。 菜单的Events查看事件日志。 进入distros配置，添加内核选项。也可以通过profiles配置。 设置网卡名为ethN系列 修改或编写ks文件 也可进入菜单system进行system配置。 参考文章 骏马金龙—无人值守CentOS7kickstart文件详解KICKSTART无人值守安装Cobbler-自动化部署神器cobbler无人值守批量安装Linux系统Cobbler原理解析Linux就该这么学Linux运维之道（第二版）]]></content>
      <tags>
        <tag>无人值守</tag>
        <tag>PXE</tag>
        <tag>Kickstart</tag>
        <tag>Cobbler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rsync文件同步服务器学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2FRsync%E6%96%87%E4%BB%B6%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容 Rsync介绍与搭建 quick check算法介绍 rsync的工作方式 rsync命令使用 规则解析 Rsync服务器搭建 Rsync部分报错解决 Rsync+Inotify文件自动同步 Mutt+Msmtp实现邮件监控 Rsync介绍与搭建Rsync（Remote Synchronize）是一个远程数据同步工具，可使本地主机不同分区或目录之间及本地和远程两台主机之间的数据快速同步镜像，远程备份等功能。 Rsync特点： 使用TCP 873端口 可根据数据变化进行差异备份或增量备份，减少数据流量 传输可以通过ssh协议加密数据 支持拷贝特殊文件如链接，设备等 可以镜像保存整个目录树和文件系统 可以保持原来文件或目录的所有属性均不改变 可使用rsh、ssh，或直接通过socket连接 支持匿名的或认证的进程模式传输 使用Rsync自己的quick check算法 rsync传输大文件时速度大概是scp的20倍以上 rsync同步过程由两部分模式组成：决定哪些文件需要同步的检查模式，文件同步时的同步模式。 检查模式是指按照指定规则来检查哪些文件需要被同步。 默认情况下，rsync使用quick check算法。可以通过rsync命令选项设置指定的检查模式。 同步模式是指在文件确定要被同步后，在同步过程发生之前要做哪些额外工作。 quick check算法介绍比较源文件和目标文件的文件大小和修改时间mtime（修改时间），只要存在不同，就发送端会传输该文件，如果目标路径下没有文件，则rsync会直接传输文件。若存在差异，并不会传送整个文件，而是只传源文件和目标文件所不同的部分，实现真正的增量同步。 rsync的增量传输体现在两个方面：文件级别的增量传输和数据块级别的增量传输。 文件级别的增量传输是指源主机上有，但目标主机上没有将直接传输该文件 数据块级别的增量传输是指只传输两文件所不同的那一部分数据。 两台计算机Host-A与Host-B，其中Host-A是源主机，即数据的发送端Sender，Host-B是目标主机，即数据的接收端Receiver。Host-A上存在文件file-A，Host-B上存在file-B。注：file-A与file-B是同名文件。rsync的实现有以下过程： Host-A告诉Host-B有文件file-A要传输。 Host-B收到信息后，将文件file-B划分为一系列大小固定的数据块(大小在500-1000字节之间)，并以chunk号码对数据块进行编号，同时还会记录数据块的起始偏移地址以及数据块长度。 Host-B对每一个分割好的数据块执行两种校验：一种是 32 位的滚动弱校验（rolling checksum），另一种是 128 位的 MD5 强校验。将file-B计算出的所有滚动弱校验和强校验码跟随在对应数据块chunk[N]后形成校验码集合，然后发送给主机Host-A 不同数据块的滚动弱校验值有可能相同，但几率非常小。 Host-A通过搜索file-A 的所有该固定大小的数据块（偏移量可以任选），并计算它的校验码和校验码集合中的校验码进行匹配。 如果能匹配上校验码集合中的某个数据块条目，则表示该数据块和file-B中数据块相同，不需要传输。 如果不能匹配校验码集合中的数据块条目，则表示该数据块是非匹配数据块，它需要传输给Host-B，于是Host-A将跳转到下一个字节，从此字节处继续取数据块进行匹配。 数据匹配过程有三个层次：首先比较hash值，然后比较弱滚动校验，最后比较强校验。 当Host-A发现是匹配数据块时，将只发送这个匹配块的附加信息给Host-B。同时，如果两个匹配数据块之间有非匹配数据，则还会发送这些非匹配数据。 当Host-B陆陆续续收到这些数据后，会创建一个临时文件，并通过这些数据重组这个临时文件，使其内容和file-A 相同。临时文件重组完成后，修改该临时文件的属性信息(如权限、所有者、mtime等)，然后重命名该临时文件替换掉file-B。 rsync的工作方式 本地传输方式：首先rsync命令执行时，会有一个rsync进程，然后根据此进程fork另一个rsync进程作为连接的对端，连接建立之后，后续所有的通信将采用管道的方式。 远程shell连接方式：本地敲下rsync命令后，将请求和远程主机建立远程shell连接（如ssh连接），连接建立成功后，在远程主机上将fork远程shell进程调用远程rsync程序，并将rsync所需的选项通过远程shell命令（如ssh）传递给远程rsync。这样两端就都启动了rsync，之后它们将通过管道的方式进行通信。 网络套接字连接远程主机上的rsync daemon：当通过网络套接字和远程已运行好的rsync建立连接时，rsync daemon进程会创建一个子进程来响应该连接并负责后续该连接的所有通信。这样两端也都启动了连接所需的rsync，此后通信方式是通过网络套接字来完成的。 远程shell临时启动一个rsync daemon：不要求远程主机上事先启动rsync服务，而是临时派生出rsync daemon，它是单用途的一次性daemon，仅用于临时读取daemon的配置文件，当此次rsync同步完成，远程shell启动的rsync daemon进程也会自动停止。 发起连接的一端称为Client端，就是执行rsync命令的一端，连接的另一端称为Server端。 注：当Client端和Server端都启动好rsync进程并建立好了rsync连接(管道、网络套接字)后，将使用Sender端和Receiver端来代替Client端和Server端的概念。 当两端的rsync连接建立后，Sender端的rsync进程称为Sender进程，该进程负责Sender端所有的工作。Receiver端的rsync进程称为Receiver进程，负责接收sender端发送的数据，以及完成文件重组的工作。Receiver端还有一个核心进程Generator进程，该进程负责在Receiver端执行--delete动作、比较文件大小和mtime以决定文件是否跳过、对每个文件划分数据块、计算校验码以及生成校验码集合，然后将校验码集合发送给Sender端。 三个进程的作业流程：Generator进程的输出结果作为Sender端的输入，Sender端的输出结果作为Recevier端的输入。并且，这三个进程是完全独立、并行工作的。 数据同步方式 推 push：一台主机负责把数据传送给其他主机，服务器开销很大，比较适合后端服务器少的情况 拉 pull：所有主机定时去找一主机拉数据，可能就会导致数据缓慢 rsync命令使用1234567891011本地传输方式: rsync [OPTION...] SRC... [DEST]远程shell连接方式: Pull: rsync [OPTION...] [USER@]HOST:SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST:DEST连接远程主机上的rsync daemon: Pull: rsync [OPTION...] [USER@]HOST::SRC... [DEST] rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST::DEST rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST 若主机与路径用:分隔，则为shell连接，若为::，则为daemon连接。 注：源路径如果是一个目录的话，带上尾随斜线和不带尾随斜线是不一样的，不带尾随斜线表示的是整个目录包括目录本身，带上尾随斜线表示的是目录中的文件，不包括目录本身。 若只有源路径或只有目的路径，则相当于ls -l查看指定文件或目录属性。 常用选项： 12345678910111213141516171819202122232425262728293031-a 归档模式，表示递归传输并保持文件属性。等同于&quot;-rtopgDl&quot;。-P 显示文件传输的进度信息-v 显示rsync过程中详细信息(最多支持-vvvv)-r 递归-t 保持mtime属性(最好加上，否则时间会设置为当前系统时间，在增量备份时会因为时间出错)-o 保持owner属性-g 保持group属性(属组)。-p 保持perms属性(权限，不包括特殊权限)。-D 拷贝设备文件和特殊文件。-l 如果文件是软链接文件，则拷贝软链接本身而非软链接所指向的对象。-z 传输时进行压缩提高效率。-R 使用相对路径。意味着将命令行中指定的全路径而非路径最尾部的文件名发送给服务端，包括它们的属性-u 仅在源mtime比目标已存在文件的mtime新时才拷贝。接收端判断，不会影响删除行为。--size-only 只检查文件大小（默认算法是检查文件大小和mtime不同的文件）--max-size 限制rsync传输的最大文件大小。可以使用单位后缀，还可以是一个小数值(例如：&quot;--max-size=1.5m&quot;)--min-size 限制rsync传输的最小文件大小。这可以用于禁止传输小文件或那些垃圾文件。--exclude 指定排除规则来排除不需要传输的文件。一个exclude只能指定一条规则，若有多条规则，就要写多个exclude--exclude-from 若规则有多条，可以写在文件中，并使用此选项加载规则文件--include 指定传输规则，只传输符合该规则的文件，与exclude相反--delete 接收端的rsync会先删除目标目录下已经存在，但发送端目录不存在的文件，以SRC为主，对DEST进行同步。多则删之，少则补之。注意&quot;--delete&quot;是在接收端执行的，所以它是在exclude/include规则生效之后才执行的。-b --backup 对目标上已存在的文件做一个备份，备份的文件名后默认使用&quot;~&quot;做后缀。--backup-dir 指定备份文件的保存路径，若指定，保存路径必须存在。 不指定时默认和待备份文件保存在同一目录下。 默认没有后缀，可通过&quot;--suffix=&quot;指定-e 指定所要使用的远程shell程序，默认为ssh。--port 连接daemon时使用的端口号，默认为873端口。--password-file daemon模式时的密码文件，是rsync模块认证的密码。-W --whole-file rsync将不再使用增量传输，而是全量传输。在网络带宽高于磁盘带宽时，该选项比增量传输更高效。--existing 要求只更新目标端已存在的文件，目标端还不存在的文件不传输。注意，使用相对路径时如果上层目录不存在也不会传输。--ignore-existing 要求只更新目标端不存在的文件。和&quot;--existing&quot;结合使用有特殊功能。--remove-source-files 要求删除源端已经成功传输的文件。 最常用组合-avz。 命令示例： 1234567891011rsync -r -R /etc/dir-1 /tmp 将/etc/dir-1目录复制到/tmp目录下，tmp目录下将会有etc/dir-1子目录rsync -r -R /etc/./dir-1 /tmp 将/etc/dir-1目录复制到/tmp目录下，但在/etc/和dir-1目录间加上了“.” 因此仅仅将dir-1目录复制过去作为子目录，tmp目录下将有dir-1子目录rsync -r -b --backup-dir --suffix=&apos;.bak&apos; /etc/dir-1 /tmp 备份文件，若不存在就直接复制，若已存在就添加后缀以区分rsync -r --exclude=&quot;*.txt&quot; /etc/dir-1 /tmp 将/etc/dir-1目录下的以&quot;.txt&quot;结尾的文件排除rsync -r -v --delete --exclude=&quot;*.txt&quot; /etc/dir-1 /tmp 将/tmp/dir-1中存在而/etc/dir-1不存在的文件删除，并且不删除&quot;.txt&quot;结尾的文件（即使源中不存在）sending incremental file listdeleting dir-1/a3.logdeleting dir-1/a2.logdeleting dir-1/a1.log 规则解析规则作用时间：当发送端敲出rsync命令后，rsync将立即扫描命令行中给定的文件和目录(扫描过程中还会按照目录进行排序，将同一个目录的文件放在相邻的位置)，这称为拷贝树(copy tree)，扫描完成后将待传输的文件或目录记录到文件列表中，然后将文件列表传输给接收端。筛选规则的作用时刻是在扫描拷贝树时，所以会根据规则来匹配并决定文件是否记录到文件列表中(严格地说是会记录到文件列表中的，只不过排除的文件会被标记为hide隐藏起来)，只有记录到了文件列表中的文件或目录才是真正需要传输的内容。筛选规则的生效时间在rsync整个同步过程中是非常靠前的，它会影响很多选项的操作对象，最典型的如--delete，--delete是在generator进程处理每个文件列表时、生成校验码之前进行的，这样就无需为多余的文件生成校验码。 rsync规则：通过选项--filter指定规则 exclude规则：即排除规则，只作用于发送端，被排除的文件不会进入文件列表(实际上是加上隐藏规则进行隐藏)。 include规则：即包含规则，也称为传输规则，只作用于发送端，被包含的文件将明确记录到文件列表中。 hide规则：即隐藏规则，只作用于发送端，隐藏后的文件对于接收端来说是看不见的，也就是说接收端会认为它不存在于源端。 show规则：即显示规则，只作用于发送端，是隐藏规则的反向规则。 protect规则：即保护规则，该规则只作用于接收端，被保护的文件不会被删除掉。 risk规则：即取消保护规则。是protect的反向规则。 clear规则：删除include/exclude规则列表。 上述内容都引用自骏马金龙－rsync介绍与用法 Rsync服务器搭建实验环境： Rsync服务器：192.168.205.135 Rsync客户端：192.168.205.134 首先，两台主机都需要安装rsync，yum/dnf install rsync，fedora已默认安装。 由于rsync的配置文件默认不存在，所以需要手动创建。Rsync有三个配置文件： rsyncd.conf：主配置文件 rsyncd.secrets：密码文件 rsyncd.motd：服务器信息文件 创建/etc/rsyncd.conf文件，具体参数可通过man rsyncd.conf查看 配置文件分为两部分：全局参数，模块参数全局参数：对 rsync 服务器生效，如果模块参数和全局参数冲突，冲突的地方模块参数生效模块参数：定义需要通过 rsync 输出的目录定义的参数 12345678910111213141516171819202122232425262728293031# 常见全局参数：port = 873 监听端口address = 192.168.205.135 监听服务器地址uid = nobody 数据传输时使用的用户ID，默认nobodygid = nobody 数据传输时使用的组ID，默认nobodyread only = yes 是否只读max connections = 10 并发连接数，0表示无限制。超出并发连接数时若再访问，会收到稍后重试的消息use chroot = no 是否开启chroot，若设为yes，rsync会首先进行chroot设置，将根映射到模块中path指定目录 需要root权限，在同步符号连接资料时仅同步文件名，不同步文件内容transfer logging = yes 开启Rsync数据传输日志功能#log format = 设置日志格式，默认log格式为：&quot;%o %h [%a] %m (%u) %f %l&quot;# 默认log格式表达的是：&quot;操作类型 远程主机名[远程IP地址] 模块名 (认证的用户名) 文件名 文件长度字符数&quot;#syslog facility = 指定rsync发送日志消息给syslog时的消息级别，默认值是daemonlock file = /var/run/rsync.lock 设置锁文件log file = /var/log/rsyncd.log 设置日志文件pid file = /var/run/rsyncd.pid 设置进程号文件motd file = /etc/rsyncd.motd 设置服务器信息提示文件hosts allow = 192.168.205.134 设置允许访问服务器的主机# 模块配置[rsync_test]comment = rsync test 添加注释path = /root/rsync_test 同步文件或目录路径ignore errors 忽略一些IO错误# exclude = 可以指定不同步的目录或文件，使用相对路径auth users = tom,jack 允许连接的用户，可以是系统中不存在的secrets file = /etc/rsyncd.secrets 设置密码验证文件，该文件的权限要求为只读（600），该文件仅在设置了auth users才有效list = false 是否允许查看模块信息timeout = 600 可以覆盖客户指定的 IP 超时时间。确保rsync服务器不会永远等待一个崩溃的客户端。 超时单位为秒钟，0表示没有超时定义，这也是默认值。 对于匿名rsync服务器来说，一个理想的数字是600 相关系统操作： 1234567useradd tom &amp;&amp; echo &quot;redhat&quot; | passwd tom --stdinecho &quot;tom:redhat&quot; &gt;&gt; /etc/rsyncd.secretsecho &quot;jack:redhat&quot; &gt;&gt; /etc/rsyncd.secrets 添加用户到密码文件chmod 600 /etc/rsyncd.secrets 修改密码文件权限echo &quot;Welcome to Rsync&quot; &gt;&gt; /etc/rsyncd.motd# firewall-cmd --permanent --add-port=873/tcp 若开启了防火墙，就放行端口rsync --daemon --config=/etc/rsyncd.conf 启动rsyncd服务 客户端同步文件：rsync -r tom@192.168.205.135::rsync_test /root/rsync_test 自动备份脚本，可配合crond使用 123456789101112#!/bin/bash# 本脚本是将服务器端的文件定期同步到本端# 设置服务器端模块和本端目录SRC=rsync_testDEST=/root/rsync_testServer=192.168.205.135# 设置验证用户名和密码User=tomPassword=redhat# 若本地同步目录不存在，就创建目录。同步时会删除目录中本端存在，但服务器端不存在的文件[ ! -d $DEST ] &amp;&amp; mkdir $DESTrsync -az --delete $&#123;User&#125;@$&#123;Server&#125;::$SRC $DEST/$(date +%Y%m%d) 若使用Xinetd服务管理Rsync，需要先安装xinetd。创建文件/etc/xinetd.d/rsync，添加以下内容。 123456789service rsync &#123; disable = no socket_type = stream wait = no user = root server = /usr/bin/rsync server_args = --daemon --config=/etc/rsyncd.conf log_on_failure += USERID&#125; 然后重启xinetd服务即可。 Rsync部分报错解决12rsync: failed to connect to 192.168.205.135 (192.168.205.135): No route to host (113)rsync error: error in socket IO (code 10) at clientserver.c(125) [Receiver=3.1.2] 解决：防火墙问题，放行端口或直接关闭 12@ERROR: auth failed on module rsync_testrsync error: error starting client-server protocol (code 5) at main.c(1648) [Receiver=3.1.2] 解决：用户名与密码问题或模块问题，检查用户名与密码是否匹配，服务器端模块是否存在 12rsync: read error: Connection reset by peer (104)rsync error: error in rsync protocol data stream (code 12) at io.c(759) [Receiver=3.1.2] 解决：服务器端配置文件/etc/rsyncd.conf问题，检查配置文件参数是否出错 Rsync+Inotify文件自动同步Inotify介绍Inotify是一个 Linux特性，是inode notify的简写，能监控文件系统操作，反应灵敏，异步传输信息，比cron高效，通过Inotify能试试了解文件系统发生的所有变化。 注：Linux内核需要大于2.6才集成了Inotify，先要通过uname -r查看内核版本 Inotify一些特点： 允许程序员使用标准 select 或者 poll 函数来监视事件 使用一个独立的文件描述符，可以通过系统调用获得 使用rsync工具与inotify机制相结合，可以实现触发式备份（实时同步）。 在系统/proc/sys/fs/inotify/目录中有三个文件： max_queued_events：inotify实例事件队列可容纳的事件个数，默认16384 max_user_instances：每个用户可以运行的inotifywait或inotifywatch命令的进程数，默认128 max_user_watches：每个进程最多监控文件数，默认8192 若要监控的文件量较大时，需要适当增大这三个值 可以在/etc/sysctl.conf中添加以下内容修改这三个值，或通过sysctl -w直接设置。 123fs.inotify.max_queued_events =fs.inotify.max_user_instances =fs.inotify.max_user_watches = Inotify常用的文件系统事件： 事件名 描述 IN_ACCESS 文件访问事件 IN_MODIFY 文件修改事件 IN_ATTRIB 文件属性修改事件 IN_OPEN 文件打开事件 IN_CLOSE_WRITE 可写文件被关闭事件 IN_CLOSE_NOWRITE 不可写文件被关闭事件 IN_MOVED_FROM IN_MOVED_TO 文件移动或重命名事件 IN_DELETE 文件或目录删除事件 IN_CREATE 文件或目录创建事件 IN_DELETE_SELF 自删除事件 若系统为fedora，可直接安装dnf install inotify-tools，若系统为CentOS，则需要先安装epel-release再安装yum install inotify-tools inotify-tools提供两个应用程序：inotifywait和inotifywatch inotifywait命令用法： 1234567891011121314151617inotifywait [options] file... @&lt;file&gt; 排除监控指定文件 --exclude &lt;pattern&gt; 使用正则表达式匹配例外文件，区分大小写 --excludei &lt;pattern&gt; 使用正则表达式匹配例外文件，不区分大小写 -m|--monitor 一直监听，不退出。若不加此项，监听到一个事件后就退出 -d|--daemon 相当于-m，但是是在后台运行，需要-o或--outfile指定输出文件，或者通过再指定--syslog将错误信息输出至syslog系统日志 -r|--recursive 递归监控目录 --fromfile &lt;file&gt; 从文件中读取需要监控与例外的文件名，每行一个文件，若文件名以@开头，表示例外文件 -o|--outfile &lt;file&gt; 将事件信息输出到文件，默认输出到标准输出 -s|--syslog 将错误事件日志发送到syslog，而不是stderr -q|--quiet 静默模式，只输出事件 -qq 静默模式，什么都不输出（包括事件） --format &lt;fmt&gt; 指定输出信息格式 --timefmt &lt;fmt&gt; 设置时间格式 -c|--csv 使用CSV格式输出 -t|--timeout &lt;seconds&gt; 在指定时间内若监听到事件，就退出 -e|--event &lt;event1&gt; [ -e|--event &lt;event2&gt; ... ] 只监控指定事件 实例：inotifywait -m -d -r -o /var/log/html_monitor /var/www/html 然后进入/var/www/html进行以下操作 123456touch a.htmlvim a.html cp a.html b.htmlrm a.html chmod -r b.html mv b.html a.html 在/var/log/html_monitor中就有以下信息 123456789/var/www/html/ CREATE a.html/var/www/html/ OPEN a.html/var/www/html/ ATTRIB a.html/var/www/html/ CLOSE_WRITE,CLOSE a.html/var/www/html/ OPEN,ISDIR /var/www/html/ ACCESS,ISDIR ...../var/www/html/ MOVED_FROM b.html/var/www/html/ MOVED_TO a.html 仅仅几步操作，就生成了170多行事件信息。 Inotify与Rsync实时同步数据要求分析：数据发布服务器既是Rsync服务器同时也是Inotify监控服务器，该服务器是用于发布数据的，将数据同步到Web服务器，实现Web服务器与此数据发布服务器的同步。 实验环境： 数据发布服务器：192.168.205.135 Web服务器：192.168.205.134 首先需要在Web服务器上编写rsyncd.conf，添加模块 123456[www]comment = web file dictionarypath = /var/www/htmlauth users = wwwsecrets file = /etc/rsyncd.secretshosts allow = 192.168.205.135 进行系统准备： 1234567891011# 在Web服务器上创建用户wwwuseradd www &amp;&amp; echo &quot;redhat&quot; | passwd www --stdinecho &quot;www:redhat&quot; &gt;&gt; /etc/rsyncd.secretschmod 600 /etc/rsyncd.secrets查看/var/www是否所属于www，若不是就chown -R www:www /var/www# 在数据发布服务器上ssh-keygenssh-copy-id -i ~/.ssh/id_rsa.pub www@192.168.205.134# 在Web服务器上，同理，双向交换ssh公钥ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.205.135 数据发布服务器上触发同步脚本示例： 1234567#!/bin/bashSRC=/var/www/web_html/DST=www@192.168.205.134::www/usr/bin/inotifywait -d -r -o var/log/inotify_web -e modify,delete,create,attrib $&#123;SRC&#125; | while read linedo /usr/bin/rsync -az --delete $&#123;SRC&#125; $&#123;DST&#125; 2&gt;&amp;1done &amp; 加上执行权限chmod a+x并写入/etc/rc.local，echo &quot;脚本名&quot; &gt;&gt; /etc/rc.local 参考文章 rsync Rsync原理详解及部署 Rsync完全手册 inotify+rsync+mutt+msmtp 实现linux文件或者目录自动更新并且实现发邮件给管理员 Linux运维之道（第二版） 真正的inotify+rsync实时同步 彻底告别同步慢]]></content>
      <tags>
        <tag>server</tag>
        <tag>Rsync</tag>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux性能监控常用命令]]></title>
    <url>%2F2018%2F08%2F01%2FLinux%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[top与htop uptime,free和vmstat mpstat与iostat ps和pstree top与htoptop查看动态进程状态，默认每5秒刷新一次。 123456top-d：指定top刷新的时间间隔，默认是5 秒-b：批处理模式，每次刷新分批显示-n：指定top刷新几次就退出，可以配合-b使用-p：指定监控的pid，指定方式为-pN1 -pN2 ...或-pN1, N2 [,...]-u：指定要监控的用户的进程，可指定UID或用户名 1234567891011121314151617181920212223top - 02:20:36 up 6:48, 1 user, load average: 0.00, 0.00, 0.00Tasks: 145 total, 2 running, 143 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 2029396 total, 1600964 free, 161512 used, 266920 buff/cacheKiB Swap: 2097148 total, 2097148 free, 0 used. 1670652 avail Mem # Tasks为进程数# us：用户占用cpu百分比 sy：系统占用cpu百分比 ni：进程空间内改变过优先级的进程占cpu百分比 id：空闲cpu百分比 wa：I/O等待时间比率 hi：不可中断睡眠时间比率 si：可中断睡眠时间比率 st：被偷走时间比率，一般为虚拟机占用 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND # PR：优先级# NI：nice值，负数为高优先级，正数为低优先级# VIRT：虚拟内存总量 # RES：进程实际使用内存 # SHR：共享内存 # S：进程状态。有五种状态：D-不可中断的睡眠态 R-运行态 S-睡眠态 T-停止 Z-僵尸态# TIME+：进程使用CPU的时间总计（单位1/100秒） 进入top视图后的操作 12345678910111213141516171819201：查看每个逻辑CPU的状况P：按cpu使用率排序（默认） M：按内存使用率排序 N：按PID排序 T：根据TIME+进行排序H：切换为线程l：切换负载信息m：切换显示内存信息（只是将数字改为类似进度条）t：切换显示进程和CPU状态信息（只是将数字改为类似进度条）k：指定要杀死的进程号A：切换显示模式。有四个窗口，在左上角显示，按a（后一个）或w（前一个）进行窗口切换 Def：默认字段组 Job：任务字段组 Mem：内存字段组 Usr：用户字段组d或s：修改刷新间隔f：选择要添加显示的字段，标上*为已选的R：反向排序c：显示进程的完整命令路径名V：树视图，命令会按进程的父子关系显示u：显示指定用户的进程n或#：设置最多显示的进程量r：设置指定进程的nice优先级 htop默认没有安装，需要dnf install htop 可通过鼠标点击操作，h查看帮助 uptime,free和vmstatuptime获取主机运行时间，查询系统负载 1234509:05:53 up 12 days,13:33,2 users,load average: 0.01,0.02,0.0509:05:53--当前时间up 12 days, 13:33--系统启动时长2 users--当前登录系统的用户数load average: 0.01,0.02,0.05--系统在最近的1,5,15分钟的平均负载 负载率(load)，即特定时间长度内，cpu运行队列中的平均进程数(包括线程)，一般平均每分钟每核的进程数小于3都认为正常，大于5时负载已经非常高。Linux运行队列包括正在运行的、在等待的、处于可中断睡眠态（IO等待）的进程。若为多核CPU，还需要除以核数。 平均负载最佳值为1，意味着每个进程都能立刻访问CPU，并且没有丢失CPU周期 free查看内存与swap分区使用状况，实际是从/proc/meminfo中读取数据的 123456789101112131415free -b 单位b -k 单位kb（默认） -m 单位mb -g 单位gb -h 自动选择单位 -l 显示高内存、低内存详细统计数据 -t 显示内存与swap的总和 -s N 设置刷新周期（单位秒），ctrl+C退出 -c N 设置刷新次数 -w 分开显示buffers和cachetotal used free shared buff/cache available# cache为缓存：把读取的数据放在内存中，再次读的话就直接从内存中读了，加快读取# buffer为缓冲：写入数据时，把分散的写入操作保存到内存中，然后集中写入硬盘，减少磁盘碎片与硬盘反复寻道，加快写入 vmstat报告进程、内存、分页、块IO、中断、CPU活动信息，能够显示平均数据和实时样本。 123456789101112vmstat [options] [delay [count]] -a 显示内存信息 -f 显示自从系统启动以来产生的子进程数量 -m 显示slab信息 -n 与-a类似 -s 事件计数器和内存状态 -d 磁盘状态 -D 磁盘状态概述 -p 分区 磁盘分区统计信息 -S 单位 输出与-n一致，但可指定单位 -t 显示时间戳，输出比-n增加了一项CST时间戳 刷新间隔 [次数] 设置持续刷新间隔及刷新次数 虚拟内存模式 1234567891011121314151617181920212223242526vmstat procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa stProc： r：可运行进程的数量（正在运行+等待运行） b：不可中断睡眠进程的数量memory： swpd：虚拟内存使用量 free：空闲内存 buff：缓冲区内存 cache：用作缓存的内存swap： si：swap in,从磁盘换入的内存数量/s so：swap out,交换到磁盘的内存数量/sio： bi：block in,从块设备收到的块数/s bo：block out,发送到块设备的块数/ssystem： in：interrupt,每秒中断数量 cs：context switch,每秒上下文切换数量cpu： us：非内核代码运行时间 sy：内核代码运行时间 id：idle,空闲花费时间，包含IOwait时间 wa：wait,IO等待花费时间 st：steal,虚拟软件花费时间 磁盘模式 1234567891011121314151617vmstat -ddisk- ------------reads------------ ------------writes----------- -----IO------ total merged sectors ms total merged sectors ms cur secdisk：磁盘名reads： total：成功读取的总量 merged：合并后分组的读 sectors：成功读取的扇区 ms：读取花费时间（单位毫秒）writes： total：成功写入的总量 merged：合并后分组的写 sectors：成功写入的扇区 ms：写入花费时间（单位毫秒）IO： cur：正在进行的IO sec：IO花费时间（单位秒） mpstat与iostatmpstat与iostat都在sysstat包中，若没有这两个命令，则需要安装dnf install sysstat mpstat用于报告在多处理器服务器上每个可用CPU的统计数据。 12345678910111213mpstat [ 选项 ] [ &lt;时间间隔&gt; [ &lt;次数&gt; ] ] -A 相当于-u -I ALL -P ALL -I &#123;SUM|CPU|SCPU|ALL&#125; 报告中断统计数据 SUM 报告每个处理器中断的总数量，显示CPU编号和intr/s一个或多个CPU每秒接收每个独特中断的个数 CPU 显示intr/s，但排列难以阅读 SCPU 显示intr/s，排版容易阅读 ALL 显示所有中断统计信息 -P &#123;cpu编号|ON|ALL&#125; cpu 指明统计的cpu编号（0开始） ON 每个在线CPU的统计数据 ALL 所有CPU的统计数据 -u 统计CPU使用率，输出与-P一致 时间间隔interval [次数times] 指定报告时间间隔及次数，最后会生成平均值 123456789101112mpstat -uCPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idleCPU：CPU编号%usr：用户级别（应用）执行时CPU使用率%nice：用户级别使用nice优先级执行时CPU使用率%sys：系统级别（内核）执行时CPU使用率（不包括硬件软件中断服务的时间）%iowait：系统未完成磁盘I/O请求期间，CPU空闲时间百分比%irq：CPU硬件中断时间百分比%soft：CPU软件中断时间百分比%steal：虚拟化软件为其他虚拟CPU服务时，虚拟CPU非主动等待时间百分比%guest：CPU运行虚拟处理器花费时间百分比%idle：CPU空闲时间百分比 iostatps和pstreepsps命令有两种风格：BSD和Unix。BSD格式的参数前不加-，Unix格式会在参数前加- 查看所有进程 123456789101112131415161718192021222324252627ps ax # a表示此tty下的所有程序（不区分用户），x表示所有程序（不区分tty终端机），若增加u参数，可以用户为主的格式来显示程序状况ps -ef # -e显示所有程序，只显示PID、TTY、TIME、CMD，-f增加显示UID、PPID、C、STIMEps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDUSER：进程发起用户 PID：进程号 %CPU，%MEM：CPU，内存占用率VSZ：虚拟内存（单位kb） RSS：常驻内存（实际物理内存）（单位kb） TTY：该进程在哪个终端运行STAT：进程状态 S：可中断睡眠 &lt;：高优先级 s：子进程 +：位于后台 R：运行（Running） T：停止状态（Terminate） Z：僵尸进程（Zombie）START————进程开启时间TIME：进程已启动时间COMMAND：产生进程的命令名ps -ef中不同的几个PPID：父进程IDC：CPU占用率STIME：进程启动时间 显示用户进程 12ps -f -u [用户名1,用户名2...] #-u指定用户，可指定多个，不能加-e，不然等于没指定例：ps -f -u apache 显示指定进程 123ps -f -C [进程] # -C指定进程名，进程名必须是精确的，不能用通配符。同样不能指定-e例：ps -f -C httpdps -f -p [进程号] # -p指定进程号 通过cpu或内存占用对进程排序 123ps -ef --sort=[+|-]pcpu,[+|-]pmem--sort用于指定多个字段，pcpu为按CPU排序，pmem为按内存排序，+为升序，-为降序例：ps -ef --sort=-pcpu | head -6 显示CPU占用排名前五的进程 以树显示进程层级关系 12ps -f --forest例：ps -f --forest -C httpd 查看指定父进程下的所有子进程 1ps --ppid [PPID] 显示进程的线程 12ps -f -L -C [进程]或-p [进程号] #显示指定进程的线程例：ps -f -L -C httpd 指定要显示的列 12ps -o pid,uname,pcpu,pmem,comm,etime其中：uname为用户名，etime为进程已运行时间 通过watch命令将ps变为实时查看器 1234watch -n 指定指令执行间隔 -d 高亮显示指令输出信息不同之处例：watch -n 1 &apos;ps -e -o pid,uname,cmd,pmem,pcpu --sort=-pcpu,-pmem | head -11&apos; pstree查看进程树，常用选项 12345678910-p 显示进程PID-g 显示进程组ID，即PGID-u 显示进程所属用户-a 显示进程的命令及参数-H PID 高亮显示指定进程及它的所有父进程-T 只显示进程，不显示线程-t 显示完整的线程名-s 显示进程的父进程-n 按PID排序输出-Z 显示selinux上下文（需要开启selinux） 参考文章 10 basic examples of Linux ps command ps命令的10个例子 Linux性能优化大师]]></content>
      <tags>
        <tag>运维</tag>
        <tag>监控</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVM逻辑卷与RAID磁盘阵列学习笔记]]></title>
    <url>%2F2018%2F08%2F01%2FLVM%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8ERAID%E7%A3%81%E7%9B%98%E9%98%B5%E5%88%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容 LVM逻辑卷 LVM概述 LVM创建与调整 LVM快照 RAID磁盘阵列 RAID概述 RAID基础搭建 LVM逻辑卷LVM概述LVM(Logical Volume Manager)逻辑卷管理器，可以灵活调整存储空间大小，并不会对现有数据造成任何损坏。红帽系的系统全部默认开启了LVM。 几个关键术语： PV(Physical Volume，物理卷)：最低层的存储设备（硬盘，分区） VG(Volume Group，卷组)：单个或多个PV构成的存储资源池，不能直接存放数据 LV(Logical Volume，逻辑卷)：从VG中划分出的存储空间，可直接存放数据 PE(Physical Extend，物理扩展单元)：逻辑层面上最小的存储单元（类似block），一个PE大小4MB，是告诉PV，表明存储单元位于PV的哪个位置。PE大小必须满足2的指数幂 LE(Logical Extend，逻辑扩展单元)：与PE类似，默认情况下，PE与LE一样大。LE告诉LV，表明存储单元处于VG的哪个位置 LVM创建流程： 使用几块硬盘或分区（未创建文件系统）创建物理卷，并将分区的识别号设置为LVM，即8e 将多个物理卷组合成一个卷组，卷组会根据指定的PE大小将空间划分为多个PE，在LVM中存储以PE为单元 在卷组中分出逻辑卷，这些逻辑卷在外界看来就是多个独立的硬盘分区 对逻辑卷制作文件系统，并挂载 LVM写入机制：LV是从VG中划分出来的，LV中的PE很可能来自于多个PV。在向LV存储数据时，有多种存储机制，其中两种是： 线性模式(linear)：先写完来自于同一个PV的PE，再写来自于下一个PV的PE。 条带模式(striped)：一份数据拆分成多份，分别写入该LV对应的每个PV中，所以读写性能较好，类似于RAID 0。 尽管striped读写性能较好也不建议使用该模式，因为lvm的着重点在于弹性容量扩展而非性能，要实现性能应该使用RAID来实现，而且使用striped模式时要进行容量的扩展和收缩将比较麻烦。默认的是使用线性模式。 引用自骏马金龙的LVM详解 LVM创建与调整实验环境： CentOS7 /dev/sdb 大小20G 将/dev/sdb分为4个分区，每个分区5G，并将磁盘标识号设为8e，表示LVM 1234567891011121314# fdisk -l /dev/sdbDisk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0xde948938 Device Boot Start End Blocks Id System/dev/sdb1 2048 10487807 5242880 8e Linux LVM/dev/sdb2 10487808 20973567 5242880 8e Linux LVM/dev/sdb3 20973568 31459327 5242880 8e Linux LVM/dev/sdb4 31459328 41943039 5241856 8e Linux LVM 准备裸磁盘与裸分区，制作PV使用pvcreate [裸磁盘/裸分区]创建PV 12345# pvcreate /dev/sdb1 /dev/sdb2 /dev/sdb3 /dev/sdb4 Physical volume &quot;/dev/sdb1&quot; successfully created. Physical volume &quot;/dev/sdb2&quot; successfully created. Physical volume &quot;/dev/sdb3&quot; successfully created. Physical volume &quot;/dev/sdb4&quot; successfully created. 可使用pvdisplay [磁盘/分区]查看pv信息1234pvdisplay选项列表 若不指定磁盘或分区，就是查看所有PV -m # 查看该设备中PE的使用分布图 -s # 查看pv简短信息 pvs或pvscan也可查看所有PV信息12345678# pvscan PV /dev/sda2 VG centos lvm2 [&lt;19.00 GiB / 0 free] PV /dev/sdb4 lvm2 [&lt;5.00 GiB] PV /dev/sdb2 lvm2 [5.00 GiB] PV /dev/sdb1 lvm2 [5.00 GiB] PV /dev/sdb3 lvm2 [5.00 GiB] Total: 5 [&lt;39.00 GiB] / in use: 1 [&lt;19.00 GiB] / in no VG: 4 [&lt;20.00 GiB] 最后一行显示的是&quot;pv的总容量/已使用的pv容量/空闲的pv容量&quot; pvremove [分区]删除PVpvmove [分区]删除PV中的所有数据 制作VGvgcreate [VG名][多个裸磁盘]制作卷组12345vgcreate选项列表 -s # 指定PE大小。不指定默认大小4M -l # 卷组上允许创建的最大逻辑卷数 -p # 卷组中允许添加的最大物理卷数 在创建VG后，只有VG没有数据时才能修改属性，如PE大小 1234# vgcreate -s 8M my_vg1 /dev/sdb1 /dev/sdb2 Volume group &quot;my_vg1&quot; successfully created# vgcreate -s 8M my_vg2 /dev/sdb3 /dev/sdb4 Volume group &quot;my_vg2&quot; successfully created vgdisplay [VG名]查看VG信息vgs和vgscan也可显示所有VG信息 vgreduce [VG名] [PV名]从VG中删除指定PVvgextend [VG名] [PV名]添加PV到VG中1234# vgreduce my_vg1 /dev/sdb2 Removed &quot;/dev/sdb2&quot; from volume group &quot;my_vg1&quot;# vgextend my_vg1 /dev/sdb2 Volume group &quot;my_vg1&quot; successfully extended 1234vgchange [选项] [VG名] 修改卷组的属性经常被用来设置卷组是处于活动状态或非活动状态。处于活动状态的卷组无法被删除，必须使用vgchange命令将卷组设置为非活动状态后才能删除。 -a y|n 设置卷组的活跃|非活跃状态 vgremove [VG名]删除VG 创建逻辑卷LVlvcreate -L N -n [LV名][VG名]创建逻辑卷1234lvcreate选项列表 -L N # 指定逻辑卷大小N，若N不是PE的整数倍，系统会自动将LV大小变大为PE整数倍 -n # 指定LV名 -l n # 指定PE个数，即通过PE个数指定逻辑卷大小 12345678910# lvcreate -L 6G -n my_lv1 my_vg1 Logical volume &quot;my_lv1&quot; created.# lvcreate -l 1000 -n my_lv2 my_vg2 Logical volume &quot;my_lv2&quot; created.# lvscan ACTIVE &apos;/dev/centos/swap&apos; [2.00 GiB] inherit ACTIVE &apos;/dev/centos/root&apos; [&lt;17.00 GiB] inherit ACTIVE &apos;/dev/my_vg2/my_lv2&apos; [7.81 GiB] inherit ACTIVE &apos;/dev/my_vg1/my_lv1&apos; [6.00 GiB] inherit lvdisplay [LV名]查看指定或所有LV详细信息lvs和lvscan可查看全部LV信息 lvextend [选项] +[扩容大小] [LV]用于扩展逻辑卷的空间大小，而不中断应用程序对逻辑卷的访问12345lvextend选项 -L 指定逻辑卷的大小 -l 指定逻辑卷的大小（LE数） 若不添加加号，则要指定扩容后的大小（一定要比增容前大） 若添加加号，则要指定要扩容的大小 12345678# lvextend -L +100M /dev/my_vg1/my_lv1 Rounding size to boundary between physical extents: 104.00 MiB. Size of logical volume my_vg1/my_lv1 changed from 6.00 GiB (768 extents) to 6.10 GiB (781 extents). Logical volume my_vg1/my_lv1 successfully resized.# lvextend -l +10 /dev/my_vg2/my_lv2 Size of logical volume my_vg2/my_lv2 changed from 7.81 GiB (1000 extents) to 7.89 GiB (1010 extents). Logical volume my_vg2/my_lv2 successfully resized. lvreduce [选项] -[缩小大小] [LV]减少LVM逻辑卷占用的空间大小。有可能会删除逻辑卷上已有的数据参数与用法与lvextend一致lvresize [选项] [+|-][扩大或缩小大小] [LV]调整LVM逻辑卷的空间大小，可以增大空间和缩小空间，可能会使逻辑卷上已有的数据丢失参数与用法与lvextend与lvreduce一致。 若该LV已制作完文件系统并挂载完成，而要对该LV进行容量的改变操作，首先需要umount将挂载取消，然后使用上述命令进行容量改变操作，然后再制作文件系统并挂载。然而，通过任何查看命令都会发现LV大小并没有改变。因此，在改变大小后，还要继续以下操作。 若文件系统为ext4，则需要执行resize2fs [LV路径] 若文件系统为xfs，则需要执行xfs_growfs [LV路径]xfs文件系统只支持增大分区空间的情况，不支持减小的情况。硬要减小的话，只能在减小后将逻辑分区重新通过mkfs.xfs命令重新格式化才能挂载上，这样的话这个逻辑分区上原来的数据就丢失了。xfs是不支持裁剪的，ext是支持裁剪的，所以xfs尽量不要缩小LV 建议在修改容量后执行e2fsck -f [LV路径]检查是否修改后的大小会影响数据。12345678# e2fsck -f /dev/my_vg1/my_lv1 e2fsck 1.42.9 (28-Dec-2013)Pass 1: Checking inodes, blocks, and sizesPass 2: Checking directory structurePass 3: Checking directory connectivityPass 4: Checking reference countsPass 5: Checking group summary information/dev/my_vg1/my_lv1: 11/400624 files (0.0% non-contiguous), 64167/1599488 blocks lvremove [LV名]删除指定LV LVM快照LVM提供快照功能，可将逻辑卷的数据进行备份，并可快速恢复 实验选用/dev/my_vg1/my_lv1，并将该LV挂载在/my_lv112345678# lvdisplay /dev/my_vg1/my_lv1 --- Logical volume --- LV Path /dev/my_vg1/my_lv1 LV Name my_lv1 VG Name my_vg1...... LV Size 6.10 GiB...... lvcreate -s -n [快照名] -L [快照大小] [LV路径]创建快照123-s 创建快照-n 指定快照名-L 快照大小 1234567891011# lvcreate -s -L 1G -n my_snapshot /dev/my_vg1/my_lv1 Using default stripesize 64.00 KiB. Logical volume &quot;my_snapshot&quot; created.可通过lvscan查看，最后多了一条快照信息# lvscan ACTIVE &apos;/dev/centos/swap&apos; [2.00 GiB] inherit ACTIVE &apos;/dev/centos/root&apos; [&lt;17.00 GiB] inherit ACTIVE &apos;/dev/my_vg2/my_lv2&apos; [7.89 GiB] inherit ACTIVE Original &apos;/dev/my_vg1/my_lv1&apos; [6.10 GiB] inherit ACTIVE Snapshot &apos;/dev/my_vg1/my_snapshot&apos; [1.00 GiB] inherit 在/my_lv1中创建文件dd if=/dev/zero of=/my_lv1/files count=1 bs=100M然后将该LV卸载umount /my_lv1最后将快照恢复lvconvert --merge /dev/my_vg1/my_snapshot12345# lvconvert --merge /dev/my_vg1/my_snapshot Merging of volume my_vg1/my_snapshot started. my_lv1: Merged: 69.90% my_lv1: Merged: 100.00%快照恢复过后会自动删除 将LV重新挂载到/my_lv1，发现文件夹中已经没有任何文件了，说明快照恢复成功。 RAID磁盘阵列RAID概述Redundant Array of Independent Disks独立硬盘组，作用是防止硬盘物理损坏以及增加存储设备的吞吐量。常见的RAID形式有：RAID 0、RAID 1、RAID 3、RAID 5、RAID 6、RAID 10、RAID 01、RAID 50。 RAID 0：将多个磁盘合并为1个大磁盘，读写速度极大提高，但不具冗余，因为通过硬件或软件串联，数据是依次被写入各个硬盘，所以任何一块损坏都会导致数据丢失。 RAID 1：两组以上的N个硬盘相互做镜像，让数据被多块硬盘同时写入。一块损坏可立刻通过热交换恢复数据。由于做备份，硬盘空间只有50%。 RAID 3：将数据条块化分布于不同的硬盘上，使用简单的奇偶校验，并用单块磁盘存放奇偶校验信息。如果一块磁盘失效，奇偶盘及其他数据盘可以重新产生数据;如果奇偶盘失效则不影响数据使用。RAID 3对于大量的连续数据可提供很好的传输率，但对于随机数据来说，奇偶盘会成为写操作的瓶颈。 RAID 5：使用硬盘分割技术，至少需3块硬盘。既提高传输速度，也可实现镜像备份。但采用奇偶校验信息，写速度相当慢，读速度与RAID0相近，且镜像保障程度也不及RAID1。空间利用率高。是在所有磁盘上交叉存储数据与奇偶校验信息，并不是单独保存在某块内存中，而是分别互相保存在每一块硬盘，raid5并不是备份实际硬盘数据，而是在硬盘出现故障后通过奇偶校验信息尝试恢复数据。RAID5的利用率为总可用盘容量的(n-1)/n RAID 6：相较RAID5增加第二个独立的奇偶校验信息块，数据可靠性非常高，需要四个以上硬盘 RAID 7：全称是最优化的异步高 I/O 速率和高数据传输率，不仅仅是一种技术，它还是一个独立存储计算机，自身带的操作系统和管理工具，完全可以独立运行。采用了非同步访问，极大地减轻了数据写瓶颈，提高了 I/O 速度，存储计算机操作系统可使主机 I/O 传递性能达到最佳，能够自动执行恢复操作，并可管理备份磁盘的重建过程。该技术已被raid7公司垄断。 RAID 10（企业主要用）/01： 10为1+0 先镜射再分割数据，两个两个组成raid1，再两组两组组成raid0，拥有较高速度与较高数据保护性，但需要4块以上且数量为偶数的硬盘数，因为使用raid1，所以利用率也是50%。安全性比01强，速度也比01强，恢复速度快于5 01为0+1 先分割再镜射，两个两个组raid0，再两组两组组raid1 RAID 50：至少需要6块硬盘，将数据分为条带同时存入多个磁盘，以数据校验位保证数据安全，目的在于提高RAID5的读写性能 RAID基础搭建RAID的创建管理由mdadm命令实现123456789101112131415161718mdadm [模式] [RAID设备名] [选项] [成员设备] -a # 检测设备名 -As # 激活raid（停止的时候） -n # 指定设备数量 -c # 指定数据块大小 -l # 指定raid级别 -C # 创建 -v # 显示过程 -G # 修改raid -f # 模拟设备损坏 -r # 移除设备 [raid] -a [磁盘] 将磁盘添加到raid阵列 [raid] -r [磁盘] 将磁盘移出raid阵列 -Q # 查看摘要信息 -D # 查看详细信息（cat /proc/mdstat查看阵列状态） -S # 停止阵列 -x # 备份盘个数 --detail # 查看RAID阵列 实验目的：搭建RAID 10实验环境 CentOS7 /dev/sdb分出4分区，每个5G大小 mdadm -Cv /dev/md0 -a yes -n 4 -l 10 /dev/sdb1 /dev/sdb2 /dev/sdb3 /dev/sdb4创建RAID 可通过cat /proc/mstat查看简要RAID信息1234# cat /proc/mdstat Personalities : [raid10] md0 : active raid10 sdb4[3] sdb3[2] sdb2[1] sdb1[0] 10475520 blocks super 1.2 512K chunks 2 near-copies [4/4] [UUUU] 也可通过mdadm -D /dev/md0查看指定RAID信息12345678910111213141516171819202122232425262728293031323334353637# mdadm -D /dev/md0 /dev/md0: Version : 1.2 Creation Time : Thu Aug 2 09:56:25 2018 Raid Level : raid10 Array Size : 10475520 (9.99 GiB 10.73 GB) # Array Size总共能使用的空间，因为是raid10，所以总可用空间为400M左右，除去元数据，大于370M左右 Used Dev Size : 5237760 (5.00 GiB 5.36 GB) # Used Dev Size每颗raid组或设备上的可用空间，也即每个RAID1组可用大小为190M左右 Raid Devices : 4 # raid中设备的个数 Total Devices : 4 # 总设备个数，包括raid中设备个数，备用设备个数等 Persistence : Superblock is persistent Update Time : Thu Aug 2 09:57:17 2018 State : clean # 当前raid状态，有clean/degraded(降级)/recovering/resyncing Active Devices : 4 Working Devices : 4 Failed Devices : 0 Spare Devices : 0 Layout : near=2 # RAID10数据分布方式，有near/far/of set，默认为near，即数据的副本存储在相邻设备的相同偏移上。 # near=2表示要备份2份数据 Chunk Size : 512KConsistency Policy : resync Name : bogon:0 (local to host bogon) UUID : 1aa0ce46:4762919a:71542e42:47b8bc7b Events : 17 Number Major Minor RaidDevice State 0 8 17 0 active sync set-A /dev/sdb1 1 8 18 1 active sync set-B /dev/sdb2 2 8 19 2 active sync set-A /dev/sdb3 3 8 20 3 active sync set-B /dev/sdb4 制作文件系统并挂载该RAIDmkfs.ext4 /dev/md0 &amp;&amp; mount /dev/md0 /mnt/md0 模拟RAID损坏，这里模拟损坏/dev/sdb3mdadm /dev/md0 -f /dev/sdb3此时查看RAID信息12345678910111213141516# mdadm -D /dev/md0 ...... State : clean, degraded Active Devices : 3 # 活跃的设备仅3台 Working Devices : 3 # 工作中的设备仅3台 Failed Devices : 1 # 出现故障的设备1台 Spare Devices : 0...... Number Major Minor RaidDevice State 0 8 17 0 active sync set-A /dev/sdb1 1 8 18 1 active sync set-B /dev/sdb2 - 0 0 2 removed 3 8 20 3 active sync set-B /dev/sdb4 2 8 19 - faulty /dev/sdb3 # /dev/sdb3的状态为faulty 由于raid10允许一组raid1存在故障，不会影响使用。 进行恢复，首先要卸载文件系统umount /mnt/md0然后移除/dev/sdb3，mdadm /dev/md0 -r /dev/sdb3最后再次添加进RAID组，mdadm /dev/md0 -a /dev/sdb3立刻查看RAID状态1234567891011121314151617181920212223242526# mdadm -D /dev/md0...... Active Devices : 3 Working Devices : 4 Failed Devices : 0 Spare Devices : 1 Layout : near=2 Chunk Size : 512KConsistency Policy : resync Rebuild Status : 38% complete Name : bogon:0 (local to host bogon) UUID : 1aa0ce46:4762919a:71542e42:47b8bc7b Events : 30 Number Major Minor RaidDevice State 0 8 17 0 active sync set-A /dev/sdb1 1 8 18 1 active sync set-B /dev/sdb2 4 8 19 2 spare rebuilding /dev/sdb3 3 8 20 3 active sync set-B /dev/sdb4可以看出此时活跃设备仍为3台，但工作设备已变为4台，空闲设备为1台Rebuild Status : 38% complete 表示正在重建该设备在/dev/sdb3的状态上也可看出正在重建rebuilding 若要彻底停用该阵列，只需要先卸载文件系统，然后执行mdadm -S /dev/md0即可。 使用RAID 5进行备份mdadm -Cv /dev/md0 -n 3 -x 1 -l 5 /dev/sdb1 /dev/sdb2 /dev/sdb3 /dev/sdb4其中-n 3表示选择3块磁盘做主盘，-x 1表示选1张做备份盘，加起来一共4张磁盘。此时查看RAID信息12345678910111213141516171819202122232425262728293031323334# mdadm -D /dev/md0 /dev/md0: Version : 1.2 Creation Time : Thu Aug 2 10:35:01 2018 Raid Level : raid5 Array Size : 10475520 (9.99 GiB 10.73 GB) Used Dev Size : 5237760 (5.00 GiB 5.36 GB) Raid Devices : 3 Total Devices : 4 Persistence : Superblock is persistent Update Time : Thu Aug 2 10:35:28 2018 State : clean Active Devices : 3 Working Devices : 4 Failed Devices : 0 Spare Devices : 1 Layout : left-symmetric Chunk Size : 512KConsistency Policy : resync Name : bogon:0 (local to host bogon) UUID : 9d0e9a0d:38372c14:2ad4666f:feb13f5c Events : 18 Number Major Minor RaidDevice State 0 8 17 0 active sync /dev/sdb1 1 8 18 1 active sync /dev/sdb2 4 8 19 2 active sync /dev/sdb3 3 8 20 - spare /dev/sdb4可看出/dev/sdb4做了备份盘，状态为空闲 参考资料 百度百科—RAID磁盘阵列RAID基础，RAID10与RAID01比较，RAID10与RAID5比较骏马金龙—RAID骏马金龙—LVM图文并茂 RAID 技术全解Linux就该这么学]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>LVM</tag>
        <tag>RAID</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生成树学习笔记]]></title>
    <url>%2F2018%2F07%2F31%2F%E7%94%9F%E6%88%90%E6%A0%91%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <tags>
        <tag>网络</tag>
        <tag>华三</tag>
        <tag>生成树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STP学习笔记]]></title>
    <url>%2F2018%2F07%2F31%2FSTP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[组播学习笔记]]></title>
    <url>%2F2018%2F07%2F31%2F%E7%BB%84%E6%92%AD%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于华三网络学习笔记（理论） 组播概述 组播组管理协议 组播转发机制 组播路由协议 组播概述组播用于实现点到多点的传输。 效率高，分布式应用，多点传输 数据源仅发送一份数据包，链路仅传输一份数据包，只有组播组中接受者能收到数据包 尽最大努力交付 无拥塞控制 数据报重复 数据包无序交付 组播需求问题与相关技术： 如何标识接受者——-组播地址机制 接受者动态加入或离开组播组——-组成员关系管理 组播报文如何在网络中转发——组播报文转发过程 组播报文转发路径（组播转发树）构建——-组播路由协议 组播地址：组播地址范围：224.0.0.0---239.255.255.255 本地协议预留组播地址：224.0.0.0---224.0.0.255，属于局部范围，不会被路由器转发 用户组播地址：224.0.1.0---238.255.255.255，用户可用组播地址，全网有效232.0.0.0/8为SSM组地址，其余属于ASM组 本地管理组地址：239.0.0.0---239.255.255.255，特定本地范围有效，属于ASM组 组播MAC地址：以太网：01-00-5e-xx-xx-xx 组播地址映射：组播MAC地址中高24位固定为0x01005E，第25位为0，低23位来自组播IP地址的低23位。组播IP地址的高4位为1110，标识组播，而低28位只有23位被映射到组播MAC地址，即有5位的丢失，一共会有2^5即32个IP地址公用一个组播MAC，也就是可能会接受所在组播组外的其他组播数据。 举例：12345678组播IP地址为：224.231.123.14换成二进制：11100000 11100111 01111011 00001110组播MAC地址高24位为01005E，即0000 0001 0000 0000 0101 1110 1110|00001|11001110111101100001110 组播IP地址，共32位000000010000000001011110|0|11001110111101100001110 组播MAC地址，共48位组播IP地址中第二部分，案例中00001部分，在MAC地址中没有任何对应，一共有32种可能 组播组管理协议常用的组播组管理协议为IGMP（Internet Group Management Protocol因特网组管理协议）。主机通过IGMP通知路由器加入或离开某个组播组，路由器通过IGMP周期查询组播组成员是否处于活动状态，收集成员关系并维护 IGMP有三个版本： IGMPv1：定义了基本的组成员查询和报告过程 IGMPv2：添加了组成员快速离开机制 IGMPv3：添加了成员可指定接受或拒绝组播源的报文，支持SSM模型 IGMPv2IGMP报文： Type：IGMP报文类型，包含Membership Query、Report、Leave Group Max Reps Time：最大响应时间，只有Membership Query使用该字段 checksum：校验和 Group Address：组地址。不同报文填的不同。普遍查询填0，特定组查询填指定组播组地址，报告报文和离开报文填组播组地址 IGMPv2原理： 当同一网段中有多个IGMP路由器时，通过查询器选举机制（最小接口IP）选出唯一查询器。 查询器周期发送普遍查询消息General Query，目的地址224.0.0.1，TTL为1，进行组成员关系查询。主机收到后发送报告消息Report响应。也有称为Membership Report，但本篇统一为Report 主机若要加入组播组，可直接向查询器发送Report，离开组播组时，直接发送Leave，目的地址为224.0.0.2，通告所有组播路由器。查询器收到Leave后，会发送特定组查询消息Group-Specific Query确定该组所有成员是否都离开。 若是加入，查询器则会查看组播转发表项，若不存在就添加，表项为(组播源IP地址,组播组IP)，若为*表示任意源。组播转发表项还包含：组播指定报文的入接口、出接口等 案例完整流程： IGMP Snooping：解决二层组播。原因：组播数据在二层以广播发送主机发往IGMP查询器的报告消息经过交换机时，交换机会监听并将组播MAC和端口做映射，建立表项。当交换机收到组播数据时，就按表项转发，也就只向组成员发送了 IGMPv3概述：1.可对源过滤 2.新的报文类型与格式 3.报告报文的组播地址为224.0.0.22 4.取消成员报告抑制机制IGMPv3主机为接口上每个组播组维护一个表项（组地址，过滤模式，源列表）过滤模式：INCLUDE：只接收来自源列表的组播源的数据包 EXCLUDE：只接收不在源列表的组播源的数据包三种状态：当前状态，过滤模式改变状态，源列表改变状态。对应三种记录当主机接口维护的组状态变化时，会主动发送组记录类型为过滤模型变化或源列表变化的报告报文。当接收到查询报文时，会响应记录类型为当前状态的报告报文 组播分发树模型：是组播数据的转发数据，分为最短路径树(S,G)和共享树(*,G)组播转发机制：逆向路径转发组播路由协议：域内：DVMRP（基于路径矢量协议）、MOSPF（基于OSPF）、PIM 域间：MSDP、MBGP域内协议：基于SPT：PIM DM、DVMRP、MOSPF 基于RPT：PIM SM组播模型：ASM任意信源组播：接收端只选择加入组播组，不能选择组播源 SSM指定信源组播：接收端可以指定组播源 组播分发树：由组播路由协议建立的无环传输路径SPT最短路径树：组播源到接受者的最短路径。要为每个组播源建一棵最短路径树缺点：路由器必须为每个组播源保存路由信息RPT共享树：以某个路由器作为树根，该路由器称为汇聚点RP，以RP为树根建立到每个接收者的最短路径树。所有组播源和接收者都使用这棵树收发报文。组播源先向RP发数据，再由RP发送到所有接收者。优点：路由器保留的路由信息很少缺点：数据报文先要经过RP，再到达接收者，对RP的可靠性和性能要求高组播报文转发机制RPF逆向路径转发原因：组播报文是发送给一组接收者的，路由器收到组播报文后，必须根据报文的源地址确定正确的入接口和下游方向，然后向下游方向转发。该过程就是RPF。目的：确保组播数据沿正确路径传输，避免出现环路检查过程：在单播路由表上查找组播源（分发树为SPT）或RP（分发树为RPT）对应的RPF接口，若数据包是在RPF端口接收到的，则RPF检查成功，转发数据包。否则检查失败，直接丢弃PIM协议无关组播：与单播路由无关，但仍然依靠单播路由表进行组播路由。使用RPF转发报文。分为两种模式：PIM-DM（密集模式），PIM-SM（稀疏模式）PIM-DM：用于小型网络中接收者较多且密集的情况，采用“推”方式将流量泛洪。邻居发现：路由器周期发送PIM Hello消息，发现其他PIM路由器，建立邻居关系，判断叶子网络，选举DR（若运行的是IGMPv1，通过Hello选举，其他版本就不需要选举DR）。扩散-剪枝：将组播数据扩散到每个节点，每个节点创建(S,G)表项（包含出接口（除RPF接口外所有连接PIM-DM邻居或组播组成员的接口）与入接口列表），若节点没有该组播组成员，就向上游发送Prune剪枝消息，若共享网段有路由器上有接收者，就向上游发送Join消息，覆盖其他路由器发送的Prune。 扩散-剪枝过程周期进行。最终形成SPT。Prune消息发送情况：1.若路由器(S,G)表中出接口表为空 2.路由器从非RPF接口收到组播报文，会触发断言Assert机制，断言失败一方会向成功一方发送Prune消息。断言Assert：若同一网段有多个组播路由器，相同报文可能会被重复发送，通过断言选取网段唯一转发组播数据的路由器。过程：路由器在重复接收到报文的接口上发送Assert消息，包含S，G，单播路由的优先级，开销Metric。先比较路由优先级（高的胜），再比较开销（小的胜），再比较本地接口IP地址（大的胜）。当一台路由器上游接口故障时，该路由器将Metric值设为无穷大并广播Assert，引发新一轮断言，保证流量不会长时间中断。状态刷新机制：与组播源直连的路由器发送State Refresh，其他路由器收到后重置剪枝超时定时器，并向所有连接PIM-DM邻居的路由器发送该消息，对于处于转发的接口，消息中剪枝位为0，处于剪枝的接口，剪枝位为1。周期发送该消息可使剪枝状态的接口维持状态，减少不必要的扩散。嫁接：当被剪枝的节点上出现接收者时，节点会主动向上游发送嫁接Graft消息，上游收到后回复Graft Ack消息确认，节点从剪枝状态变为转发状态。两个消息都是单播发送。PIM-SM：用于中大型网络中，组播组成员相对分散，范围较广，采用“拉”方式。核心任务是构造维护RPT，选出RP作为共享树的根。过程：组播源侧DR向RP注册，将注册报文单播发给RP，该报文到达RP后触发建立SPT，组播源把数据沿SPT发给RP，再由RP沿RPT发给接收者 ASM模型：任意源模型。任何发送者都可作为组播源向组播组发数据，接收者无法预先知道组播源位置，但可以在任意时间加入离开组播组SSM模型：指定信源组播模型。接收端能指定组播源。SSM模型无需RP，无需构建RPT，无需组播源注册过程。]]></content>
      <tags>
        <tag>网络</tag>
        <tag>组播</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSPF学习笔记]]></title>
    <url>%2F2018%2F07%2F31%2FOSPF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于华三网络学习笔记（理论） 本篇包含以下内容 OSPF特性与基本术语 OSPF报文 OSPF邻居建立维护与状态机 OSPF特殊区域 OSPF特性与基本术语Open Shortest Path First开放最短路径优先 属于IGP，优先级AS内部10，外部150 采用链路状态算法SPF防环 封装在IP报文中，协议号89 度量值为开销cost=带宽参考值/接口带宽，参考值通常为100M，若求得的数小于1，则cost就取1 报文更新方式为触发更新+周期更新（30min。LSA老化时间60min） 增量更新（通过LSA），组播更新报文 组播地址224.0.0.5（主要，所有OSPF路由器都能收到）或224.0.0.6（DR、BDR可收到） 没有跳数限制，可用于大规模组网 路由生成过程： 生成LSA描述自身接口状态（链路开销、IP地址等） 同步OSPF区域内每台路由器的LSDB（通过交换LSA） SPF算法计算路由：每个路由器以自身为根计算最短路径树（即根到各节点的开销都是最小的），加入路由表，若两条路径开销相同，则都加入表中形成等价路由。 开启OSPF的路由器上与路由转发相关的三张表： 邻居表：记录建立了邻居关系的路由器 LSDB表：记录所有链路状态信息，需要实时同步 路由表：记录经SPF算法计算的路由 OSPF选路原则： 按路由类型优先级：区域内路由&gt;区域间路由&gt;第一类外部路由&gt;第二类外部路由 类型相同，选路由开销小的 以上都相同，形成等价路由 两类外部路由： 第一类外部路由：偏向于AS内部的选路，并不关心AS外的开销。用于控制入AS的路由选路。如图中RTA，若选择第一类外部路由，则关心AS内部的开销，会选择开销较小的RTB路线。 第二类外部路由：偏向与AS外部的选路，并不关心AS内的开销。用于控制出AS的路由选路。如图中RTA，若选择第二类外部路由，则关心AS外部的开销，会选择开销较小的RTC路线。 若同一网段的路由信息同时通过第一类外部路由和第二类外部路由学习到，在其他条件相同的情况下，会优选第一类外部路由。 骨干区域：area 0，负责转发非骨干区域之间的路由。区域间路由规则： 非骨干区域必须与骨干区域相连 非骨干区域之间不能传递路由，必须通过骨干区域 骨干区域传出的路由不能传回非骨干区域 OSPF防环：从一个区域学习到的路由不会再向该区域注入。非骨干区域间不能直接通信 当骨干区域被分割或非骨干区域不与骨干区域相连时，可通过虚连接解决。两台ABR（区域边界路由器）通过一个非骨干区域建立一条逻辑通道，对于通道上的路由器是透明的。 划分区域的好处： 减少了区域内LSDB中链路状态信息的数量 便于管理 减少路由震荡的影响范围 OSPF路由器类型： 区域内路由器Internal：所有接口都属于同一个区域 区域边界路由器Area Border：连接骨干与非骨干区域（物理上或逻辑上） 骨干路由器Backbone：至少有一个接口属于骨干区域，即所有区域内和区域边界路由器都是骨干路由器 自治系统边界路由器Autonomous System Border：与其他AS路由器交换路由信息，不一定在AS的边界，只要该路由器引入外部路由，就是ASBR。 Router ID用来在AS中唯一标识一个路由器，RouterID的选取优先级如下：局部 &gt; 全局 &gt; 自动选举局部：创建OSPF进程时同时指定router-id全局：系统视图下指定router id自动选举：环回口中最大的，若无环回口，则选取接口中IP地址最大的 网络类型： Broadcast广播：当链路层为以太网协议时，默认为Broadcast，以组播地址发报文(.5|.6)，需要DR，Hello定时器10s，邻居失效时间40s。 NBMA非广播多点可达网络：当链路层为帧中继或ATM时，默认为NBMA，以单播发报文，需要DR，Hello定时器10s，邻居失效时间40s。 P2P点到点：当链路层为PPP、HDLC时，默认P2P，以组播发报文(.5)，不需要DR，Hello定时器30s，邻居失效时间120s。 P2MP点到多点：需要手动修改，以组播发报文(.5)，不需要DR，Hello定时器30s，邻居失效时间120s。 OSPF报文OSPF五种报文： Hello报文：发现维护邻居关系，包含定时器、DR、BDR和已知邻居 DD报文：数据库描述报文，描述本地LSDB中LSA摘要，进行主从关系协商，用于路由器间LSDB同步 LSR(Request)报文：链路请求报文，向对方请求所需LSA（通过比对DD报文知道自己缺哪些LSA） LSU(Update)报文：链路状态更新报文，向对方发送所要求的LSA LSAck报文：链路状态确认报文，对收到的LSA进行确认 OSPF邻居建立维护与状态机邻居建立与维护： 组播发送Hello报文（.5），双方协商参数，若验证、区域等都相同，则表示邻居发现 邻居周期交换Hello报文，若邻居失效时间超时未收到Hello则认为邻居失效，将该邻居从邻居表中删除 DR/BDR选举：目的：减少邻接关系的数量，所有路由信息都发给DR（指定路由器），再由DR发LSA若不设置DR/BDR，则邻接关系数量R=n(n-1)/2个若设置DR/BDR，则邻接关系数量R=2(n-2)+1个 BDR是DR的备份。若DR失效，BDR立刻成为DR。DR/BDR选举原则： 首先比较Hello报文中的优先级，最高的为DR，次高的为BDR，若为0不参加选举。 优先级相同则比较RouterID，大的优 选举完毕后，即使有更优的路由器加入区域，也不会更换DR/BDR（可以在用户视图重置ospf进程，使ospf重新选举） 只有广播和NBMA网络选举DR/BDR 剩余路由器成为DRother，只与DR、BDR建立邻接关系 邻接关系建立： 初始状态，A的邻居为Down，由于邻居表为空，所以DR字段置为0.0.0.0，发送Hello报文，B收到Hello报文后，将A添加进邻居表中，邻居状态变为Init，两个路由器比较RouterID，大的（假设A）会在后面的Hello报文中将DR字段设为自己的RouterID。 B收到Hello报文，发现邻居表中有自己的RouterID，于是将邻居表中A状态变为2-way。B也收到后，同理。若当前两台路由器都是DRother，则邻接状态就会维持在2-way。只有其中一个是DR或BDR，才会继续建立关系 若进一步建立邻接关系，A会将B状态设为ExStart，并发送一个不包含LSA的DD报文，开始主从协商。其中DD报文包含MS位，最开始该MS位置1，表示路由器以自己为Master。Master路由器的作用就是在交换DD报文时，主动发送DD报文，并控制报文的序列号。Slave路由器仅能接受Master指定的序列号并被动发送DD。 B收到DD后，将发送方的状态设为ExStart。对比RouterID，若大（假设A）就在DD报文中将MS位也置为1，表明自己是Master，并回复。B收到DD报文后，同意A为Master，将MS位置0，表明自身Slave，采用A规定的序列号向A发DD报文，此时DD报文中包含LSA摘要，A收到后将B状态改为Exchange。B收到A的DD报文后也将A状态改为Exchange。 A与B都对DD报文的LSA与LSDB进行比对，若LSA信息在LSDB中都存在，就直接进入Full状态。若一方LSDB不完全包含LSA，则向另一方请求，并将对方状态置为Loading，发送LSR。另一方收到后根据LSR返回LSU。再次比对后相同就进入Full。 OSPF状态机其中有三个稳定状态：Down、2-way、Full down：未启动ospf init：收到对方hello包，但hello包中的邻居表没有自己 2-way：收到对方hello包，且在hello包中看到自己 exstart：互相发送空的DD协商主从报文，以决定谁发DD报文 exchange：交换真正的DD报文 loading：交互路由信息 full：路由学习完毕，邻接关系建立 影响OSPF建立邻接关系的因素： area是否一致 接口是否开启OSPF 接口是否开启验证 是否启用了静默接口，或开启过滤 是否处于特殊区域 Hello/Dead定时器是否一致 Router-id是否不同 链路两端接口掩码是否不同（广播类型链路hello会携带掩码信息） 两端MTU是否不同（若不同会一直在Exstart状态） 链路状态广播LSALSA老化时间3600s（1小时），每1800s（半小时）ospf就会泛洪一次全部路由信息 报文字段： LS age：LSA产生后经过的时间（单位秒） LS type：LSA类型（1-11） Link State ID：LSA链路ID，根据LSA类型而定 Advertising Router：始发LSA的路由器ID，也称LSA通告路由器LS type、Link State ID、Advertising Router三个参数唯一标识一个LSA LSA sequence number：LSA序列号，用于判断是否是最新的LSA LS checksum：LSA信息的校验和 length：LSA总长度 LSDB更新过程：收到一条LSA更新报文，在LSDB中查找该LSA，若未找到就将这条LSA加入LSDB，若找到，就对比LSA的序列号，若该条的大，就更新，否则不更新。 LSA类型： 一类：Router LSA，描述区域内部与路由器直连的链路信息，所有OSPF路由器始发，仅在区域内传播。不携带掩码信息 二类：Network LSA，记录广播或NBMA上所有路由器RouterID，DR始发，仅在区域内传播。携带网段掩码信息，和一类LSA共同计算网段一类和二类LSA解决了区域内部的通信 三类：Network Summary LSA，包含区域网段与开销，传播给相邻区域，ABR始发，区域间传播。实际就是收集一类和二类的LSA。每个三类LSA包含一个网段一、二、三类LSA解决了区域内和区域间通信 四类：ASBR Summary LSA，描述ASBR的RouterID和开销，传播给非ASBR区域，ABR始发。辅助五类LSA，实现到达ASBR。告诉OSPF内部路由器如何到达ASBR 五类：AS External LSA，描述到AS外部的路由，包含外部网段、开销等，传播给整个OSPF系统，ASBR始发。每个五类LSA包含一个网段。 七类：NSSA Exteranl LSA，只在NSSA中传播，描述到AS外部的路由，ASBR始发 路由聚合：ABR和ASBR可将具有相同前缀的路由聚合发布。 安全： 协议报文验证：通过验证的OSPF报文才能被接收（路由器+接口都要配置验证：Simple或MD5） 禁止端口发送OSPF报文：该端口成为被动端口（静默），不再发送Hello报文 过滤计算出的路由：通过过滤规则的路由才加入路由表 过滤三类LSA：设置规则过滤外部路由（本地有效） OSPF特殊区域OSPF特殊区域： Stub：不允许注入四、五类LSA。不能存在ASBR。虚连接不可穿过。若有多个ABR可能产生次优路由 Totally Stub：不允许注入三、四、五类LSA。虚连接不可穿过。ABR会产生一条0.0.0.0/0的三类LSA NSSA：不允许四、五类LSA，允许七类LSA。虚连接不可穿过。该区域存在一个ASBR，该区域不希望接收其他ASBR的外部路由。七类默认路由LSA由ASBR产生，在NSSA中传播，当到达ABR时，会转换为五类LSA传到别的区域。Totally STub和NSSA都是Stub的变形或改进 Totally NSSA：不允许注入三、四、五类LSA，而是用七类默认路由取代。虚连接不可穿过。]]></content>
      <tags>
        <tag>网络</tag>
        <tag>OSPF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BGP学习笔记]]></title>
    <url>%2F2018%2F07%2F31%2FBGP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于华三网络学习笔记（理论） 本篇包含以下内容 BGP特性与基本术语 BGP消息与状态机 BGP路由属性 BGP选路规则 BGP特性与基本术语Border Gateway Protocol边界网关协议。用于自治系统间，进行不同AS间路由传递。 路径矢量路由协议 基于TCP，端口号179 EGP协议，优先级255 支持路由聚合与CIDR 只发送增量路由 路由信息中携带经过的所有AS路径表 支持CIDR和路由聚合 丰富的路由属性、强大的路由过滤和路由策略 可传输大量路由（基于TCP的可靠传输和滑动窗口） 只能点对点连接（TCP的点对点） 基本术语 BGP发言者：发送BGP消息的路由器 Router ID：32位，在AS中唯一标识一台主机，必须配置 BGP对等体Peer：相互交换消息的BGP发言者互为对等体，也可称BGP邻居。 IBGP对等体：处于同一AS的对等体，不需要直连从IBGP获得的路由不会向其他IBGP邻居发布（为了防环）从IBGP获得的路由是否发个EBGP邻居与是否同步有关（为了防止路由黑洞）全连接：为解决部分连接导致的无法学习路由，每两个路由器都建立IBGP邻居则可以保持AS内的所有BGP路由器路由信息相同 EBGP对等体：处于不同AS的对等体，且通常要求直连从EBGP获得的路由会发布给所有IBGP邻居EBGP的TTL=1，所以只能是直连对端接口，不可跨设备（可修改TTL实现跨设备）而IBGP的TTL=255可与AS内任意BGP路由器建邻居 BGP防环： 对于EBGP：使用AS-PATH 对于IBGP：禁止将从IBGP邻居学到的路由发布出去。缺点：有路由器学不到路由。解决：全连接 BGP同步：IBGP与IGP之间同步，避免转发黑洞。收到IBGP邻居发布的路由后，会查看该路由是否在IGP表中，只有IGP表中存在，才会置为有效并发布，否则无效不发布。路由器默认关闭同步。 BGP消息与状态机BGP所有消息都是消息头+消息体，消息头长度19字节，包含以下字段： Marker：16字节，用于BGP验证的计算，不使用验证时所有位都置为1 Length：2字节，BGP消息总长度（包括报文头） Type：1字节，BGP消息的类型，取值为1到5，分别表示Open、Update、Notification、Keepalive、Route-Refresh BGP消息种类： Open：用于建立BGP邻居。TCP连接后的第一个消息，进行参数协商。包含以下字段： BGP版本 AS号 routerID Hold Time：保存时间，若超时仍未收到对端的Keepalive或Update消息，则认为BGP连接中断。建立对等体时要协商该参数并保持一致 认证信息或多协议扩展等功能 Update：在邻居间交换路由信息（发布或撤销）。可通告一类相同属性的可达路由和不可达路由。包含以下字段： 不可达路由字段长度。单位字节，若为0表示没有Withdrawn Routes Withdrawn Routes不可达路由列表，即存放被撤销的路由 路径属性字段长度。单位字节，若为0表示没有Path Attibutes Path Attibutes，存放与NLRI相关的所有路径属性列表，每个路径属性由一个TLV三元组构成。 NLRI可达路由的前缀和前缀长度二元组，存放一类相同属性的可达路由 Notification：错误通知（消息错误或断开BGP连接）。包含以下字段： 差错码，指定错误类型 差错字码，提示错误类型的详细信息 数据，出错部分的数据。用于辅助发现错误的原因，依赖于差错码和差错子码 Keepalive：维护邻居关系或对Open消息回应。只有消息头。周期发送，默认周期30s。 Route-refresh：要求对等体重新发送指定地址族的路由 BGP状态机： Idle：空闲。初始状态，等待Start事件。一旦有Start，就向邻居发起TCP建立请求 Connect：连接。等待TCP建立完成。若TCP完成，状态改为Open-sent。若失败，状态改为Active。 Active：活跃。TCP未成功建立。若超时，会返回Connect。若成功，进入Open-sent状态。 Open-sent：Open消息已发送。已发出Open消息，等待邻居的Open消息。若收到邻居的Open消息且无错误，进入OpenConfirm状态，并发送Keepalive。否则，进入Notification。 OpenConfirm：Open消息已确认。Keepalive已发送，等待邻居的Keepalive。若收到邻居的Keepalive，则进入Established状态。若收到Notification，则断开连接 Established：BGP连接建立。可发送Update交换路由，发送Keepalive维护连接，若收到Notification则断开连接 BGP路由属性 公认必遵属性：BGP路由器必须识别，必须存在于Update ORIGIN：定义路由信息来源类型：IGP—路由产生于AS内 EGP—路由通过EGP学到 Incomplete—路由来源不确定优先级：IGP&gt;EGP&gt;Incomplete AS_PATH：路由更新经过的AS路径列表，保证AS间无环。可用于路由选择和过滤当BGP将一条路由通告到其他AS时，会把本地AS号添加到AS-PATH最前优先选择AS-PATH最短的路由。若向EBGP邻居发送路由更新修改，IBGP间不修改 NEXT_HOP：路由下一跳向邻居发布路由时，会将下一跳设为自己与对端连接的端口从EBGP邻居得到的路由发给IBGP邻居时，不会修改下一跳 公认可选属性：BGP路由器必须识别，不必须存在于Update LOCAL_PREF：用于IBGP选择离开AS时的路由，表明BGP路由器的优先级仅在IBGP对等体间交换。默认值100 可选传递属性：在AS间可传递，路由器可不支持，仍可接收并通告 COMMUNITY AGGREGATOR 可选非传递属性：若BGP路由器不支持，属性会被忽略，且不通告 MED：度量值。告诉EBGP邻居进入AS的路由。仅在相邻AS间交换，收到MED的AS不会再通告给其他AS通常只比较来自同一AS的MED 私有BGP属性： Preferred-value：对从邻居学习到的路由分配优先级本地有效，不通告。初始为0 对于BGP路由处理： 接收BGP路由 路由过滤、属性设置 路由优选 发布策略 发布路由过滤、属性设置、路由聚合 BGP选路规则路由选路优先级（高到低）： 丢弃下一跳不可达的路由 Preferred-value选大 LOCAL_PREF选大 聚合路由，本地路由 AS_PATH选小 ORIGIN按优先级选 MED选小 依次选从EBGP、联盟、IBGP学到的路由 下一跳度量值最低 CLUSTER_LIST选短 ORIGINATOR_ID最小 RouterID最小路由器发布的路由 地址最小的邻居发布的路由 BGP一定能选出唯一的最优路由，且可以负载分担路由下一跳不一定是直连邻居，原因：IBGP发布路由不改变下一跳。路由器会查找直连可达地址，到达要发布路由的下一跳（去往该下一跳的路由为依赖路由，过程为路由迭代）。路由器支持基于迭代的负载分担。 BGP路由发布策略： 只发布最优路由 只发布自己使用的路由 发布所有从EBGP邻居学到的路由给所有BGP邻居（IBGP和EBGP） 不把从IBGP邻居学到的路由发布给IBGP邻居 IBGP路由发到EBGP：BGP同步关—直接发布。BGP同步开—IGP也发布时才发布 BGP连接建立后，发布所有BGP路由 BGP下一跳原则：若从EBGP邻居学到的路由传给IBGP邻居时下一跳不变，可能会导致BGP设备因为下一跳不可达而不加入路由表。解决：应在EBGP路由传给IBGP邻居时将下一跳改为自身 BGP路由不优的原因：1.同步打开，但网络不满足同步要求 2.下一跳不可达 BGP源IP地址原则：BGP设备收到一个BGP报文，会检查报文源IP地址，若与peer所指IP地址一致，则设备接收该报文，若不一致，则丢弃报文，在建环回口建立BGP关系时，要修改BGP报文源 默认情况，BGP使用到达对等体的最佳路由作为出接口作为与对等体建TCP连接的源接口将建立TCP的源接口配置为环回口，在网络中存在冗余链路时不会因为某个接口或链路故障而使BGP，提高了可靠性和稳定性 控制BGP路由常用属性：preferred-value、Local-preference、MED、next-hop-local路由首选值Preferred-value：优选大的。默认从对等体学来的路由首选值为0本地优先级Local-preference：判断离开AS的最佳路由AS路径过滤表AS_PATH list：一个基于AS表的ACL，使用正则表达式对路由携带的AS路径属性域进行匹配 正则表达式： ^ 匹配字符串的开始 $ 匹配字符串的结束 * 匹配*前的字符（串）0或多次 + 匹配+前的字符（串）1或多次 . 通配符，匹配任何一个字符 _ 下划线，匹配一个符号 - 连接符，连接两个字母或数值 ( ) 字符组，一般与-连用 [ ] 匹配[ ]中任意一个字符 常用正则组合： ^$只匹配本地路由 .*匹配所有路由 ^100匹配AS100、1001等邻居的路由 ^100_只匹配AS100邻居发的路由 _100$匹配AS100始发的路由 _100_匹配经过AS100的路由 BGP补充知识点BGP对等体组peer group：具有某些相同属性的对等体集合，可分为IBGP或EBGP对等体组 BGP团体属性：一组具有相同特征目的地址的集合，与所在AS无关，一条路由可以有多个团体属性。 公认团体属性INTERNET：有这一属性的路由可以被通告给所有对等体。路由缺省属于该团体NO_EXPORT：该团体路由不能被发布到本地AS外，若使用联盟，不能发布到联盟外NO_ADVERTISE：不能被通告任何BGP对等体NO_EXPORT_SUBCONFED：不能被发布到任何其他AS BGP聚合两种聚合：手动、自动自动：聚合为自然路由。只能引入IGP子网路由聚合，不能对BGP邻居学来的或network发布的路由进行聚合。手动：手动配置灵活的聚合，可以对从BGP邻居学习的、引入IGP的、network生成的路由聚合 BGP反射作用：可代替IBGP对等体全连接原理：允许设备从IBGP对等体接收到的路由信息发布给特定IBGP对等体，这些网络设备称为路由反射器。]]></content>
      <tags>
        <tag>BGP</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Compose学习笔记]]></title>
    <url>%2F2018%2F07%2F30%2FDocker-Compose%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[环境：docker：18.06.1，docker-compose：1.22.0 docker18.06对应的Compose文件格式版本为3.7 本篇包含以下内容： docker-compose介绍 Compose文件格式 docker-compose示例 docker-compose介绍Docker Compose是一个编排多容器分布式部署的工具，提供命令集管理容器化应用的完整开发周期，包括服务构建，启动和停止。在配置文件中，所有的容器通过services来定义，然后使用docker-compose脚本来启动，停止和重启应用，和应用中的服务以及所有依赖服务的容器。 Compose的特性 通过项目名称将单个主机隔离成多个环境，能将应用环境复制多份，还能防止使用相同名称的服务的应用间的干扰 能够保护卷中的数据，如果Compose发现存在之前运行过的容器，它会把旧容器中的数据卷拷贝到新的容器中 只会重新创建改变过的容器，Compose会缓存用于创建容器的配置信息，当你重启服务时，如果服务没有被更改，Compose就会重用已经存在的容器，加快了修改应用的速度 编排：Orchestration，根据被部署的对象间的耦合关系以及被部署对象对环境的依赖，制定部署流程中各个动作的执行顺序，部署过程中所需要的依赖文件和被部署文件的存储位置和获取方式，以及如何验证部署成功。这些信息都会在编排工具中以制定格式定义并保存。 部署：Deployment，按照编排所指定的内容和流程，在目标机器上执行编排指定环境初始化，存放指定的依赖和文件，运行指定的部署动作，按照编排中规则确认是否部署成功。 以上编排和部署定义摘选自《docker容器与容器云》 docker-compose安装 使用pip快速安装pip install docker-compose docker-compose参数选项： 12345678910111213141516docker-compose [-f &lt;arg&gt;...] [options] [COMMAND] [ARGS...] -f, --file FILE 指定compose文件，默认为docker-compose.yml -p, --project-name NAME 指定项目名，默认为所在目录名 --verbose 显示详细过程信息 --log-level LEVEL 设置日志级别(DEBUG, INFO, WARNING, ERROR, CRITICAL) --no-ansi 不打印ANSI控制字符 -H, --host HOST 指定要连接的主机 --tls 使用tls，就是指--tlsverify --tlscacert CA_PATH 指定只承认该CA颁发的证书 --tlscert CLIENT_CERT_PATH TLS证书路径 --tlskey TLS_KEY_PATH TLS密钥路径 --tlsverify 使用TLS --skip-hostname-check 不根据客户端证书中指定的名称检查守护程序的主机名 --project-directory PATH 指定工作目录，默认为compose文件所在目录 --compatibility Compose将尝试将v3文件中的部署密钥转换为其非Swarm等效项 docker-compose命令： build：构建或重构服务（services） 1234567build [options] [--build-arg key=val...] [SERVICE...] --compress 使用gzip压缩构建上下文 --force-rm 始终移除中间容器 --no-cache 构建镜像时不使用缓存 --pull 总是尝试拉取最新镜像 -m, --memory MEM 设置构建镜像的内存上限 --build-arg key=val 设置服务的构建时变量 bundle：从Compose文件生成Docker包 镜像必须存储摘要，这需要与Docker Registry进行交互。如果没有为所有镜像存储摘要，可以使用docker-compose pull或docker-compose push来获取。 123bundle [options] --push-images 在打包时自动推送已使用build指定的服务的镜像 -o, --output PATH 包文件路径，默认为&quot;项目名.dab&quot; config：校验并查看compose文件 12345config [options] --resolve-image-digests 将镜像标签写入摘要 -q, --quiet 静默模式，只校验配置，不打印信息 --services 列出所有服务 --volumes 列出所有数据卷 down：停止并删除容器、网络、镜像、数据卷 默认能删除的内容： Compose文件中定义的服务的容器 Compose文件的networks中定义的网络 默认网络（如果使用） 1234567down [options] --rmi type 删除镜像，必须指定类型： &apos;all&apos;: 删除任何服务使用的所有镜像 &apos;local&apos;: 只删除没有通过image指定自定义标签的镜像 -v, --volumes 删除在Compose文件的&quot;volumes&quot;中声明的命名卷和附加到容器的匿名卷。 --remove-orphans 为服务删除没有在compose文件中声明的容器 -t, --timeout TIMEOUT 指定几秒后关闭（默认10s） events：从容器接收实时事件 12events [options] [SERVICE...] --json 使用json格式输出事件 exec：在运行的容器中执行命令 12345678exec [options] [-e KEY=VAL...] SERVICE COMMAND [ARGS...] -d, --detach 后台运行命令 --privileged 给进程额外的权限 -u, --user USER 指定运行命令的用户 -T 禁止分配伪终端，exec默认分配一个伪终端 --index=index 设置容器的索引（如果一个服务有多个容器），默认为1 -e, --env KEY=VAL 设置环境变量 -w, --workdir DIR 设置工作目录 images：列出镜像 12images [options] [SERVICE...] -q, --quiet 静默模式，只显示镜像号 kill：杀死容器 12kill [options] [SERVICE...] -s SIGNAL 发送给容器的SIGNAL，默认为SIGKILL logs：显示容器的输出 12345logs [options] [SERVICE...] --no-color 单色输出 -f, --follow 按照日志输出 -t, --timestamps 显示时间戳 --tail=&quot;all&quot; 显示日志的末尾行数 pause：暂停服务 1pause [SERVICE...] ps：列出容器，执行此命令时必须cd到项目的根目录下 1234ps [options] [SERVICE...] -q, --quiet 静默，只显示容器号 --services 显示服务 --filter KEY=VAL 根据属性过滤服务 port：显示用于绑定的公共端口 123port [options] SERVICE PRIVATE_PORT --protocol=proto 选择协议，tcp或udp，默认tcp --index=index 设置容器的索引，默认为1 pull：拉取服务镜像 123456pull [options] [SERVICE...] --ignore-pull-failures 忽略拉取失败的镜像 --parallel 并行拉取多个镜像，默认开启，官方不推荐 --no-parallel 禁止并行拉取多个镜像 -q, --quiet 静默模式，不显示拉取信息 --include-deps 同时拉取依赖的服务 push：推送服务镜像 12push [options] [SERVICE...] --ignore-push-failures 忽略推送失败的镜像 restart：重启服务 12restart [options] [SERVICE...] -t, --timeout TIMEOUT 指定几秒后重启（默认10s） rm：删除停止的容器 1234rm [options] [SERVICE...] -f, --force 不询问确认删除 -s, --stop 在删除前自动停止容器 -v 删除任何关联的匿名数据卷，默认不会删除 run：运行一次性命令 123456789101112131415run [options] [-v VOLUME...] [-p PORT...] [-e KEY=VAL...] [-l KEY=VALUE...] SERVICE [COMMAND] [ARGS...] -d, --detach 后台运行 --name NAME 设置容器名 --entrypoint CMD 覆盖容器的ENTRYPOINT -e KEY=VAL 设置环境变量 -l, --label KEY=VAL 添加或覆盖标签 -u, --user=&quot;&quot; 以指定用户执行，可设置用户名或uid --no-deps 不启动相连的服务，默认依赖的服务也会启动 --rm 在运行后删除容器，不与-d兼容 -p, --publish=[] 发布公共端口 --service-ports 通过已启用并映射到主机的端口执行命令 --use-aliases 在容器连接的网络中使用服务的网络别名 -v, --volume=[] Bind mount挂载一个数据卷 -T 禁止分配伪终端（tty），默认run会分配一个 -w, --workdir=&quot;&quot; 容器中的工作目录 start：启动已存在的容器 1start [SERVICE...] stop：停止运行中的容器，并不会删除它们 12stop [options] [SERVICE...] -t, --timeout TIMEOUT 指定几秒后关闭（默认10s） top：显示服务的进程 1top [SERVICE...] unpause：恢复暂停的服务 1unpause [SERVICE...] up：创建并启动容器 默认会启动相连的服务。 1234567891011121314151617up [options] [--scale SERVICE=NUM...] [SERVICE...] -d, --detach 后台运行。与--abort-on-container-exit不兼容 --no-color 单色输出 --quiet-pull 静默拉取 --no-deps 不启动连接的服务 --force-recreate 强制重建服务（即使配置和镜像都没变） --always-recreate-deps 重建依赖的服务，与--no-recreate不兼容 --no-recreate 若容器存在就不会重建，与--force-recreate和-V不兼容 --no-build 即使镜像丢失也不重建镜像 --no-start 在构建服务后不启动该服务 --build 在启动容器前先构建镜像 --abort-on-container-exit 如果任何容器停止，就停止所有容器，与-d不兼容 -t, --timeout TIMEOUT 设置容器几秒后关闭（默认10s） -V, --renew-anon-volumes 重建匿名卷而不是从以前的容器中恢复数据。 --remove-orphans 删除服务的compose文件中未定义的容器 --exit-code-from SERVICE 返回指定服务的退出码 Implies --abort-on-container-exit. --scale SERVICE=NUM 将SERVICE扩展到NUM个实例。会覆盖Compose文件中的&quot;scale&quot;设置（如果存在） Compose文件格式Compose文件采用YAML语法，文件名以.yml或.yaml结尾，默认应存放在项目的根目录中，文件名应为docker-compose.yml。在Compose文件中无需再指定Dockerfile中已定义的项。 文件格式为3.7，所以compose文件最开始要写上version: &quot;3&quot; 然后定义服务services，在services:下添加服务，开始对服务的配置。 build：用于指定在构建时应用的配置选项。 context：用于指定构建上下文。 dockerfile：用于指定Dockerfile文件 args：用于给Dockerfile文件中ARG定义的参数传参 123456789101112131415161718192021version: &quot;3&quot;services: webapp: build: ./dir 可以这样直接指定上下文路径 webapp: build: 也可以作为具有在上下文中指定的路径的对象 context: ./dir 然后通过context指定上下文路径 当提供的值是相对路径时，context被解释为相对于Compose文件的位置。此目录也是发送到Docker daemon的构建上下文 build: context: . dockerfile: webapp.dockerfile 还可以指定Dockerfile文件 args: 可以为Dockerfile文件传参 args1: 123 args2: 345 也可以这样表示： args: - args1=123 - args2=345 image: webapp:tag 可以指定构建镜像，会生成一个名为webapp，并打上tag标签的镜像 在群集模式下使用Compose文件（版本3）部署堆栈时，将忽略image选项。 docker stack命令仅接受预先构建的图像。 注：YAML布尔值（true，false，yes，no，on，off）必须用引号括起来，以便解析器将它们解释为字符串。 cache_from：指定Docker引擎用于实现缓存的镜像列表 labels：使用标签将元数据添加到生成的镜像中，可使用数组或字典 shm_size：为构建的容器设置/dev/shm分区的大小，指定字节数或字节值字符串，如2mb或2000000 target：根据Dockerfile中的定义构建指定的阶段 123build: context: . target: prod cap_add和cap_drop：添加或删除容器功能 123456cap_add: - ALLcap_drop: - NET_ADMIN - SYS_ADMIN command：覆盖容器启动后默认执行的命令 123command: bundle exec thin -p 3000或使用列表表示：command: [&quot;bundle&quot;, &quot;exec&quot;, &quot;thin&quot;, &quot;-p&quot;, &quot;3000&quot;] container_name：自定义该容器名称。由于Docker容器名称必须是唯一的，因此如果指定了自定义名称，则无法将服务扩展到多个容器 volumes：卷挂载路径设置。格式：宿主机源路径:容器目的路径[:访问权限]，默认访问权限为读写。可使用相对路径，相对于compose文件所在目录。 links：链接到另一个服务中的容器，格式：服务名[:别名] external-links：链接到docker-compose.yml外部的容器，甚至并非 Compose 管理的容器。 expose：暴露端口，但不映射到宿主机，只被连接的服务访问。最好使用字符串表示数字，因为YAML会解析xx:yy这种数字格式为 60 进制，容器端口小于 60 可能出错。 ports：暴露端口信息，格式：[宿主机IP:][端口:]容器端口，可用-表示一个端口范围 docker-compose示例首先是docker-compose官方文档中的示例： 12 参考文章 Docker三剑客之Compose-一 Docker三剑客之Compose-二 Docker三剑客之Compose-三 docker-compose教程（安装，使用, 快速入门） docker-compose官方文档 Docker系列之（五）：使用Docker Compose编排容器]]></content>
      <tags>
        <tag>docker</tag>
        <tag>docker-compose</tag>
        <tag>云计算</tag>
        <tag>容器编排</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes学习笔记-1]]></title>
    <url>%2F2018%2F07%2F13%2FKubernetes%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Kubernetes概述 Kubernetes简单部署 Kubernetes概述Kubernetes协调一个高可用的计算机集群，这些计算机连接起来作为一个单元工作，以更有效的方式自动化跨集群分发和调度应用程序容器。 K8s集群节点的两种角色：Master管理节点和Nodes工作节点。 每个节点都有一个Kubelet，它是管理节点并与Master通信的代理。该节点还应具有用于处理容器操作的工具，例如Docker或rkt。处理生产流量的Kubernetes集群应至少有三个节点。 节点使用主服务器公开的Kubernetes API与Master进行通信。用户还可以直接使用Kubernetes API与群集进行交互。 K8s对外提供容器服务偏向于Mesos方式，即用户提交容器集群运行所需要的资源的申请（通常是一个配置文件），然后有k8s负责完成这些容器的调度，自动为容器选择运行的宿主机。 K8S的功能： 自动化容器的部署和复制 ，控制器维护pod副本数量，保证一个pod或一组同类pod数量始终可用 随时扩展或收缩容器规模，弹性伸缩，自动缩放pod副本数 将容器组织成组（pod），并且提供容器间的负载均衡，集群服务入口为ClusterIP 服务发现，可使用环境变量或DNS插件保证容器中程序发现pod入口 使用数据卷，实现pod间共享数据 应用程序健康检查，保证健壮性 很容易地升级应用程序容器的新版本，滚动更新，服务不中断，一次更新一个pod 服务编排，通过文件描述部署服务 资源监控，node节点集成cAdvisor资源收集，通过Heapster汇总整个集群节点资源数据，存储到InfluxDB 提供认证和授权，支持属性访问控制（ABAC）、角色访问控制（RBAC） 常见术语 pod：最小的部署单元，包含一组容器和卷。同一个Pod里的容器共享同一个网络命名空间，可以使用localhost互相通信。Pod是短暂的，不是持续性实体。 service：是一个应用服务抽象，定义了pod逻辑集合和访问这个pod集合的策略，对外提供一个访问入口，会有一个集群的IP地址，会将目的是该IP的请求负载均衡到pod的容器。 label：标签，用于区分对象（pod，service），每个对象可以有多个标签，可通过标签关联对象。 基于基本对象的更高层次抽象 ReplicaSet：下一代的Replication Controller。确保任何给定时间指定的pod副本数量，并提供声明式更新等功能。 Replication Controller：确保任意时间都有指定数量的Pod副本在运行。能根据指定的副本数量动态增加或删除副本。 ReplicaSet和Replication Controller的区别：前者支持新的基于集合的标签，后者仅支持基于等式的标签 Deployment：管理ReplicaSets和pod，提供声明式更新等功能。官方建议用Deployment管理ReplicaSets，而不是直接使用ReplicaSets。 StatefulSet：适合持久化的应用，具有唯一的网络标识符（IP地址）、持久存储、有序部署、扩展、删除和滚动更新。 DaemonSet：确保所有或一些节点运行同一个pod，当节点加入k8s集群中，pod会被调度到该节点上运行，当节点从集群中删除时，pod也会被删除。 Job：一次性任务，运行完成后pod销毁。 k8s结构与组件Master组件： kube-apiserver：K8s API，集群的统一入口，以HTTP API提供接口服务，所有对象资源的增删改查和监听工作都交给API Server处理，再交给etcd存储（可选） kube-controller-manager：控制器管理，处理集群中常规后台任务，一个资源对应一个控制器。 kube-scheduler：根据调度算法为创建的pod选择节点。 Node组件： kubelet：Master在Node上的Agent，管理本机运行的容器的生命周期，如创建容器、挂载数据卷，获取节点状态等工作，将每个pod转换为一组容器。 kube-proxy：在Node节点上实现pod网络代理，维护网络规划和四层负载均衡工作。 docker或rkt：底层容器引擎。 第三方服务： etcd：分布式键值存储系统，用于保持集群状态，如pod、service对象信息。 在Kubernetes中运行的Pod正在一个私密的隔离网络上运行。默认情况下，它们可以从同一个kubernetes集群中的其他pod和服务中看到，但不能在该网络之外。当我们使用kubectl时，我们通过API端点进行交互以与我们的应用程序进行通信。 kubectl命令可以创建一个代理，将代理转发到群集范围的专用网络。 Kubernetes简单部署实验环境： 3台虚拟机CentOS7 Kubernetes版本1.12 Docker版本18.06（k8s1.12最高支持docker18.06） 如果版本过高需要重新下载安装yum install docker-ce-&lt;VERSION STRING&gt;，如yum install docker-ce-18.06.0.ce Node1：Master，192.168.60.130 Node2：Node，192.168.60.131 Node3：Node，192.168.60.132 Master节点上不需要安装docker，但需要安装etcd、kubectl、kubeadm Node节点上要安装docker、kubelet 所有节点都要关闭selinux，确保时间都同步了，并在/etc/hosts中设置主机名 123192.168.60.130 kubenode1192.168.60.131 kubenode2192.168.60.132 kubenode3 在Master上先开启API Server代理端口8080 kubectl proxy --port=8080 &amp;，并且关闭防火墙，关闭selinux，否则可能会报错： 1The connection to the server localhost:8080 was refused - did you specify the right host or port? 通过curl localhost:8080/api查看是否能访问 123# curl localhost:8080/apiI1126 00:30:27.335378 37820 log.go:172] http: Accept error: accept tcp 127.0.0.1:8080: accept4: too many open files; retrying in 5msI1126 00:30:27.335676 37820 log.go:172] http: proxy error: dial tcp 127.0.0.1:8080: socket: too many open files 能够访问了，但可能会出现报错，too many open files，可以设置ulimit -n增大即可，然后需要重新开启proxy。 然后初始化Master，仍可能出现报错 1# kubeadm init --apiserver-advertise-address 192.168.60.130 --pod-network-cidr=10.1.1.0/24 还需要做以下操作： 12sysctl -w net.bridge.bridge-nf-call-iptables=1swapoff -a # 关闭swap 再次执行初始化。期间会拉取k8s.gcr.io的镜像，若无法上外网则会失败。可以先在docker上拉取镜像后再启动。注：一定要加上版本号（Master初始化失败会提示镜像的版本） 1234567docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.12.2docker pull mirrorgooglecontainers/kube-controller-manager-amd64:v1.12.2docker pull mirrorgooglecontainers/kube-scheduler-amd64:v1.12.2docker pull mirrorgooglecontainers/kube-proxy-amd64:v1.12.2docker pull mirrorgooglecontainers/pause-amd64:3.1docker pull mirrorgooglecontainers/etcd-amd64:3.2.24docker pull coredns/coredns:1.2.2 然后一定要打上标签，因为初始化命令始终是查找k8s.gcr.io的镜像的。 1234567docker tag coredns/coredns k8s.gcr.io/coredns:1.2.2docker tag mirrorgooglecontainers/kube-proxy-amd64:v1.12.2 k8s.gcr.io/kube-proxy:v1.12.2docker tag mirrorgooglecontainers/kube-apiserver-amd64:v1.12.2 k8s.gcr.io/kube-apiserver:v1.12.2docker tag mirrorgooglecontainers/kube-controller-manager-amd64:v1.12.2 k8s.gcr.io/kube-controller-manager:v1.12.2docker tag mirrorgooglecontainers/kube-scheduler-amd64:v1.12.2 k8s.gcr.io/kube-scheduler:v1.12.2docker tag mirrorgooglecontainers/etcd-amd64:3.2.24 k8s.gcr.io/etcd:3.2.24docker tag mirrorgooglecontainers/pause-amd64:3.1 k8s.gcr.io/pause:3.1 再次执行命令初始化，等一段时间，会提示初始化成功，并提供了集群加入的指令。 1Your Kubernetes master has initialized successfully! 在两个node上也进行设置： 1234systemctl enable kubeletsystemctl stop firewalld &amp;&amp; systemctl disable firewalldswapoff -asysctl -w net.bridge.bridge-nf-call-iptables=1 将Master提供的加入指令在node上执行，便可加入集群。 由于kubectl暂时无法使用命令补全，所以需要启用自动补全。 1echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc Kube初始化过程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[init] using Kubernetes version: v1.12.2# kubeadm执行初始化前的检查[preflight] running pre-flight checks[preflight/images] Pulling images required for setting up a Kubernetes cluster[preflight/images] This might take a minute or two, depending on the speed of your internet connection[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;# 生成token和证书[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;[preflight] Activating the kubelet service[certificates] Generated etcd/ca certificate and key.[certificates] Generated etcd/server certificate and key.[certificates] etcd/server serving cert is signed for DNS names [kubenode1 localhost] and IPs [127.0.0.1 ::1][certificates] Generated apiserver-etcd-client certificate and key.[certificates] Generated etcd/healthcheck-client certificate and key.[certificates] Generated etcd/peer certificate and key.[certificates] etcd/peer serving cert is signed for DNS names [kubenode1 localhost] and IPs [192.168.60.130 127.0.0.1 ::1][certificates] Generated ca certificate and key.[certificates] Generated apiserver-kubelet-client certificate and key.[certificates] Generated apiserver certificate and key.[certificates] apiserver serving cert is signed for DNS names [kubenode1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.60.130][certificates] Generated front-proxy-ca certificate and key.[certificates] Generated front-proxy-client certificate and key.[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;[certificates] Generated sa key and public key.# 生成kubeconfig文件，kubelet使用这个与Master通信[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/admin.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/kubelet.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/controller-manager.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/scheduler.conf&quot;[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot; [init] this might take a minute or longer if the control plane images have to be pulled[apiclient] All control plane components are healthy after 32.514538 seconds[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace[kubelet] Creating a ConfigMap &quot;kubelet-config-1.12&quot; in namespace kube-system with the configuration for the kubelets in the cluster[markmaster] Marking the node kubenode1 as master by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;[markmaster] Marking the node kubenode1 as master by adding the taints [node-role.kubernetes.io/master:NoSchedule][patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;kubenode1&quot; as an annotation[bootstraptoken] using token: h1flky.ajnxfe5s28hnhsm9[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes master has initialized successfully! 参考文章 十分钟带你理解Kubernetes核心概念 Kubernetes Handbook——Kubernetes中文指南/云原生应用架构实践手册 Kubernetes中文社区 | 中文文档 和我一步步部署 kubernetes 集群 docker容器与容器云 Docker高级应用实战——李振良——视频课程 Kubernetes 1.12.2版，使用docker 镜像安装 Kubernetes：如何解决从k8s.gcr.io拉取镜像失败问题]]></content>
      <tags>
        <tag>云计算</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker存储学习笔记-1]]></title>
    <url>%2F2018%2F07%2F06%2FDocker%E5%AD%98%E5%82%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[主要是对docker文档(v18.03)的翻译以及自己的学习笔记本篇主要包含以下内容 Docker存储介绍 BindMount Volume数据卷 数据卷容器 Docker存储介绍Docker为容器提供了两种存放数据的资源： storage driver：管理的镜像层和容器层 特点：Copy-on-Write。新数据会存放在最上层容器层，修改现有数据会先从镜像层复制到容器层，修改后的数据直接保存在容器中，镜像层保持不变。若多层中有同名文件，用户只能看到最上层的文件。 可通过docker info查看到。Docker优先使用默认的storage driver。 data volume数据卷 特点：是目录或文件，不是磁盘，volume数据可以被永久的保存，即使使用它的容器已经销毁。 分为两种volume：bind mount 和docker managed volume 存储驱动：目前docker支持五种存储驱动。详见存储引擎 AUFS Btrfs Device Mapper Overlay ZFS 原理： Copy-On-Write写时复制 所有驱动都是用到Cow写时复制（copy-on-write），只在需要写时才复制。可以让所有容器都共享一个image文件系统，所有数据都从image读取，容器需要写操作时，才将要写的文件从image复制到自己的文件系统，即所有写操作都是对image中副本的修改。有效提高了磁盘利用率。 allocate-on-demand用时分配 在要写入一个文件时才按需分配空间 驱动： AUFS：一种Union FS联合文件系统，文件级存储。支持将不同目录挂载到同一个虚拟文件系统，下层文件系统只可读，最上层可写。若要修改，AUFS会创建一个该文件的副本，放在可写层，结果也保存在可写层。 Overlay：一种UnionFS，文件级存储。只有两层：upper层和lower层 Device Mapper：RHEL下Docker Engine的默认存储驱动，基于同名级卷管理技术框架的存储引擎。 默认情况下，在容器内创建的所有文件都存储在可写容器层中，仅存储在主机系统的内存中，即tmpfs方式，永远不会写入主机系统的文件系统，因此一旦容器停止，容器内所有文件的改动都会丢失，所以需要通过一些机制将文件保存以至于在容易停止后仍不会丢失。 docker有三种存储容器数据的方式： bind mount：可将容器数据存放在宿主机的任何位置。 volumes：通过创建数据卷将容器数据持久化到文件系统。 tmpfs：数据存放在内存中，不会写入文件系统。 BindMountbind mount可使容器中的文件存储在主机系统的任何位置。Docker主机或Docker容器上的非Docker进程可以随时修改它们。bind mount非常高效，但它们依赖于具有特定目录结构的主机文件系统。 docker提供两种选项进行bind mount。 -v或--volume：三个字段组成，冒号分隔。 第一个字段：卷名，若是匿名卷，则可省略 第二个字段：文件或目录在容器中安装的路径 第三个字段：可选项，例如ro，默认是可读可写 --mount：由多个键值对组成，用逗号分隔，键和值用=连接。以下是提供的键： type：挂载的类型，可以是bind，volume或tmpfs。 source或src：挂载源，即卷名。匿名卷可省略。 destination或dst或target：挂载到的容器中的指定目录或文件路径 readonly：以只读方式挂载，可选。 volume-opt：卷选项，可指定多次，也是键值对形式 bind-propagation：绑定传播，有以下选择：rprivate，private，rshared，shared，rslave，slave注：—mount不支持设置selinux的z或Z选项 如果使用-v或--volume绑定安装Docker主机上尚不存在的文件或目录，则-v会为您创建端点。它始终作为目录创建。而如果使用--mount，Docker不会自动为您创建它，但会生成错误。 注：bind mount允许访问敏感文件使用bind mount的一个副作用：可以通过容器中运行的进程更改主机文件系统，包括创建，修改或删除重要的系统文件或目录。这是一种强大的功能，可能会产生安全隐患，包括影响主机系统上的非Docker进程。 当挂载一个bind mount或非空数据卷到容器中的一个非空目录，则该目录中原有的文件会被掩盖（并非删除），而只显示挂载的卷内容。当挂载一个空数据卷到容器中的一个非空目录，则该目录中的文件都会复制到该卷中。若启动容器时指定了一个不存在的数据卷，则会自动创建一个卷。 123456使用-v挂载docker run -v &lt;源目录或文件&gt;:&lt;容器中目录或文件&gt;# 路径都需要绝对路径# 若添加单个文件，主机源文件必须存在，否则会当做一个新目录挂载到容器使用--mount挂载docker run --mount type=bind,src=&lt;源目录或文件&gt;,dst=&lt;容器目录或文件&gt; docker inspect 容器查看是否挂载了数据卷 bind-propagation传播挂载在指定的bind mount或数据卷上挂载是否能被复制到挂载的目录中去。用于做动态，可通过编排工具方便实现。 有以下几种选项： shared：源挂载的子挂载会暴露给副本挂载，副本挂载的子挂载也会复制到源挂载。 slave：类似于shared，但只在一个方向上。如果源挂载暴露了子挂载，则副本挂载可以看到它。但是，如果副本挂载暴露了子挂载，则源装载无法看到它。 private：此挂载是私人的。其中的子挂载不会暴露给副本挂载，副本挂载的子挂载不会暴露给源挂载。 rshared：与shared相同，但传播也扩展到嵌套在任何源或副本挂载中的挂载点。 rslave：与slave相同，但传播也扩展到嵌套在任何源或副本挂载中的挂载点。 rprivate：默认值。与private相同，源或副本挂载中任何位置的挂载点都不会沿任一方向传播。 Selinux标签如果使用selinux，则可以添加z或Z选项以修改要挂载到容器的主机文件或目录的selinux标签。这会影响主机本身上的文件或目录，并且可能会影响到Docker外部。 z选项表示绑定装载内容在多个容器之间共享。 Z选项表示绑定装载内容是私有且非共享的。使用Z选项绑定安装系统目录（例如/home或/usr）会导致主机无法运行。 当bind mount和service一起使用时，会自动忽略selinux标签（z和Z）还有ro。 Volume数据卷卷是保存Docker容器生成和使用的数据的首选机制，并且卷完全由Docker管理。写入容器的可写层需要存储驱动程序来管理文件系统，存储驱动程序使用Linux内核提供联合文件系统UFS。而数据卷是经过特殊设计的目录，可以绕过联合文件系统，为多个容器提供访问。数据卷的目的在于数据永久化，完全独立于容器的生存周期，容器删除时挂载的数据卷不会被删除。 特点： 卷比bind mount更容易备份或迁移。 卷适用于Linux和Windows容器。 可以在多个容器之间更安全地共享卷。 在容器启动时初始化，若挂载点已有数据，则会被拷贝到新初始化的数据卷中 数据卷变化不会影响镜像更新 卷驱动程序允许在远程主机或云提供程序上存储卷，加密卷的内容或添加其他功能。 可通过docker volume create 数据卷名创建数据卷。每创建一个volume，就会在/var/lib/docker/volumes中创建一个同名目录。若不指定数据卷名，就会随机生成一个volume ID作为数据卷名。 docker volume命令12345create 创建数据卷inspect 查看数据卷信息ls 查看所有数据卷prune 删除未使用的数据卷rm 删除指定数据卷 在创建volume时或启动使用为创建卷的容器时，可以指定卷的驱动。数据卷驱动可通过docker plugin install [选项] 驱动名。如果卷驱动程序要求您传递选项，则必须使用--mount标志来装入卷 docker提供-v和--mount选项进行挂载。使用与bind mount基本一致。如果需要指定卷驱动程序选项，则必须使用--mount。将卷与服务一起使用时，仅支持--mount。 注：挂载数据卷不支持单个文件，只能是目录。且不权限控制，均为可读写。因为容器配置文件里的可以指定docker inspect查看，发现Mounts中的Source字段，其中已指定了源，源为：/var/lib/docker/volumes/容器长ID/_data。 以上两种方法数据源其实还是宿主机中的，并不是真正放在volume container中，可以在通过dockerfile的ADD将数据打包进镜像并指定VOLUME，将ADD指定的目录与VOLUME设为一致，此法称为data-packed volume container。 Tmpfs使用tmpfs mount创建容器时，容器可以在容器的可写层之外创建文件。tmpfs挂载是临时的，仅保留在主机内存中。当容器停止时，将删除tmpfs挂载，该数据不可被共享，Docker默认使用tmpfs挂载。--tmpfs：安装tmpfs挂载而不允许指定任何可配置选项，并且只能与独立容器一起使用。也可以通过--mount指定type=tmpfs。 数据卷容器容器挂载数据卷，其他容器通过挂载该容器实现数据共享，挂载数据卷的容器称为数据卷容器。 创建容器时--volumes-from 数据卷容器创建数据卷容器注：由于数据卷容器仅是提供数据，所以只要create，不用rundocker rm -v 容器 在删除容器时一并删除数据卷。但是，只要有容器还在使用该数据卷，数据卷就不会删除。宿主机上的数据卷若删除，就真的没了。 123456789101112131415161718&gt; docker volume create volume_1&gt; docker volume create volume_2# 创建数据卷容器，挂载volume_1，volume_2&gt; docker create \ -v volume_1:/volume1 \ -v volume_2:/volume2 \ --name vol_container \ alpine# 创建容器挂载数据卷容器&gt; docker run -it \ --volumes-from vol_container \ --name test \ alpine/ # lsbin home mnt run sys vardev lib proc sbin tmp volume1etc media root srv usr volume2# 数据卷容器中挂载的数据卷也被挂载到新容器的根目录了，也可通过-v设置挂载点 数据卷备份、还原与迁移使用数据卷能方便地进行数据备份、迁移和还原。 备份一个容器首先创建一个数据卷，用于存放备份数据。docker volume create vol_backup然后创建一个数据卷容器，挂载该数据卷123docker create --name backup_container\ -v vol_backup:/backup \ alpine 接着运行要备份容器，挂载数据卷容器backup_container，并将要备份的数据打包放入数据卷。1234docker run --rm \ --volumes-from backup_container \ -v /backup \ alpine tar -cvf /backup/data.tar /usr /var 在主机的/var/lib/docker/volumes/vol_backup/_data/中出现了打包后的data.tar 还原一个容器12345docker run --rm \ --volumes-from backup_container \ -v /backup \ alpine \ bash -c &quot;cd /dbdata &amp;&amp; tar xvf /backup/data.tar --strip 1&quot; 删除一个数据卷删除的数据卷有两种情况： 命名卷在容器外部有指定源，删除了容器，数据卷并不会被删除 匿名卷没有指定源，在删除容器时，该匿名卷也会被删除。也可在创建容器时，加上--rm参数，关闭时自动删除容器和匿名卷。 存储引擎参考资料Docker官方文档-存储每天5分钟玩转docker容器技术]]></content>
      <tags>
        <tag>docker</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见VPN技术笔记]]></title>
    <url>%2F2018%2F06%2F18%2F%E5%B8%B8%E8%A7%81VPN%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[华三网络学习笔记（理论） 本篇包含以下知识点 VPN概述 GRE-VPN L2TP-VPN IPSEC-VPN GRE-OVER-IPSEC IPSEC-OVER-GRE MPLS BGP-MPLS-VPN SSL-VPN VPN概述Virtual Private Network虚拟私有网，利用共享公共网络仿真WAN设施，构建私有的专用网络。基于IP的VPN体系的核心是使用Tunnel隧道技术。 VPN的优势 快速构建，降低部署周期 与私有网络一样的安全性、可靠性与可管理性 提高了基础资源的利用率 简化了用户端的配置和维护工作 概念术语 承载协议：在公网传输时使用的协议 封装协议：用于标识承载协议中封装的数据包，放置在承载协议头与载荷协议头间 载荷协议：最初封装数据包的协议 隧道协议：决定如何实现隧道的协议 主要VPN技术L2 VPN技术 L2TP VPN：二层隧道协议，可实现拨号VPN与专线VPN PPTP VPN：点到点隧道协议，支持PPP在IP网络上的隧道封装，使用增强GRE技术为传输的PPP报文提供流控与拥塞控制的封装 MPLS L2 VPN：多协议标签交换L3 VPN技术 GRE VPN：通用路由封装，可在任意协议中封装任意协议的封装方法 IPSEC VPN：IP安全，并不是单个协议，而是一系列协议组成的数据安全体系，包括AH、ESP、IKE等，实现对数据私密性、完整性保护与源校验 BGP/MPLS VPN：多协议BGP，利用MPLS与MP-BGP技术 SSL VPN：安全套接字层，使用SSL协议实现远程VPN GRE-VPNGeneric Routing Encapsulation通用路由封装，是一种能在任意协议中封装任意协议的封装方法，可以直接使用GRE封装建立GRE隧道，为IP协议，协议号47。以下为GRE封装包的格式。 GRE头包含了2字节的Protocol Type，用于指示载荷协议类型，IP协议为0x0800。此外还有扩展GRE头，增加了Key和Sequence Number，具备标识数据流和分组次序的能力。IP协议使用协议号47标识GRE头，说明IP头后跟着GRE头。而GRE头中protocol type若为0x0800，说明GRE头后跟着IP头。 双方通过Tunnel接口（逻辑接口）建立隧道，再通过实际物理接口进行转发。tunnel口为载荷协议服务，物理口为承载协议服务。 GRE隧道通信过程： 隧道起点路由查找：隧道两端的路由器必须是私网边界路由器。收到数据包时查找ip路由表 加封装：查找路由表确认下一跳为tunnel口，则进行GRE封装。 承载协议路由转发：对封装后的包进行公网路由查询。 中途转发：即公网转发 解封装：到达对端私网边界路由器后，该路由器检查IP地址，若是自己则解开IP头，发现有GRE头，就交给目标Tunnel口，tunnel口解开GRE头 隧道终点路由转发：解开GRE头后，发现私网IP目的地址，然后查表转发。 每个运行GRE的路由器只有一个路由表，公网和私网之间只能通过不同的路由加以区分，因此公网私网IP地址能重复，且公网私网必须采用不同策略。 连接到私网的物理接口和Tunnel口属于私网路由AS，采用一致的私网路由策略。 连接到公网的物理接口属于公网路由AS，必须和公网采用一致的路由策略。 优点： 支持多种协议 支持IP路由协议和组播 缺点： 点对点隧道 静态配置隧道 缺乏安全性 不可分配地址空间 部署复杂 静态路由配置：配置到达目的IP的私网网段路由，下一跳为对端Tunnel口的地址。动态路由配置：将隧道和私网作为一个AS看待，动态路由需要将Tunnel口和私网都包括。 Tunnel口虚假状态：GRE本身不对隧道状态维护，系统默认根据接口状态设置Tunnel状态，即若物理链路中出现故障，物理口仍为UP，则隧道口也为UP，而此时隧道却不通。只存在于静态配置时。解决：tunnel口keepalive机制：允许路由器探测隧道口的实际状态。路由器会从tunnel口周期发keepalive消息，默认周期10s，若连续3次未收到，则认为隧道不通，会自动删除该tunnel口为出接口的静态路由。 L2TP-VPN对PPP协议链路提供隧道，允许二层链路端点和PPP会话点驻留在不同设备上，并采用分组交换技术进行信息交互。使用PSTN/ISDN拨号、xDSL直接连接到ISP位于本地的POP（存在点），或直接连接到Internet获得IP通信服务，然后ISP设备或用户设备建立L2TP通道连接对端。 L2TP特点： L2TP支持对用户和隧道的验证，和对客户端的动态地址分配。可使用PPP验证，也可使用LAC提供的AAA验证 具备点到网络特性。适合单个或少量接入 不提供加密，但可结合IPSec等加密 面向连接，为信息提供一定的可靠性 L2TP组件： LAC：L2TP访问集中器，隧道就在LAC和LNS间建立 LNS：L2TP网络服务器 NAS：网络访问服务器，抽象概念，是远程访问的接入点，可以是LAC或LNS 两种拓扑方式： 独立LAC：ISP提供LAC，不依赖IP接入点。条件：ISP支持L2TP，验证系统支持VPDN属性特点：终端用户不需要配置VPN拨号软件，只需要执行普通拨号，登录一次就可以接入企业网。 客户LAC：远程系统安装VPDN客户端，直接对LNS发起连接请求。不依赖LAC，验证只能由LNS执行条件：远程系统必须接入Internet，远程系统需要安装专用客户端软件并配置特点：只需配置VPN软件即可与企业网建立VPN连接。对用户的验证只能由LNS端执行。 L2TP封装：L2TP以UDP/IP为承载协议，UDP端口号为1701。L2TP头中Type字段标识消息类型，若为1表示控制消息，若为0表示数据消息。Tunnel ID字段标识L2TP控制连接，即隧道标识符，是在隧道建立时通过Assigned Tunnel ID AVP交换的。Session ID字段用于标识一个隧道中的各个会话，是在隧道建立时通过Assigned Session ID AVP交换的。 控制连接：在L2TP隧道内部，建立维护和释放会话与隧道控制消息：LAC与LNS间交换的隧道内消息，用于对隧道操作。包含AVP（属性值对，通过发送AVP对隧道建立维护或释放，即管理隧道和会话） L2TP协议操作： 建立控制连接：由PPP触发（1）LAC使用任意UDP端口向LNS的UDP1701端口发起连接（SCCRQ打开控制连接请求）（2）LNS将连接重定向到一个随机UDP端口并回应（SCCRP打开控制连接应答）（3）LAC收到后返回确认（SCCCN打开控制连接已确认）（4）LNS收到后再确认，隧道建立（ZLB零长度体）若要执行隧道验证，可在SCCRQ或SCCRP中加上Challenge AVP（挑战AVP）发起验证，接收方要在回应中加上Challenge Response AVP（挑战响应AVP）。 建立会话：前提为控制连接的建立。由PPP模块触发LAC发起：（1）LAC向LNS发送ICRQ（入呼叫请求）发起会话建立（2）LNS收到请求后返回ICRP（入呼叫应答）（3）LAC收到应答后返回ICCN（入连接已连接）（4）LNS再回应ZLB，会话建立LNS发起：（1）LNS发送OCRQ（出呼叫请求）发起会话建立（2）LAC收到后返回OCRP（出呼叫应答）（3）LAC执行呼叫，返回OCCN（出呼叫已连接）（4）LNS收到后回应ZLB，会话建立会使用Tunnel ID和Session ID区分不同隧道和会话 隧道状态维护LAC与LNS互发Hello消息维持会话，默认周期60s，若三次未收到对方的Hello消息，则认为隧道断开。 关闭会话与控制链接关闭会话：（1）LAC发送CDN（呼叫断开通知），通知LNS关闭会话（2）LNS收到后返回ZLB，并关闭会话关闭控制连接：（1）LAC发送StopCCN（停止控制连接通知），通知LNS关闭控制连接（2）LNS收到后回应ZLB，并关闭控制连接 L2TP验证1.对拨入的远程系统PPP验证2.LAC与LNS间隧道验证3.LNS对远程系统再次PPP验证。方式分为三种： 1）代理验证：LAC将从远程系统得到的验证信息和自身的验证信息都发给LNS 2）强制CHAP验证：LNS直接对远程系统进行CHAP验证 3）LCP重协商：LNS与远程系统重新进行LCP协商，采用相应虚拟模板接口上配置的验证方式进行验证 LAC端对远程系统用户的AAA验证包括： 本地验证：需要LAC端配置本地用户名、密码、服务类型等信息，与用户输入的通过对比进行验证。 远程验证：需要与RADIUS或TACACS服务器协同验证，需要在RADIUS或TACACS服务器上配置用户验证信息，LAC将用户输入的信息发送给验证服务器进行验证。 下图为：独立LAC隧道会话建立 下图为：客户LAC隧道会话建立 IPSEC-VPN一种网络层安全保障机制。可实现访问控制、机密性、完整性校验、数据源校验、拒绝重播报文等。IPSec是可扩展的体系，不受限于任何一种特定算法，可引入多种验证算法、加密算法、密钥管理机制。缺点：复杂，消耗大量资源、数据延迟、点对点、不支持组播 IPSec SAIPSec SA：IPSec安全联盟，安全服务通过SA实现。SA是双方的安全协定，包括协议、算法、密钥。SA是单向的，入站和出站数据流分别由入站SA和出站SA处理。 SA的三元组： SPI：安全参数索引，32位数值 IP目的地址：对方IP地址 安全协议标识符：标识AH或ESP SA建立方式： 手工配置：两端手动设置参数 自动协商：双方通过IKE生成维护 SA具有生存时间，有两种方式： 时间：每隔定时长更新SA 流量：每传输一定流量更新SA SA协商信息存放在SPD（安全策略数据库），SPD的项指向SAD（安全联盟数据库）相应项 IKEIKE：因特网密钥交换。基于UDP协议，端口号500，为IPSec提供自动协商交换密钥、建立SA服务，实际提供安全服务的是IPSec，采用DH算法交换密钥（精髓）。且可以定时更新密钥和SA，提供了完善的前向安全性。可以为IPSec自动重新建立SA，允许IPSec提供抗重播服务（通过SPI值）。 采用ISAKMP的密钥交换框架体系IKE安全机制： 身份验证：预共享密钥（默认）、RSA数字签名、DES数字签名 DH密钥交换 PFS完善前向安全性：通过在第二阶段再进行一次DH交换，使IKE SA密钥与IPSec SA密钥无派生关系 协商两个阶段： 阶段1：建立一个IKE SA，为阶段2提供保护分为主模式main和野蛮模式aggressive 主模式：强制实现的阶段1交换模式。共三步，六条消息 策略协商：A向B发送本地IKE策略，B查找匹配的策略，并确认其中协商属性包括：加密算法，散列算法（MD5、SHA等），验证方法（预共享密钥、DSS、RSA），DH组信息（默认MODP 768），DH公共值，IKE生存时间，身份信息 DH交换：A向B发起密钥生成信息，B生成密钥并回应。 ID交换验证：A向B发送身份和验证数据，B回应身份验证。 野蛮模式：远程拨号时，由于拨号用户IP无法确定，可以使用野蛮模式 A向B发送本地IKE策略，开始DH交换 B查找匹配策略，回应验证信息 A接收确认信息并验证，生成密钥，向B发送验证载荷 B验证 阶段2：在IKE SA的保护下完成IPSec SA的协商。采用快速模式 野蛮模式安全性差于主模式，但过程简单快速。在不知道对端IP且需要使用预共享密钥的情况下，必须用野蛮模式。 IPSec包处理流程出站包处理： 查找SPD，三种结果：丢弃、旁路安全服务：直接转发、提供安全服务：查找IPSec SA 若第一步结果是提供安全服务，就在SAD中找IPsec SA，若找到就根据参数提供安全服务，若找不到就查找IKE SA 若找到IKE SA，就只要创建IPSec SA，若找不到IKE SA，就要先创建IKE SA，再创建IPSec SA。 入站包处理： 检查目的地址是否本地，若是则检查数据包是否被IPSec保护 若被IPSec保护，则查找IPSec SA，若不被IPSec 保护，则交给上层 若找到IPSec SA，则解封装，若未找到则丢弃 安全协议 AH：验证头，提供完整性保护、数据源验证、抗重播服务。不支持机密性保护。IP协议，协议号51。AH头格式： Next Header：8位，指示AH头后的载荷协议类型 Payload Length：8位，指示AH的长度并减2，单位为32位 SPI：32位任意数值，用于和目的IP地址和安全协议标识结合，唯一标示一个SA Sequence Number：32位无符号整数，SA建立时为0，随着数据包发送而增大，接收方通过该值确定数据包的序列 Authentication Data：包含该数据包的完整性校验值ICV（使用HMAC算法对IP头+AH头+载荷+共享密钥加密计算），变长且必须是32位的整数倍。AH强制实现HMAC-MD5-96和HMAC-SHA-1-96两种验证算法 ESP：封装安全载荷，有AH所有功能且支持加密。包含ESP头和ESP尾。IP协议，协议号50。ESP头格式： Next Header：同上。强制包含。 SPI：同上 Sequence Number：同上 Payload Data：Next Header描述的数据，即载荷数据，长度为字节的整数倍。若加密，ESP强制实现了基础加密算法DES-CBC。强制包含。 Padding：填充，使载荷数据达到指定长度。 Pad Length：填充长度，范围为0到255。强制包含。 Authentication Data：ICV，长度由验证算法决定。可选，验证服务开启时才包含。同样强制实现HMAC-MD5-96和HMAC-SHA-1-96ESP尾格式：Padding、Pad Length、Next Header IPSec有两种工作模式： 传输模式：保护端到端安全，两个终端间直接运行IPSec，所有加解密、协商都是端系统完成，网络设备完全不参与IPSec，只进行正常路由转发。 隧道模式：保护站点到站点安全，两个安全网关间运行IPSec，整个数据包都计算AH或ESP头，AH或ESP头加上数据都被封装在一个新的IP包中。所有加解密、协商都是安全网关完成，终端主机不参与。 因此AH和ESP对两种工作模式分别有封装的方式： AH 传输模式原IP包、AH头与密钥通过散列函数（如RSA）生成校验值。将校验值封装在AH头中，再由TCP和原IP头封装。 隧道模式新IP头（根据隧道起点终点建立隧道IP头）、AH头与原IP包生成校验值。将校验值封装在AH头中，封装原IP包，再用新IP头封装。 ESP 传输模式原IP包（不包括原IP头）、ESP尾与密钥加密（通过DES等算法）生成密文。将生成的密文与ESP头和验证密钥通过数字签名算法（通过RSA）生成校验值。最后将用ESP头和原IP头封装密文和校验值。 隧道模式将整个原IP包、ESP尾、加密密钥通过加密算法（如DES）生成密文。将密文与ESP头和验证密钥通过散列函数（如RSA）生成校验值。用ESP头和新IP头封装密文和校验值。 GRE-OVER-IPSEC使用Gre Over IPsec的原因：GRE不保证数据机密性与完整性，不能数据源验证。 特性 GRE IPSec 多协议 支持 不支持 虚接口 支持 不支持 组播 支持 不支持 路由协议 支持 不支持 IP协议族 支持 支持 机密性 不支持 支持 完整性 不支持 支持 数据源验证 不支持 支持 封装：原始IP包被封装在GRE隧道包中。GRE隧道包被封装在IPSec包中。 IPSEC-OVER-GREMPLSMulti Protocol Labal Switching：多协议标签交换MPLS使用定长标签封装网络层分组。标签位于数据链路层和网络层之间，称为2.5层。多协议指：MPLS被多种二层协议封装，也可封装多种三层协议 两种工作模式： 帧模式：用于PPP、以太网、帧中继 信元模式：作用于ATM 组成： LSR：位于MPLS内部的核心交换机或路由器，提供标签交换和分发 LER：位于MPLS网络边缘，提供标签映射、移除和分发 FEC：转发等价类，转发过程中以等价方式处理的一组数据分组，可根据IP地址、隧道、COS标识创建FECLSP：标签交换通道，属于同一个FEC的数据流在每个节点赋予一个确定的标签，按照一个确定的标签转发表项进行转发，每个FEC流会有固定的转发路径，该路径就成为该FEC的LSP MPLS标签：4个字节。分为四个字段 Label：标签值，20位，标签转发表的关键索引 EXP：标识QoS优先级，3位 S：栈底标识，1位，若为1说明是最后一个标签，若为0说明后面还有MPLS标签。可实现多层MPLS标签嵌套 TTL：存活时间，8位，每经过一台LSR，TTL就减1 链路层协议为MPLS分配的标识： PPP：0x0281 以太网或HDLC：0x8847 帧中继：0x0080 标签分配协议：用于在LSR间分配标签，建立LSP。有以下四种： LDP标签分发协议：最通用 CR-LDP基于路由受限的标签分发协议：可进行路由约束、QoS，用于流量工程 RSVP-TE基于流量工程扩展的资源预留协议：用于流量工程中MPLS标签分配 MP-BGP多协议扩展BGP协议：为BGP路由分配MPLS标签 LDP消息类型： 发现Discover消息：LDP邻居的发现维护 会话Session消息：LDP邻居会话的建立维持与终止 通告Advertisement消息：向LDP邻居宣告Label、地址等信息 通知Notification消息：向LDP邻居通知事件或错误 所有LDP消息都采用TLV结构，具有扩展性（TLV：Type-Length-Value 类型-长度-值） LDP会话建立维护： 邻居发现：互发Hello消息，组播地址224.0.0.2，UDP端口646 TCP连接：LSR-ID大的，即IP地址大的一方主动发起，TCP端口646 会话建立：Master发出初始化Initialization消息，携带协商参数。协商成功Session建立 会话维持：互发Keepalive消息维持会话。LSR之间发送Label mapping消息，形成标签转发表。期间若收到任何差错消息都会关闭会话，断开TCP连接。 LDP邻居状态机：两台LDP邻居间建立LDP Session后，状态会维持在Operational 标签分配过程：上下游根据数据转发方向而定。LDP Session建立后路由器根据路由表分配标签，生成MPLS标签转发表标签转发表包含：入标签IN，出标签OUT，出接口next-hop标签为随机生成，16以下系统保留 标签分配模式： DOD下游按需标记分配：上游LSR向下游LSR发送标签请求信息。下游LSR为此FEC分配标签，通过标签映射消息反馈给上游LSR。原则：下游设备需要收到上游的标签请求才能分配标签 DU下游自主标记分配：下游LSR在LDP会话建立后主动向上游LSR发布标签映射消息，不需等待上游请求 标签控制模式： 有序：只有最下游设备能分发标签，上游设备只有收到了下游的标签映射消息，才能再向上游发送标签映射信息。使得MPLS的转发是端到端的 独立：不管是不是最下游，不管是否收到下游的标签映射信息，都向上游发送标签映射信息。任何的数据流经过MPLS网络都可进行MPLS转发 标签保持方式：收到下游的标签映射后，是否记录标签信息的原则 保守：只保留下一跳邻居的标签，丢弃所有非下一跳邻居发来的标签优点：节约空间缺点：当网络故障时，LSP收敛较慢 自由：保留来自邻居的所有标签。优点：网络故障后，路由切换时收敛快缺点：消耗空间 常用组合：DU + 有序 + 自由 MPLS转发：第一阶段：标签PUSH：报文进入MPLS网络，LER设备发现报文目的IP地址有关联的标签，对报文进行压标签。该报文就变为了MPLS报文第二阶段：标签SWAP：报文在MPLS网络内进行标签交换。第三阶段：标签POP：报文转出MPLS网络时，在最后一跳弹出标签。倒数第二跳的设备上标签表的出标签为3，说明此为倒数第二跳。一旦包查找到出标签为3，就直接弹出标签。 BGP-MPLS-VPN解决了传统VPN的问题：1.实现隧道动态建立 2.解决本地地址冲突问题 3.VPN私网路由易于控制 多VPF组网多VRF技术用于解决同一台设备（PE）上地址冲突问题。存在以下路由器角色： CE：直接与ISP相连的用户设备 PE：公网边缘路由器，与CE相连，负责VPN接入 P：公网核心路由器，负责路由与快速转发 实现：将一台路由器划分为多个VRF，每个VRF相互独立，拥有各自的路由表、端口、协议，每个VRF类似一台虚拟路由器。未划分VRF的路由在公网路由表中。各个VRF与各自的网络运行一个实例，该实例学到的路由只能加入该VPN路由表。实例与所属VPN进行绑定。并且，端口与VPN绑定，与VRF绑定的接口只会出现在该VRF对应的路由表中，当报文从该接口进入路由器后只能查询该VRF对应的路由表。确保了不同VRF数据间不会冲突。 多VRF与路由协议多实例：各VRF与各自用户网络之间运行一个路由实验，该路由实例学习到的路由只能加入该VPN的路由表。各个路由实例与所属VPN绑定，互相独立，只能学到各自的邻居信息。 MP-BGPMP-BGP（Multi Protocol BGP，多协议BGP）是对BGP根据特性（TCP连接、TLV扩展属性位）进行扩展的协议。MP-BGP相对于BGP的新增特性： 普通BGP只能传递IPv4信息，MP-BGP能承载多个协议路由信息。 新增了MP_REACH_NLRI和MP_UNREACH_NLRI两个属性，并新增了扩展团体属性（Extended_Communities）。 MP-BGP可传递BGP MPLS VPN、L2VPN、6PE等路由信息。 MP_REACH_NLRI和MP_UNREACH_NLRI两个属性都是路由更新消息属性。MP_REACH_NLRI代替了原BGP更新消息中的NLRI和Next-hop。增加了地址族的描述Address-Family、私网Label和RD，包含原有的Next-hop。若地址族描述为VPNv4，则NLRI包含两个部分，一个是私网标签（一个MPLS标签），第二部分是VPNv4地址（RD+IPv4地址）MP_UNREACH_NLRI代替了原BGP更新消息中的Withdrawn Routes。可撤销通过MP_REACH_NLRI发布的各种地址族的路由。包含Address-Family和Withdrawn Routes。 VPNv4地址族主要用于PE路由器间传递VPN路由，并只存在于MP-BGP路由信息和PE设备的私网路由表中，即只出现在路由的发布学习过程中，在穿越ISP公网时，数据包头是没有VPNv4地址的。 下图为MP_REACH_NLRI属性 下图为MP_UNREACH_NLRI属性 BGP的扩展团体属性：RT（Route Target）路由目标。本质是每个VPN实例表达自己的路由取舍方式。RT的格式有三种，都表示RT。 0x0002：2字节的AS号，加上4字节的用户自定义数字，如100:1、200:1 0x0102：4字节的IP地址，加上2字节的用户自定义数字，如192.168.1.1:1、10.1.1.1:2 0x0202：4字节的AS号，加上2字节的用户自定义数字 通常设置为冒号后的数字设置为VPN实例编号。 RT由两个部分组成：Export Target和Import Target。MP-BGP在PE间交互私网路由时，需要遵循以下规则： 在PE设备上，发送某一个VPN用户的私网路由给BGP邻居时，需要在扩展团体属性区域中增加该VPN的Export Target属性。 在PE设备上，需要将收到的MP-BGP路由的扩展团体属性中携带的RT值与本地每个VPN的Import Target对比，若存在交集，则可以将该路由添加进实例的路由表。 通过对RT的操作可实现两种模式：Hub-Spoke和Extranet。Hub-Spoke模式：用户总部可与每个分布互通，但每个VPN分布之间禁止互通。Extranet模式：使指定的节点可以与其他节点互通。 RD（Route Distinguisher）路由区分。本质就是用于私网路由的撤销，因为在撤销路由时是不能携带属性值的（包括RT），PE在删除路由时无法判断撤销哪个VPN的路由。长度6字节。RD有两种格式： 2字节的AS号，加上4字节用户自定义数，如100:1 4字节的IP地址，加上2字节用户自定义数，如192.168.1.1:1 只要保证存在相同地址的两个VPN实例的RD不同即可，但最好为每个VPN实例配置一个RD。若两个VPN实例中存在相同IP地址，则这两个实例一定不能互访，间接互访也不行。 私网标签Label，用于帮助PE判断该报文前往的VPN，是通过MPLS的多标签嵌套实现的。 BGP MPLS VPN实现分为以下步骤： 公网隧道建立：公网IGP协议开启，PE间互通。 本地VPN建立：PE上设置本地VPN并设置RD、RT属性，然后将VPN与接口绑定，即配置VRF。 私网路由的学习：PE与CE间运行路由协议多实例，各VPN实例进行路由学习。PE间建立MP-BGP邻居，下游LSR分配标签，建立标签转发表。并会生成一条MP-BGP更新消息，包含VPNv4路由前缀（即IP地址）、下一跳地址、RT属性、私网标签。PE设备会对比RT值，若通过就会记录该路由信息并发布给本地VPN。 私网数据转发：数据会根据标签转发表进行转发。]]></content>
      <tags>
        <tag>网络</tag>
        <tag>vpn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FTP笔记]]></title>
    <url>%2F2018%2F06%2F06%2FFTP%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇笔记包含以下内容 FTP原理 VSFTP搭建 服务器端 常用客户端软件 TFTP原理 服务器端 客户端 FTP原理File Transfer Protocol文件传输协议，基于TCP协议，采用C/S模式，控制连接端口21，数据连接端口20。 控制连接：负责FTP客户端与服务器交互命令与信息的传输，在整个会话过程中始终打开。 数据连接：负责客户端与服务器数据的传输，传输完毕就会关闭 文件类型：一共有４种，但目前主流仅支持以下两种。 ASCII：默认模式，发送方将文件转为ASCII码传输，适合文本文件传输 二进制：也称图像文件传输模式，按比特流传输，适合程序文件传输 格式控制：有三种选项，但目前主流配置只允许非打印。非打印：表示文件中不含有垂直格式信息。 数据结构：有四种选项，但主流配置只允许文件结构。文件结构认为数据是一个连续的字节流。 传输模式：有四种选项，但主流仅允许流方式，文件以字节流形式传输。对于文件节后，发送方在文件结束处提示关闭数据连接。 数据传输方式： 主动PORT 首先客户端（随机端口）与服务器（21端口）TCP三次握手建立连接，建立控制连接通道 客户端向服务器发送PORT命令，告知服务器使用主动模式。其中PORT命令携带参数（客户端IP地址, P1, P2），P1与P2用于标识客户端数据连接的临时端口号，具体为256*P1+P2，IP地址也是四段，每段用逗号分隔 服务器收到PORT命令后按照参数用20端口与客户端指定端口三次握手建立数据传输通道。 数据传输完毕，发送方发送FIN报文，关闭数据连接 注：若客户端在防火墙内部网络，主动方式会出现问题，因为客户端提供的端口是随机的，防火墙若未放行该端口，则无法建立FTP连接。此时需要使用被动方式建立连接 被动PASV 首先客户端（随机端口）与服务器（21端口）TCP三次握手建立连接，建立控制连接通道 客户端向服务器发送PASV命令，参数与PORT一致。但IP是服务器的，标识的是服务器端的临时端口号。 客户端用随机端口与服务器的指定临时端口TCP三次握手建立数据连接通道。 数据传输完毕，发送方发送FIN报文，关闭数据连接 FTP应答格式：服务器端处理完命令后，会将状态信息，如命令是否执行成功、出错类型、是否就绪等，通过控制连接发送给客户端，即应答。应答的目的就是对数据传输过程进行同步，也为了让客户端了解服务器目前的状态。 FTP应答由3个ASCII码数字组成，并跟随解释性文本符号。数字面向机器，文本面向用户。 第一位： 1：确定预备应答：仅仅是在发送另一个命令前期待另一个应答时启动 2：确定完成应答：要求的操作已完成，可接受新命令 3：确定中间应答：该命令已被接受，另一个命令必须被发送 4：暂时拒绝完成应答：请求的命令没有执行，但差错状态是暂时的，命令以后可以再发。 5：永久拒绝完成应答：该命令不被接受，并要求不要再重试。 第二位： 0：语法错误 1：一般性的解释信息 2：与控制和数据连接有关 3：与认证和账户登录过程有关 5：与文件系统有关 第三位：未明确规定，指示对第二位的进一步细化。 常见FTP应答： 110：重新启动标记应答 120：服务在多久时间内准备 125：数据连接打开，传输开始 150：文件状态正常，打开数据连接端口 200：命令执行成功 202：命令执行失败 211：系统状态或是系统求助响应 212：目录的状态 213：文件的状态 214：帮助信息 215：名称系统类型 220：新的联机服务准备 221：服务控制连接关闭，可注销 225：数据连接开启，但无传输动作 226：关闭数据连接端口，请求的文件操作成功 227：进入passive modes 250：请求的文件操作完成 331：用户名已接受，需要输入密码 332：登录时需账号信息 350：请求的命令需要进一步的命令 421：无法提供服务，关闭控制连接 425：无法开启数据连接 426：关闭联机，终止传输 450：请求的操作未执行 451：命令终止，有本地错误 452：未执行命令，磁盘空间不足 500：格式错误，无法识别命令 501：参数语法错误 502：命令执行失败 503：命令顺序错误 504：命令所接的参数不正确 530：未登录 532：存储文件需要账户登录 550：未执行请求的操作 551：请求的命令终止，类型未知 552：请求的文件终止，储存位溢出 553：未执行请求的命令，名称不正确 VSFTP搭建Very Secure FTP安全文件传输软件。针对系统的程序权限设计，有以下特点： 将PID的权限降低 使用chroot机制 服务的启动者就是一个一般用户 任何需要执行具有较高执行权限的VSFTP指令都由特殊的上层程序控制 VSFTPD有两种启动方式： stand alone：CentOS默认使用该方式启动VSFTPD，适合主要用于提供大量下载的任务，服务速度快。使用systemd管理就是stand alone super daemon：适合内部人员小范围使用。使用xinetd管理就是super daemon 服务器端安装vsftpd服务yum install vsftpdsystemctl enable vsftpdsystemctl start vsftpd 安装完在/etc/vsftpd中有四个默认文件： ftpusers：指定哪些用户不能访问FTP服务器，即黑名单 user_list：实行访问控制的用户列表 vsftpd.conf：VSFTP主配置文件 vsftpd_conf_migrate.sh：VSFTPD操作的一些变量和设置的脚本 配置文件/etc/vsftpd/vsftpd.conf简单解析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849listen = YES # IPv4监听，默认是以StandAlone方式启动listen_ipv6 = NO # IPv6监听 # ipv6监听若v4为yes则v6必须为no,同理v6为yes则v4为nolisten_address = # 监听的IP地址listen_port = 21 # 监听的端口port_enable = YES # 开启端口监听ftp_data_port = 20 # 数据传输端口20connect_from_port_20=YES # 数据连接的端口号pasv_enable = YES # 是否启用被动连接pasv_max_port = # 被动连接的最大端口号pasv_min_port = # 被动连接的最小端口号connect_timeout = 60 # 主动连接若60秒tcp无法建立就不建立了accept_timeout = 60 # 被动连接若60秒tcp无法建立就不建立了max_clients = 2000 # 最多允许2000用户同时登录（0为不限制）max_login_fails = 3 # 最多允许3次登录失败max_per_ip = 20 # 同一地址最多允许多少连接（0为不限制）data_connection_timeout = 300 # 数据连接超时时间（数据无响应）就断开idle_session_timeout = 300 # 用户登录上后无操作时间300s则断开user_config_dir = /etc/vsftpd/conf # dirmessage_enable=YES # 是否启用目录提示信息，默认YES。 # 当用户进入某个目录时，会先检查该目录是否存在message_file参数指定的文件 # 若有就显示文件中的内容，通常用于放置欢迎语或目录说明message_file = # 设置文件路径，该文件用于存放目录的说明或欢迎语（当dirmessage_enable为YES时生效）xferlog_enable=YES # 是否启用详细记录上传下载的日志功能，日志文件路径由xferlog_file指定xferlog_file = /var/log/xferlog # 设置文件路径，该文件用于存放目录的说明或欢迎语（当xferlog_enable为YES时生效）pam_service_name=vsftpd # PAM认证服务配置文件名，放在/etc/pam.d/目录中tcp_wrappers=YES # 开启TCP_wrappers防火墙，用于在一定程度上限制某种服务的访问权限ftpd_banner = # 登录FTP服务器时的欢迎语，默认为空download_enable = YES # 是否允许下载userlist_enable = YES # 是否启用用户名单（对名单中的用户进行访问控制）chroot_list_enable = YES # 是否启用锁定用户在自己的主目录中的功能。 # 被锁定的用户登录FTP服务器后只能进入自己的主目录，不能进入其他目录，默认为NO，应该禁用。 # 锁定的用户名单文件由chroot_list_file参数指定chroot_local_user = YES # 是否将用户限制在自己的根目录中chroot_list_file = /etc/vsftpd/chroot_list # 实行或不实行chroot的用户名单，默认就是该文件。文件中是一个用户一行记录 # 若chroot_list_enable为enable，则该文件中的用户会chroot # 若chroot_local_user为enable（chroot_list_enable为enbale仍为前提），则该文件中的用户不会chrootwrite_enable = YES # 是否允许修改，默认NOuserlist_enable=YES # 当用户登录FTP服务器时，在输入完账户名后，服务器会根据userlist_file中指定的用户列表进行控制 # 若在该文件中，则禁止该用户输入密码。默认NOuserlist_file = /etc/vsftpd/user_list # 禁止访问的，默认该文件uesrlist_deny = NO # 是否不允许该文件中的用户登录ftp，需要userlist_enable=YES # NO表示只允许该文件中的用户访问，YES表示禁止文件中的用户登录FTPuse_localtime = YES # VSFTPD默认使用GMT（格林威治）时间，为防止文档时间错误，需要改为YES，即使用本地时间banner_file = /etc/vsftpd/welcome.txt # 当用户登录时会显示的文字，文件必须存在 认证访问控制VSFTPD提供三种认证方式： 匿名访问anoymous：无需认证即可登入 本地用户local：使用ftp服务器中的用户登录 虚拟用户：创建独立ftp账户。是最安全的 匿名访问无需提供真正用户名和密码就能登录FTP服务器。最好不要开启匿名登录，若要开启就进行限制行为。 只允许匿名用户使用少量基本的操作命令 限制文件下载数量，不要允许上传 限制匿名登录的最大同时联机数 配置文件相关参数：123456789101112anonymous_enable = YES # 是否允许匿名用户登录，默认YES # 因为是匿名模式，所以要开启。否则尽量不要匿名访问anon_umask = 077 # 匿名用户创建文件的umask值，默认077，此时匿名传递的文档权限为600anon_root = /var/ftp/anon # 匿名用户的ftp根目录anon_upload_enable = NO # 允许匿名用户上传文件（这项生效的条件为write_enable为YES且ftp匿名用户对该目录有写权限），默认NOanon_mkdir_writable_enable = NO # 是否允许匿名用户创建目录（需要该目录的父目录的写权限），默认为NOanon_other_writable_enable = NO # 是否开放匿名用户其他写入权限，最好关闭anon_world_readable = YES # 仅允许匿名用户下载可读文档anon_max_rate = 0 # 匿名用户最大传输速率，0为不限制，单位字节/秒# 传输速率的控制大概有20%的上下浮动，即范围为速度*80%到120%no_anon_password = NO # 匿名用户登录是否需要密码（NO为需要，YES为不需要，默认为NO） # 若为需要，登录时输入任意字符串即可 在客户端上匿名登录ftp服务器：只要在输用户名时输入anonymous，并任意输入字符串作为密码 本地用户使用ftp服务器本地的用户进行登录，会更加安全，也是最常用的方式。 配置文件相关参数：1234local_enable = YES # 允许本地用户登录ftp，默认YES，在实际工作环境中，应该将这项设为NOlocal_umask = 022 # 本地用户上传文件的umask，默认为077local_root = /var/ftp # 本地用户的根目录local_max_rate = 0 # 本地用户最大传输速率，0为不限制，单位字节/秒 虚拟用户 本地用户登录时会自动转为虚拟用户，即使有大量用户登录，但最终也仅仅转为一个虚拟用户，避免了创建大量的系统用户。 12guest_enable = YES # 是否开启虚拟账户guest_username = ftp # 虚拟账户映射的用户名 使用本地用户认证创建FTP用户限制该用户仅能登录FTP服务器useradd ftpuser -s /sbin/nologin并设置密码。为该用户创建一个主目录，即用户登录FTP后的根目录。mkdir -p /data/ftp/ftpuser/pub。其中/data/ftp/ftpuser为用户ftpuser的主目录，该目录不得上传文件，该目录下的pub目录供ftpuser用户上传文件。usermod -d /data/ftp/ftpuser ftpuserchmod a-w /data/ftp/ftpuserchmod a+w -R /data/ftp/ftpuser/pub 配置文件中几条修改项：12local_enable = YESlocal_root = /data/ftp 使用虚拟账户首先创建虚拟用户文件/etc/vsftpd/visualusers，文件中列出虚拟用户名和密码 1234ftp_visual_1123456ftp_visual_2234567 生成虚拟用户数据库（可选）。需要工具libdb4-utils（Berkeley DB工具，CentOS中是该软件包） db_load -T -t hash -f /etc/vsftpd/visualusers /etc/vsftpd/visualusers.db ，然后修改该备份文件的访问权限chmod 600 /etc/vsftpd/{visualusers,visualusers.db} 创建PAM文件，设置账户验证。 PAM配置文件位于/etc/pam.d/vsftpd，该文件的名称取决于vsftpd主配置文件的pam_service_name字段。将默认配置注释，然后添加以下内容： 12auth required /lib64/security/pam_userdb.so db=/etc/vsftpd/visualusers.dbaccount required /lib64/security/pam_userdb.so db=/etc/vsftpd/visualusers.db 所有的虚拟用户都需要映射到一个真实的系统用户，因此需要添加一个系统账户并设置家目录。 useradd -s /sbin/nologin -d /home/virtual virtual 查看修改主配置文件（有的不用改）： 1234local_enable = YESchroot_local_user = YESpam_service_name = vsftpduser_config_dir = /etc/vsftpd/visual_config # 设置虚拟用户配置文件主目录 创建虚拟用户配置文件的存放目录/etc/vsftpd/visual_config，这样可以为每个账户做单独的权限设置 创建用户visual的独立配置（举例）： 1234# vim /etc/vsftpd/visual_config/visualguest_enable = YESguest_username = ftp_visual_1anon_max_rate = 100000 常用客户端软件TFTP原理Trivial File Transfer Protocol简单文件传输协议，基于UDP协议，端口号69特点： 仅提供简单文件传输功能（上传，下载） 无存取授权与认证机制，无目录功能 由客户端发起 下载过程： 客户端向服务器发送读请求 服务器根据请求回应数据报文（块编号从1开始） 客户端收到数据后回应确认报文。重复2.3步直至完成下载 上传过程： 客户端向服务器发送写请求 服务器回应确认报文（块编号为0） 客户端发送数据报文（块编号从1开始） 服务器收到后回应确认报文。重复3，4步直至上传完成 文件传输时，将文件分成多个文件块，封装到数据报文中并打上文件块编号 传输文件模式： netASCII：对应FTP的ASCII模式 octet：对应FTP二进制模式 协议报文： RRQ读请求报文 WRQ写请求报文 数据报文 确认正确/错误报文 报文的头两个字节是操作码字段，1为读请求，2为写请求，3为数据报文，4为确认正确，5为错误。文件传输过程中读写出错就发送差错报文，数据传输就停止，差错报文不会被确认也不会重传。TFTP每次传输的数据报文中文件块大小固定为512字节，若文件大小刚好是512字节的整数倍，则传完文件后还要再发一个空文件块的数据报文表明文件传输完成。]]></content>
      <tags>
        <tag>server</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Iptables、Selinux与防火墙笔记]]></title>
    <url>%2F2018%2F06%2F06%2FIptables%E3%80%81Selinux%E4%B8%8E%E9%98%B2%E7%81%AB%E5%A2%99%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本片包含以下内容： Iptables Netfilter/Iptables框架 iptables规则 iptables应用 Selinux Selinux介绍 安全上下文 Selinux管理 firewalld 防火墙部署结构 firewalld服务 IptablesNetfilter/Iptables框架Netfilter是Linux 2.4.x引入的一个子系统，它作为一个通用的、抽象的框架，为每种网络协议都提供一整套的hook函数的管理机制，使得诸如数据包过滤、网络地址转换(NAT)和基于协议类型的连接跟踪成为了可能。Netfilter的架构就是在整个网络流程的若干位置放置了一些检测点（HOOK），而在每个检测点上登记了一些处理函数进行处理。 Netfilter采用的关键技术： 连线跟踪（Connection Tracking）：是包过滤、地址转换的基础，它作为一个独立的模块运行。在协议栈低层截取数据包，将当前数据包及其状态信息与历史数据包及其状态信息进行比较，从而得到当前数据包的控制信息，根据这些信息决定对网络数据包的操作，达到保护网络的目的。 包过滤（Packet Filtering）：检查通过的每个数据包的头部，然后根据规则处理 地址转换（NAT）：网络地址转换分为源NAT（SNAT）、目的NAT（DNAT）和端口转换（PNAT）。SNAT修改数据包的源IP，DNAT修改数据包的目的IP。SNAT在数据包送出之前的最后一刻做好转换工作，DNAT在数据包进入后立刻完成转换。 包处理（Packet Mangling）：可以设置或改变数据包的服务类型（TOS），改变包的生存期（TTL），在包中设置标志值，利用该标志值可以进行带宽限制和分类查询。 资料摘自百度百科-netfilter Netfilter为IPv4定义了5个hook函数，这些hook函数会在数据报流过协议栈的5个关键点被调用。 NF_IP_PRE_ROUTING：刚刚进入网络层的数据包通过此点（已完成版本号，校验和等检测）， 目的地址转换在此点进行 NF_IP_LOCAL_IN：经路由查找后，送往本机的数据包通过此检查点，INPUT包过滤在此点进行 NF_IP_FORWARD：要转发的包通过此检测点，FORWARD包过滤在此点进行 NF_IP_POST_ROUTING：所有马上要通过网络设备出去的包通过此检测点，内置的源地址转换SNAT功能（包括地址伪装）在此点进行 NF_IP_LOCAL_OUT：本机进程发出的包通过此检测点，OUTPUT包过滤在此点进行 Netfilter所有的过滤规则都以模块存放在/usr/lib/modules/$(uname -r)/kernel/net/netfilter/目录中。在Linux内核版本2.6前，netfilter分为IPv4版和IPv6版，分别存放在/usr/lib/modules/$(uname -r)/kernel/net/ipv4和/usr/lib/modules/$(uname -r)/kernel/net/ipv6中，Linux2.6后进行了整合，使得Netfilter更加简单高效。 iptables规则iptables是一个工具，位于用户空间，用于插入，修改，删除数据包过滤表的规则。 iptables分为三部分： 表：分为四张表 raw表：是否对该数据包进行状态跟踪 mangle表：为数据包设置标记，修改数据包（TOS，TTL，MARK） nat表：修改数据包中源、目的IP地址或端口 filter表：过滤数据包（对数据包） 顺序：raw -&gt; mangle -&gt; nat -&gt; filter 链：分为五条链 在路由选择前处理数据包（PREROUTING） 处理流入的数据包（这条规则起到保证内网不被侵犯的关键作用）（INPUT） 处理流出的数据包（OUTPUT） 处理转发的数据包（FORWARD） 在路由选择后处理数据包（POSTROUTING） 链顺序： 入站：prerouting -&gt; input 出站：output -&gt; postrouting 转发：prerouting -&gt; forward -&gt; postrouting 规则：规则被分组在链中，规则被添加到相应的链中，链被添加在表中。规则表默认是允许，则规则链就是被禁止的规则。若规则表是禁止的，则规则链就是被允许的规则 完整包过滤流程： 包到达网络接口 进入raw表的prerouting链（在连接跟踪前处理数据包） 连接跟踪（若要做） 进入mangle表的prerouting链，修改数据包 进入nat表的prerouting链，做DNAT（目标地址转换，改变数据包目的地址使包能到达内网某服务器），但不做过滤 路由判断 若是要转发：进入mangle表forward链，然后进入filter表的forward链过滤，进入mangle表的postrouting链，进入nat表的postrouting链，做SNAT，但不过滤，然后数据包离开本机。 若是发给本地的：进入mangle表的input链，进入filter表的input链，对数据包过滤，然后交给本地程序，处理完后先判断路由，进入raw表的output链，连接跟踪对包的处理，进入mangle表的output链，可修改数据包但不过滤，进入nat表的output链，做NAT，然后路由，进入filter表的output链，可过滤包，进入mangle表的postrouiting链，进入nat表的postrouting链，做SNAT但不过滤，包离开本机。 iptables应用iptables有八种匹配后的触发动作： ACCEPT：允许通过 DROP：丢弃 REJECT：拒绝 LOG：记录日志（syslog） DNAT：目的地址转换 SNAT：源地址转换 MASQUERADE：地址欺骗 REDIRECT：重定向 123456789101112131415161718192021iptables [-t 表名] 选项 [链名] [条件] [-j 控制类型（上面八种）] -P INPUT (DROP|ACCEPT) 设置默认策略 -L 查看规则链 -F 清空规则链 -A 在链末尾加新规则 -I num 在链头部加新规则 -D num 删除指定规则 -R 替换指定链中的一条匹配规则 -N 创建一个新链 -X 删除指定用户的定义链，若未指定就删除所有用户链 -C 检查数据包是否与指定链规则匹配 -Z 将指定链中的所有规则byte计数器清零 匹配参数： -s 匹配源IP/mask，加！表示除该IP -d 匹配目的地址 -i [网卡] 匹配流入网卡的数据 -o [网卡] 匹配流出网卡的数据 -p [协议] 匹配协议 -n ip地址会以数字显示 --dport num 匹配目标端口号 --sport num 匹配源端口号 SelinuxfirewalldRHEL7中firewalld取代了iptables。firewalld将所有网络流量都分类汇集到zones，然后通过zones管理防火墙规则。 firewalld匹配规则： 数据包进入系统，首先检查源IP地址和网卡接口，若与某个zone匹配，则按照该zone的规则过滤。每个zone都有开启或关闭的服务和端口列表，数据包根据列表决定是否放行。如果数据包不与任何定义的zone匹配，则进入默认zone，默认zone的名称为public。firewalld提供以下默认zone：home/drop/work/internal/block/public/trusted/dmz/external，在fedora中，还会默认提供FedoraWorkstation和FedoraServer两个zone。 firewall命令： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657firewall-cmd Status Options --state 返回firewalld状态 --reload 重新加载firewalld，会保留状态信息 --complete-reload 重载firewalld，不会保留状态信息 --runtime-to-permanent Create permanent from runtime configuration --permanent 设置为永久配置 --get-default-zone 显示默认zone --set-default-zone=&lt;zone&gt; 设置默认zone --get-active-zones 显示活跃的zone --get-zones 显示所有预设的zone --get-services 显示所有预设服务 --list-all-zones 列出所有zone的信息 --new-zone=&lt;zone&gt; 创建新的zone --delete-zone=&lt;zone&gt; 删除指定zone --load-zone-defaults=&lt;zone&gt; 加载zone的默认配置 --zone=&lt;zone&gt; 指定zone进行设置 --info-zone=&lt;zone&gt; 显示指定zone的信息 --list-all 列出活跃的zone的信息 --list-services 列出放行的服务 --add-service=&lt;service&gt; 添加放行的服务 --remove-service=&lt;service&gt; 取消放行服务 --query-service=&lt;service&gt; 返回服务是否放行 --list-ports 列出zone中放行的端口 --add-port=&lt;portid&gt;[-&lt;portid&gt;]/&lt;protocol&gt; 放行端口 --remove-port=&lt;portid&gt;[-&lt;portid&gt;]/&lt;protocol&gt; 取消放行端口 --query-port=&lt;portid&gt;[-&lt;portid&gt;]/&lt;protocol&gt; 返回端口是否放行 --list-protocols 列出指定区域添加的协议 --add-protocol=&lt;protocol&gt; 为指定区域添加协议 --remove-protocol=&lt;protocol&gt; 去除协议 --query-protocol=&lt;protocol&gt; 查询是否协议被添加到区域 --list-source-ports 查看区域中定义的源端口 --add-source-port=&lt;portid&gt;[-&lt;portid&gt;]/&lt;protocol&gt; 添加设置源端口 --remove-source-port=&lt;portid&gt;[-&lt;portid&gt;]/&lt;protocol&gt; 去除源端口 --query-source-port=&lt;portid&gt;[-&lt;portid&gt;]/&lt;protocol&gt; 查询源端口是否属于该区域 --list-rich-rules 列出所有rich rules --add-rich-rule=&lt;rule&gt; 添加rich rules --remove-rich-rule=&lt;rule&gt; 去除rich rules --query-rich-rule=&lt;rule&gt; 查询指定rich rules是否属于该域 --list-interfaces 列出区域中的网卡 --add-interface=&lt;interface&gt; 在区域中添加网卡 --query-interface=&lt;interface&gt; 查询网卡是否属于一个区域 --remove-interface=&lt;interface&gt; 从区域移除网卡 --list-sources 查看区域中定义的源 --add-source=&lt;source&gt;[/&lt;mask&gt;] 添加源 --query-source=&lt;source&gt;[/&lt;mask&gt;] 查询区域中是否有指定源 --remove-source=&lt;source&gt;[/&lt;mask&gt;] 去除区域中指定源 参考文章 firewall-cmd]]></content>
      <tags>
        <tag>iptables</tag>
        <tag>安全</tag>
        <tag>Linux</tag>
        <tag>Selinux</tag>
        <tag>防火墙</tag>
        <tag>firewalld</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP笔记]]></title>
    <url>%2F2018%2F06%2F05%2FDHCP%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容 DHCP原理 DHCP服务器配置 服务器端 客户端 DHCP中继 DHCP原理DHCP（Dynamic Host Configuration Protocol）用于为客户端动态分配IP地址、子网掩码并设置网关等信息。前身为BOOTP协议，工作在应用层，基于UDP协议，端口号67（服务器端），68（客户端），还有一个546端口用于DHCPv6的客户端。 DHCP与BOOTP最重要的区别：DHCP支持租期，BOOTP不支持，BOOTP分配的IP地址是永久的。 DHCP提供三种分配方式： 手动分配：静态绑定固定IP，这些IP固定给特定设备使用（打印机，DNS，web服务器等） 自动分配：服务器给客户端分配租期无限长的IP地址，只有客户释放，其他客户才能使用该地址 动态分配：服务器给客户端分配租期有限长的IP地址，一旦租期到期而未续约，地址就会释放。 DHCP的基本原则：尽可能为客户端分配原来使用的地址。DHCP的分配顺序：1.静态分配的 2.客户端曾经会用过的 3.最先找到的可用IP。 DHCP报文与请求过程 DHCP工作过程 发现阶段： 提供阶段： 选择阶段： 确认阶段： 重新申请： 更新租约： DHCP报文 Discover：客户端第一次向服务器发送的请求报文，广播发送 Offer：服务器对客户端Discover的回应，包含分配的IP、掩码、网关等信息，广播或单播发送 Request：客户端发送给服务器的请求报文，包括服务器的选择与租期更新等，单播或广播发送（根据客户端状态） Release：客户端若想释放当前地址，则单播发送给服务器 Ack/Nak：服务器对客户端的回应，请求报文正确时回复Ack，否则回复Nak Decline：客户端收到服务器的Ack后，对获取的IP进行确认，使用ARP，若发现该IP已被使用，则广播向服务器发送Decline报文，拒绝使用该IP。 Inform：当客户端通过其他方式已获取了IP，若还需要向服务器索取其他配置信息时，会向服务器发送Inform，若服务器能根据要求分配则会回复Ack，否则不操作。 DHCP续约 更新状态：使用时间达到租约的50%，客户端进入更新状态，单播向服务器发送Request，服务器若同意续约则回复Ack，否则回复Nak 重新绑定状态：使用时间达到租约的87.5%，客户端进入重新绑定状态。客户端广播Request请求，请求对有效租期进行更新。进入该状态的原因：客户端未收到服务器对续约Request的回应。若Request未收到回应，客户端会在一定时间内重发Request报文，若直到租期结束也未更新租期，则被迫释放IP地址。 DHCP中继DHCP只适用于客户端与服务器在同网段（原因：广播请求），但可以通过中继使客户端可向其他网段的DHCP服务器请求。实现：中继路由器收到请求广播报文，便向服务器单播发送，同理服务器也单播回应中继，中继再广播回应客户端。 DHCP服务器配置实验环境：全部为CentOS-7 服务器端：system2 192.168.163.102 客户端：system3 192.168.163.103 服务器端 安装DHCP服务yum install dhcp dhcp-devel dhcp为服务器端基础组件，dhcp-devel为服务器开发工具 开机自启 systemctl enable dhcpd systemctl start dhcpd 修改配置文件/etc/dhcp/dhcpd.conf注：该文件是空的，可以参考模板添加项，模板为/usr/share/doc/dhcp-4.2.5/dhcpd.conf.example，其中dhcp的版本号可能不一致，可用find命令查找 以下为配置文件常见参数的解析，可通过man 5 dhcpd.conf查看完整配置参数解析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# 服务器名server-name “system2”; # DNS域名option domain-name &quot;example.org&quot;;# DNS服务器域名（最多指定三个）option domain-name-servers ns1.example.org, ns2.example.org;# 默认租期，单位秒。在默认租期内，可以进行续约操作default-lease-time 600;# 最大租期，单位秒。max-lease-time 7200;# 最大租期即客户端IP租约时间的最大值，当客户端超过默认租约时间，虽此时已无法续约，但DHCP会仍然允许用户在最大租约时间内使用该IP，之后就收回该IP# dhcp与dns动态信息更新模式（必选）# 三种选择：interim--dns互动更新 ad-hoc--特殊dns更新 none--不支持# 全局设置中一定要有这个，否则不能成功启动#ddns-update-style none;# 如果该DHCP服务器是本地网络的授权服务器，则需要取消注解#authoritative;# 忽略客户端更新ignore client-updates;# 设置网关option routers 192.168.163.254;# 日志类型log-facility local7;# 设置ntp服务器ntp-server [IP地址]# 子网设置subnet 10.5.5.0 netmask 255.255.255.224 &#123; # 设置地址池 range 10.5.5.26 10.5.5.30; option domain-name-servers ns1.internal.example.org; option domain-name &quot;internal.example.org&quot;; option routers 10.5.5.1; # 广播地址 option broadcast-address 10.5.5.31; default-lease-time 600; max-lease-time 7200;&#125;# shared-network用于跨网段分配IP地址，多用于中继，形成超级作用域shared-network 224-29 &#123; # 配置子网1 subnet 10.17.224.0 netmask 255.255.255.0 &#123; option routers rtr-224.example.org; &#125; # 配置子网2 subnet 10.0.29.0 netmask 255.255.255.0 &#123; option routers rtr-29.example.org; &#125;&#125;# host指定客户端客户端的IP地址绑定# hostname仅仅是标识，无意义host hostname &#123; # 指定目标主机 hardware ethernet [MAC地址]; # 绑定IP地址 fixed-address [ip地址];&#125; 注：划分子网时，如果选择直接配置多作用域实现动态IP分配的任务，则必须要为DHCP服务器添加多块网卡，并配置多个IP地址，否则DHCP服务器只能分配与其现有网卡IP地址对应网段的作用域。 DHCP租约文件/var/lib/dhcpd/dhcpd.leases租约数据库文件用于保存一系列的租约声明，其中包含客户端的主机名、MAC地址、分配到的IP地址，以及IP地址的有效期等相关信息。这个数据库文件是可编辑的ASCII格式文本文件。每当发生租约变化的时候，都会在文件结尾添加新的租约记录。 客户端需要安装先dhclient，然后修改/etc/sysconfig-network-scripts/ifcfg-ens33（根据实际网卡名称），修改BOOTPROTO=dhcp，重启网络。 DHCP中继DHCP中继代理（DHCP Relay Agent）用于转发其他网段的客户端DHCP请求。当客户端请求]]></content>
      <tags>
        <tag>server</tag>
        <tag>dhcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP协议基础笔记]]></title>
    <url>%2F2018%2F05%2F31%2FHTTP%E5%8D%8F%E8%AE%AE%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容 Web概述 HTTP概述 HTTP报文 HTTP首部 状态码 HTTP请求方式 HTTP_Cookie Web概述WWW（World Wide Web）环球信息网，也称万维网，由W3C万维网联盟管理。万维网并不等同互联网，万维网只是互联网所能提供的服务其中之一，是靠着互联网运行的一项服务。WWW的三种技术：HTML，HTTP，URL URI：统一资源标识符，表示服务器资源名称，给定了URI，HTTP便能解析资源。URI有两种形式： URL统一资源定位符：描述特定服务器上指定资源的位置，是固定的。包含三部分： 方案：说明访问资源使用的协议方式，如http:// 服务器因特网地址 指定服务器上的指定资源几乎所有URI都是URL URN统一资源名：特定资源的唯一名称，与资源所在地址无关，资源可以四处搬运。 HTTP概述超文本传输​​协议Hyper Text Transfer Protocol（HTTP）是用于传输诸如HTML的超媒体文档的应用层协议，用于Web浏览器和Web服务器之间的通信，基于TCP/IP，采用C/S模式。HTTP是无状态协议，意味着服务器不会在两个请求之间保留任何数据（状态）。 HTTP的三个常见版本： HTTP/1.0：客户端只能从web服务器获取一个web资源 HTTP/1.1：客户端能在一个连接上获取多个web资源（有数量限制，超出部分请求被阻塞） HTTP/2.0：多流并行，一个连接可获取多个web资源 特点： 简单快速：HTTP协议简单，报文简单易懂，HTTP服务器程序规模 小，通信速度快。 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 可扩展：通过HTTP首部，只要服务端和客户端就新首部达成语义一致，新功能就可以被轻松加入进来。 无状态：在同一个连接中，两个执行成功的请求之间是没有关系的。但是可以通过HTTP的头部扩展和HTTP Cookies解决，把Cookies添加到头部中，让每次请求都能共享相同的上下文信息，来创建有状态的会话。 HTTP报文HTTP消息头（HEADER，也称首部）1.通用（一般）头：适用于请求和响应消息，但与最终消息主体中传输的数据无关2.请求头：包含有关要获取的资源或客户端本身更多信息3.响应头：包含有关服务器响应的补充信息，如其位置或服务器本身（名称和版本等）4.实体头：包含有关实体主体的更多信息，比如主体长(Content-Length)度或其MIME类型 HTTP请求方式 GET：请求访问已被URL识别的资源，不会对信息产生影响，每次GET方法都是相同的，GET放在URL首部，GET提交的数据大小一般限制为1024字节，大小随浏览器而。采用明文传输，速度快。只产生一个TCP数据包。GET能被缓存。 POST：请求服务器传输信息实体的主体，POST放在报文中，没有具体限制，由于放在报文中所以无法看见，安全，form表单必须使用POST。会产生两个TCP数据包。POST不可被缓存。POST提交数据大小没有限制。 PUT：传输文件，在请求报文的主体中包含文件内容，然后保存到请求URL指定的位置（出于安全，网站一般不会用） HEAD：获取报文首部，用于确认URI的有效性及资源更新的日期时间等 DELETE：请求URL删除指定的资源，与PUT相反（同样一般不用） OPTIONS：查询指定URL资源支持的方法 TRACE：追踪路径，让服务器将之前的请求通信返还给客户端 CONNECT：要求在与代理服务器通信时建立隧道，实现用隧道协议进行TCP通信，主要使用SSL（安全套接层）和TLS（传输层安全）协议把通信内容加密后经过网络传输。 GET与POST的区别： GET POST 请求访问已被URL识别的资源 将实体提交到指定资源 放在URL首部，明文传输，可见 封装在报文中，不可见 产生一个TCP包 产生两个TCP包 能被缓存 不可被缓存 数据传输大小随浏览器而定，一般为1024字节 没有具体限制 HTTP首部HTTP请求报文（Request）12345678GET https://developer.mozilla.org/zh-CN/docs/Web/HTTP HTTP/2.0Host: developer.mozilla.orgUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:60.0) Gecko/20100101 Firefox/60.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflate, brCookie: dwf_sg_task_completion=False; messages=&quot;67ba01ba64d7aac589a5e34d72bb89050449f64e$[[\&quot;__json_message\&quot;\0541\05430\054\&quot;Redirected from https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/Forms\&quot;\054\&quot;wiki_redirect\&quot;]]&quot;Connection: keep-alive 报文解析：第一行为请求行，包含三个部分： 执行动作：即请求方式。 请求目标：完整路径，通常是一个URL，或者是协议、端口和域名的绝对路径 绝对路径，末尾加上?与查询字符串，称为原始形式 完整URL，称为绝对形式，通常GET使用 域名:端口，仅在使用 CONNECT 建立 HTTP 隧道时才使用 星号形式*，配合 OPTIONS 方法使用，代表整个服务器 HTTP版本 第二行以后的内容都称为HTTP首部（Headers）。 Host：请求的服务器主机名User-Agent：用户代理端，即客户端（浏览器），包含详细的浏览器名和 HTTP响应报文（Response）1234567891011121314151617HTTP/2.0 200 OKcontent-type: text/css; charset=&quot;utf-8&quot;access-control-allow-origin: *cache-control: max-age=315360000, public, immutabledate: Tue, 05 Jun 2018 16:24:09 GMTlast-modified: Tue, 05 Jun 2018 15:59:27 GMTserver: meinheld/0.6.1strict-transport-security: max-age=63072000x-content-type-options: nosniffx-xss-protection: 1; mode=blockcontent-encoding: gzipvary: Accept-Encodingage: 336026x-cache: Hit from cloudfrontvia: 1.1 ec1e0045303188984bc160bff8921bbd.cloudfront.net (CloudFront)x-amz-cf-id: D0Bs8VzYr7qYkVfUiXYivsQqygQPctoPwabrnWC0zSPCwYedUyHAWg==X-Firefox-Spdy: h2 响应报文解析：第一行为响应行，包含两个部分： HTTP版本 状态码第二行开始为响应首部 Content-Type：指示服务器文档的MIME类型。帮助用户代理（浏览器）去处理接收到的数据。 状态码类别： 1XX：信息类———-&gt;请求正在处理，属于临时响应 2XX：成功类———-&gt;请求正常处理完毕 3XX：重定向———-&gt;需要附加操作完成请求 4XX：客户端错误——&gt;服务器无法处理请求 5XX：服务器错误——&gt;服务器处理请求出错 常见状态码： 1XX信息响应 100 Continue：迄今为止的所有内容都是可行的，客户端应该继续请求，如果已经完成，则忽略它。 101 Switching Protocol：响应客户端的 Upgrade 标头发送的，并且指示服务器也正在切换的协议。 102 Processing (WebDAV)：服务器已收到并正在处理该请求，但没有响应可用。 2XX成功响应 200 OK：正常，客户端的请求在服务器被正常处理 201 Created：该请求已成功，并因此创建了一个新的资源。这通常是在PUT请求之后发送的响应。 202 Accepted：请求已经接收到，但还未响应，没有结果。意味着不会有一个异步的响应去表明当前请求的结果，预期另外的进程和服务去处理请求，或者批处理。 203 Non-Authoritative Information：服务器已成功处理了请求，但返回的信息可能来自另一来源。 204 No Content：正常处理，但无资源返回，响应报文中不含实体主体 205 Reset Content：服务器成功处理了请求，且没有返回任何内容。 206 Partial Content：客户端进行了范围请求且服务器成功执行了这部分的GET请求 3XX重定向 300 Multiple Choice：针对请求，服务器可执行多种操作。 服务器可根据user agent选择一项操作，或提供操作列表供请求者选择。 301 Moved Permanently：永久性重定向，请求的资源已被分配了新的URI（以后都用新URI） 302 Found：临时性重定向，请求的资源被暂时的移动到了由Location 头部指定的 URL 上（本次使用新URI访问） 303 See Other：请求对应的资源存在另一个URI,应该使用GET方法定向获取请求的资源当301、302、303响应状态码返回，几乎所有浏览器都会把POST改成GET，并删除请求报文内的主体，之后请求自动再次发送 304 Not Modified：如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。304响应禁止包含消息体，因此始终以消息头后的第一个空行结尾。 305 Use Proxy：请求者只能使用代理访问请求的网页。 （已不再使用，但目前仍能生效） 307 Temporary Redirect：服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 308 Permanent Redirect：资源现在永久位于响应头中Location指定的另一个URI。 4XX请求错误 400 Bad Request：响应状态码表示由于语法无效，服务器无法理解该请求 401 Unauthorized：发送的请求需要有通过http认证（BASIC认证、DIGEST认证）的认证信息。该响应必须包含一个适用于被请求资源的 WWW-Authenticate 信息头用以询问用户信息。若之前已经进行了一次请求，则表示用户认证失败 403 Forbidden：服务器端有能力处理该请求，但是拒绝授权访问 404 Not Found：服务器端无法找到所请求的资源 405 Method Not Allowed：禁用请求中指定的方法。 406 Not Acceptable：无法使用请求的内容特性响应请求的网页。 407 Proxy Authentication Required：此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。 408 Request Timeout：服务器等候请求时发生超时。 409 Conflict：服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。 410 Gone：如果请求的资源已永久删除，服务器就会返回此响应。 411 Length Required：服务器不接受不含有效内容长度标头字段的请求。 412 Precondition Failed：服务器未满足请求者在请求中设置的其中一个前提条件。 413 Payload Too Large：服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。 414 URI Too Long：请求的URI过长，服务器无法处理。 415 Unsupported Media Type：请求的格式不受请求页面的支持。 416 Requested Range Not Satisfiable：如果页面无法提供请求的范围，则服务器会返回此状态代码。 417 Expectation Failed：服务器未满足”期望”请求标头字段的要求。 5XX服务器错误 500 Internal Server Error ：服务器端错误，所请求的服务器遇到意外的情况并阻止其执行请求。 502 Bad Gateway：服务器作为网关或代理，从上游服务器收到无效响应。 503 Server Unavailable：服务器暂时处于超负载或者正在停机维护，现在无法处理请求 504 Gateway Timeout：服务器作为网关或代理，但是没有及时从上游服务器收到请求。 505 HTTP Version Not Supported：服务器不支持请求中所用的 HTTP 协议版本。 参考文章 HTTP | MDN https://developer.mozilla.org/zh-CN/docs/Web/HTTP关于HTTP协议，一篇就够了 https://www.cnblogs.com/ranyonsue/p/5984001.html开发之前应该了解的HTTP https://blog.csdn.net/qq_35414779/article/details/78981151]]></content>
      <tags>
        <tag>http</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAProxy笔记-1]]></title>
    <url>%2F2018%2F05%2F31%2FHAProxy%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容： HAProxy介绍 HAProxy简单搭建 HAProxy+Keepalived搭建 HAProxy介绍HAProxy是一个提供高可用性、负载均衡，以及可基于TCP（第四层）和HTTP（第七层）的应用代理软件。 HAProxy适合处理高负载Web站点的HTTP请求，这些站点通常需要会话保持或七层处理，HAProxy完全支持数以万计的并发连接，并且能使后端的Web服务器不会暴露。HAProxy还支持服务器健康检查，当后端服务器出现故障后，HAProxy会自动移除该服务器，在故障排除后自动将该服务器加入。 HAProxy特点： 支持连接拒绝：通过限制连接防御攻击蠕虫，降低被DDOS攻陷的可能 支持全透明代理 支持健康检查 实现会话保持 实现HTTP重写与重定向 自带服务器状态监控页面，实现监控统计 原生配置了SSL证书 支持虚拟主机 支持双机热备 支持服务器健康检查 单进程 支持RDP协议（远程桌面协议） HAProxy支持的代理模式： 基于四层的TCP代理：仅在客户端和服务器间进行流量转发。可用于邮件服务（SMTP、POP3等）、内部协议通信服务器、MySQL、https等 四层根据负载均衡算法直接修改报文的目的IP地址，然后发送给后端，相当于一个转发的功能。 基于七层的HTTP代理：能分析应用层协议，且能根据协议信息灵活控制访问。 七层是查看请求报文内容，根据内容选择后端服务器。不仅可以根据IP和端口进行负载分流，还能根据URL、域名、浏览器、语言等报文参数决定负载均衡策略。 在七层模式下，负载均衡器与客户端还有后端服务器会分别建立一次TCP连接，因此七层负载对设备的要求更高，而处理能力也不如四层负载。 HAProxy的frontend和backend功能： frontend：ACL规则匹配，根据任意HTTP请求头内容做规则匹配，然后将请求重定向到指定的backend backend：事先定义的server pool，等待前端将请求转到的服务器组 HAproxy实现性能最大化的做法： 单进程、事件驱动模型降低了上下文切换的开销和内存占用 O(1)事件检查器允许其在高并发连接中对任何连接的任何事件实现即时探测 在任何可用情况下，单缓冲（Single Buffering）机制能以不复制任何数据的方式完成读写操作，能够节约大量CPU时钟周期（CPU主频的倒数。周期小说明执行速度变快）及内存带宽。 MRU内存分配器在固定大小的内存池中可实现即时内存分配，能显著减少创建一个会话的时长。 借助内核的splice()系统调用，可实现零复制转发（Zero-copy forwarding），还可实现零复制启动（Zero-Starting）。 树型存储：实现了O(logN)的低开销保持计时器命令、保持运行队列命令、管理轮询和最少连接队列。 优化了HTTP首部分析，避免在分析过程中重读任何内存区域 降低了系统调用，大部分工作在用户空间中完成，如时间读取、缓冲聚合、问价描述符的启用和禁用等。 HAproxy进程消耗比系统空间消耗低20倍以上，在某些系统上，HAproxy的七层性能可能超过硬件负载均衡设备。 负载均衡器的性能评估要素 会话率：单位时间内的处理请求数。该指标决定了一个负载均衡器是否能将所有请求分发出去，依赖于CPU性能。 当关闭了 keep-alive 连接保持功能，session/s（每秒会话数）和 requests/s（每秒请求数）或者 hits/s（每秒命中数）是一样的。 当开启了 keep-alive 连接保持功能，requests/s 或者 hits/s 要高很多 会话并发能力：并发处理能力。当并发会话数上升时，session/s 会下降。该指标被系统允许的最大文件描述符数量以及内存大小限制。 数据率：处理数据能力。当传输大的对象时，会增加并发会话数，可获得更高的数据率，这时session的创建与销毁是最少的。使用MB/s或GB/s为单位 HAProxy与LVS的异同 LVS是基于Linux内核实现的一种负载，HAProxy是基于第三方应用实现的负载 LVS仅是四层IP负载均衡，HAProxy提供四层与七层负载，提供TCP和HTTP应用的负载 LVS的状态检测功能单一，HAProxy因为能在四层和七层负载，可支持端口、URL、脚本等多种状态检测方式 HAProxy的整体性能低于LVS，LVS拥有接近硬件设备的网络吞吐和连接负载能力 HAProxy负载均衡算法： roundrobin：与LVS的轮询一致。 static-rr：与LVS的wrr一致。 leastconn：与LVS的Least conn一致。 source：类似LVS的源地址散列source hashing。对源IP进行哈希。同一客户端IP访问同一台服务器 uri：类似LVS的目的地址散列destination hashing。对目的地址进行哈希，同一请求的URI总是访问同一个服务器 url_param：根据URL参数调度。将同一个用户信息都发往同一个后端服务器。 hdr(name)：根据HTTP请求头锁定每一次HTTP请求。若缺少头，则用rr代替 rdp-cookie(name)：查询每个TCP请求，并哈希RDP cookie，用于退化的持久模式，使同一个用户或会话ID总是发送到同一台服务器。若没有cookie，则使用rr代替。 HAProxy配置文件直接通过yum install haproxy安装（版本可能很老），版本为1.6。或者在haproxy下载源码包，版本会更加新。安装后会自动创建用户haproxy。可以通过systemctl管理。 源码包安装下载的是1.8.14版本的源码包。进入解压目录 123make PREFIX=/usr/local/haproxy1.8 TARGET=linux2628# 其中TARGET是指定Linux内核版本，一定要写，Linux2.6以及3.X都是写linux2628make install PREFIX=/usr/local/haproxy1.8 若使用源码安装，则不会自动创建haproxy用户及用户组，需要手动创建。并且没有任何配置文件，都要手动创建。有模板文件，在解压目录的example/目录中，叫option-http_proxy.cfg，在安装目录中创建一个conf目录，再将该配置文件复制过去。 HAProxy操作HAProxy命令： 12345678910111213141516171819202122232425haproxy -v 显示版本 -vv 显示详细的构建选项信息 -d 进入debug模式 -f 指定配置文件 -dM[&lt;byte&gt;] poisons memory with &lt;byte&gt; (defaults to 0x50) -D 后台运行; -C changes to &lt;dir&gt; before loading files. -q 静默模式 -c 检查配置文件语法 -n 设置最大连接数，默认2000 -m 限制可用的内存量，单位MB -N sets the default, per-proxy maximum # of connections (2000) -L 设置本地peer name，默认为主机名 -p writes pids of all children to this file -de 禁止使用epoll()函数 -dp 禁止使用poll()函数 -dS disables splice usage (broken on old kernels) -dR disables SO_REUSEPORT usage -dV 禁止服务器端的SSL -sf/-st [pid ]* finishes/terminates old pids.常用操作：选项不可连起来，只能分开haproxy -c -f /etc/haproxy/haproxy.cfg 检查配置文件，一定要-c -f都指定haproxy -D -f /etc/haproxy/haproxy.cfg 以daemon模式启动haproxy -vv 显示编译与启动信息killall haproxy 关闭HAProxy HAproxy配置文件HAProxy主配置文件/etc/haproxy/haproxy.cfg HAProxy的配置有五个部分：global，defaults，frontend，backend，listen global：设置全局配置参数，属于进程级的配置，和操作系统配置有关 defaults：默认参数的配置。默认会自动被引用到下面的 frontend、backend 和 listen 部分中。如果在 frontend、backend 和 listen 部分中也配置了与 defaults 部分一样的参数，那么 defaults 部分参数对应的值自动被覆盖。 frontend：设置接收用户请求的前端虚拟节点 backend：设置后端服务器集群的配置 listen：是 frontend 部分和 backend 部分的结合体。是为了兼容1.3版本以前的配置而保留下来的。可以不用。 全局global配置： 1234567891011121314151617global进程管理与安全性参数 log 127.0.0.1 local2 [level] #日志使用local2输出到本地，后面还可以添加日志等级 chroot /var/lib/haproxy #改变haproxy的工作目录 pidfile /var/run/haproxy.pid #指定PID文件路径 user haproxy #执行HAProxy进程的用户 group haproxy #执行HAProxy进程的用户组 daemon #后台执行 stats socket /var/lib/haproxy/stats #用户访问统计数据的接口 stats maxconn 10 #默认stats socket仅限10个并发连接 nbproc 1 #启动的haproxy进程的个数，只能用于守护进程模式性能调整参数 maxconn 4000 #最大连接数 spread-checks #设置HealthCheck时间间隔 noepoll #禁用使用epoll事件轮询系统 nopoll #禁用poll事件轮询系统 nosplice #禁用套接字之间使用内核tcp拼接 为了配置文件中的日志参数，创建独立的日志文件，需要修改/etc/rsyslog.conf，添加以下参数，然后重启rsyslog服务 1local2.* /var/log/haproxy.log 注：HAProxy要求ulimit -n的值（即最大打开文件数）要大于maxconn * 2 + 18。 默认defaults配置： 12345678910111213141516171819defaults mode http # 默认模式，tcp为4层，http为7层，health只返回ok option httplog # 采用http日志格式 option httpclose # 防止多余的cookie信息影响到客户端请求的处理结果 retries 3 # 尝试连接的次数，若连接失败则认为服务器不可用 option http_proxy # 开启代理（仅是基本的代理功能） option dontlognull # 不记录空连接 option http-server-close # 开启connection closing option forwardfor except 127.0.0.0/8 # 服务器能获取客户端的真实IP地址 option redispatch # 当客户端将请求发往了故障的服务器，则会自动将请求发往其他正常的机器 # option abortonclose # 当服务器负载很高的时候，自动结束掉当前队列处理比较久的链接 # 时间单位可以是us（微秒）|ms（毫秒）|s（秒）|m（分）|h（时）|d（天） timeout http-request 10s # http请求超时时间 timeout queue 1m # 队列超时时间 timeout connect 10s # 连接超时时间 timeout client 1m # 客户端响应超时时间 timeout server 1m # 服务器端响应超时时间 timeout http-keep-alive 10s # keepalive持久连接超时时间 timeout check 10s # 检查时间间隔 前端服务frontend配置： 12345678frontend main *:5000 # 在1.8版本中不能这么写，而是用bind # 设置acl规则 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js use_backend static if url_static # 调用后端服务器并检查是否匹配acl规则 default_backend app # 客户端访问时默认调用后端服务器地址池，与backend关联 stats uri /stats # 开启HAProxy的状态查看网页，通过/stats查看 后端服务backend配置： 12345678backend static # 定义后端服务器，static是配置存放静态资源的后端服务器 balance roundrobin # 算法 server static 127.0.0.1:4331 check # 对后端进行健康检查backend app # 运行应用的动态服务器 balance roundrobin server app1 127.0.0.1:5001 check server app2 127.0.0.1:5002 check 例： 123456789backend static balance roundrobin server static 172.16.246.135:80 check server static 172.16.246.136:80 checkbackend app balance roundrobin server tomcat1 172.16.246.151:8080 check server tomcat2 172.16.246.136:8080 check 访问HAproxy服务器的5000端口，就能访问后端服务器 web查看状态可以配置专门的frontend设置haproxy自带的stats，监控haproxy状态。 1234567frontend stats bind *:8080 stats enable # 开启stats stats refresh 3s # 刷新间隔 stats uri /stats # 访问uri stats auth admin:redhat # 认证用户密码 stats admin if TRUE # 开启认证 ACL配置ACL操作通常包括阻止请求，选择后端或添加报文头。 从数据流，表或环境中提取数据样本 可选地对提取的样本进行一些格式转换 在此样本上应用一个或多个模式匹配方法 仅在模式与样本匹配时执行操作 ACL的数量没有强制限制。 未使用的不会影响性能，只消耗少量内存。 acl格式： 1acl acl名 acl方法（也称测试标准） [flags] 匹配路径或文件 常用acl方法： hdr_reg(host)：正则匹配 12# 匹配URL是www.exam.com和www1.exam.com的请求acl www hdr_reg(host) -i ^(www.exam.com|www1.exam.com) hdr_dom(host)： hdr_beg(host)：测试请求报文的指定首部的开头部分是否符合指定的模式 12# 匹配提供静态请求的主机img\video\ftpacl host_static hdr_beg(host) -i img. video. ftp. url_sub： url_dir： path_beg：测试请求的URL是否以后面指定的模式开头 1acl url_static path_beg -i /static #匹配url以/static开头 path_end：测试请求的URL是否以后面指定的模式结尾 1acl url_static path_end -i .jpg .js #匹配url以.jpg或.js结尾 1234567891011121314frontend main bind *:5000 acl host_1 hdr_dom(name) -i host1.example.com acl host_2 hdr_dom(name) -i host2.example.com use_backend host1 if host_1 use_backend host2 if host_2backend host1 balance roundrobin server host1 192.168.60.130:80 check backend host2 balance roundrobin server host2 192.168.60.131:80 check 然后通过host1.example.com可访问host1的后端主机池，host2.example.com访问host2的后端主机池。 HAProxy+Keepalived搭建安装keepalived，可以直接yum安装，也可以源码安装。源码安装版本2.0.10。 1234./configure --prefix=/usr/local/keepalived \ --bindir=/usr/bin \ --sbindir=/usr/sbin \ --sysconfdir=/etc 然后直接make &amp;&amp; make install即可。 修改配置/etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# Master配置global_defs &#123; # 可以不用改 notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.60.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0&#125;vrrp_instance VI_1 &#123; state MASTER # master这边要改 interface ens32 # 改为面向集群的网卡（内网网卡） virtual_router_id 51 priority 120 # master的优先级一定要比backup高 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.60.200 # VIP &#125;&#125;# backup配置vrrp_instance VI_1 &#123; state BACKUP #backup这里要改 interface ens32 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.60.200 &#125;&#125; 修改完后直接systemctl restart keepalived，查看Master的网卡 12345672: ens32: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:38:e9:f3 brd ff:ff:ff:ff:ff:ff inet 192.168.60.134/24 brd 192.168.60.255 scope global noprefixroute ens32 valid_lft forever preferred_lft forever inet 192.168.60.200/32 scope global ens32 #VIP在Master这，Backup上是没有该VIP的 valid_lft forever preferred_lft forever.... 关闭Master，再查看Backup，发现VIP已转移到此主机上，且已变为Master。 参考文章 HAProxy用法详解 全网最详细中文文档 HAproxy负载均衡-特性篇 转 笔记 1. HAProxy 介绍 http反向代理之haproxy详解 Haproxy的负载均衡、动静分离、状态监控、近期网络架构 CentOS7 haproxy+keepalived实现高可用集群搭建 Haproxy原理(1) HAProxy从零开始到掌握 HAProxy 骏马金龙 Linux集群与自动化运维]]></content>
      <tags>
        <tag>server</tag>
        <tag>HAproxy</tag>
        <tag>代理</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Varnish笔记]]></title>
    <url>%2F2018%2F05%2F31%2FVarnish%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Varnish概述 Varnish基本配置 Varnish概述Varnish是一款高性能、开源的反向代理服务器和缓存服务器。并且，Varnish还能提供以下功能： web应用防火墙 DDoS防护 网站防盗链 负载均衡 单点登录（SSO）网关 认证与授权 后端主机快速修复 HTTP路由 Varnish缓存策略的实现是通过VCL（Varnish Configuration Language）实现，VCL的语法简单，继承了C语言的很多特性，使得VCL样式看起来很像C和PELR语言，运行Varnish时，此配置将转换为C代码，然后送入C编译器，加载并执行。 Squid与Varnish对比 软件 存储模式 共享存储 性能 Squid 硬盘 可并联，但很复杂 较高 Varnish 硬盘/内存 不能 很高 Varnish对比Squid的优点： Varnish稳定性比Squid高，Squid发生故障的几率要高于Varnish Varnish访问速度比Squid快，因为Varnish采用了Visual Page Cache，所有缓存之久从内存中读取，而Squid从硬盘读取，所以Varnish会更快。 Varnish支持更高的并发连接，因为Varnish的TCP连接释放要比Squid快。 Varnish可以通过管理端口，使用正则表达式批量清除缓存。 Varnish可通过fork进行多进程处理，而Squid仅是单进程。 Varnish对比Squid的缺点： 一旦Varnish宕机或重启，缓存数据会在内存中丢失，所有请求就又给了后端服务器，造成后端的压力。 Varnish在高并发下，CPU、I/O和内存资源开销会高于Squid。 Varnish基本配置最好直接从官网下载，不要通过epel库下载，因为epel库中的varnish版本过老。或者从varnish官方提供的repo中下载。官方repo配置（貌似已不可用）。或者下载源码编译安装。 编译安装可能需要的依赖python-docutils、libedit-devel 进入解压目录，直接./configure --prefix=/usr/local/varnish6编译之后make &amp;&amp; make install即可。 Varnish提供以下工具： varnishd：是Varnish的核心进程，以守护进程方式运行，接收http请求并转发到后端，进行缓存并响应客户端。存放在安装目录的sbin中 varnishtest：Varnish测试工具，可验证Varnish安装、可自定义client请求模型、可与Varnish交互 varnishadm：Varnish实例命令行管理工具 varnishstat：可访问全局计算器，提供全面统计信息。 varnishlog：显示Varnish日志，显示的是实时日志，最好设置好过滤规则，支持精确日志匹配 varnishncsa、varnishtop、varnishhist是Varnish的性能及状态分析工具 varnishhist：读取varnish日志，生成连续的柱状图，若缓存命中则标记|，若没命中则标记# 1234515_ | | | | #+--------------+--------------+--------------+--------------+----|1e-6 |1e-5 |1e-4 |1e-3 |1e-2 varnishtop：读取日志，显示实时日志信息，类似varnishlog，支持过滤 varnishncsa：实时显示请求日志信息 安装目录中是没有配置文件的，需要将解压目录中etc/example.vcl复制到安装目录中，并改名为default.vcl。 修改配置文件 1234backend default &#123; # 默认的后端服务器配置，默认为本机 .host = &quot;172.16.246.135&quot;; # 后端服务器IP .port = &quot;80&quot;; # 本地的代理端口。当要从后端取数据时，就会访问本地的该指定端口&#125; 然后开启varnish。varnishd -f /var/local/varnish6/default.vcl，通过-f指定配置文件，而且配置文件的路径一定要是绝对路径，否则会提示没有该文件。确保该指定端口在本地没有被占用。 启动成功后，可以看到默认varnish启动了两个进程 123# ps -ef | grep varnishroot 62560 1 0 02:23 ? 00:00:00 sbin/varnishd -f /usr/local/varnish6/default.vclroot 62571 62560 0 02:23 ? 00:00:00 sbin/varnishd -f /usr/local/varnish6/default.vcl 通过浏览器访问Varnish服务器，使用开发者工具可看到响应头中的消息显示是Varnish返回的。 可以通过backend块定义多个后端服务器。 12345backend host2 &#123; .host=&quot;172.16.246.136&quot;; .port=&quot;81&quot;; .connect_timeout=3s;&#125; 参考文章 Varnish从菜鸟到专家（一） 高性能网站构建实战]]></content>
      <tags>
        <tag>代理</tag>
        <tag>缓存</tag>
        <tag>varnish</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Squid笔记-1]]></title>
    <url>%2F2018%2F05%2F31%2FSquid%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Squid介绍 代理服务器概念 Squid安装 Squid常规配置 Squid访问控制 Squid多级代理配置 Squid实验 cachemgr.cgi管理Squid Squid日志 Squid调优 Squid介绍Squid是一个支持HTTP、HTTPS、FTP等服务的Web缓存软件，可通过缓存页面实现降低带宽占用并优化页面相应时间。 Squid特点与功能： 不仅能缓存Web页面资源，还能对DNS查询结果进行缓存 强大的访问控制功能 保护内网，并加速内网对外网的连接 记录内网用户访问外网行为 提供用户认证 减少出口流量 工作在TCP/IP的应用层，TCP端口3128 Squid支持的网络协议：HTTP、FTP、Gopher（信息查找协议）、WAIS（广域信息查询系统）、SSL Squid支持的内部缓存和管理协议：HTTP、ICP（互联网缓存协议，用于从缓存中查找指定对象）、Cache Digests（用于生成缓存中对象的索引）、SNMP（用于为外部工具提供缓存信息）、HTCP（用于发现HTTP缓存区，存储管理HTTP数据） Squid请求过程： 客户端访问Squid服务器，由代理服务器代表客户端向web服务器（后端Real Server）请求资源 Web服务器将相应数据返回给代理服务器 代理服务器将数据返回给客户端，并保留一份在本地 其他客户端向该代理服务器请求相同的资源 代理服务器直接将本地的该资源缓存返回给客户端 squid的硬件环境：内存与磁盘是缓存性能的重要体现。所有对象都会尽可能缓存到内存中，更大的磁盘空间实现更多的缓存目标和更高的命中率，最好使用SAS，尽量不用SATA。磁盘与内存间也有关联，最好每G的磁盘空间有32M的内存对应。 代理服务器概念代理服务器一般构建于内网和Internet间，负责转发内网对Internet的访问，并进行访问控制与记录，可实现安全保护、缓存数据、内容过滤、访问控制等功能。 Web代理维护着庞大的缓存数据，因此对内存和硬盘的要求很高，更大的内存和硬盘意味着更多的缓存和更高的缓存命中率。 Web缓存类型： 客户端缓存：一般就存放在浏览器中。有两个缺点：1.缓存容量小，不能存储大的Web对象，因此命中率较低。2.缓存在本地，不能共享，因此存在大量重复数据。 代理服务器缓存：位于网络中间位置。容量大，缓存能与内网所有客户端共享。但若性能达不到要求，反而会造成网络瓶颈。代理缓存应具有健壮性、可扩展性、稳定性、负载均衡的特点 服务器缓存：是为了减轻web服务器的负载，并不是为了提高资源命中率。服务器缓存减少了web服务器的流量、并保护了web服务器的安全，因为web服务器仅向服务器缓存提供数据，并不直接面向客户机。并且提高了网站的可靠性，因为各个服务器缓存间可实现共享。 三种典型代理方式： 传统代理：在浏览器中设置，指出代理服务器的IP地址和网络端口。便于用户对访问管理控制，配置简单。 透明代理（正向代理）：为内网提供外网的访问，即普通的代理服务器。但增加了网络设备的负担，并需要做好更详细的配置，会有一定的延时。若程序的一系列请求是相关的并涉及多个目标对象，有可能会出问题。 反向代理：能代理外部网络访问内网服务器。主要为本地网站做缓存，加快web服务器的响应速度。相当于服务器缓存。反向代理结合智能DNS即可实现基本的CDN Squid安装Squid版本：3.5 可直接通过yum install squid安装。然后systemctl start squid启动。 安装时会自动创建用户squid，并且是系统用户，家目录为/var/spool/squid，且禁止登录。 注：一定要做到squid服务器的时间同步，否则无法进行缓存 Squid的相关配置文件： /etc/httpd/conf.d/squid.conf：用于在Apache中添加运行cachemgr.cgi的配置 /etc/logrotate.d/squid：Squid的日志轮替配置 /etc/squid/squid.conf：Squid主配置文件 /etc/squid/cachemgr.conf：设置可通过cachemgr.cgi管理的主机 /etc/squid/mime.conf：定义MIME类型的文件 Squid其他相关文件： /var/log/squid/：存放squid日志的目录 /var/spool/squid/：存放squid缓存的目录 /usr/share/squid/errors/：存放给客户端的报错信息HTML，目录中包含各个语言的子目录 /usr/lib64/squid/cachemgr.cgi：squid cache manager，用于管理主机的动态网页 squid提供两个命令： squid：用于管理squid守护进程 squidclinet：用于管理squid客户端 1234567891011121314151617181920212223squid [options] -a port 指定HTTP端口，默认3128 -d level 将指定调试等级的信息发送到标准错误输出 -f file 指定配置文件启动 -k 向squid服务器发送指令 reconfigure 重载配置文件 rotate 轮替日志文件 shutdown 安全关闭 restart 重启服务 interrupt 中断服务 kill 杀死服务 debug 开启debug check 检查运行状态 parse 检查配置文件 -s 启用syslog -u port 指定ICP端口，默认3130，若要关闭，就指定0 -z 创建缓存目录，即初始化缓存 -C 不捕获fatal信号 -D 不进行DNS参数测试 -F 不响应任何请求直到存储重建 -N 不使用daemon模式 -S 在重建期间仔细检查swap分区 -X 强制进入完全调试模式 123456789101112131415161718192021222324252627squidclient [Basic Options] [HTTP Options] -s | --quiet 静默模式，不打印输出 -v | --verbose 显示详细信息，最多-vv -v：显示向外发的请求信息 -vv：显示动作跟踪信息 -h | --host host 指定将信息发给的主机，默认为localhost -l | --local host 指定绑定的本地IP地址，默认为空 -p | --port port 指定服务端口，默认3128 -T timeout 指定读写操作的超时时间 --ping [options] 允许ping模式 -g count 指定ping包的个数，默认一直ping -I interval 指定ping包发送间隔，默认1sHTTP Options: -a 不包含“accept:header” -j hosthdr Host header content -k 保持长连接，默认只接收一个请求就关闭连接 -m method 指定请求方法，默认GET -n 代理协商认证（kerberos） -N www协商认证（kerberos） -P file 将指定文件作为请求载荷 -r 强制缓存重新加载URL -t count 跟踪计数缓存跳数 -u user 代理认证用户名 -U user www认证用户名 -w password 代理认证密码 -W password www认证密码 Squid常规配置12345678910111213141516171819202122232425262728293031323334353637383940414243http_port 3128 [模式] [options] #Squid监听的端口# 若要添加多个端口，用空格隔开 常用模式： accel：加速或反向代理模式 intercept：支持IP层NAT拦截传输到该Squid端口的流量 从squid3开始就没有transparent透明模式了icp_port 3130 #ICP端口# ICP是专门运行在代理服务器间交换缓存数据的协议。ICP使用UDP端口3130cache_effective_user squid #运行squid进程的用户#squid进程是root启动的，但启动后会由指定的普通用户继续运行cache_effective_group squid #运行squid进程的用户组pid_filename /var/run/squid.pid #squid的PID文件位置# 此文件由root在启动squid时创建logformat squid %ts.%03tu %6tr %&gt;a %Ss/%03&gt;Hs %&lt;st %rm %ru %un %Sh/%&lt;A %mt #指定日志记录格式access_log /var/log/squid/access.log squid #日志路径，类型为squidcache_mem 8 MB #cache内存#设定squid能用多少额外的内存来缓存对象的限制值cache_dir ufs /var/spool/squid 100 16 256 #指定缓存类型为ufs，保存在/var/spool/squid，是默认值#大小限制为100MB，第1层子目录为16个，第2层子目录为256个cache_store_log /var/log/squid/store.log #数据缓存的日志，是默认值maximum_object_size_in_memory 8 KB #squid保存在内存中的对象最大为8KB#内存中的对象访问速度最快，但内存有限，需要根据内存大小设置maximum_object_size 4096 KB #最大的缓存对象的字节数4096KB#只有小于该值的对象才会被缓存，若硬盘足够大，可适度提高cache_swap_low 90 #设置Squid缓存空间的使用策略。cache_swap_high 95 #当缓存中数据占到整个缓存大小的95%时 #就会按算法删除缓存中的数据 #直到缓存数据占到整个缓存大小的90% #可以最大限度利用缓存空间，但也不会出现空间溢出coredump_dir /var/spool/squid #放置squid进程运行时coredump文件的目录cache_mgr root #Squid管理员用户的Emailvisible_hostname proxy.example.com #设置对外可见的主机名，会在错误信息中显示 logformat日志格式设置 Squid会设置在缓存目录下建立多个目录，每个目录又建立多个子目录，在最里层的目录存放缓存文件，缓存文件是通过对客户端请求的URL进行哈希运算生成的。Squid会在内存建立一张哈希表，记录硬盘中缓存文件配置的情形。 使用squid -k parse检查配置文件语法，确认没有报错后squid -z初始化缓存目录，会显示Making directories in /var/spool/squid/00等信息，发现，第一层的目录数量是16，第二层目录的数量是256，目录名都是由十六进制标号，与配置文件cache_dir配置的一致。若无法创建，可能是该目录的权限问题。 再使用squid -N -d1测试，没有报错，则说明启动完成。 通过浏览器测试，设置代理服务器 Squid访问控制123acl name type value1 value2... #设置ACL名字和对象的值http_access &lt;allow|deny&gt; [!]ACL对象1 ... #将客户端请求与http_access的对象匹配，指定allow或deny。!为取反。#若一个请求与所有http_access都不匹配，则执行与最后一条http_access指定的动作相反的动作 常见的ACL类型： 类型 含义 src 源IP地址，可以单个IP地址，可以是地址范围 dst 目的IP地址，同上 myip 本地网络接口IP地址 srcdomain 客户所属的域，Squid会根据客户IP地址进行反向DNS查询 dstdomain 服务器所属的域，与客户请求的URL匹配 time 时间段 port 指向其他计算机的网络端口，即是目标服务器上的端口 myport 指向squid服务器的端口，是squid服务器上的端口 proto 客户端请求所使用的协议，如http、https、ftp、gopher method HTTP请求方法 proxy_auth squid认证的用户名 url_regex 关于URL的正则表达式（域名） urlpath_regex 关于URL资源的正则表达式（资源路径，不带有域名） ident 指定用户 acl对象的值间的关系为”或“，只要满足一个就匹配了该acl规则。而http_access与其他规则的设置使用”与“逻辑。squid默认配置拒绝每个请求，因此在使用代理前，必须先添加访问控制规则。 若value为文件名，对象的值实际上是文件的内容。 常见案例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354Squid3已默认定义acl名：all、localhost、manager、to_localhost acl all src 0.0.0.0/0 acl localhost src 127.0.0.1/32 acl manager proto cache_object #cache_object是squid自定义的协议，用于访问squid的缓存管理接口 acl to_localhost dst 127.0.0.1/8因此以上四个acl名字不能再使用，且可以直接调用，无需再定义acl worktime time MTWHF 08:00-17:00 #时间从周一到周五，早上8点到下午5点 S-Sun M-Mon T-Tue W-Wed H-Thu F-Fri A-Satacl mynet src 10.1.1.1/24#源10.1.1.1/24的子网命名为mynetacl aim dstdomain .baidu.com .google.com#匹配指定目的域名acl giffile url_regex -i \.gif$#匹配以.gif结尾的URLacl other srcdomain &quot;/etc/squid/other&quot;#匹配文件中指定的源域名acl safe_port port 80#匹配指定的目标服务器端口acl Users ident tomhttp_access allow tom#只允许tom访问acl mynet src 10.1.1.1-10.1.1.10http_access allow mynethttp_access deny all#仅允许mynet子网访问acl user1 src 10.1.1.1acl user2 src 10.1.1.2acl user1_time time MTWHT 08:00-12:00acl user2_time time MTWHT 08:00-13:00http_access allow user1 user1_timehttp_access allow user2 user2_time#给两个用户分别指定上外网的时间acl ftpmp3 url_regex -i &quot;^ftp://.*\.mp3$&quot;http_access deny ftpmp3#禁止从任何ftp上下载mp3文件acl cgi urlpath_regex -i &quot;^/cgi-bin&quot;http_access deny cgi#禁止访问cgi网页acl limit maxconn 16http_access deny limit#限制同一IP客户端的最大连接数 squid默认acl配置： 12345678910111213141516171819202122232425262728#所有内网acl localnet src 10.0.0.0/8 acl localnet src 172.16.0.0/12 acl localnet src 192.168.0.0/16 acl localnet src fc00::/7 acl localnet src fe80::/10 acl SSL_ports port 443 #SSL443端口acl Safe_ports port 80 # 放行httpacl Safe_ports port 21 # 放行ftpacl Safe_ports port 443 # 放行https..... #放行的其他服务acl CONNECT method CONNECT #connect方法，是HTTP中用于代理的方法http_access deny !Safe_ports ##只允许本机转发客户机对非Safe_ports的请求http_access deny CONNECT !SSL_ports #拒绝所有非SSL_ports的CONNECT请求，只允许本机用connect连接非SSL_portshttp_access allow localhost manager #允许localhost使用cache_object协议http_access deny manager #拒绝所有其他网络使用cache_objecthttp_access allow localnet #允许内网访问http_access allow localhost #允许本地访问http_access deny all #剩下的都不允许http_port 3128 coredump_dir /var/spool/squid refresh_pattern ^ftp: 1440 20% 10080refresh_pattern ^gopher: 1440 0% 1440refresh_pattern -i (/cgi-bin/|\?) 0 0% 0refresh_pattern . 0 20% 4320 Squid多级代理配置在大型网络中一台Squid服务器的性能不能应对巨大的访问量，需要构建多级代理服务器，类似与计算机集群，使用ICP交换缓存，形成一个逻辑上的大型Squid服务器。 代理服务器间的结构可分为：同级结构、层次结构、网状结构。最常见是层次结构。 需要配置参数cache_peer hostname type http_port icp_port options hostname为另一台Squid服务器的域名或IP地址 type为ICP请求的类型：parent或sibling http_port为对端的Squid监听请求端口 icp_port为对端ICP的端口 ICP的两种请求类型type： parent：会把客户端的请求发送给对方，对方的缓存中若有请求的数据，则返回，若没有，则对方向web服务器读取数据，再返回。（类似DNS的递归查询）一般对象处于上一级时使用此类型，因为上一级会更加接近于web服务器。 sibling：不会把客户端请求发给对方，仅仅询问有没有缓存。如果没有，则对方仅仅告诉回复没有，并不会向web服务器请求数据。一般对象处于同等级别时用此类型。de 常见的options参数： 选项 含义 proxy-only 从对方得到的数据不做缓存，默认会做 weight=n 指定对方的权重，有多个cache_peer时会按权重选择，默认根据网络响应时间自动选择 no-query 不向对方发送ICP请求，只发送HTTP代理请求，一般用于对方不支持ICP或不可用的情况 default 与no-query一起用，当对方都不支持ICP时，就用该peer no-digest 不使用内存摘要表查询，直接ICP通信 login=user:password 若对方需要认证，就提供用户名和密码 示例： 12cache_peer system3.example.com parent 3128 3130 proxy-only defaultcache_peer system4.example.com sibling 3128 3130 proxy-only 若要通过规则选择不同的上级代理服务器，达到负载均衡，还需要配置： cache_peer_domain cache-host domain ... cache_peer_access cache-host allow|deny [!]ACL对象... 示例： 12345cache_peer system1.example.com parent 3128 3130cache_peer system2.example.com sibling 3128 3130 proxy-onlycache_peer_domain system1.example.com examplecache_peer_domain system2.example.com !example#system1为example域的代理服务器，system2为非example域的代理服务器 Squid实验透明二级代理环境： client1：192.168.1.128 server1：192.168.1.129 server2：192.168.1.130,192.168.205.140 web1：192.168.205.139 server1 上的配置squid.conf添加或修改以下内容： 12345678910111213141516171819202122http_port 3128 accel #配置为透明代理icp_port 3130cache_effective_user squidpid_filename /var/run/squid.pidlogformat squid %ts.%03tu %6tr %&gt;a %Ss/%03&gt;Hs %&lt;st %rm %ru %un %Sh/%&lt;A %mtaccess_log /var/log/squid/access.log squidcache_dir ufs /var/spool/squid 100 16 256cache_store_log /var/log/squid/store.loghosts_file /etc/hosts #用于解析IP地址visible_hostname system1.example.com #错误信息中显示的主机名cache_effective_user squid #若不设置user和group，会默认使用nobodycache_effective_group squidacl PURGE method PURGE #purge是squid自定义的方法，用于删除squid缓存中的对象（能让管理员强制删除） #squid是默认拒绝Purge请求的http_access allow localhost manager #只允许本机使用cache_object协议http_access allow localhost PURGE #只允许本机使用purge方法http_access deny manager PURGEicp_access allow all #允许所有客户机访问ICP端口http_reply_access allow all #允许对所有客户机进行请求的回复 并且需要进行端口转发，即重定向，因为代理服务器需要将客户端发往80端口的数据包改为发往自己的3128端口，实现代理。因此需要开启防火墙firewalld或iptables服务。 若是使用firewalld，则先要确定是否开启了伪装IP功能（Masquerade） firewall-cmd --query-masquerade，若为no，则需要开启firewall-cmd --add-masquerade --permanent。 设置端口转发：firewall-cmd --add-forward-port=port=80:proto=tcp:toport=3128 --permanent 若为iptables，则添加两条规则： 123iptables -t nat -A PREROUTING -i ens33 -p tcp --dport 80 -j --REDIRECT --to-ports=3128iptables -t nat -A POSTROUTING -o ens36 -s 192.168.205.0/24 MASQUERADE# ens33为内网卡，ens36为外网卡 然后打开转发，无论是firewalld还是iptables，都要打开。 12echo &quot;net.ipv4.ip_forward=1&quot; &gt;&gt; /etc/sysctl.conf sysctl -p 最后放行80和443端口，放行http和https服务 12firewall-cmd --permanent --add-port=80/tcp --add-port=443/tcpfirewall-cmd --permanent --add-service=http --add-service=https 反向二级代理cachemgr.cgi管理Squid通过web界面管理Squid，需要cachemgr.cgi动态网页文件，存放在/usr/lib64/squid/中。可以将该cgi文件复制到/var/www/cgi-bin中，也可不动，但要注意文件的权限问题，一定要改为apache。然后在httpd的主配置文件中添加，Location配置 12345ScriptAlias &quot;/squidcgi&quot; &quot;/var/www/cgi-bin/cachemgr.cgi&quot;&lt;Location &quot;/squidcgi&quot;&gt; Order deny,allow #逗号后不能有空格 Allow from all&lt;/Location&gt; 然后浏览器通过主机IP/squidcgi访问。 默认不需要填用户名密码即可登录。若要设置登录用户名密码，只需要在主配置文件中添加cachemgr_password参数。 1234cachemgr 密码 行为action要禁用一个操作，就把密码设为disable，后面跟上要禁止的操作要允许不输入密码的操作，就把密码设为none，后面跟上允许的操作action为all表示为所有操作设置相同密码 Squid日志Squid日志不仅记录服务器进程的运行，还记录用户的访问情况、缓存存储状况、缓存访问状况等。 Squid三个日志：access.log，cache.log，store.log 和日志文件相关的配置： cache_log /var/log/squid/cache.log：指定缓存信息日志的路径。包含了缓存的起始配置信息，分类的错误信息，性能警告。 cache_store_log /var/log/squid/store.log：指定对象存储记录日志的路径。包含被写入缓存空间的对象、被从缓存空间清除的对象等。可设为none禁止 cache_swap_log /var/spool/squid/cache_swap.log：指定每个交换日志的路径。包含存储在交换空间的对象元数据。这类日志最好不要删除，否则可能会导致Squid故障。 debug_options ALL,1：控制日志记录内容的多少，第一个参数决定对哪些行为做记录，ALL表示对所有行为做记录，第二个参数表示详细程度，1表示详细程度最低。 log_fqdn：控制access.log日志中客户机地址的记录方式。on表示会记录客户机的域名，off则记录IP地址。开启会增加系统负担 logformat squid %ts.%03tu %6tr %&gt;a %Ss/%03Hs %&lt;st %rm %ru %un %Sh/%&lt;A %mt是在配置文件中日志格式的参数配置。 %ts.03tu：记录请求完成时间。%ts为相对于Unix纪元（1970-1-1）的秒数，%03tu表示3个宽度的毫秒数，.为写入日志的固定符号。 %6tr：响应时间，表明了Squid处理请求的时间（接收到HTTP请求到响应报文发出），单位毫秒。ICP响应时间一般为0，非常快速。 %&gt;a：记录客户端地址，若开启了log_fqdn，则会记录客户端主机名。还可通过client_netmask隐藏客户端IP的一部分 %Ss/%03Hs：记录请求结果和状态码，%Ss是Squid特有的请求结果码，%03Hs是HTTP状态码 %&lt;st：记录传输的字节数。是整个数据包的大小，会比实际载荷信息大。 %rm：记录请求的方法。HTTP的常见请求和ICP的ICP_QUERY请求 %ru：记录客户端请求的URI。默认不会记录URL中第一个?后所有信息 %un：记录客户端用户身份。Squid使用RFC1413或HTTP的验证头部确认用户身份 %Sh/%&lt;A：记录peer主机（其他代理服务器）信息 %mt：记录MIME类型。从响应的Content-type域获取信息，若没有就使用一个-代替。 logfile_rotate：轮询保存的文件数，超过限制就会从头开始覆盖 日志轮询Squid并没有自动轮询的机制，只能使用squid -k rotate命令，并编写脚本通过cron周期执行。 1234#!/bin/bash cd /var/log/squid/[ -f access.log ] &amp;&amp; mv access.log access_$(date +%F).logsquid -k rotate Sarg工具分析日志Sarg是一个Squid的日志分析工具，输出为html文件。Sarg下载-tar.gz包 依赖gd库，pcre库。在sarg安装完成后，进入安装目录的bin目录，执行sarg命令，sarg会自动寻找Squid的日志文件，并分析。SARG: Records in file: 595935, reading: 100.00%，然后会生成一个目录，是自动存放在/var/www/html/squid-reports下，目录名为起始日期-结束日期，该目录下有index.html 通过浏览器访问该index文件，数据量相当庞大，并提供图表和日期时间的数据记录 sarg命令： 123456789101112131415sarg [options] --convert 将access.log文件转换为易读的日期格式 -d DATE 指定报告的日志范围dd/mm/yyyy-dd/mm/yyyy -e MAIL 将报告发送给指定email -f FILE 指定配置文件，默认为安装目录的etc/sarg.conf --keeplogs 保留以前生成的每个报告 -l FILE 指定日志文件 -n 使用rDNS将IP地址解析成域名 -o DIR 报告存放目录 -p 使用IP地址而不是userid --split 按-d指定的日期切割日志文件 -t TIME 指定时间范围[HH:MM 或 HH:MM-HH:MM] -u USER 只报告指定用户的行为 -x 开始分析，且会先输出完整的配置信息 -z 显示完整的输出信息 Sarg配置，存放在安装目录的etc/sarg.conf 1234access_log /usr/local/squid/var/logs/access.log #squid日志路径output_dir /var/www/html/squid-reports #报告输出目录date_format u #日期格式，u为美国格式mm/dd/yy，e为欧洲格式dd/mm/yyoverwrite_report no #是否对已存在的日期的报告覆盖 Squid调优调整文件描述符Squid在高负载下，需要大量内核资源，又因为Squid是做缓存服务器，所以极度消耗文件描述符，而unix对文件描述符是有限制的（1024），这样会造成极大的性能影响，当squid用完所有文件描述符后，就不能接收新的请求了，并且squid发现文件描述符短缺后，就会发布警告。 因此，需要先查看文件描述符是否满足使用，大多数情况1024已经足够使用，当出现高负载情况时，则需要更多，因此最好将系统限制的文件描述符数量设为每个进程限制的两倍。 123456ulimit -a 查看当前的资源限制信息找到open files，就是同时能打开的文件数量，即文件描述符，默认为1024优化性能，将此值设为2048ulimit -Hn 2048 # -H 设定资源的硬性限制，也就是管理员所设下的限制# -n 设置同时最多能打开的文件数 注：ulimit仅仅作为临时设置，可以作用于通过使用其命令登录的 shell 会话，在会话终止时便结束限制，并不影响于其他 shell 会话。 若要永久设置，可写入/etc/profile：echo &quot;ulimit -Hn 2048&quot;&gt;&gt;/etc/profile 或写入/etc/security/limits.conf：echo &quot;* - nofile 2048&quot;&gt;&gt;/etc/security/limits.conf 调整临时端口范围临时端口是TCP/IP栈分配出连接的本地端口，当squid发起一条连接到另一台服务器，内核给本地socket分配一个端口号。CentOS默认的临时端口范围是32768到60999 当squid高负载时，若临时端口号短缺，会造成很大的性能影响，因为一些TCP连接在关闭时会进入TIME_WAIT状态，此状态下临时端口不能重用。 可通过sysctl -a | grep net.ipv4.ip_local_port_range查看 设置范围4000到65000，sysctl -w net.ipv4.ip_local_port_range=&quot;4000 65000&quot; 参考文章 Linux服务器架设指南（第二版） Linux系统管理与网络管理（第二版） Linux运维之道（第二版） 高性能网站构建实战]]></content>
      <tags>
        <tag>server</tag>
        <tag>代理</tag>
        <tag>缓存</tag>
        <tag>squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nagios监控搭建-1]]></title>
    <url>%2F2018%2F05%2F31%2FNagios%E7%9B%91%E6%8E%A7%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容 Nagios概述 Nagios搭建 服务器端 客户端安装 目录与配置文件概述 Nagios监控界面解析 Nagios性能分析图表 邮件告警配置 基于Nagios4.4.1，Nagios-Plugin2.2.1 Nagios概述Nagios是一款用于监控系统和网络的开源应用软件，能有效的监控windows，linux和unix的主机状态。采用C/S结构。Nagios由ANSI C编写。 Nagios结构分为Nagios Core核心主程序和Nagios Plugins插件。核心只提供很少的监控功能，用户需要给Nagios安装相应插件以搭建完善的监控系统。 Nagios如何工作 监控：监控关键IT基础架构组件，包括系统指标，网络协议，应用程序，服务，服务器和网络基础架构。 告警：在关键基础架构组件发生故障和恢复时发送警报，为管理员提供重要事件的通知。警报可以通过电子邮件，短信或自定义脚本提供。 响应：IT人员可以确认警报并开始解决中断并立即调查安全警报。如果未及时确认警报，则警报可以升级到不同的组。 报告：报告提供中断，事件，通知和警报响应的历史记录，供以后查看。 维护：计划停机可防止在计划维护和升级窗口期间发出警报。 计划：通过趋势和容量规划图表和报告，运维人员可以在发生故障之前识别必要的基础架构升级。 Nagios特点 网络服务监控（SMTP、POP3、HTTP、NNTP、ICMP、SNMP、FTP、SSH、端口，URL，丢包，进程数，网络流量、交换机端口流量，路由器，打印机） 本地和远端主机资源监控（CPU、内存、磁盘、日志、负载uptime、I/O，Raid级别，温度，passwd文件的变化，本地所有文件指纹识别），也包括Windows主机（使用NSClient++ plugin） 业务数据监控（用户登陆失败次数，用户登陆网站次数，输入验证码失败次数，某个API接口流量并发，网站订单，支付交易数量） 可以指定自己编写的Plugin通过网络收集数据来监控任何情况（温度、警告……）。可以通过配置Nagios远程执行插件远程执行脚本 远程监控支持SSH或SSL加通道方式进行监控 简单的plugin设计允许用户很容易的开发自己需要的检查服务，支持很多开发语言（shell scripts、C++、Perl、ruby、Python、PHP、C#等） 包含很多图形化数据Plugins（Nagiosgraph、Nagiosgrapher、PNP4Nagios等） 可并行服务检查 能够定义网络主机的层次，允许逐级检查，就是从父主机开始向下检查 当服务或主机出现问题时发出通告，可通过email, pager, sms 或任意用户自定义的plugin进行通知 能够自定义事件处理机制重新激活出问题的服务或主机 自动日志循环 支持冗余监控 包括Web界面可以查看当前网络状态，通知，问题历史，日志文件等 Nagios插件概述默认搭建的Nagios服务器只能监控简单的几个项目，而其他服务之类的监控项目都是需要插件来实现，插件可用官方提供的，也可以自己编写。插件是Nagios Core的独立扩展，可以使用Core监控任何事情。插件处理命令行参数，执行特定检查，然后将结果返回给Nagios Core。它们可以是编译的二进制文件（用C，C ++等编写）或可执行的脚本（shell，Perl，PHP等）。 NRPE概述NRPE 总共由两部分组成: check_nrpe 插件，位于监控主机上 NRPE daemon，运行在远程被监控的 Linux 主机上 当监控远程主机服务或资源时，工作流程如下： nagios会运行check_nrpe插件并指定检查项 check_nrpe插件会通过ssl连接到远程的NRPE daemon NRPE daemon会运行相应的Nagios插件来执行检查动作 NPRE daemon将检查的结果返回给check_nrpe插件，插件将其递交给Nagios做处理 NRPE 的检测类型分为两种: 直接检测：检测的对象是运行NRPE的那台Linux主机的本地资源，直接使用NRPE插件监控远程Linux主机的本地或者私有资源 间接检测：当运行Nagios的监控主机无法访问到某台被监控主机，但是运行NRPE的机器可以访问得到的时候，运行NRPE的主机就充当一个中间代理，将监控请求发送到被监控对象上 就如下图中check_disk和check_load是直接检测，check_http和check_ftp是间接检测。 Nagios搭建服务器端需要安装的软件： LAMP：因为Nagios需要web端显示，所以需要LAMP的web环境，也可以是LNMP。 Nagios-core：Nagios的主程序 Nagios-plugins：Nagios的插件 NRPE：Nagios的一个功能扩展，可在远程主机上执行插件程序，是客户端程序。 客户端需要安装的软件 Nagios-plugins NRPE 服务器端 首先搭建LAMP环境yum install httpd php php-gd gd* gcc* glibc* openssl*注：gd是图像处理库 创建用户nagios，创建用户组nagcmd，将apache和nagios都添加到nagcmd副组中。组nagcmd用于从Web接口执行外部命令 创建安装目录/usr/local/nagios，编译安装123456789101112131415161718192021222324252627282930313233进入nagios-4.4.1解压目录./configure \ --prefix=/usr/local/nagios \ --with-command-group=nagcmd General Options: ------------------------- Nagios executable: nagios Nagios user/group: nagios,nagios Command user/group: nagios,nagcmd Event Broker: yes Install $&#123;prefix&#125;: /usr/local/nagios Install $&#123;includedir&#125;: /usr/local/nagios/include/nagios Lock file: /run/nagios.lock Check result directory: /usr/local/nagios/var/spool/checkresults Init directory: /lib/systemd/system Apache conf.d directory: /etc/httpd/conf.d Mail program: /usr/bin/mail Host OS: linux-gnu IOBroker Method: epoll Web Interface Options: ------------------------ HTML URL: http://localhost/nagios/ CGI URL: http://localhost/nagios/cgi-bin/ Traceroute (used by WAP): /usr/bin/traceroutemake all \ &amp;&amp; make install \ # 安装Nagios主程序的CGI和HTML &amp;&amp; make install-init \ # 在/lib/systemd/system创建Nagios启动脚本，即可通过systemctl操作 &amp;&amp; make install-commandmode \ # 配置目录权限 &amp;&amp; make install-config \ # 安装示例配置文件，在/usr/local/nagios/etc目录 &amp;&amp; make install-webconf # 生成配置文件/etc/httpd/conf.d/nagios.conf 至此，Nagios Core安装完成。 下面安装nagios plugins 1234567进入nagios-plugins-2.2.1解压目录./configure \ --prefix=/usr/local/nagios make &amp;&amp; make install查看/usr/local/nagios/libexec目录下是否有插件文件，若有则安装成功 nagios plugins安装后，继续安装NRPE。 123456789101112131415进入nrpe-3.2.1解压目录./configuremake all \&amp;&amp; make install \&amp;&amp; make install-plugin \&amp;&amp; make install-daemon \&amp;&amp; make install-config General Options: ------------------------- NRPE port: 5666 NRPE user: nagios NRPE group: nagios Nagios user: nagios Nagios group: nagios 因为可能开启邮件告警功能，所以要启动sendmail服务，不需要做任何配置。yum install sendmail*systemctl enable sendmailsystemctl start sendmail 也可以使用postfix服务进行邮件告警，同样不需要任何配置yum install postfix*systemctl enable postfixsystemctl start postfix注：sendmail和postfix同时只开启一个，一个开启则另一个会自动停止 至此，服务器端核心组件安装完成。 如果要进行汉化，则可以安装中文插件nagios-cn。下载后直接解压进入目录，然后./configure，make &amp;&amp; make install即可。 先检查下/usr/local/nagios/bin中是否有命令nagios和nagiostats，如果没有，就将nagios-4.4.1目录中base目录下的nagios命令和nagiostats命令复制到/usr/local/nagios/bin/中，因为通过systemctl启动nagios时，会调用该目录的nagios命令。若不存在会报错无法启动。 为配置文件还有nagios和nagiostats命令创软链接。ln -s /usr/local/nagios/etc/nagios.cfg /etc/nagios.cfgln -s /usr/local/nagios/etc/cgi.cfg /etc/cgi.cfg 为nagios默认登录用户nagiosadmin创建http验证密码。htpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin 将/usr/local/nagios的所有者和所属组都改为nagios 使用nagios -v /etc/nagios.cfg检查配置文件是否正确。 确保Selinux关闭，确保防火墙放行80端口或关闭。 启动httpd和nagios以及nrpe服务，并设为开机自启。systemctl start httpd nagios nrpesystemctl enable httpd nagios nrpe 在浏览器上输入IP地址/nagios，会先要求输入htpasswd设置的用户名密码登录验证。登录成功后跳转到Nagios主页面。 服务器端配置NRPEln -s /usr/local/nagios/etc/nrpe.cfg /etc/nrpe.cfg 修改commands.cfg文件，添加check_nrpe命令 1234define command &#123; command_name check_nrpe command_line $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$&#125; 修改service.cfg，添加服务 123456define service &#123; use local-service host_name system3 service_description users check_command check_nrpe!check_users # 在check_nrpe!后直接使用nrpe.cfg定义的command变量&#125; 完成后重启nrpe 客户端安装 安装nagios plugins 123进入nagios-plugins-2.2.1解压目录./configure --prefix=/usr/local/nagios make &amp;&amp; make install 安装NRPE 12345678进入nrpe-3.2.1解压目录./configuremake all \ 构建nrpe和check_nrpe&amp;&amp; make install \ 安装nrpe和check_nrpe&amp;&amp; make install-plugin \ 安装check_nrpe插件&amp;&amp; make install-daemon \ 安装nrpe daemon&amp;&amp; make install-config 安装nrpe 配置文件&amp;&amp; make install-init 安装systemd文件 查看配置文件/usr/local/nagios/etc/nrpe.cfg，若要添加监控命令，便找到以下配置，按照格式进行添加command 1234567command[check_users]=/usr/local/nagios/libexec/check_users -w 5 -c 10command[check_load]=/usr/local/nagios/libexec/check_load -r -w .15,.10,.05 -c .30,.25,.20command[check_hda1]=/usr/local/nagios/libexec/check_disk -w 20% -c 10% -p /dev/hda1command[check_zombie_procs]=/usr/local/nagios/libexec/check_procs -w 5 -c 10 -s Zcommand[check_total_procs]=/usr/local/nagios/libexec/check_procs -w 150 -c 200# command后中括号里内容就是定义的变量，名称可任意指定 （可选）修改/etc/services，添加nrpe 5666/tcp # Nagios_client。 启动nrpe，systemctl start nrpe，并使用ps -ef查看nrpe是否启动。 使用插件/usr/local/nagios/libexec/check_nrpe -H localhost检验nrpe是否启动成功。若成功，会输出NRPE的版本号。 修改配置文件/usr/local/nagios/nrpe.cfg 12345#server_address=127.0.0.1 # 客户端主机IP地址# 添加监控服务器地址，声明合法的NRPE服务对象allowed_hosts=127.0.0.1,监控服务器地址或域名 # 若没有在这指定监控服务器地址，则监控服务器无法获取本机的服务信息 给命令nrpe和配置文件nrpe.cfg创软链接，并以守护进程启动。nrpe -c /etc/nrpe.cfg -d也可通过systemctl start nrpe启动。 测试nrpe是否成功启动/usr/local/nagios/libexec/check_nrpe -H 127.0.0.1，输出NRPE版本号则启动成功。 测试nrpe是否能与客户端通信，同样使用check_nrpe指定对端IP地址或域名，输出NRPE版本号则通信正常。若报错 目录与配置文件概述在Nagios服务器端安装完后，/usr/local/nagios中有以下目录：bin，etc，sbin，share，libexec，var，var/archives，var/rw。其中libexec是存放外部插件的。share是存放网页文件的。var/archives是存放归档日志的。var/rw是存放外部命令的。 配置文件或目录 说明 cgi.cfg 控制cgi访问的配置文件 nagios.cfg Nagios主配置文件 resource.cfg 变量定义文件 objects 目录，存放配置文件模板，用于定义Nagios对象 objects/commands.cfg 命令定义配置文件，定义的命令可悲其他配置文件使用 objects/contacts.cfg 定义联系人和联系人组 objects/localhost.cfg 定义监控本地主机 objects/printer.cfg 定义监控打印机，默认未开启 objects/switch.cfg 定义监控路由器，默认未开启 objects/templates.cfg 定义主机、服务，默认未开启 objects/timeperiods.cfg 定义监控时间段 objects/windows.cfg 定义windows主机，默认未开启 Nagios配置中涉及到的定义：（建议按以下顺序配置） 主机、主机组、服务、服务组 监控命令 监控时间 联系人、联系人组 Nagios监控的主机资源和服务在配置文件中称为对象。建议将Nagios各个定义对象创建独立的配置文件，如： 创建hosts.cfg定义主机和主机组 创建services.cfg定义服务和服务组 其余的对象都用默认文件即可。 templates.cfg定义主机和服务的模板1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162define contact &#123; # 定义联系人 name generic-contact ; 联系人名 service_notification_period 24x7 ; 服务通知时间，默认24x7任何时间 host_notification_period 24x7 ; 主机通知时间，默认24x7任何时间 service_notification_options w,u,c,r,f,s ; 服务发送通知的状态条件 # w：警告warn u：未知unknown c：紧急criticle r：重新恢复recover host_notification_options d,u,r,f,s ; 主机发送通知的状态条件 # d：宕机down u：未知/不可达unreachable r：重新恢复 service_notification_commands notify-service-by-email ; 服务发送通知的方式 host_notification_commands notify-host-by-email ; 主机发送通知的方式&#125;define host &#123; # 定义主机 name generic-host ; 主机名（对于配置文件，并非系统主机名） notifications_enabled 1 ; 是否开启主机通知，1为开启，2为不开启 event_handler_enabled 1 ; 是否开启事件处理 flap_detection_enabled 1 ; 是否启用报警延时 process_perf_data 1 ; 是否启用数据输出 retain_status_information 1 ; 是否在程序重启期间保留状态信息 retain_nonstatus_information 1 ; 是否在程序重启期间保留非状态信息 notification_period 24x7 ; 主机通知时间，默认任何时间&#125;define host &#123; name linux-server ; 主机名 use generic-host ; 引用指定的主机，此处引用了上面定义的主机的配置 check_period 24x7 ; 检查主机的时间段，默认不间断 check_interval 5 ; 检查主机的时间间隔，默认5分钟 retry_interval 1 ; 重试检查时间间隔，默认1分钟 max_check_attempts 10 ; 对主机检查的最多次数。并不是检查一次就判断，而是多检查几次才判断是否故障。单位次 check_command check-host-alive ; 默认检查命令 notification_period workhours ; 发送通知的时间段 notification_interval 120 ; 发送通知的间隔，单位分钟 notification_options d,u,r ; 发送通知的状态条件 contact_groups admins ; 联系人组&#125;后面还有对打印机、交换机的主机定义然后就是对服务的定义define service &#123; # 定义服务 name generic-service ; 服务名 active_checks_enabled 1 ; 是否开启动态检查 passive_checks_enabled 1 ; 是否开启主动检查 parallelize_check 1 ; 应该并行化活动服务检查（禁用此功能可能会导致严重的性能问题） obsess_over_service 1 ; 默认为1 check_freshness 0 ; 默认为0 notifications_enabled 1 ; 是否启用服务通知 event_handler_enabled 1 ; 是否启用事件处理 flap_detection_enabled 1 ; 是否启用报警延时 process_perf_data 1 ; 是否启用数据输出 retain_status_information 1 ; 是否在程序重启期间保留状态信息 retain_nonstatus_information 1 ; 是否在程序重启期间保留非状态信息 is_volatile 0 ; 是否稳定，0为稳定，1为不稳定 check_period 24x7 ; 检查服务的时间段，默认不间断 max_check_attempts 3 ; 对服务检查的最多次数 check_interval 10 ; 检查时间间隔，默认10分钟 retry_interval 2 ; 重试检查时间间隔，默认2分钟 contact_groups admins ; 联系人组 notification_options w,u,c,r ; 发送通知的状态条件 notification_interval 60 ; 发送通知的间隔，单位分钟 notification_period 24x7 ; 发送通知的时间段&#125; resource.cfg定义变量的模板。变量需要先定义才能在别的配置文件中调用，否则nagios就会报错。1234# 变量$USER1$指定了nagios插件的安装路径$USER1$=/usr/local/nagios/libexec# $USER2$定义了事件处理的安装路径$USER2$=/usr/local/nagios/libexec/eventhandlers Nagios宏Nagios配置有两个特征：继承与引用，在命令行定义中使用宏，通过宏，Nagios可灵活获取主机、服务等对象的信息。在命令执行前，Nagios会对命令进行宏替换。宏分为：默认宏、按需而成的宏、用户自定义宏 默认宏：主机IP地址宏 1234567891011define host&#123; host_name linuxbox address 192.168.1.2 check_command check_ping...&#125;define command&#123; command_name check_ping command_line /usr/local/nagios/libexec/check_ping -H $HOSTADDRESS$ -w 100.0,90% -c 200.0,60%&#125;在执行时，就会把宏替换为IP地址 命令参数宏向命令传递参数，参数指定在对象中定义，用一个!分隔。 1234567891011define service&#123; host_name linuxbox service_description PING check_command check_ping!200.0,80%!400.0,40%...&#125;define command&#123; command_name check_ping command_line /usr/local/nagios/libexec/check_ping -H $HOSTADDRESS$ -w $ARG1$ -c $ARG2$&#125;在执行时，会将分隔的两个参数替换到命令中的ARG1和ARG2 注：如果要在命令中使用!，\都要使用反斜杠转义 Nagios可用的所有宏： 主机宏HOSTNAME：主机名，取自主机定义中host_nameHOSTADDRESS：主机IP地址，取自主机定义中address 服务宏SERVICESTATE：服务状态描述，三个可能：w，u，cSERVICEDESC：对当前服务的描述 联系人宏CONTACTNAME：联系人名，在联系人文件中定义 通知宏NOTIFICATIONTYPE：返回状态信息。 日期宏LONGDATETIME：当前日期，时间戳 文件宏LOGFILE：日志文件保存位置$MAINCONFIGFILE：主配置文件保存位置 其他宏ADMINMAIL：管理员E-mail地址ARGn：第n个命令参数，n是数字。最多支持32个参数宏。 commands.cfg定义命令。123456define command &#123; command_name check-host-alive # 命令名 # 命令执行 command_line $USER1$/check_ping -H $HOSTADDRESS$ -w 3000.0,80% -c 5000.0,100% -p 5 # 调用插件check_ping，-w为warning警告状态，-c为紧急，80%表示ping的临界值。-p 5表示每次发5个ping包&#125; hosts.cfg默认不存在，定义主机。123456789101112define host &#123; use linux-server # 引用templates.cfg中linux-server的配置 host_name web # 主机名 alias web-system5 # 别名 address 192.168.163.137 # IP地址&#125;define hostgroup &#123; hostgroup_name web-servers # 主机组名 alias web-servers # 别名 members web # 组成员（填host_name，逗号分隔）&#125; services.cfg默认不存在，定义服务。123456789101112define service &#123; use local-service # 引用templates.cfg中local-service的配置 host_name web # 主机名 service_description ping # 服务描述 check command check_ping..... #引用命令&#125;define servicegroup &#123; # 服务组，配置类似主机组 servicegroup_name alias members &#125; contacts.cfg定义联系人。1234567891011define contact &#123; contact_name # 联系人名 use # 使用templates.cfg中指定模板信息 alias email # 联系人邮箱&#125;define contactgroup &#123; contactgroup_name # 联系人组名 alias members&#125; timeperiods.cfg定义监控时段。123456789101112131415define timeperiod &#123; name 24x7 #定义时段名 # 之前host和service中的24x7就是引用这里定义的时段名 timeperiod_name 24x7 alias 24 Hours A Day, 7 Days A Week # 定义监控时间，若某天不监控则不要写那天 sunday 00:00-24:00 monday 00:00-24:00 tuesday 00:00-24:00 wednesday 00:00-24:00 thursday 00:00-24:00 friday 00:00-24:00 saturday 00:00-24:00&#125; cgi.cfg控制cgi脚本。用于在web界面执行cgi脚本，如重启nagios进程、关闭通知、停止检测等。以下为修改权限涉及的参数12345678default_user_name=guestauthorized_for_system_information=nagiosadmin # 验证系统信息authorized_for_configuration_information=nagiosadmin # 验证配置信息authorized_for_system_commands=nagiosadmin # 验证系统命令authorized_for_all_services=nagiosadmin # 验证所有服务authorized_for_all_hosts=nagiosadmin # 验证所有主机authorized_for_all_service_commands=nagiosadmin # 验证所有服务命令authorized_for_all_host_commands=nagiosadmin # 验证所有主机命令 nagios.cfgNagios的核心配置文件，所有配置文件必须在此文件中引用才有作用。1234567891011121314151617181920log_file=/usr/local/nagios/var/nagios.log # 日志文件路径cfg_file=/usr/local/nagios/etc/objects/commands.cfgcfg_file=/usr/local/nagios/etc/objects/contacts.cfgcfg_file=/usr/local/nagios/etc/objects/timeperiods.cfgcfg_file=/usr/local/nagios/etc/objects/templates.cfgcfg_file=/usr/local/nagios/etc/objects/localhost.cfg# 继续添加配置文件即可启用指定配置文件。# 也可以直接将文件放入一个目录，然后通过cfg_dir=指定object_cache_file=/usr/local/nagios/var/objects.cache # 指定一个所有对象配置文件的副本文件，也称为对象缓冲文件。# nagios会将所有对象文件的内容都写入该文件resource_file=/usr/local/nagios/etc/resource.cfg # 指定nagios资源文件的路径，可在nagios.cfg定义多个资源文件status_file=/usr/local/nagios/var/status.dat # 指定状态文件，用于保存nagios当前状态、注释、宕机信息等status_update_interval=10 # 状态文件的更新周期，单位秒，最小1秒nagios_user=nagios # nagios进程所属用户nagios_group=nagios # nagios进程所属用户组check_external_commands=1 # 是否允许nagios在web界面执行cgi命令interval_length=60 # 指定nagios时间单位，默认60s，即nagios配置中所有 时间单位为分钟 Nagios监控界面解析左侧菜单栏中Current Status目录如下123456789101112Tactical Overview 总览Map 拓扑图Hosts 主机Services 服务Host Groups 主机组- Summary 汇总- Grid 表格Service Groups 服务组，也分为汇总和表格Problems 问题故障- Service(Unhandled) 未解决的服务故障- Hosts(Unhandled) 未解决的主机故障- Network Outages 网络整体 Reports目录如下：12345678Availability 可用性Trends 趋势Alerts 报警- History 历史- Summary 汇总- Histogram 历史图Notification 通知Event Log 事件日志 System目录如下：123456Comments 注释Downtime 停机计划Process Info 进程信息Performance Info 性能查询Scheduling Queue 定时查询Configuration 配置 常用操作Nagios对主机和服务有几个描述的状态 Hosts Up启动（绿） Down未启动（红） Unreachable不可达（黄） Pending等待（灰色） Services Ok正常（绿） Warning警告（黄） Unknown未知（橙） Critical紧急（红） Pending等待（灰） Nagios性能分析图表 需要安装pnp软件包，基于PHP和Perl，利用rrdtool工具将nagios收集的数据绘制成图表。pnp官网首先，需要安装gd库、zlib库、jpeg库yum install gd gd-devel zlib zlib-devel jpeg*接着安装rrdtool工具yum install rrdtool*安装perl环境yum install perl最后去pnp官网下载源码包安装12345678910111213141516171819202122232425262728./configure \ --with-nagios-user=nagios \ --with-nagios-group=nagios \ --with-rrdtool=/usr/bin/rrdtool \ --with-perfdata-dir=/usr/local/nagios/share/perfdatamake all \ &amp;&amp; make install \ &amp;&amp; make install-config \ &amp;&amp; make install-init \ &amp;&amp; make install-webconf或者直接make fullinstall（包含以上所有make） General Options: ------------------------- ------------------- Nagios user/group: nagios nagios Install directory: /usr/local/pnp4nagios HTML Dir: /usr/local/pnp4nagios/share Config Dir: /usr/local/pnp4nagios/etc Location of rrdtool binary: /usr/bin/rrdtool Version 1.7.0 RRDs Perl Modules: FOUND (Version 1.6999) RRD Files stored in: /usr/local/nagios/share/perfdata process_perfdata.pl Logfile: /usr/local/pnp4nagios/var/perfdata.log Perfdata files (NPCD) stored in: /usr/local/pnp4nagios/var/spool Web Interface Options: ------------------------- ------------------- HTML URL: http://localhost/pnp4nagios Apache Config File: /etc/httpd/conf.d/pnp4nagios.conf 安装完后，将/usr/local/pnp4nagios的所有者和所属组都改为nagios 配置pnp将/usr/local/pnp4nagios/share目录下所有文件复制到/usr/local/nagios/share/pnp中。将/usr/local/pnp4nagios/etc中npcd.cfg、rra.cfg、process_perfdata.cfg后面的-sample去除（如果有的话）。 首先修改process_perfdata.cfg。12345# 指定日志路径LOG_FILE = /usr/local/pnp4nagios/var/perfdata.log# 日志输出级别，默认为0，最好改为2，即debugLOG_LEVEL = 2# 三个等级：0==slient 1==normal 2==debug 然后将pnp与nagios进行整合，对templcates.cfg配置，添加以下定义。1234567891011121314define host &#123; name hosts-pnp register 0 action_url /nagios/pnp/index.php?host=$HOSTNAME$ process_perf_data 1&#125;define service &#123; name services-pnp register 0 action_url /nagios/pnp/index.php?host=$HOSTNAME$&amp;srv=$SERVICEDESC$ process_perf_data 1&#125;# 注：必须在不应处理其性能数据的每个主机或服务的定义中禁用数据处理（process_perf_data 设为0）。 然后在hosts.cfg和services.cfg和localhost.cfg中要进行数据分析的服务或主机的name参数后加上hosts-pnp或service-pnp，如下：123456define service &#123; use local-service,serviecs-pnp host_name web service_description ping check command check_ping..... &#125; 修改nagios.cfg123456789101112131415161718192021# 开启Nagios数据输出。会将收集到的数据写入文件process_performance_data=1# 取消注释，启用主机和服务的输出功能host_perfdata_command=process-host-perfdata service_perfdata_command=process-service-perfdatahost_perfdata_file=/usr/local/pnp4nagios/var/host-perfdataservice_perfdata_file=/usr/local/pnp4nagios/var/service-perfdatahost_perfdata_file_template=[HOSTPERFDATA]\t$TIMET$\t$HOSTNAME$\t$HOSTEXECUTIONTIME$\t$HOSTOUTPUT$\t$HOSTPERFDATA$service_perfdata_file_template=[SERVICEPERFDATA]\t$TIMET$\t$HOSTNAME$\t$SERVICEDESC$\t$SERVICEEXECUTIONTIME$\t$SERVICELATENCY$\t$SERVICEOUTPUT$\t$SERVICEPERFDATA$host_perfdata_file_mode=aservice_perfdata_file_mode=ahost_perfdata_file_processing_interval=0service_perfdata_file_processing_interval=0host_perfdata_file_processing_command=process-host-perfdata-fileservice_perfdata_file_processing_command=process-service-perfdata-file 修改commands.cfg1234567891011define command &#123; command_name process-host-perfdata-file # 将原来的command_line注释，改为如下参数 command_line /usr/local/pnp4nagios/libexec/process_perfdata.pl --bulk=/usr/local/pnp4nagios/var/host-perfdata&#125;define command &#123; command_name process-service-perfdata-file # 将原来的command_line注释，改为如下参数 command_line /usr/local/pnp4nagios/libexec/process_perfdata.pl --bulk=/usr/local/pnp4nagios/var/service-perfdata&#125; 重启nagios和httpd进入web端，点击左侧菜单services。进入如下页面 点击红框框出的图标，即可进入pnp测试界面 若全部通过，便会提示删除或重命名/usr/local/nagios/share/pnp/install.php。于是将该php文件删除。rm -f /usr/local/nagios/share/pnp/install.php 如果在点击pnp图标时，出现以下报错： 则需要检查nagios.cfg和commands.cfg配置文件，查看commands.cfg配置可知command_name为process-host-perfdata的默认存放路径bulk为/usr/local/pnp4nagios/var/host-perfdata，同理，process-service-perfdata的存放路径为/usr/local/pnp4nagios/var/service-perfdata。 而在nagios.cfg中host_perfdata_file默认路径为/usr/local/nagios/var/host-perfdata，service_perfdata_file默认路径为/usr/local/nagios/var/service-perfdata，两个文件不一致，导致pnp4nagios无法获取。 将nagios.cfg的两条配置，改为与commands.cfg的一致即可 12host_perfdata_file=/usr/local/pnp4nagios/var/host-perfdataservice_perfdata_file=/usr/local/pnp4nagios/var/service-perfdata 邮件告警配置先安装sendmail或postfix，安装完后开启。本篇使用sendmail服务。使用mail命令发送测试邮件。若没有mail命令，需要先下载mailx软件mail -s test XXXX@XX.com输入内容完后ctrl+d结束。 关于邮件告警主要涉及以下几个文件： templates.cfg 12345678910111213其中有关于contact的定义define contact &#123; name generic-contact service_notification_period 24x7 host_notification_period 24x7 service_notification_options w,u,c,r,f,s host_notification_options d,u,r,f,s service_notification_commands notify-service-by-email host_notification_commands notify-host-by-email register 0 &#125;# 发送服务通知使用的是notify-service-by-email命令 发送主机同时使用的是notify-host-by-email命令 于是查找commands.cfg文件 1234567891011如果不成功，一定要注意到此文件中发送通知的命令默认使用sendmail命令，若主机没有就不可能发送成功。需要替换为mail或mailx。还要注意这两个命令的目录，是/bin还是/sbindefine command &#123; command_name notify-host-by-email command_line /usr/bin/printf &quot;%b&quot; &quot;***** Nagios *****\n\nNotification Type: $NOTIFICATIONTYPE$\nHost: $HOSTNAME$\nState: $HOSTSTATE$\nAddress: $HOSTADDRESS$\nInfo: $HOSTOUTPUT$\n\nDate/Time: $LONGDATETIME$\n&quot; | /usr/bin/mail -s &quot;** $NOTIFICATIONTYPE$ Host Alert: $HOSTNAME$ is $HOSTSTATE$ **&quot; $CONTACTEMAIL$&#125;define command &#123; command_name notify-service-by-email command_line /usr/bin/printf &quot;%b&quot; &quot;***** Nagios *****\n\nNotification Type: $NOTIFICATIONTYPE$\n\nService: $SERVICEDESC$\nHost: $HOSTALIAS$\nAddress: $HOSTADDRESS$\nState: $SERVICESTATE$\n\nDate/Time: $LONGDATETIME$\n\nAdditional Info:\n\n$SERVICEOUTPUT$\n&quot; | /usr/bin/mail -s &quot;** $NOTIFICATIONTYPE$ Service Alert: $HOSTALIAS$/$SERVICEDESC$ is $SERVICESTATE$ **&quot; $CONTACTEMAIL$&#125; 最后通过contacts.cfg设置联系人，在email中填写自己的邮箱 123456define contact &#123; contact_name nagiosadmin use generic-contact alias Nagios Admin email XXXX@XX.com&#125; 当服务出现重启或故障时，系统会自动发送邮件。 参考资料 Nagios配置安装详解使用 Nagios 搭建监控服务器Nagios官方文档Pnp官方配置文档Nagios 监控系统架设全攻略CentOS7安装nagios并配置出图详解2017年11月最新Nagios4.3.4部署高性能Linux服务器构建实战：运维监控、性能调优与集群应用]]></content>
      <tags>
        <tag>运维</tag>
        <tag>监控</tag>
        <tag>Nagios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible基础学习笔记]]></title>
    <url>%2F2018%2F05%2F28%2FAnsible%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下内容 Ansible结构 Ansible安装 Inventory Ansible常见模块 Playbook Ansible变量 Jinja2过滤器 Ansible-Tower Ansible是一个部署一群远程主机的工具，使用SSH实现管理节点和远程节点间的通信，实现批量自动化操作。 Ansible有企业版本的收费软件Ansible Tower，中心化的Ansible管理节点，向管理员提供web接口。实现：1. 管理员在Ansible Tower上使用分享主机的SSH密钥，但不能查看和复制私钥 2. Ansible的web上的所有管理员都可共享Playbook脚本 3. Ansible Tower可收集展示所有主机的Playbook执行情况。 Ansible Tower提供了一个数据库来存储inventory配置信息，这个数据库可以通过web访问，或通过REST访问。Tower与所有使用的Ansible动态inventory源保持同步，并提供了一个图形化的inventory编辑器。 Ansible结构Ansible具有以下核心组件： ansible core：ansible核心程序 Host Inventory：主机信息文件 Playbooks：剧本，用于简便管理主机 Core Modules：核心模块，Ansible通过模块进行管理 Custom Modules：自定义模块，补充核心模块的功能 Connection Plugins：连接插件，用于Ansible和主机的通信 Plugins：其他各种插件，提供连接或功能接口 Ansible特性： 基于Python实现，有三个关键模块：Paramiko（ssh连接插件）、PyYAML（YAML语言）、jinja2（定义模板，即Playbook） 部署简单，轻量级，无需在客户端安装agent，去中心化 默认使用SSH。1.基于密钥 2.在inventory文件指定密码 支持自定义模块，支持各种编程语言 主从模式master和slave 使用playbook进行主机管理 幂等性：一种操作重复多次结果相同，只需运行一次playbook就可将需要配置的机器都置为期望状态，同一台机器多次执行一个playbook是安全的 Ansible是模块化的，通过调用模块来实现管理 支持多层部署，可通过VM和容器为多层应用程序的部署配置提供支持 为架构的多个层次带来一致性，借助Ansible可通过编程操作计算架构中从基础设施到应用程序的每一层 Ansible支持异构IT环境，支持Windows和Linux及多个硬件平台和云平台 实验系统CentOS-7主节点服务器：192.168.163.102从节点服务器：192.168.163.103 Ansible安装首先安装epel-release，能够获得更多的Ansible包资源。 yum install epel-release然后安装Ansible yum install ansible Ansible有以下配置文件： /etc/ansible/ansible.cfg 主配置文件 /etc/ansible/hosts Inventory配置文件 Ansible配置以ini格式存储数据，Ansible几乎所有配置都可通过Playbook或环境变量重新赋值。当运行Ansible命令时，会按照以下顺序查找并读取配置文件。 ANSIBLE_CONFIG：环境变量指定的路径 ./ansible.cfg：当前目录的ansible.cfg配置文件 ~/ansible.cfg：家目录的ansible.cfg配置文件 /etc/ansible/ansible.cfg：ansible主配置文件 Ansible主配置文件中的几个重要参数12345678910111213inventory = /root/ansible/hosts # inventory文件的位置library = /usr/share/my_modules/ # ansible模块位置forks = 5 # 默认情况下Ansible最多能有多少个进程同时工作，默认5个进程并行处理。 # 可以根据控制端性能和被管理节点的数量来确定sudo_user = root # 默认执行命令的用户remote_port = 22 # 指定连接被管理节点的管理端口，默认是22host_key_checking = False # 是否检查SSH主机的密钥timeout = 20 # SSH连接的超时间隔，单位：秒log_path = /var/log/ansible.log # Ansible默认不记录日志# 若开启了日志，则要通过该参数设置日志文件路径# 模块将会调用被管节点的rsyslog来记录，执行Ansible的用户需要有写入日志的权限remote_tmp = ~/.ansible/tmp # 远程主机的临时文件存放位置local_tmp = ~/.ansible/tmp # 本机的临时文件存放位置 Ansible提供文档命令可查看指定的用法说明ansible-doc命令用于查看Ansible帮助文档123-h 查看帮助-l 列出所有Ansible模块-s &lt;module&gt; 查找指定模块的用法 公钥认证Ansible默认开启公钥认证，Ansible主节点应该与所有要管理的节点进行ssh验证。主要使用以下命令：12ssh-keygen 创建密钥对ssh-copy-id -i ~/.ssh/id_rsa.pub root@&lt;节点IP地址&gt; 然后在/etc/ansible/hosts添加该节点的IP地址 如果有个主机重新安装并在/home/.ssh/known_hosts文件中中有了不同的key，就会一直提示错误。若节点主机未进行公钥认证，即没有在该文件中初始化，则每次使用ansible命令时都会要求确认key信息。 若要禁用ansible确认密钥的行为，可在主配置文件中参数host_key_checking = False设置，也可以通过环境变量ANSIBLE_HOST_KEY_CHECKING=False设置。 ansible主命令1234567ansible &lt;host-pattern&gt; [options] # host-pattern可填inventory的组名，ip地址，all（所有主机） # 一些简单常用参数 -f 设置一次处理的主机个数，即并行执行 -m 设置使用的模块 -a 模块的参数 -i 指定inventory文件 InventoryAnsible可同时操作属于一个组的多台主机,组和主机之间的关系通过inventory文件配置，默认的文件路径为/etc/ansible/hosts。inventory文件遵循INI文件风格，方括号[]中是组名,用于对系统进行分类,便于对不同系统进行个别的管理。一个系统可以属于不同的组，属于两个组的变量都可以为这台主机所用。组名可自定义。 1234567891011121314151617181920212223242526272829# 可以直接写要管理的主机IP地址或域名192.168.163.103#也可设置管理组[test]192.168.163.103system[1:5].example.com# 数字简写模式，表示system1--sysetm5# 也支持字母简写，system[a:f].example.com# 可对每个服务器设置连接类型和连接用户名localhost ansible_connection=localsystem3.example.com ansible_connection=ssh ansible_ssh_user=ansible# 可定义变量，可使用变量定义的配置主机变量host1 http_port=80 maxRequestsPerChild=808# 也可定义组变量[test:vars]ntp_server=ntp.example.com# 还可组嵌套，即在其他组中引用一个组# 这些变量可以给ansible-playbook使用,但不能给ansible使用。[team1]host1[team2]host2[test:hosts]team1team2 当Inventory中存在有效主机时，ansible就默认隐式地可以使用localhost作为本机，但inventory中没有任何主机时是不允许使用它的，且all或*所代表的所有主机也不会包含localhost。 一些常见的Inventory参数：1234567891011121314ansible_ssh_host # ansible使用ssh要连接的主机ansible_ssh_port # ssh的端口。默认为22ansible_ssh_user # ssh登录的用户名。默认为rootansible_ssh_pass # ssh登录远程用户时的认证密码 # 不安全，最好使用 --ask-passansible_sudo_pass # sudo命令输入的root密码（当使用非root用户操作时） # 不安全，最好使用 --ask-sudo-passansible_connection # 连接远程主机使用的模式，默认为smart智能模式 # smart：若本地ssh支持持久连接时采用ssh连接，否则采用python的paramiko ssh连接 # paramiko：python的ssh连接库ansible_ssh_private_key_file # ssh登录远程用户时的认证私钥文件ansible_ssh_common_args # 指定ssh、scp等命令的参数ansible_shell_type # 指定远程主机执行命令时的shell解析器，默认为shansible_python_interpreter # 远程主机上的python解释器路径。默认为/usr/bin/python Inventory配置文件可以有多个，且可以通过Dynamic Inventory来动态生成只需在ansible的主配置文件中将inventory参数设置为对应的文件或目录即可，如果是目录，那么此目录下的所有文件都是inventory文件。 可创建多个独立文件用于保存变量，然后在主文件中引用注：这些独立文件的格式为YAML在独立文件/etc/ansible/group_vars/servers中添加 123---ntp_server: ntp.example.comdatabase_server: system2.example.com 然后在inventory文件中指定该文件/etc/ansible/group_vars/servers可以为一个主机，或一个组，创建一个目录，目录名就是主机名或组名。目录中的可以创建多个文件，文件中的变量都会被读取为主机或组的变量。 Ansible常见模块cron1234567891011121314151617181920cron 计划任务模块 month # 指定月份 minute # 指定分钟 job # 指定任务（需要state=present） day # 指定小时 hour # 指定小时 weekday # 周几 name # 指定名称（默认为*） user # 使用的用户身份去执行 special_time # 指定执行的时间 reboot # 重启时 yearly # 每年 # 还有annually monthly weekly daily hourly state # 添加或删除 present # 安装 absent # 移除 backup # 对远程主机上原有任务计划做备份 cron_file # 使用指定文件替换远程主机上/etc/cron.d/中的任务计划 例：ansible webserver -m cron -a &apos; minute=&quot;*/10&quot; job=&quot;/bin/echo hello&quot; name=&quot;test&quot; state=present &apos; user123456789101112131415161718user 用户账号管理 name # 用户名 uid # UID state # 状态 present # 添加 absent # 移除 password # 设置密码 group # 所属组 groups # 附加组（用逗号分隔） home # 家目录 createhome # 是否创建家目录 comment # 注释 system # 是否设为系统用户 generate_ssh_key=yes # 是否加密密码 ssh_key_bits=2048 # 加密密钥长度 ssh_key_file=.ssh/id_rsa # 密码文件 注：指定password参数时，不能使用后面这一串密码会被直接传送到被管理主机的/etc/shadow文件中，所以需要先将密码字符串进行加密处理。然后将得到的字符串放到password中即可。 默认加密方式是根据/etc/login.defs的ENCRYPT_METHOD指定，默认为SHA512 group12345group 组管理 gid # GID name # 组名 state # 状态 system # 是否是系统组 copy123456789101112131415copy 复制文件，类似scp，需要关闭所有机器的selinux，否则会报错 src # 本地源路径 dest # 远程主机目标路径 owner # 指定拥有者 group # 指定所属组 mode # 设置权限 content # 取代src=，表示直接用此处信息生成文件内容 backup # 在覆盖前备份原文件，两个选项（yes | no） directory_mode # 递归设置目录权限，默认为系统默认权限 force # 用于设置当目标主机包含该文件，但内容不同时的操作 # 若设置为yes，则强制覆盖，若为no，则只有当目标主机的目标位置不存在该文件时，才复制。 # 默认为yes# 所有的file模块里的选项都可以在这里使用# 若出现了有关selinux的报错，可在被控机上安装libselinux-python解决# ansible all -m yum template用法和copy模块用法基本一致，主要用于复制模板。123456789101112template backup # 拷贝的同时也创建一个包含时间戳信息的备份文件，默认为no dest= # 目标路径 force # 设置为yes (默认)时，将覆盖远程同名文件。设置为no时，忽略同名文件的拷贝 group # 设置远程文件的所属组 owner # 设置远程文件的所有者 mode # 设置远程文件的权限。使用数值表示时不能省略第一位，如0644。 # 也可以使用&apos;u+rwx&apos;或&apos;u=rw,g=r,o=r&apos;等方式设置 src= # ansible控制器上Jinja2格式的模板所在位置，可以是相对或绝对路径 validate # 在复制到目标主机后但放到目标位置之前，执行此选项指定的命令。 # 一般用于检查配置文件语法，语法正确则保存到目标位置。 # 如果要引用目标文件名，则使用%s，下面的示例中的s%即表示目标机器上的/etc/nginx/nginx.conf。 file12345678910111213141516171819file 设置文件属性 path # 设置文件路径（必填） dest # 设置目的路径 name # 设置文件名 owner # 指定拥有者 group # 指定所属组 mode # 设置权限 recurse # 递归设置目录属性 state # 文件状态 file # 文件不存在就不会被创建 dictionary # 若目录不存在，就自动创建 link # 创建软连接 hard # 创建硬链接 touch # 若不存在就自动创建 absent # 删除文件或目录 src # 指定源文件，只应用于state=link的情况 force # 强制创建软链接。 # 两种情况：1.当源文件不存在，但之后会建立 2.要先取消已创建的软链接，再重新创 service123456789101112131415service 管理服务运行状态 enabled # 是否开机自启（yes| no） name # 指定服务名（必填） state # 指定服务状态 started # 启动 stoped # 停止 restarted # 重启 reloaded # 重新加载 arguments # 服务参数 pattern # 设置模式 # 通过status指令来查看服务的状态时 # 若没有响应，就会通过ps指令在进程中根据该模式进行查找 # 如果匹配到，则认为该服务依然在运行 runlevel # 运行级别 sleep # 若执行restarted，则在stop和start键沉睡几秒 command若不指定模块，则默认使用command模块。command模块不能解析变量(如$HOME)和某些操作符(“&lt;”, “&gt;”, “|“, “;”以及”&amp;”)，若需要使用以上符号，就要用shell模块。12345command chdir # 在执行定义的命令前进入指定目录 creates # 创建文件，参数为一个文件或一个glob表达式，若已经存在就不会执行 removes: # 删除文件，参数为一个文件或一个glob表达式，若不存在就不会执行 stdin: # 可要求输入读取指定值 shell12shell 在远程主机上运行命令，一般要使用管道符语法时，会使用shell模块。与raw模块类似 例：ansible all -m shell -a &apos;echo hello&apos; script12script 将本地脚本复制到远程主机并运行 例：ansible all -m script -a &apos;/tmp/a.sh&apos; yum12345678910yum 安装程序包 config_file # yum的配置文件 disable_gpg_check # 关闭gpg_check disablerepo # 不启用某个源 enablerepo # 启用某个源 name # 程序包名 state # 设置状态 present # 安装 latest # 安装 absent # 卸载 注：yum模块是基于python2，若要基于python3安装，需要模块dnf。否则会以下报错：1234 192.168.163.103 | FAILED! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;The Python 2 bindings for rpm are needed for this module. If you require Python 3 support use the `dnf` Ansible module instead.. The Python 2 yum module is needed for this module. If you require Python 3 support use the `dnf` Ansible module instead.&quot;&#125; 也可通过command模块直接安装：ansible 主机 -m command -a &#39;yum -y install 软件&#39; dnf类似yum，但由于yum基于python2，若有依赖于python3的软件包则会报错，因此可用dnf代替，并且dnf的安装速度都有提升。常用参数与yum一致。 setup1234setup 收集远程主机的facts，获取主机信息 # 每个被管理节点在接受并运行管理命令前，会将自己主机相关信息（如操作系统信息，IP地址等报告给ansible） filter # 过滤器（正则表达式） 例：ansible 192.168.163.103 -m setup -a &apos;filter=ansible_eth[0-2]&apos; 1234567---- hosts: group1 remote_user: root tasks: - name: get system info debug: msg=&quot;system = &#123;&#123; ansible_os_family &#125;&#125; kernel = &#123;&#123; ansible_kernel &#125;&#125; ip_addr = &#123;&#123; ansible_all_ipv4_addresses &#125;&#125;&quot;# 用ansible XXX -m setup就能看到所有变量名 收集Facts会消耗额外的时间，若不需要，可以在playbook中关闭 12- hosts: group1 gather_facts: no synchronize1234567891011121314synchronize 使用rsync同步文件 archive # 归档，相当于同时开启recursive(递归)、links、perms、times、owner、group、-D选项都为yes ，默认该项为开启 checksum # 跳过检测sum值，默认关闭 compress # 是否开启压缩，默认yes copy_links # 复制链接文件，默认为no ，注意后面还有一个links参数 delete # 删除不存在的文件，默认no dest # 目录路径 dest_port # 默认目录主机上的端口 ，默认是22，走的ssh协议 dirs # 传速目录不进行递归，默认为no，即进行目录递归 rsync_opts # rsync参数部分 set_remote_user # 主要用于/etc/ansible/hosts中定义或默认使用的用户-与rsync使用的用户不同的情况 mode # push或pull 模块 # push模式一般用于从本机向远程主机上传文件 # pull 模式用于从远程主机上取文件 mount1234567891011mount 设置挂载点 dump fstype # 必选项，挂载文件的类型 name # 必选项，挂载点 opts # 传递给mount命令的参数 src # 必选项，要挂载的文件 state # 必选项present：只处理fstab中的配置 present # 只处理fstab中的配置 absent # 删除挂载点 mounted # 自动创建挂载点并挂载 umounted # 卸载 get_url1234567get_url 用于从http、ftp、https服务器上下载文件（类似于wget） sha256sum # 下载完成后进行sha256 check； timeout # 下载超时时间，默认10s url # 下载的URL dest # 本地存放路径 url_password/url_username # 主要用于需要用户名密码进行验证的情况 use_proxy # 使用代理，代理需事先在环境变更中定义 查看模块用法信息ansible-doc 模块名 Playbook一个简单的配置管理和多主机部署系统。Playbook是由一个或多个“Plays”组成的列表。将事先归为一组的主机装扮为通过Ansible的任务Task定义好的角色。任务也就是调用Ansible的模块将多个“play”组织到一个playbook中。playbook的模板使用Python的jinja2模块处理。 Playbook的组成： Inventory Modules Ad Hoc Commands Playbooks，包含以下部分12345Tasks：任务，即调用模块完成的某操作。这是Playbook的核心，定义顺序执行的Action，每个Action调用一个Ansible模块Variables：变量Template：模板Handlers：处理器，由某事件触发执行的操作Roles：角色 playbook基本组件play的主体部分是task list，task list中各个任务按次序逐个在hosts指定的主机上运行，即在所有主机上完成第一个任务后再按顺序完成第二个，若中途某个主机出现错误，则所有执行的任务都可能回滚。 建议每个任务都定义一个name标签，且每个task执行一个模块123456789- hosts: test # 指定主机组，也可指定单个主机 remote_user: root # 指定远程主机上执行任务的用户（也可用于各个task中） sudo: yes # sudo执行命令，也可在task中添加 sudo_user: # sudo身份 tasks: # 任务列表 - name: install latest apache yum: name=httpd state=latest - name: run apache service: name=httpd state=started # 运行service模块，后面跟上参数选项 命令解析ansible-playbook对yaml文件进行执行 1234567891011ansible-playbook [选项] yml文件 -f # 指定并行进程数，默认为5 -i 或 --inventory # 指定Inventory文件 -e 或 --extra-vars= # 设置额外的环境变量 --flush-cache # 清空收集到的facts缓存 --list-tasks # 列出所有将被执行的tasks --list-tags # 列出所有可获得的tags --step # 每执行一步都进行交互式确认 --syntax-check # 检查playbook语法 --list-hosts # 列出执行该playbook会影响的主机 -v 或 --verbose # 查看详细输出 ansible-pull拉取指定主机的配置 变量引用12345678910111213- hosts: test vars: service: httpd package: httpd # 或直接在本地创建变量文件，然后在playbook中通过vars_files调用 vars_files: - XXX/XXX.yml tasks: - name: install latest apache # 若要通过上面定义的变量引用，则需要两对大括号调用 yum: name=&#123;&#123; package &#125;&#125; state=latest - name: run apache service: name=&#123;&#123; service &#125;&#125; state=started 12345678910111213141516171819202122232425# 若定义的是一个对象，可直接用中括号或点调用子属性---- hosts: group1 remote_user: root vars: foo: field1: one field2: two tasks: - name: echo foo.field1 # debug: msg="echo &#123;&#123;foo.field1&#125;&#125;" debug: msg="echo &#123;&#123;foo['field1']&#125;&#125;" - name: echo foo.field2 debug: msg="echo &#123;&#123;foo.field2&#125;&#125;"结果：TASK [echo foo.field1] *********************************************************ok: [172.16.246.133] =&gt; &#123; "msg": "echo one"&#125;TASK [echo foo.field2] *********************************************************ok: [172.16.246.133] =&gt; &#123; "msg": "echo two"&#125; 简单试验分析： 12345678910111213141516171819202122232425262728293031323334353637创建test.yml- hosts: system3 tasks: - name: echo hello command: 'echo hello' - name: create user user: name=apache password=redhat state=present uid=1003root@system2 ~ &gt; ansible-playbook test.ymlPLAY [system3] *****************************************************************TASK [Gathering Facts] *********************************************************ok: [192.168.163.103]TASK [echo hello] **************************************************************changed: [192.168.163.103]TASK [create user] *************************************************************changed: [192.168.163.103]PLAY RECAP *********************************************************************192.168.163.103 : ok=3 changed=2 unreachable=0 failed=0 # changed说明发生了改变。# 若再次执行一遍，会出现以下改变TASK [echo hello] **************************************************************changed: [192.168.163.103]TASK [create user] *************************************************************ok: [192.168.163.103]PLAY RECAP *********************************************************************192.168.163.103 : ok=3 changed=1 unreachable=0 failed=0 # 创建用户不再是changed，而是ok，而输出打印hello仍然为changed。# 因为用户已创建了，就不会再创建，这体现了playbook的幂等性。而打印文字并不符合只需要执行一遍的特性。 registerregister为注册变量，即：将任务执行的结果当做一个变量的值，待后面的任务使用。 12345678910111213---- hosts: group1 remote_user: root tasks: - shell: ls register: result - debug: msg="&#123;&#123; result.stdout &#125;&#125;"# 就能输出在对端主机ls得到的结果结果：TASK [debug] *******************************************************************ok: [172.16.246.133] =&gt; &#123; "msg": "anaconda-ks.cfg"&#125; 命令行传参123- hosts: '&#123;&#123;group&#125;&#125;' # 一定要加引号（无论是单引号还是双引号），否则会产生YAML陷阱，报错 remote_user: '&#123;&#123;user&#125;&#125;' ..... 在执行ansible-playbook时添加参数--extra-vars &quot;group=group1 user=root&quot; notify与handler当远端发生改动时，playbooks本身可以识别这种改动,并且有一个基本的事件系统,可以响应这种改动。notify会在playbook的每一个task结束时触发,即使有多个不同的task通知发生了改动（changed），notify只会被触发一次。Handlers也是task的列表，若notify有定义，则handlers一定要有对应的处理方法。handlers主要用在重启服务，或系统重启。 一个handler最多只执行一次，并且在所有task都执行完后再执行，即handler是按照定义的顺序执行的，并不是按照task的调用顺序执行的。如果有多个任务调用同一个handler，则也只执行一次。 1234567891011- hosts: test tasks: - name: install apache yum: name=httpd state=latest notify: yum error # 关注可能发生的错误（不一定是错误），类似抛出异常 # 若notify有多个，可通过列表定义 - yum error - httpd error # 定义了多个，则handler也要有对应处理 handlers: # 当关注的资源发生变化时采取的措施 - name: yum error # 当有notify抛出，也要有对应的解决方案，name要与对应的notify的名字一致。 service: name=httpd state=restarted 逻辑控制三种逻辑控制语句： when：条件判断，类似if loop：（迭代）循环，类似while block：将几个任务组成一个代码块，以便针对一组操作的异常进行处理 条件判断当需要根据变量等信息判断是否需要执行某task时，则需要条件判断 1234567891011121314151617181920212223242526272829303132333435363738tasks: - name: echo hello command: echo hello when: ansible_fqdn == 'system3.example.com'# 在task后添加when子句即可进行条件测试，when语句支持jinja2语法# when语句中还能使用Jinja2的很多'filter'执行结果：TASK [echo hello] **************************************************************skipping: [192.168.163.104]changed: [192.168.163.103]PLAY RECAP *********************************************************************192.168.163.103 : ok=2 changed=1 unreachable=0 failed=0192.168.163.104 : ok=1 changed=0 unreachable=0 failed=0# 经过判断system4不满足when条件，所以skipping跳过，而system3满足，所以changed可使用and、or、not进行逻辑连接或判断，==、!=、&gt;、&lt;、&gt;=、&lt;=进行算数比较可使用is exists或is not exists判断指定的文件是否存在，且可通过not取反即not XXX is exists 等于 XXX is not exists可使用defined、undefined、none判断变量是否已定义，以及变量是否为空可使用success或succeeded、failure或failed、change或changed、skip或skipped分别判断任务返回状态是否为成功、任务返回状态是否为失败、任务返回状态是否为改变、任务返回状态是否为跳过可使用file、directory、link、mount判断路径是否为一个文件、目录、链接、挂载点可使用lower、upper判断字符串是否为纯小写、纯大写可使用even、odd判断数值是否为偶数、奇数，可用divisibleby(num)判断是否可以整除数值num可用version(version值,'算数比较符')比较版本与指定值的大小可用string、number分别判断值是否为字符串或数字可用subset、superset（版本2.5及以上）|issubset、issuperset（版本2.5以下）判断一个list是否是另一个list的子集或父集 迭代（循环）重复同类的task时使用。item定义迭代，with_items定义循环列表。with_items中的列表值可以使字典，若是字典，引用时要使用item.键名 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566列表形式- apache- php字典形式- &#123;name: apache, conf: /etc/httpd.conf&#125;- &#123;name: php, conf: /etc/php.ini&#125;试验：- name: create user user: name=&#123;&#123;item&#125;&#125; state=present with_items: - zhangsan - lisi就相当于 user: name=zhangsan state=present user: name=lisi state=present或者在vars中定义列表，然后使用with_items调用vars: user_list=['zhangsan', 'lisi']tasks: - user: name=&#123;&#123;item&#125;&#125; state=present with_items: "&#123;&#123; user_list &#125;&#125;" 嵌套循环tasks: - debug: msg="&#123;&#123; item.0 &#125;&#125; &#123;&#123; item.1 &#125;&#125;"#或 -debug: msg="layer1: &#123;&#123;item[0]&#125;&#125; layer2: &#123;&#123;item[2]&#125;&#125;" with_nested: # 使用with_nested进行嵌套循环 - ['1', '2'] # 这个循环用item.0表示 - ['4', '5'] # 这个循环用item.1表示结果：TASK [debug] *******************************************************************ok: [172.16.246.133] =&gt; (item=[u'1', u'4']) =&gt; &#123;... "msg": "1 4"&#125;ok: [172.16.246.133] =&gt; (item=[u'1', u'5']) =&gt; &#123;... "msg": "1 5"&#125;ok: [172.16.246.133] =&gt; (item=[u'2', u'4']) =&gt; &#123;... "msg": "2 4"&#125;ok: [172.16.246.133] =&gt; (item=[u'2', u'5']) =&gt; &#123;... "msg": "2 5"&#125;文件列表循环在当前目录下创建demo目录，并在其中创建httpd_1.conf和httpd_2.conf，编写Playbook tasks: - debug: msg="&#123;&#123; item &#125;&#125;" with_fileglob: # 使用with_fileglob进行文件列表循环 - ./demo/* # 要循环的文件路径结果：TASK [debug] *******************************************************************ok: [172.16.246.133] =&gt; (item=/root/./demo/httpd_1.conf) =&gt; &#123; "item": "/root/./demo/httpd_1.conf", "msg": "/root/./demo/httpd_1.conf"&#125;ok: [172.16.246.133] =&gt; (item=/root/./demo/httpd_2.conf) =&gt; &#123; "item": "/root/./demo/httpd_2.conf", "msg": "/root/./demo/httpd_2.conf"&#125; Block块1234567891011多个Action组成block块，可进行一个块的执行 tasks: - debug: msg: "task1 not in block" - block: - debug: msg: "task2 in block" - debug: msg: "task3 in block" when: 2 &gt; 1 # block块中的when是用于判断block块是否执行的条件 但Block块更常见的用法是“错误处理”。当某任务出错时，能够执行指定的其他任务。作用与when XXX is failed一致。 1234567891011121314151617181920 tasks: - block: - shell: "ls ./aaa" # 该目录不存在，会出错 rescue: # 一旦出错就会调用rescue任务，类似except，处理异常 - debug: msg: "caught an error" always: # 总是会执行的语句，类似finally - debug: msg: "this always executes"结果：TASK [command] fatal: ......TASK [debug] ok: [172.16.246.133] =&gt; &#123; "msg": "caught an error"&#125;TASK [debug] ok: [172.16.246.133] =&gt; &#123; "msg": "this always executes"&#125; 模板通过配置模板，可将配置文件中的参数按照inventory文件中变量以及ansible facts中变量动态赋值，使得每个指定的主机的配置都是定制的。首先要创建一个templates目录。mkdir /etc/ansible/templates将配置文件放入该目录，并最好改名为xxx.conf.j212345678910111213141516171819202122232425262728293031323334以httpd为例，修改配置文件/etc/ansible/templates/httpd.conf.j2Listen &#123;&#123; http_port &#125;&#125; # 使用inventory定义变量User &#123;&#123; username &#125;&#125; # 同上Group &#123;&#123; groupname &#125;&#125; # 同上ServerName &#123;&#123; ansible_fqdn &#125;&#125; # 使用facts变量然后修改/etc/ansible/hosts文件[test]192.168.163.103 http_port=8081 username=system3 groupname=system3 192.168.163.104 http_port=8082 username=system4 groupname=system4 然后在playbook中将本地的配置文件复制到远端，以下是完整试验- hosts: test vars: service: httpd tasks: - name: alter config template: src=/etc/ansible/templates/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf notify: - restart httpd - name: start httpd service: name=&#123;&#123; service &#125;&#125; enabled=true state=started handlers: - name: restart httpd service: name=&#123;&#123; service &#125;&#125; state=restarted执行ansible-playbook test.yml。之后查看103和104主机的httpd配置文件system3和system4上，httpd配置文件都更改成功。以下为system3上的配置Listen 8081Include conf.modules.d/*.confUser system3Group system3ServerAdmin root@localhostServerName system3.example.com tags标签可以为playbook中的每个任务都打上标签，标签的主要作用是可以在ansible-playbook中设置只执行被打上tag的任务或忽略被打上tag的任务。12345678910111213141516tasks:- name: install apache yum: name=httpd state=present tags: apache- name: install mysql yum: name=mysql-server state=present tags: mysql当执行playbook时，可通过--tags= 运行打上指定tag的taskansible-playbook test.yml --tags="apache" 则只运行安装打上apache标签的taskansible-playbook test.yml --skip-tags="apache"则会跳过执行apache标签的task tags: always打上always标签的task总会被执行，不管是否指定了--tags="XXX"--tags tagged # 会执行所有打上tag的task，不管打上的是什么标签--tags untagged # 会执行所有没有打标签的task--tags all # 执行所有任务，无论是否打标签 include和roles如果把所有play都写在一个playbook中，会导致文件不易阅读。ansible可以将多个不同任务分别写在不同的playbook中，然后使用include将其包含进去，实现Playbook的重用。roles也是一种整合playbook的方式。include的维护成本较高，重用能力有限，而role更加灵活，且可以重用一组文件。 include使用include语句引用task文件的方法，可允许你将一个配置策略分解到更小的文件中，将tasks从其他文件拉取过来（handlers也是tasks）。即include可以导入两种文件：导入task、导入playbook。1234567891011121314151617181920212223242526272829导入task：创建一个单独的yml配置文件，a.yml--- - name: echo hello command: echo 'hello' - name: echo value command: echo &#123;&#123;value&#125;&#125;在主playbook中便可通过include引用该文件- hosts: test tasks: - include: a.yml value='hello' # 可以直接在文件名后传参数 # 也可以通过vars传参 tasks: - include: a.yml vars: value: hello导入playbook：并不在task中通过include调用yml了，而是直接在最外层导入playbook- hosts: test.....- include: test1.yml- include: apache.yml http_port=8000 # 传参方式与上面一样在include中使用tags- include: test1.yml tags: [aaa, bbb] roles角色，封装playbook，实现复用性，能够根据层次型结构自动加载变量文件、tasks以及handlers等。roles就是通过分别将变量、文件、任务、模板以及处理器放置于单独的目录中，然后通过include调用的一种机制。roles一般用于基于主机构建服务的场景中，也可以使用于构建守护进程的场景中。 创建role的步骤： 在playbooks目录中创建roles目录 在roles目录中创建角色名的目录 在每个角色命令的目录中创建files、handlers、meta、tasks、templates、vars目录。若用不到的目录也可不创 在playbook中调用各角色 如果定义了环境变量ANSIBLE_ROLES_PATH，则也会查找该目录下的role role有默认的存放目录/etc/ansible/roles，若既没有定义环境变量，也没有在playbook中定义变量roles_path，则会在该默认目录中查找role。如果既定义了环境变量，又定义了roles_path，则后者失效。 roles中各目录： tasks目录：至少包含一个main.yml，其定义了此角色的任务列表，此文件可用include包含其他task目录 files目录：存放有copy或script等模块调用的文件 templates目录：template模块会自动在此文件中寻找jinja2模板 handlers目录：此目录中应包含一个main.yml，定义此角色用到的handler yml文件：用于定义此角色用到的个handler， vars目录：应包含一个main.yml，定义此角色用到的变量 meta目录：应包含一个main.yml，定义此角色的特殊设定和依赖关系 defaults目录：应包含一个main.yml，为当前角色设定默认变量时使用此目录 可使用命令ansible-galaxy init role-name在当前目录中自动生成指定的role目录 案例目录结构 123456789101112131415roles├── test1│ ├── files│ ├── handlers│ ├── meta│ ├── tasks│ ├── templates│ └── vars└── test2 ├── files ├── handlers ├── meta ├── tasks ├── templates └── vars 将要编写的task文件存放在tasks目录中，编写main.yml。将httpd的配置文件复制到files目录中。 1234567891011- name: install httpd yum: name=httpd state=present- name: install config copy: src=httpd.conf dest=/etc/httpd/conf/httpd.conf # 这里copy的源可直接写文件名，会自动定位到files目录中 tags: - conf notify: - restart httpd- name: start httpd service: name=httpd state=started 然后在handlers中添加handler文件，在目录中创建main.yml12- name: restart httpd service: name=httpd state=restarted 在于roles平级的目录中创建site.yml文件（名字可自定义），就是主配置文件。roles后面也可跟上参数，也可跟上条件判断。1234567891011- hosts: system1 remote_port: root roles: - test1- hosts: system3 roles: - test2- hosts: system4 roles: - test1 - test2 带参数的role 1234567891011121314151617181920212223242526272829a.yml和roles的目录结构a.ymlroles/└── myrole └── tasks └── main.yml在main.yml中指定task--- - debug: msg=&quot;&#123;&#123; param &#125;&#125;&quot;在a.yml中的配置如下：---- hosts: group1 remote_user: root roles: - role: myrole param: &quot; task first&quot; - role: myrole param: &quot; task second&quot;执行结果：TASK [myrole : debug] ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot; task first&quot;&#125;TASK [myrole : debug] ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot; task second&quot;&#125;会循环遍历a.yml中设置指定参数执行 role的默认参数defaults，在myrole中创建defaults目录，并创建main.yml 123456789101112131415161718roles/└── myrole ├── defaults │ └── main.yml └── tasks └── main.yml在defaults中的main.yml中只要配置---param: &quot;default param&quot;将a.yml中的myrole下的参数配置删除roles: - myrole再执行，就会调用defaults中的指定参数TASK [myrole : debug]ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;default param&quot;&#125;但执行速度会变慢 role与when的结合：当满足条件时才采用指定值 1234567891011121314roles: - role: myrole param: &quot;myrole param&quot; - role: myrole when: 2&gt;1结果：TASK [myrole : debug] ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;myrole param&quot;&#125;TASK [myrole : debug]ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;default param&quot;&#125; 在role中使用tags 123roles: - role: myrole tags: [&apos;aaa&apos;, &apos;bbb&apos;] role和tasks的执行顺序 pre_tasks：是在最先执行的task roles：roles会在tasks前执行 tasks post_tasks：最后执行的task 常用技巧 若要使command或shell的成功返回值不为0，有以下两种方式12345678tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true或tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand ignore_errors: True Ansible变量Ansible有三个组成部分： Global：作用域为全局。在以下方面定义： Ansible配置文件中定义 环境变量 ansible及ansible-playbook命令行传入的变量 Play：作用域为Play（一个Playbook由多个Play组成）。在以下方面定义： Play中vars关键词定义的变量 通过模块include_vars定义的变量 role在文件default/main.yml和vars/main.yml中定义的变量 Host：作用域为某个主机。在以下方面定义： 定义在主机Inventory中的变量 主机的系统变量 注册变量 Ansible所有变量的优先级（从高到低）： extra vars：通过命令传入的变量 task vars：仅在该任务中使用的变量 1234tasks: - XXXX vars: XXX: XXX block vars：只在Playbook的任务中某个block定义的变量 123456tasks:.... - block: - XXX: XXXX vars: XXX: XXX role include vars：在tasks/main.yml中，通过include加载的变量 12- name: xxx include_vars: &quot;XXX.yml&quot; role and include vars：role的变量。在vars/main.yml中定义的变量 set_facts：这是一个模块，通过该模块加入一些Facts变量 12- set_fact: XXX: XXX registered vars：注册变量 play vars_files：将变量单独放在一个文件中，通过关键字var_files从文件中加载的变量 12var_files: - XXX.yml play vars_prompt：需要用户在执行Playbook时输入的变量 1234567vars_prompt: - name: &quot;yourname&quot;tasks: - debug: msg=&quot;your name is &#123;&#123;yourname&#125;&#125;&quot;在执行Playbook时传参ansible-playbook a.yml -e &apos;yourname=zhangsan&apos; play vars：Playbook中的vars关键字下定义的参数 host facts：Ansible在执行Playbook时，收集到的远程主机的信息 playbook host_vars：Playbook同级子目录host_vars中文件内定义的变量 playbook group_vars：Playbook同级子目录group_vars中文件内定义的变量 inventory host_vars：可在两个地方定义。一是在inventory文件中直接定义，二是在Inventory文件的同级子目录host_vars中与host同名的文件中定义 inventory group_vars：可在两个地方定义。一是在inventory文件中直接定义，二是在Inventory文件的同级子目录group_vars中与group同名的文件中定义 inventory vars：Inventory文件中定义的变量 role defaults：role的默认变量，在defaults/main.yml中定义 Lookuplookup既能读取Ansible管理节点上文件系统的文件内容，还能读取数据库内容。 lookup读取文件 123vars: contents: &quot;&#123;&#123; lookup(&apos;file&apos;, &apos;data/test.txt&apos;) &#125;&#125;&quot;将data/test.txt中的内容赋给变量contents，file指定读取的对象类型是文件 lookup生成随机密码，若文件不存在，会自动创建，并将生成的密码存入。若文件存在，则直接读取作为密码 12345678910vars: password: &quot;&#123;&#123; lookup(&apos;password&apos;, &apos;/etc/password/zhangsan length=6&apos;) &#125;&#125;&quot;tasks: - debug: msg=&quot;password &#123;&#123;password&#125;&#125;&quot; 执行结果：TASK [debug]ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;password BWNcQ2 &quot;&#125; lookup读取环境变量 1234567tasks: - debug: msg=&quot;&#123;&#123; lookup(&apos;env&apos;, &apos;HOME&apos;) &#125;&#125;&quot; 结果：ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;/root&quot;&#125; lookup读取Linux命令执行结果 1234567tasks: - debug: msg=&quot;&#123;&#123; lookup(&apos;pipe&apos;, &apos;uname -r&apos;) &#125;&#125;&quot; 结果：ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;4.8.6-300.fc25.x86_64&quot;&#125; lookup读取template变量替换后的文件 12tasks: - debug: msg=&quot;&#123;&#123; lookup(&apos;template&apos;, &apos;./httpd.conf.j2&apos;) &#125;&#125;&quot; lookup读取配置文件 1234567891011121314151617181920212223242526272829demo.ini配置文件：[global]port = 873.....[rsync_test]comment = rsync testpath = /root/rsync_test.....tasks: - debug: msg=&quot;global-port &#123;&#123; lookup(&apos;ini&apos;, &apos;port section=global file=./demo.ini&apos;) &#125;&#125;&quot; - debug: msg=&quot;rsync_test-path &#123;&#123; lookup(&apos;ini&apos;, &apos;path section=rsync_test file=./demo.ini&apos;) &#125;&#125;&quot;# lookup的第二个参数分为几个部分：要查的字段 section=节的名称 file=文件名 若是properties文件，则需要添加参数type=properties完整的几个参数：参数名 默认值 含义type ini 文件类型file ansible.ini 文件名section global 节re False 字段的正则表达式default &quot;&quot; 字段不存在时的返回值 执行结果：ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;global-port 873&quot;&#125;ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;rsync_test-path /root/rsync_test&quot;&#125; lookup读取CSV文件的指定单元 123456789101112131415161718csv文件：name age sexzhangsan 22 malelisi 23 maletasks: - debug: msg=&quot;&#123;&#123;lookup(&apos;csvfile&apos;, &apos;lisi file=./demo.csv delimiter=, col=0&apos;)&#125;&#125;&quot;# 获取lisi的第0列，即名字lisiok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;lisi&quot;&#125;支持的参数：参数名 默认值 含义file ansible.csv 文件名col 1 列号（从0开始计数）delimiter TAB CSV文件的分隔符default &quot;&quot; 元素不存在时的返回值encoding utf-8 CSV文件的编码 lookup读取DNS解析的值。可以向DNS服务器查询指定域的DNS记录，可查询任何DNS记录（包括正向和反向） 123456789101112131415161718192021222324252627tasks: - debug: msg=&quot;ipv4 address of baidu.com &#123;&#123; lookup(&apos;dig&apos;, &apos;baidu.com&apos;) &#125;&#125;&quot; - debug: msg=&quot;txt record of baidu.com &#123;&#123; lookup(&apos;dig&apos;, &apos;baidu.com&apos;, &apos;qtype=TXT&apos;) &#125;&#125;&quot; - debug: msg=&quot;txt record of baidu.com &#123;&#123; lookup(&apos;dig&apos;, &apos;baidu.com./TXT&apos;) &#125;&#125;&quot; - debug: msg=&quot;MX record of 163.com &#123;&#123; lookup(&apos;dig&apos;, &apos;163.com./MX&apos;, &apos;wantlist=True&apos;) &#125;&#125;&quot; 需要安装dnspython模块，直接pip install 即可执行结果：ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;ipv4 address of &apos;baidu.com&apos; 220.181.57.216,123.125.115.110&quot;&#125;ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;txt record of &apos;baidu.com&apos; v=spf1 include:spf1.baidu.com include:spf2.baidu.com include:spf3.baidu.com a mx ptr -all,google-site-verification=GHb98-6msqyx_qqjGl5eRatD3QTHyVB6-xQ3gJB5UwM&quot;&#125;ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;txt record of &apos;baidu.com&apos; v=spf1 include:spf1.baidu.com include:spf2.baidu.com include:spf3.baidu.com a mx ptr -all,google-site-verification=GHb98-6msqyx_qqjGl5eRatD3QTHyVB6-xQ3gJB5UwM&quot;&#125;ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;MX record of &apos;163.com&apos; 50 163mx00.mxmail.netease.com.,10 163mx01.mxmail.netease.com.,10 163mx03.mxmail.netease.com.,10 163mx02.mxmail.netease.com.&quot;&#125;反向解析：- debug: msg=&quot;fqdn of &apos;8.8.8.8&apos; &#123;&#123; lookup(&apos;dig&apos;, &apos;8.8.8.8/PTR&apos;) &#125;&#125;&quot;结果：ok: [172.16.246.133] =&gt; &#123; &quot;msg&quot;: &quot;fqdn of &apos;8.8.8.8&apos; google-public-dns-a.google.com.&quot;&#125; Jinja2过滤器Jinja2是Python的web开发中常用的模板语言，也被用于管理配置文件。Jinja2是Flask作者仿Django模板开发的模板引擎。但Jinja2具有更好的性能，更加灵活，具有很好的可读性。 格式化数据 强制定义变量对于未定义变量，Ansible默认行为是fail，也可关闭。 未定义变量默认值Jinja2提供一个有用default过滤器，设置默认变量值。比强制定义变量更好。 忽略未定义变量和参数可使用default过滤器忽略未定义的变量和模块参数 Jinja2的三种语法： 控制结构 1&#123;% %&#125; 变量取值 1&#123;&#123; &#125;&#125; 注释 1&#123;# #&#125; Jinja语法Jinja2控制结构： 1234&#123;% if ... %&#125;&#123;% elif ... %&#125;&#123;% else %&#125;&#123;% endif %&#125; Jinja2的for循环： 12&#123;% for .. in .. %&#125;&#123;% endfor %&#125; for循环中的特殊变量： 变量 描述 loop.index 当前循环的次数（从1开始计数） loop.index0 当前循环的次数（从0开始计数） loop.revindex 到循环结束的次数（从1开始计数） loop.revindex0 到循环结束的计数（从0开始计数） loop.first 如果是第一次迭代，为True loop.last 如果是最后一次迭代，为True loop.length 序列中的项目数 loop.cycle 在一串序列间取值的辅助函数 Jinja2的宏。类似函数，将行为抽象成可重复调用的代码块 123&#123;% macro input(name, type=&apos;text&apos;, value=&apos;&apos;) %&#125; &lt;input type=&apos;&#123;&#123; type &#125;&#125;&apos; name=&apos;&#123;&#123; name &#125;&#125;&apos; value=&apos;&#123;&#123; value &#125;&#125;&apos;&gt;&#123;% endmacro %&#125; 宏的调用： 123456&lt;p&gt;&#123;&#123; input(&apos;username&apos;, value=&apos;user&apos;) &#125;&#125;&lt;/p&gt;&lt;p&gt;&#123;&#123; input(&apos;password&apos;, &apos;password&apos;) &#125;&#125;&lt;/p&gt;相当于&lt;p&gt;&lt;input type=&apos;text&apos;, name=&apos;username&apos;, value=&apos;user&apos;&gt;&lt;/p&gt;&lt;p&gt;&lt;input type=&apos;password&apos;, name=&apos;password&apos;&gt;&lt;/p&gt; Jinja2继承。若Jinja2仅用于配置文件，则基本用不到继承功能，而在网页开发中，继承相当强大，常用于配置模板文件，在Django和Flask中会被大量使用，减少重复代码的开发编写，使html文件更加简洁易读。 1234567891011&#123;% block block块名 %&#125;&#123;% endblock block块名 %&#125; 在endblock中block块名可以不加，但为了阅读性最好加上在html文件的最前面应该添加要继承的模板文件&#123;% extends &quot;xxx.html&quot; %&#125;继承模板中指定块的内容&#123;% block xxx %&#125;&#123;&#123; super() &#125;&#125;&#123;% endblock %&#125; 过滤器 quote：给字符串加上引号 1&#123;&#123; str | quote &#125;&#125; default：为没有定义的变量提供默认值 1&#123;&#123; variable | default(&apos;xxxx&apos;) &#125;&#125; omit：忽略变量的占位符。常与dafault合用，当定义了参数时则会调用该参数，而若没有该参数时，则不会传入任何值 12345678&#123;&#123; variable | default(omit) &#125;&#125;例：- file: dest=&#123;&#123; item.path &#125;&#125; state=touch mode=&#123;&#123; item.mode|default(omit) &#125;&#125; with_items: - path: /tmp/demo1 # demo1没有设置mode，因此mode不会传入任何值。omit起到为有值的item项占位 - path: /tmp/demo2 # demo2的path和mode都有 mode: &quot;0664&quot; mandatory：强制变量必须定义，否则报错。Ansible默认若变量没有定义，则使用未定义的变量会报错。也可以在Ansible配置文件中修改参数error_on_undefined_vars = False，即使遇到未定义变量，也不会报错。若要强制约束一个变量必须定义，则可以使用mandatory。 1&#123;&#123; undefined_variable | mandatory &#125;&#125; bool：判断变量是否为布尔类型 1&#123;&#123; variable | bool &#125;&#125; ternary：Playbook的条件表达式。类似(A?B:C) 1&#123;&#123; 条件判断 | ternary(&quot;满足时采用的值&quot;, &quot;不满足时采用的值&quot;) &#125;&#125; basename、dirname、expanduser、realpath、relpath、splitext 123456&#123;&#123; path | basename &#125;&#125; 获取路径中的文件名&#123;&#123; path | dirname &#125;&#125; 获取文件的目录&#123;&#123; path | expanduser &#125;&#125; 当前用户目录&#123;&#123; path | realpath &#125;&#125; 获取链接文件所指文件的真实路径&#123;&#123; path | relpath &#125;&#125; 获取相对于某一根目录的相对路径&#123;&#123; path | splitext &#125;&#125; 把文件名用点号分割成多个部分 123456789101112131415161718 vars: conf_path: &quot;/etc/httpd.conf&quot; yml_path: &quot;~/a.yml&quot; tasks: - debug: msg=&quot;&#123;&#123; conf_path | basename &#125;&#125;&quot; - debug: msg=&quot;&#123;&#123; conf_path | dirname &#125;&#125;&quot; - debug: msg=&quot;&#123;&#123; yml_path | expanduser &#125;&#125;&quot; - debug: msg=&quot;&#123;&#123; yml_path | realpath &#125;&#125;&quot; - debug: msg=&quot;&#123;&#123; yml_path | relpath(&apos;/home&apos;) &#125;&#125;&quot; - debug: msg=&quot;&#123;&#123; conf_path | splitext &#125;&#125;&quot; 执行结果： &quot;msg&quot;: &quot;httpd.conf&quot; #/etc/httpd.conf的文件名 &quot;msg&quot;: &quot;/etc&quot; #/etc/httpd.conf文件所在目录名 &quot;msg&quot;: &quot;/root/a.yml&quot; #~/a.yml，用实际用户替代~ &quot;msg&quot;: &quot;/root/~/a.yml&quot; #仅对链接文件有效，指向真实文件的路径 &quot;msg&quot;: &quot;../root/~/a.yml&quot; #~/a.yml相对于指定路径的相对路径 &quot;msg&quot;: &quot;(u&apos;/etc/httpd&apos;, u&apos;.conf&apos;)&quot; #分隔文件与所在目录 若是Windows系统，Ansible提供的路径过滤器： 123&#123;&#123; path | win_basename &#125;&#125; # 获取文件名&#123;&#123; path | win_dirname &#125;&#125; # 获取文件所在目录路径&#123;&#123; path | win_splitdrive &#125;&#125; # 将路径分隔成多个部分 b64encode、b64decode、to_uuid、hash 123456&#123;&#123; string | b64encode &#125;&#125; # 将字符串转化为base64格式&#123;&#123; string | b64decode &#125;&#125; # 将字符串（base64格式）解码&#123;&#123; string | to_uuid &#125;&#125; # 将字符串转变为UUID&#123;&#123; string | hash(&apos;sha1&apos;) &#125;&#125; # 使用sha1求出字符串的哈希，还可用md5、blowfish求&#123;&#123; string | checksum &#125;&#125; # 使用checksum求哈希&#123;&#123; string | password_hash(&apos;&apos;) &#125;&#125; # 使用哈希算法求密码的hash 判断是否是合法IP地址。 1234&#123;&#123; ip_addr_str | ipaddr &#125;&#125; # 判断IP地址是否合法&#123;&#123; ip_addr_str | ipv4 &#125;&#125; # 返回ipv4地址&#123;&#123; ip_addr_str | ipv6 &#125;&#125; # 返回ipv6地址&#123;&#123; ip_addr_str | ipaddr(&apos;address&apos;) &#125;&#125; # 返回纯ip地址（不带掩码） to_datetime：字符串类型时间转换为时间戳 1&#123;&#123; date_str | to_datetime &#125;&#125; Json操作 1234567891011121314151617181920212223242526272829303132333435 vars: value: - key1: &quot;value1&quot; - key2: &quot;value2&quot; tasks: - name: outputfile /tmp/b.txt blockinfile: dest: /tmp/b.txt block: | &#123;&#123; value | to_json &#125;&#125; ------------------------ &#123;&#123; value | to_yaml &#125;&#125; ------------------------ &#123;&#123; value | to_nice_json &#125;&#125; ------------------------ &#123;&#123; value | to_nice_yaml &#125;&#125;执行结果：在指定的主机上查看/tmp/b.txt[&#123;&quot;key1&quot;: &quot;value1&quot;&#125;, &#123;&quot;key2&quot;: &quot;value2&quot;&#125;]------------------------- &#123;key1: value1&#125;- &#123;key2: value2&#125;------------------------[ &#123; &quot;key1&quot;: &quot;value1&quot; &#125;, &#123; &quot;key2&quot;: &quot;value2&quot; &#125;]------------------------- key1: value1- key2: value2 在Json对象中搜索符合条件的属性 12345678910111213141516 vars: host_group: cluster1: - name: &quot;host1&quot; - name: &quot;host2&quot; tasks: - debug: var=item with_items: &quot;&#123;&#123; host_group | json_query(&apos;cluster1[*].name&apos;) &#125;&#125;&quot; 执行结果：ok: [172.16.109.132] =&gt; (item=host1) =&gt; &#123; &quot;item&quot;: &quot;host1&quot;&#125;ok: [172.16.109.132] =&gt; (item=host2) =&gt; &#123; &quot;item&quot;: &quot;host2&quot;&#125; 测试变量，只返回true或false 1234567891011121314151617variable | match("正则表达式") 完全匹配，从头匹配到最后表达式中字段即可，并不是字段后还会匹配variable | search("正则表达式") 部分匹配，只要匹配字符串中包含该匹配字段即可 vars: url: "https://example.com/user/foo/resources/bar" tasks: - debug: msg="match 1 &#123;&#123;url | match("https://example.com/.*/resources/.*")&#125;&#125; " - debug: msg="match 2 &#123;&#123;url | match("/user/")&#125;&#125;" - debug: msg="match 3 &#123;&#123;url | match(".*/user")&#125;&#125;" - debug: msg="match 4 &#123;&#123;url | match("user/.*")&#125;&#125;" - debug: msg="match 5 &#123;&#123;url | search("foo")&#125;&#125;" 结果： "msg": "match 1 True " "msg": "match 2 False" "msg": "match 3 True" "msg": "match 4 False" "msg": "match 5 True" 比较版本 12345678910version | version_compare("要比较的版本号", "比较运算符") vars: version: "18.06" tasks: - debug: msg="does 12.04 &gt; version(18.06)? &#123;&#123;version | version_compare("12.04", "&gt;")&#125;&#125;" - debug: msg="does 19.04 &gt; version(18.06)? &#123;&#123;version | version_compare("19.04", "&gt;")&#125;&#125;"结果： "msg": "does 12.04 &gt; version(18.06)? True" "msg": "does 19.04 &gt; version(18.06)? False" 测试List包含关系，返回true或false 123456789101112list_1 | issuperset(list_2) list_1是否包含list_2list_2 | insubset(list_1) list_2是否是list_1的子列表 vars: list_1: ['a','b','c','d','e'] list_2: ['b','c'] tasks: - debug: msg="list_1 included list_2 &#123;&#123; list_1 | issuperset(list_2) &#125;&#125;" - debug: msg="list_2 is included in list_1 &#123;&#123; list_2 | issubset(list_1) &#125;&#125;"结果： "msg": "list_1 included list_2 True" "msg": "list_2 is included in list_1 True" 测试文件路径，返回true或false 123456789101112131415161718path | is_file 是否是文件path | is_dir 是否是目录path | is_link 是否是链接path | exists 是否存在 vars: path_1: /root/a.yml path_2: /etc tasks: - debug: msg="a.yml is file &#123;&#123;path_1|is_file&#125;&#125;" - debug: msg="/etc is dir &#123;&#123;path_2|is_dir&#125;&#125;" - debug: msg="a.yml is link file &#123;&#123;path_1|is_link&#125;&#125;" - debug: msg="/etc exists &#123;&#123;path_2|exists&#125;&#125;"结果： "msg": "a.yml is file True" "msg": "/etc is dir True" "msg": "a.yml is link file False" "msg": "/etc exists True" 测试命令执行结果，返回true或false 123456789101112131415161718result | failed # 是否失败result | changed # 是否改变result | success # 是否成功result | skipped # 是否跳过 tasks: - shell: ls register: result ignore_errors: true - debug: msg="execute failed? &#123;&#123; result|failed &#125;&#125;" - debug: msg="execute changed? &#123;&#123; result|changed &#125;&#125;" - debug: msg="execute success? &#123;&#123; result|success &#125;&#125;" - debug: msg="execute skipped? &#123;&#123; result|skipped &#125;&#125;"结果： "msg": "execute failed? False" "msg": "execute changed? True" "msg": "execute success? True" "msg": "execute skipped? False" Ansible-TowerAnsible Tower是中心化的ansible管理节点，管理员通过登录Tower来运行Playbook，无须与每台主机都建立ssh连接。 在Tower中还能实现权限管理、Playbook执行状态统计、REST API。ansible-tower下载。解压后查看其中的inventory文件 123456789101112131415161718[tower]localhost ansible_connection=local[database][all:vars]admin_password=&apos;&apos; # Tower管理员的密码pg_host=&apos;&apos;pg_port=&apos;&apos;pg_database=&apos;awx&apos; pg_username=&apos;awx&apos;pg_password=&apos;redhat&apos; rabbitmq_username=towerrabbitmq_password=&apos;&apos;rabbitmq_cookie=cookiemonster 参考资料 Ansible中文权威指南Ansible ：一个配置管理和IT自动化工具Ansible系列大神带你 20 分钟学会 Ansible！Ansible详解（一）Ansible详解（二） 朱双印个人日志-Ansible Linux集群与自动化运维 Ansible快速入门技术原理与实战]]></content>
      <tags>
        <tag>ansible</tag>
        <tag>运维</tag>
        <tag>监控</tag>
        <tag>自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS负载均衡学习笔记]]></title>
    <url>%2F2018%2F05%2F27%2FLVS%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇笔记包含以下内容 LVS原理 LVS集群的通用体系结构 三种IP负载均衡技术 LVS两种调度方式与八种算法 LVS持久连接 KeepAlived原理 LVS与KeepAlived搭建 NAT模式搭建 DR模式搭建 持久化配置 Keepalived配置 LVS原理LVS（Linux Virtual Server）Linux虚拟服务器是由章文嵩于1998年开发的负载均衡软件，提供传输层和应用层的负载均衡，传输层的负载均衡工具为IPVS，应用层的负载均衡工具为KTCPVS。 LVS集群的通用体系结构LVS集群采用三层结构： 负载调度器（load balancer）：整个集群的前端机，将网络请求无缝调度到真实服务器上，使服务器集群的结构对客户透明。因为所有的操作都是在Linux内核完成的，调度开销很小，所以具有很高的吞吐率。 服务器池（server pool）：是一组真正执行客户请求的服务器。服务器池的结点数目是可变的，可以在服务器池中增加服务器来满足不断增长的请求负载。对大多数网络服务来说，请求间不存在很强的相关性，请求可以在不同的结点上并行执行。 共享存储（shared storage）：为服务器池提供一个共享的存储区，通常是数据库、网络文件系统或者分布式文件系统，这样很容易使得服务器池拥有相同的内容，提供相同的服务。需要一个分布式锁管理器（Distributed Lock Manager）来保证应用程序在不同结点上并发访问的一致性。 前端负载均衡器称为Director Server（DR），后端的实际服务器称为Real Server(RS)，IP虚拟服务器软件称为IP Virtual Server（IPVS），IPVS工作在Linux内核中。在调度器的实现技术中，IP负载均衡技术的效率是最高的。 LVS的几种IP地址 VIP：virtual IP，DR上接收外网数据包的网卡IP地址 DIP：director IP，DR上转发数据包到RS的网卡IP地址 RIP：real IP，RS的IP地址 CIP：client IP，客户端IP地址 为什么要用共享存储？共享存储是可选的，但若网络服务需要相同的内容，应该使用共享存储，否则无共享结构的代价会很大，每台服务器需要一样大的存储空间，任何更新需要涉及每一台服务器，系统的维护代价会非常高。分布式文件系统提供良好的伸缩性和可用性，分布式文件系统在每台服务器使用本地硬盘作Cache，可以使得访问分布式文件系统的速度接近于访问本地硬盘。 如何实现高可用性？调度器上有资源监测进程时刻监视各个服务器结点的健康状况，当服务器对ICMP ping不可达时或者网络服务在指定的时间内没有响应时，资源监测进程会通知内核将该服务器从调度列表中删除。一旦监测到服务器恢复工作，通知调度器将其加入调度列表，管理员也可通过命令随时向调度列表添加或移除服务器。调度器存在单点故障问题，因此需要对调度器进行主从备份，并用HeartBeat机制进行主从故障监测。当从调度器不能听得主调度器的心跳时，从调度器通过ARP欺骗 （Gratuitous ARP）来接管集群对外的VIP，同时接管主调度器的工作来提供负载调度服务。当主调度器恢复后，有两种恢复机制。第一种为主调度器自动变成从调度器（类似抢占），另一种为从调度器释放VIP，主调度器收回VIP继续提供负载调度服务。当主调度器失效时，主调度器上所有已建立连接的状态信息将丢失，已有连接会中断。客户需要重新连接从调度器，从调度器才会将新连接调度到各个服务器上。因此，调度器在内核中实现了一种高效同步机制，将主调度器的状态信息及时同步到从调度器。当从调度器接管时，绝大部分已建立的连接会持续下去。 三种IP负载均衡技术 VS/NAT：调度器重写请求报文的目标地址，根据预设算法，将请求分派给实际服务器，实际服务器在响应报文通过调度器时，报文的源地址被重写，再返回给客户。优点：节约IP地址，能对内部进行伪装缺点：效率低，返回给请求方的流量需经过DR且请求和响应报文都要DR进行地址的重写，当客户端请求增多时，DR的处理能力会成为瓶颈完整过程： PC向调度器发送请求报文，调度器收到后根据调度算法选择后端的实际服务器，将报文中目的IP与目的端口改写为实际服务器的IP地址与端口，并进行转发。 实际服务器收到后，进行处理，将结果返回给调度器 调度器再将源IP地址与源端口改回为调度器的IP和端口，回复给PC。 数据包流向：客户端—&gt;调度器—&gt;实际服务器—&gt;调度器—&gt;客户端 VS/TUN（IP Tunneling）：调度器将请求报文通过IP隧道转发到实际服务器，实际服务器将响应报文直接回复给客户，调度器仅需处理请求报文，将请求报文的地址重写，无需重写响应报文的地址，极大解放了调度器，集群系统的最大吞吐量能提高10倍。 IP隧道技术：又称为IP封装技术，可以将带有源和目标IP地址的数据报文使用新的源和目标IP进行第二次封装，这样这个报文就可以发送到一个指定的目标主机上 由于多个RS都共享一个隧道IP（为VIP），所以需要通过ARP进行IP地址解析出MAC，而为了不让RS响应ARP请求导致出现错误，必须对RS进行抑制操作，这样只有DR进行ARP响应，也就让PC认为DR就是实际服务器。 注：由于调度器不会对IP报文进行修改，所以TCP报文中的目的端口也不会修改，因此要求RS与DR的端口号必须一致 完整过程： PC发送请求给调度器，调度器进行调度算法选择后端的实际服务器，将原报文进行第二次封装，源地址变为DIP，目的地址变为RIP，然后通过IP隧道发给指定实际服务器。 实际服务器处理完数据后直接回复给PC 实际服务器的RIP和DR的DIP可以不处于同一物理网络中，且RIP必须可以和公网通信，即集群节点可以跨互联网实现。实际服务器的隧道接口上需要配置VIP地址，以便接收DR转发的数据包，以及作为响应报文的源IP。DR给RS时需要借助隧道，隧道外层的IP头部的源IP是DIP，目标IP是RIP。而RS响应给客户端的IP头部是根据隧道内层的IP头分析得到的，源IP是VIP，目标IP是CIP。这样客户端就无法区分这个VIP到底是DR的还是服务器组中的。 VS/TUN模式一般会用来负载调度缓存服务器组，这些缓存服务器一般放置在不同网络环境，可以就近返回数据给客户端。在请求对象不能在缓存服务器本地找到的情况下，缓存服务器要向源服务器发请求，将结果取回，最后将结果返回给客户。 数据包流向：客户端—&gt;调度器—&gt;实际服务器—&gt;客户端 VS/DR（Direct Routing）：与VS/TUN类似，但调度器改写的是数据包的目的MAC地址，通过链路层进行负载分担。此法没有IP隧道的开销，但要求调度器与实际服务器必须在同一网段，也就是说RIP可用公网地址。 完整过程： PC向调度器发送请求，调度器根据调度算法选择后端实际服务器，将数据帧的目的MAC改写为该实际服务器的MAC地址，并转发。 实际服务器收到后处理完数据后直接将结果回复给PC 注：因为与VS/TUN类似，直接修改以太网帧，所以对于IP报文不会做修改，因此RS的端口号必须与DR一致。且RS上必须配置VIP（通过配置环回口IP地址），VIP为网卡别名的IP地址，仅用于回复数据包时使用作为源地址，不能用于通信。由于流出接口为RIP所在网卡接口，因此源MAC地址为RIP所在接口的MAC地址。且并不支持端口映射。 数据包流向：客户端—&gt;调度器—&gt;实际服务器—&gt;客户端 三种模式的比较DR和TUN模式的性能高于NAT，因为不需要DR对响应报文的操作DR性能高于TUN，因为不需要维护IP隧道DR中调度器和实际服务器必须在同一个网段中，TUN可实现跨网段负载均衡。 只有NAT支持端口映射，DR与TUN都不支持。 为什么VS/TUN与VS/DR要在环回口L0上配置VIP，能不能在出口网卡上配置VIP？在环回口上配置VIP使得RS能通过路由收到请求数据包，并将结果返回给客户。不可以将VIP配置在出口网卡上，否则真实服务器会响应客户端的ARP请求，客户端上的ARP表就会记录真实服务器的MAC，造成混乱，LB就失效了。必须保证路由器只保存DR上的VIP对应的MAC，即只允许DR进行ARP响应。在环回口配置VIP后，还需要设置arp_ignore=1和arp_announce=2来隐藏RS上的VIP。应该在配置VIP之前就设置arp参数，防止配置VIP后、设置arp抑制之前被外界主机发现。 arp_ignore：接收到ARP请求时的响应级别。默认为0。 0：响应目的地址是本地任意网卡上的所有IP地址的包 1：只响应目的地址恰好是入网卡的IP地址的包 arp_announce：将自己的地址向外通告时的通告级别。默认为0。 0：使用本地任意接口上的任意地址向外通告 1：尽量避免使用本地属于对方子网的IP地址向外通告 2：总是使用最佳本地地址向外通告 arp_announce为2的含义：在此模式下将忽略这个IP数据包的源地址并尝试选择能与该地址通信的本地地址。首要是选择所有网络接口的子网中包含该数据包目标IP地址的本地地址，如果没有发现合适的地址，将选择当前的发送网络接口或其他有可能接收到该ARP回应的网络接口来进行发送。 且这两项对所有参与集群调度的网卡都要设置 123456sysctl -w net.ipv4.conf.all.arp_ignore=1sysctl -w net.ipv4.conf.ens33.arp_ignore=1sysctl -w net.ipv4.conf.lo.arp_ignore=1sysctl -w net.ipv4.conf.all.arp_announce=2sysctl -w net.ipv4.conf.ens33.arp_announce=2sysctl -w net.ipv4.conf.lo.arp_announce=2 IPVS如何解决HTTPS连接问题？当客户访问HTTPS服务时，会先建立一个SSL连接，来交换对称公钥加密的证书并协商一个SSL Key，来加密以后的会话。在SSL Key的生命周期内，后续的所有HTTPS连接都使用这个SSL Key，所以同一客户的不同HTTPS连接也存在相关性。IPVS调度器提供了持久服务的功能，使得在设定的时间内，来自同一IP地址的不同连接会被发送到集群中同一个服务器结点，可以很好地解决客户连接的相关性问题。 可伸缩的缓存服务调度器一般使用IP隧道方法（VS/TUN）来架构缓存集群，因为缓存服务器可能在不同地方，而调度器与缓存服务器池可能不在同一个物理网段。若请求对象不能在本地找到，缓存服务器会向源服务器发请求，将结果取回并返回给客户。使用此方法，调度器只调度网页缓存服务器，而缓存服务器将响应数据直接返回给客户，调度器只需要调度一次请求，其余三次都由缓存服务器直接访问Web服务器完成。缓存服务器间有专用的组播通道，通过ICP（Internet Cache Protocol）协议交互信息。当一台Cache服务器在本地硬盘中未命中当前请求时，它可以通过ICP查询其他Cache服务器是否有请求对象的副本，若存在，则从邻近的Cache服务器取该对象的副本，这样可以进一步提高Cache服务的命中率。 可伸缩邮件服务服务器池有LDAP服务器和一组邮件服务器，调度器将SMTP、POP3、IMAP4和HTTP/HTTPS请求流负载较均衡地分发到各邮件服务器上。系统中可能的瓶颈是LDAP服务器，可对LDAP服务中B+树的参数进行优化。若分布式文件系统没有多个存储结点间的负载均衡机制，则需要相应的邮件迁移机制来避免邮件访问的倾斜。 LVS两种调度方式与八种算法两种调度方式 静态调度：仅根据调度算法进行调度，不管实际服务器的系统负载 动态反馈调度：会根据实际服务器的系统负载及性能，计算出可以调度的服务器对象 八种算法 静态调度 轮询（Round Robin）：调度器将请求根据调度算法按顺序轮流分配到实际服务器。调度器均等地对待每一台服务器，不管服务器上实际的连接数和系统负载。 加权轮询（Weighted Round Robin）：根据实际服务器的不同处理能力调度访问请求。使处理能力强的服务器处理更多访问流量，调度器自动询问实际服务器负载情况，并动态调整权值。 目标地址散列（Destination Hashing）：将请求的目标地址作为散列键，从静态分配的散列表中找出对应的服务器。 源地址散列（Source Hashing）：将请求的源地址作为散列键，从静态分配的散列表中找出对应服务器。 动态反馈调度 最少连接（Least Connections）：动态将网络请求调度到已建立的连接数最少的服务器上。计算方法：活跃连接数active*256+非活跃连接数inactive 加权最少连接（Weighted Least Connections）：当集群中服务器性能差异较大的情况下使用。具有较高权值的服务器将承受较大比例的活动连接负载。调度器可以自动问询真实服务器的负载情况并动态调整权值。此算法为默认调度算法。计算方法：(active*256+inactive)/weight 基于局部性最少连接（Locality-Based Least Connections）：针对IP地址的负载均衡，用于缓存集群系统。根据请求的IP地址找出该目标IP地址最近使用的服务器，若该服务器不可用，则用最少连接原则选出一个可用的服务器。该算法维护的是从一个目标IP地址到一台服务器的映射。 带复制的基于局部性最少连接（Locality-Based Least Connections with Replication）：针对IP地址的负载均衡，根据请求的目标IP地址找出与之对应的服务器组，按最小连接原则选出一台服务器。若该服务器超载，就在集群中按最小连接原则选出一台服务器，添加到服务器组中。该算法维护的是从一个目标IP地址到一组服务器的映射。 LVS持久连接无论使用哪种算法，LVS持久化都能实现在一定时间内，将来自 统一客户端请求派发到此前访问过的RS。 需要持久连接的原因：若连接是基于SSL的，则在建立连接时需要交换密钥，认证CA等操作，若每次刷新就又分配别的RS，则会造成资源浪费，速度变慢，因此需要持久连接。 每一次建立连接后，DR会在内存缓冲区中为每一个客户端与RS建立映射关系（该记录也称“持久连接模板”），并且能做到对同一客户端的所有请求（不局限于一个服务）都定位到一台RS。 持久连接分类： PPC（Persistent Port Connections）持久端口连接：将来自同一客户端对同一个集群的请求都定向到先前访问的RS上。 PCC（Persistent Client Connections）持久客户端连接：将来自同一客户端对同一个集群所有端口（即所有服务）的请求都定向到先前访问的RS上。 PNMPP（Persitent Netfilter Marked Packet Persistence）持久防火墙标记连接：通过防火墙策略，将对某类服务几个不同端口的访问定义成一类。 先对某一特定类型的数据包打上标记，然后再将基于某一类标记的服务送到后台的RS上去，后台的RS并不识别这些标记。将持久和防火墙标记结合起来就能够实现端口姻亲功能，只要是来自某一客户端的对某一特定服务（可以是不同端口）的访问都定向到同一台RS上。 KeepAlived原理KeepAlived用于RS的健康状态检查与LB主从之间的故障转移（Failover）实现。 Keepalived实现了一组健康检查器，根据其健康状况动态自适应地维护和管理负载平衡的服务器池，支持4、5、7层协议的健康检查。使用VRRP实现高可用性，VRRP是路由器故障转移的基础实现方法。此外，keepalived实现了一组到VRRP有限状态机的挂钩，提供低级别的高速协议交互。每个Keepalived框架可以独立使用或一起使用，以提供弹性基础设施。 Keepalived采用纯ANSI/ISO C编写，围绕一个中央I/O多路复用器提供实时网络设计（Realtime Networking Design）。设计重点是在所有元素之间提供均匀的模块化功能。 为了确保鲁棒性和稳定性，守护进程keepalived分为3个不同的进程： 一个精简的父进程负责分支子进程的监控 两个子进程，一个负责VRRP框架，另一个负责健康检查 每个子进程都有自己的调度I/O多路复用器，这样VRRP调度抖动得到了优化，因为VRRP调度比健康检查更关键。这种拆分设计可最小化健康检查外部库的使用情况，并将其自身行为降至最低，使主机闲置，从而避免由其本身造成的故障。 父进程监视框架称为Watchdog，每个子进程打开一个套接字，当守护进程引导时，父进程连接到套接字并向子进程周期（5s）发送hello包。若父进程无法向子进程套接字发送hello，则只要重启子进程即可。 Watchdog设计的优点：从父进程发送到子进程的hello数据包通过I/O多路复用器调度程序完成，这样可以检测到子进程调度框架中的死循环并能通过使用sysV信号来检测死亡的子进程。 Keepalived使用四个Linux内核组件： LVS框架：使用getsockopt和setsockopt调用来获取和设置套接字上的选项。 Netfilter框架：支持NAT和伪装（Masquerading）的IPVS代码。 Netlink接口：设置和删除网络接口上的VRRP虚拟IP。 组播：通过组播地址224.0.0.18发送VRRP通告。 LVS与KeepAlived搭建首先在DR上安装依赖工具包libnl3-devel、popt-static，然后安装ipvsadm。ipvsadm是ipvs的命令行管理工具，可以定义、删除、查看virtual service和Real Server的属性。 可通过grep -i &#39;ip_vs&#39; /boot/config-内核版本号查看是否内核中编译了IPVS功能 ipvsadm的下载地址也可以通过yum安装，安装完成后启动并设置开机自启systemctl enable ipvsadm,systemctl start ipvsadm ipvsadm命令123456789101112131415161718192021222324252627282930313233ipvsadm选项中，大写选项管理虚拟服务virtual service，小写选项管理关联了虚拟服务的真实服务器RealServer1. 管理virtual service -A --add-service # 添加virtual service -t --tcp-service 服务器IP[:端口] # TCP服务 -u --udp-service 服务器IP[:端口] # UDP服务 -f --fwmark-service 防火墙标记 # 防火墙标记 -s --scheduler 算法 # 指定算法 -E # 修改，参数与-A一致 -D # 删除，参数与-A一致 -t|-u|-f -C # 清空所有虚拟服务（IPVS规则） -L # 查看所有虚拟服务 -n 数字格式显示主机地址和端口 --stats 显示更详细的统计信息（连接数、入站包、出站包量等） --rate 显示速率（每秒连接数CPS、每秒入站包个数InPPS、出站包个数OutPPS等）且是实时的 --timeout 显示会话超时时间（tcp、tcpfin、udp） -p 设置持久化连接时长 --persistent-conn 查看持久化连接情况 -c 显示当前IPVS的连接状况，实时的 --sort 排序，是实时的 -S # 保存IPVS规则，并输出到屏幕。可通过 &gt;文件，导入到文件 -R #载入之前的规则（要指定规则文件）。一般通过 &lt;文件，导入规则 2. 管理RealServer -a # 添加real server -r 指定RS的IP地址和端口 -g DR模式 -i TUN模式 -m NAT模式 -t|-u|-f -w 权重 -e # 编辑real server -d # 删除real server NAT模式搭建实验环境： Client：192.168.205.151 VIP：192.168.205.152 DIP：172.16.184.130 RIP1：172.16.184.131 RIP2：172.16.184.132 Client和RS都采用单网卡，但非同一网段。DR采用双网卡，一张连接Client，一张连接RS。且此实验RS要用host-only网卡，需要设置网关 route add default gw 172.16.184.130 确保Server3和Server4的网关配置生效，否则无法给Client连接。 注：一定要将网卡配置为静态IP地址，不能使用DHCP获取，否则配置的网关会自动消失。 12345678# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 172.16.184.130 0.0.0.0 UG 0 0 0 ens36172.16.184.0 0.0.0.0 255.255.255.0 U 100 0 0 ens36# ip route default via 172.16.184.130 dev ens36 172.16.184.0/24 dev ens36 proto kernel scope link src 172.16.184.131 metric 100 Client请求过程：Client向DR发请求包，VIP接收，经过ip_forward转发到DIP，然后根据算法选择RS，将数据包发往RS。RS响应过程：RS向DR发响应包，DR的DIP接收响应包，经过ip_forward转发到VIP，最后将包回复给Client。因为VIP与DIP不是一个网段，所以DR上要开启ip_forward，并且要注意iptables与ipvs不可同时配置。 echo &quot;net.ipv4.ip_forward=1&quot; &gt;&gt; /etc/sysctl.conf &amp;&amp; sysctl -p 在Server2上配置： 123ipvsadm -A -t 192.168.205.152:80 -s rripvsadm -a -t 192.168.205.152:80 -r 172.16.184.131 -mipvsadm -a -t 192.168.205.152:80 -r 172.16.184.131 -m 通过ipvsadm -nL查看LVS服务 1234567# ipvsadm -LnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.205.152:80 rr -&gt; 172.16.184.131:80 Masq 1 0 0 -&gt; 172.16.184.132:80 Masq 1 0 0 LVS需要服务器间的时间同步，因此需要在Server2上配置chronyd服务。修改/etc/chronyd.conf，添加更新源。然后chronyc sources -v自动同步。 然后在Server3和Server4的chronyd配置文件中修改更新源server 192.168.205.152 iburst并自动更新。 在Client上多次访问192.168.205.152，因为选择的算法是轮询，所以会有以下现象。 12345678# curl 192.168.205.152Server 3# curl 192.168.205.152Server 4# curl 192.168.205.152Server 3# curl 192.168.205.152Server 4 在Server2上查看ipvsadm -L --stats 1234567# ipvsadm -L --statsIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Conns InPkts OutPkts InBytes OutBytes -&gt; RemoteAddress:PortTCP server2:http 7 34 20 2235 2240 -&gt; server3:http 3 14 8 918 896 -&gt; server4:http 4 20 12 1317 1344 修改为wrr算法。在Server2上修改IPVS规则： 123ipvsadm -E -t 192.168.205.152:80 -s wrripvsadm -e -t 192.168.205.152:80 -r 172.16.184.131:80 -m -w 5ipvsadm -e -t 192.168.205.152:80 -r 172.16.184.132:80 -m -w 3 Client上访问几次，再在Server2上查看，可发现访问Server3和Server4的包数量比例大约为5:3 1234567# ipvsadm -L -nIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.205.152:80 wrr -&gt; 172.16.184.131:80 Masq 5 0 22 -&gt; 172.16.184.132:80 Masq 3 0 13 DR模式搭建环境： DR的VIP：172.16.246.140 DIP：172.16.246.134 RIP1：172.16.246.135 RS1的VIP：172.16.246.140 RIP2：172.16.246.136 RS2的VIP：172.16.246.140 一定要确保DR和RS在同一个交换机上，即都在同一个网段，以及VIP都要在同一个网段。 首先在DR上配置，创建网卡别名ens33:0 123456789# ifconfig ens33:0 172.16.246.140 netmask 255.255.255.0 broadcast 172.16.246.255 up # 这是临时的，切要确保地址都是静态的，否则过一段时间配的地址会自动删除# ifconfig ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.16.246.134 netmask 255.255.255.0 broadcast 172.16.246.255......ens33:0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.16.246.140 netmask 255.255.255.0 broadcast 172.16.246.255 ether 00:0c:29:bf:f9:0c txqueuelen 1000 (Ethernet) 在两个后端RS服务器上pingDR上的这两个地址，测试能够联通 然后在RS上配置IP地址，也确保为静态IP。并且需要将RS的内核参数arp_ignore和arp_announce分别调整。 123456sysctl -w net.ipv4.conf.all.arp_ignore=1sysctl -w net.ipv4.conf.ens33.arp_ignore=1sysctl -w net.ipv4.conf.lo.arp_ignore=1sysctl -w net.ipv4.conf.all.arp_announce=2sysctl -w net.ipv4.conf.ens33.arp_announce=2sysctl -w net.ipv4.conf.lo.arp_announce=2 然后在环回口上配置VIP，保证DR、RS的VIP相同。 12ifconfig lo:0 172.16.246.140 netmask 255.255.255.255 boardcast 172.16.246.140 up# 一定要设置netmask为255.255.255.255，否则连接可能出问题 并且配置路由 1234567route add -host 172.16.246.140 dev lo:0# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface172.16.246.0 0.0.0.0 255.255.255.0 U 100 0 0 ens33s3 0.0.0.0 255.255.255.255 UH 0 0 0 lo 在DR上篇配置路由route add -host 172.16.246.140 dev ens33:0 确保RS与DR的防火墙都放行了http以及对应端口。 在DR上配置LVS 123ipvsadm -A -t 172.16.246.140:80 -s wlcipvsadm -a -t 172.16.246.140:80 -r 172.16.246.135 -g -w 3ipvsadm -a -t 172.16.246.140:80 -r 172.16.246.136 -g -w 4 在宿主机上测试 12345678# curl 172.16.246.140# ipvsadm -L.... -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP s1:http wlc -&gt; rs1:http Route 3 0 13 -&gt; rs2:http Route 4 0 17 持久化配置仍使用DR配置的实验环境 只需要配置一条ipvsadm -E -t 172.16.246.140:80 -p 600 123456ipvsadm -L -n..... -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 172.16.246.140:80 wlc persistent 600 -&gt; 172.16.246.135:80 Route 3 0 0 -&gt; 172.16.246.136:80 Route 4 0 0 在宿主机上访问172.16.246.140，访问到的是RS2（即172.16.246.136），在查看DR上信息 1234567ipvsadm -L -n --persistent-connProt LocalAddress:Port Weight PersistConn ActiveConn InActConn -&gt; RemoteAddress:PortTCP 172.16.246.140:80 wlc persistent 600 -&gt; 172.16.246.135:80 3 0 0 0 -&gt; 172.16.246.136:80 4 1 0 4 # 可知RS2已有一个持久化连接 Keepalived配置实验环境： DR：172.16.246.134 DR-Backup：172.16.246.133 RS1：172.16.246.135 RS2：172.16.246.136 需要在DR和DR-backup上安装keepalived，可直接通过yum安装。 设置独立的keepalived日志，因为默认keepalived日志是记录在/var/log/messages中的。修改/etc/sysconfig/keepalived 12345678910111213# 有以下配置项# --vrrp -P 只运行vrrp子进程# --check -C 只运行健康检查子进程# --dont-release-vrrp -V 不会在守护进程停止时删除VIP和路由# --dont-release-ipvs -I 不会在守护进程停止时删除IPVS拓扑# --dump-conf -d 备份日志配置文件# --log-detail -D 记录详细日志信息# --log-facility -S syslog的号码0-7# 默认配置是只有-DKEEPALIVED_OPTIONS=&quot;-D&quot;# 添加-S 0KEEPALIVED_OPTIONS=&quot;-D -S 0&quot; 然后在/etc/rsyslog.conf中添加local0的配置local0.* /var/log/keepalived.log，重启rsyslog服务即可。 keepalived的配置文件/etc/keepalived/keepalived.conf，修改前最好备份。配置文件分为是三个部分：全局配置、VRRPd配置、LVS配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 此配置截取自默认配置，仅用于说明参数# 全局配置global_defs &#123; # 邮件报警功能，可以不要 notification_email &#123; acassen@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc # 告警邮箱地址 smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL # 标识keepalived服务器的字符串 vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0&#125;# VRRP实例配置vrrp_instance VI_1 &#123; state MASTER # 角色状态，master或backup interface eth0 # 定义vrrp绑定的接口，此网卡是面向集群的网卡 virtual_router_id 51 # VRID，同实例的该值必须相同 priority 100 # 优先级，值越大越高 advert_int 1 # 心跳信息发送间隔，单位秒 authentication &#123; # 认证方式 auth_type PASS # 密码认证 auth_pass 1111 # 密码，最多8个字符 &#125; virtual_ipaddress &#123; # VIP地址设置，只要master节点设置 192.168.200.16 &#125;&#125;# LVS虚拟服务配置virtual_server 10.10.10.2 1358 &#123; # VIP与端口 delay_loop 6 # 健康检查时间间隔 lb_algo rr # LB算法 lb_kind NAT # LB类型 persistence_timeout 50 # 持久化时长 protocol TCP sorry_server 192.168.200.200 1358 # 当所有RS都宕机时，请求发送到的服务器，一般就设为DR或本节点 real_server 192.168.200.2 1358 &#123; # RS的配置 weight 1 # 权重 HTTP_GET &#123; # 健康状况检查的检查方式 # 常见的有HTTP_GET|SSL_GET|TCP_CHECK|DNS_CHECK|MISC_CHECK url &#123; path /testurl/test.jsp # 状态检查url路径的是否健康 digest 640205b7b0fc66c1ea91c463fac6334d #健康状况需要状态码，可以是status_code、digest或digest+status_code #digest值用keepalived的genhash命令生成，一般使用status_code即可 status_code 200 &#125; connect_timeout 3 # 连接超时时间，若超时则认为RS可能宕机 nb_get_retry 3 # 重试次数，防止误判 delay_before_retry 3 # 重试时间间隔 &#125; &#125;&#125; 在DR上的配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960global_defs &#123; notification_email &#123; sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0&#125;vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 51 priority 120 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 172.16.246.141 # 虚拟IP，不能和真实IP一致，随便写就行 172.16.246.142 &#125;&#125;virtual_server 172.16.246.140 80 &#123; # 虚拟主机 delay_loop 6 lb_algo wlc lb_kind DR # LVS类型为DR persistence_timeout 50 protocol TCP sorry_server 172.16.246.134 80 # 配置RS全部挂掉后访问的服务器 real_server 172.16.246.135 80 &#123; # 后端RS weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 3 nb_get_retry 3 delay_before_retry 3 &#125; &#125; real_server 172.16.246.136 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 3 nb_get_retry 3 delay_before_retry 3 &#125; &#125;&#125; 可以将DR上的该配置文件传到Backup上，修改配置。 12345# 只要修改以下配置vrrp_instance VI_1 &#123; state BACKUP priority 100&#125; 都启动keepalived，使用命令keepalived或者systemctl start keepalived即可 可查看日志文件/var/log/keepalived.log 12345678910s1 Keepalived[42451]: Starting Healthcheck child process, pid=42452s1 Keepalived[42451]: Starting VRRP child process, pid=42453s1 Keepalived_healthcheckers[42452]: Initializing ipvss1 Keepalived_healthcheckers[42452]: Opening file &apos;/etc/keepalived/keepalived.conf&apos;.s1 Keepalived_vrrp[42453]: Registering Kernel netlink reflectors1 Keepalived_vrrp[42453]: Registering Kernel netlink command channels1 Keepalived_vrrp[42453]: Registering gratuitous ARP shared channels1 Keepalived_vrrp[42453]: Opening file &apos;/etc/keepalived/keepalived.conf&apos;.s1 Keepalived_healthcheckers[42452]: Activating healthchecker for service [172.16.246.140]:80s1 Keepalived_healthcheckers[42452]: Activating healthchecker for service [172.16.246.140]:80 Keepalived配置会自动创建ipvs策略，此时看ipvsadm -L已是keepalived的配置了 1234567# ipvsadm -L -nIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 172.16.246.140:80 wlc persistent 50 -&gt; 172.16.246.135:80 Route 1 0 0 -&gt; 172.16.246.136:80 Route 1 0 0 宿主机上访问服务 1234567&gt; curl 172.16.246.140RS2&gt; curl 172.16.246.140RS2&gt; curl 172.16.246.140RS2# 因为设置了持久化，一直访问RS2 此时停止RS2的httpd服务，再访问服务 12345&gt; curl 172.16.246.140RS1&gt; curl 172.16.246.140RS1# 成功切换到RS1 恢复RS2服务，在DR上停止keepalived。再访问服务，仍能访问，keepalived配置成功。 将后端RS的httpd全部关闭，然后再次访问，就会访问到DR的页面。 几种时间间隔： advert_int：vrrp主备间发送和接收心跳信息的时间间隔 delay_loop：健康状态检查的时间间隔 connect_timeout：连接RS的超时时间 nb_get_retry：一个节点不健康的判定重试次数 delay_before_retry：判定某节点可能宕机后等待的时间，之后重试连接 几种健康检查： TCP_CHECK：TCP连接来检查后端RS是否健康 HTTP_GET：获取指定页面检查RS是否健康（通过匹配digest、status_code） SSL_GET：类似HTTP_GET，但使用的HTTPS MISC_CHECK：加载自定义健康状态检查脚本来检查对象是否健康（脚本的返回值需要是0或1） DNS_CHECK：通过DNS检查RS是否健康 参考文档LVS中文官方文档骏马金龙LVS系列文章负载均衡的原理高性能网站构建实战Linux之虚拟服务器LVS搭建 lvs arp问题配置误区 LVS 集群中持久连接详解（PPC+PCC+PNMPP）]]></content>
      <tags>
        <tag>server</tag>
        <tag>负载均衡</tag>
        <tag>LVS</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Wireshark学习笔记]]></title>
    <url>%2F2018%2F05%2F18%2Fwireshark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于wireshark v2.4.5本篇包含以下内容 基本操作 抓包过滤器 高级功能 tshark命令使用 常用操作 基本操作两种过滤器： 捕获过滤器 Capture Filter：也称抓包过滤器，使用伯克利包过滤语言（BPF），依赖于BPF的库（libpcap，Winpcap），用于限制抓的包，即抓包前的设定 显示过滤器 Display Capture：用于限制已经抓的包的显示，即抓包后的设定 捕获过滤器 type（类型）限定词 host、net、port、portrange dir（方向）限定词 src、dst proto（协议）限定词 ether、arp、icmp、ip、tcp、udp、http、ftp 逻辑运算：&amp;&amp;或and（与）、||或or（或）、!或not（非）过滤器基本语法[protocol] [direction] [host] [value] [logical operations] [other expression] 捕获—&gt;捕获过滤器 有常用的语法案例 常用过滤表达式举例：ether tshark命令使用tshark是一个网络协议分析器。 它允许从实时网络捕获数据包数据，或从先前保存的捕获文件中读取数据包，将这些数据包的解码形式打印到标准输出或将数据包写入文件。TShark的本机捕获文件格式是pcapng格式，也是wireshark和各种其他工具使用的格式。 tshark参数选项： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859捕获接口: -i: -i &lt;interface&gt; 指定捕获接口，默认是第一个非本地循环接口 -f: -f &lt;capture filter&gt; 设置抓包过滤表达式，遵循libpcap过滤语法，在抓包的过程中过滤，如果是分析本地文件则用不到 -s: -s &lt;snaplen&gt; 设置快照长度，用来读取完整的数据包，因为网络中传输有65535的限制，值0代表快照长度65535，默认也是这个值 -p: 以非混合模式工作，只关心和本机有关的流量 -I: 在监控模式（monitor）抓包 -B: -B &lt;buffer size&gt; 设置缓冲区的大小，只对windows生效，默认是2M -y: -y&lt;link type&gt; 设置抓包的数据链路层协议，不设置则默认为-L找到的第一个协议，局域网一般是EN10MB等 -D: 打印接口的列表 -L: 列出本机支持的数据链路层协议，供-y参数使用捕获停止选项: -c: -c &lt;packet count&gt; 捕获n个包之后结束，默认捕获无限个 -a: -a &lt;autostop cond.&gt; ... duration:NUM 在num秒之后停止捕获 filesize:NUM 在numKB之后停止捕获 files:NUM 在捕获num个文件之后停止捕获捕获输出选项: -b &lt;ringbuffer opt.&gt; ... ring buffer的文件名由-w参数决定,-b参数采用test:value的形式书写 duration:NUM - 在NUM秒之后切换到下一个文件 filesize:NUM - 在NUM KB之后切换到下一个文件 files:NUM - 形成环形缓冲，在NUM文件达到之后RPCAP选项: remote packet capture protocol，远程抓包协议进行抓包； -A: -A &lt;user&gt;:&lt;password&gt;,使用RPCAP密码进行认证;输入文件: -r: -r &lt;infile&gt; 设置读取本地文件处理选项: -2: 执行两次分析 -R: -R &lt;read filter&gt;,包的读取过滤器，可以在wireshark的filter语法上查看；在wireshark的视图-&gt;过滤器视图，在这一栏点击表达式，就会列出来对所有协议的支持。 -Y: -Y &lt;display filter&gt;,使用读取过滤器的语法，在单次分析中可以代替-R选项; -n: 禁止所有地址名字解析（默认为允许所有） -N: 启用某一层的地址名字解析。“m”代表MAC层，“n”代表网络层，“t”代表传输层，“C”代表当前异步DNS查找。如果-n和-N参数同时存在，-n将被忽略。如果-n和-N参数都不写，则默认打开所有地址名字解析。 -d: 将指定的数据按有关协议解包输出,如要将tcp 8888端口的流量按http解包，应该写为“-d tcp.port==8888,http”;tshark -d. 可以列出所有支持的有效选择器。 输出选项: -w: -w &lt;outfile|-&gt; 设置raw数据的输出文件。这个参数不设置，tshark将会把解码结果输出到stdout,“-w -”表示把raw输出到stdout。如果要把解码结果输出到文件，使用重定向“&gt;”而不要-w参数。 -F: -F &lt;output file type&gt;,设置输出的文件格式，默认是.pcapng,使用tshark -F可列出所有支持的输出文件类型。 -V: 增加细节输出; -O: -O &lt;protocols&gt;,只显示此选项指定的协议的详细信息。 -P: 即使将解码结果写入文件中，也打印包的概要信息； -S: -S &lt;separator&gt; 行分割符 -x: 设置在解码输出结果中，每个packet后面以HEX dump的方式显示具体数据。 -T: -T pdml|ps|text|fields|psml,设置解码结果输出的格式，包括text,ps,psml和pdml，默认为text -e: 如果-T fields选项指定，-e用来指定输出哪些字段; -E: -E &lt;fieldsoption&gt;=&lt;value&gt;如果-T fields选项指定，使用-E来设置一些属性，比如 header=y|n separator=/t|/s|&lt;char&gt; occurrence=f|l|a aggregator=,|/s|&lt;char&gt; -t: -t a|ad|d|dd|e|r|u|ud 设置解码结果的时间格式。“ad”表示带日期的绝对时间，“a”表示不带日期的绝对时间，“r”表示从第一个包到现在的相对时间，“d”表示两个相邻包之间的增量时间（delta）。 -u: s|hms 格式化输出秒； -l: 在输出每个包之后flush标准输出 -q: 结合-z选项进行使用，来进行统计分析； -X: &lt;key&gt;:&lt;value&gt; 扩展项，lua_script、read_format，具体参见 man pages； -z：统计选项，具体的参考文档;tshark -z help,可以列出，-z选项支持的统计方式。 常用操作若不使用任何选项，会抓取第一个非回环网卡的所有网络包。若指定-i网卡，则只监听该网卡的流量 12345root@kali:~# tshark -i eth0 Capturing on &apos;eth0&apos; 1 0.000000000 192.168.80.139 → 192.168.80.2 DNS 69 Standard query 0xfe4e A baidu.com 2 0.000103735 192.168.80.139 → 192.168.80.2 DNS 69 Standard query 0x7c57 AAAA baidu.com 3 0.005903526 192.168.80.2 → 192.168.80.139 DNS 101 Standard query response 0xfe4e A baidu.com A 123.125.115.110 A 220.181.57.216 输出信息从左到右依次为： 1抓包开始时间 源IP 目的IP 协议 包长度 包信息 参考文章 [Wireshark命令行工具tshark详解(含例子)-01]]]></content>
      <tags>
        <tag>网络</tag>
        <tag>wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis基础学习笔记]]></title>
    <url>%2F2018%2F05%2F17%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇笔记主要包含以下内容 Redis介绍 Redis安装 Redis数据类型 排序 发布与订阅 事务 过期时间 持久化 Redis优化技术 管道 内部编码优化 性能测试 集群 管理 Redis配置文件常用参数 在Docker上搭建Redis FAQ Redis报错问题 Redis介绍Redis（Remote Dictionary Server）是由C语言写成的高性能key-value非关系型数据库。为了保证效率，Redis的数据都缓存在内存中，并周期性地将更新的数据写入磁盘，或将修改写入记录文件，在此基础上实现了主从同步。 Redis安装 因为Redis是由C语言写的，所以要装gcc。yum install gcc 安装jemalloc，用于动态内存分配，是malloc的一个优化版本yum install jemalloc 安装工具命令语言TCLyum install tcl 解压redis包到/usr/local，进入后make &amp;&amp; make install即可编译安装，可先make test检查是否出错 建立软连接，redis的命令都存放在/usr/local/redis/src/目录下1234ln -s /usr/local/redis/src/redis-server /bin/redis-serverln -s /usr/local/redis/src/redis-cli /bin/redis-cliln -s /usr/local/redis/src/redis-benchmark /bin/redis-benchmarkln -s /usr/local/redis/redis.conf /etc/redis.conf 如果可用内存十分小，最好要设置内核参数vm.overcommit_memory为1。 overcommit_memory指定了内核针对内存分配的策略： 0：内核将检查是否有足够可用内存供应用进程使用。若不足，会报错 1：内核允许分配所有物理内存，不管当前内存状态。 2：内核允许分配超过所有物理内存和swap之和的内存大小。 echo &quot;vm.overcommit_memory=1&quot; &gt;&gt; /etc/sysctl.conf并且sysctl -p redis命令 redis-server用于开启redis服务器端 1234[redis.conf文件路径] 设置配置文件路径，即可按照指定配置启动redis-server--[配置参数] 设置指定参数例：--port=6378-v 查看redis版本 redis-cli开启客户端命令行 123456-h [hostname] 指定要连接的redis服务器主机名，默认127.0.0.1-p [port] 指定服务器端口，默认6379-s [socket] 指定服务器socket，会覆盖主机名和端口-a [password] 设置连接redis服务器时要用的密码-u [uri] 设置服务器的URIshutdown 关闭redis 注：若要让redis默认在后台启动，可修改配置文件中daemonize 参数，若为no，则是前台启动，若为yes，则是后台启动 redis-check-aof与redis-check-rdb：用于检测持久化状态或进行修复 redis-cli基本操作exists [key] 查看键是否存在，存在返回1，否则返回0del [key] 删除键type [key] 返回键的数据类型keys [pattern] 返回符合指定匹配规则的键，支持glob风格通配符格式。rename [old-key] [new-key] 重命名键dbsize 返回当前数据库的键数量expire [key] [time] 指定键的生存时间（单位秒），返回1说明设置成功。未设置默认键的生存时间是无穷，会一直占用空间。ttl [key] 返回键的剩余生存时间，-1表示永久，-2表示不存在（已删除）select [db-num] 选择数据库编号 0为默认，从1开始会在端口后显示，最大为15，即最多有16个数据库。若超出范围，虽会显示该编号，但是仅会对15号数据库操作。 move [key] [db-num] 将指定键移动到指定数据库（不是复制）flushdb 删除当前数据库中所有键flushall 删除所有数据库的所有键 glob风格通配符 符号 含义 ? 匹配一个字符 * 匹配任意个字符 [] 匹配括号建的任一字符 Redis数据类型 字符串String：可包含任意数据，包括图片和序列化对象，单个值上限512MB 列表List：双向链表，通过push和pop从链表头部或尾部添加删除元素，因此即可用作栈也可用作队列，且都是双向的 哈希Hash：也称散列，字符串类型的键值对的映射表，适合存储对象，每个Hash可存储2^32-1个键值对。 新建的hash对象以zipmap来存储，zipmap本身不是hash table，但相比正常的hash，可以节省hash自身需要的元数据存储开销。 zipmap的增删改的复杂度都是O(n)，但是一般对象的field都不多，所以速度也较快。若field或value的大小超出一定限制，则redis会自动将zipmap替换为正常的hash实现。 可通过配置文件的hash-max-ziplist-entries和hash-max-ziplist-value设置限制大小，单位字节。默认entries设为512，value设为64 集合Set：字符串类型的无序集合，通过Hash表实现，所有操作的复杂度都为O(1)，最多可包含2^32-1个键值对 有序集合Sorted Set：也称ZSet，每个元素都会关联一个double类型的分数，称为权。redis正是通过权来为集合中的成员进行从小到大的排序。有序集合的成员是唯一的,但权却可以重复。 redis-cli操作 字符串set [key] [value] 设置键值 setnx [key] [value]：设置键值，若key已存在，则不会修改该值，并返回0 setex [key] [expire time][value]：设置键值以及有效时间 mset [key1] [value1] [key2] [value2] ... 同时设置多个键值 msetnx：设置多个键值，但若key存在，则不会修改值 get [key] 获取键值mget [key1] [key2] ...同时获取多个键的值getrange [key] [start] [end] 返回键中字符串值的子字符串setrange [key] [start] [end] 设置字符串值的子串值getset [key] [value] 设置键的值并返回旧值strlen [key] 返回该键的字符串值的长度incr [key] 设置键值自增，返回新值decr [key] 设置键值自减，返回新值incrby [key] [value] 设置键值自增指定value，返回新值descby [key] [value] 设置键值自减指定value，返回新值append [key] [value] 指定键追加值value，返回新值长度substr [key] [start] [end] 取字符串（字符编号从0开始） 列表lpush [list] [member1] [member2]... 在list头部添加元素rpush [list] [member1] [member2]... 在list尾部添加元素lpop [list] 在list头部删除元素，返回删除元素rpop [list] 在list尾部删除元素，返回删除元素 linsert [list] before|after [指定值][value]：在指定list的特定位置前或后添加字符串value lset [list][index][value]：设置指定下标的值 lrem [list][num][value]：删除list中num个和value值一致的值。若num&gt;0，则从头开始删，若num&lt;0，则从尾开始删，若num为0，删除全部 llen [list] 返回list的长度lindex [list] [index] 获取列表中对应索引的元素lrange [list] [start] [end] 返回list指定区间的元素（编号从0开始）ltrim [list] [start] [end] 截取list，只保留截取区间的元素 集合sadd [set] [member1] [member2]... 添加集合元素srem [set] [member1] [member2]... 删除集合元素 spop [set] [value]：删除指定value scard [set] 返回集合元素个数smove [set1] [set2] [value] 将指定元素从set1移到set2sismember [set] [value] 判断该元素是否属于指定集合smembers [set] 返回集合中所有元素 srandmember [set]：随机返回set中的一个值 sinter [set1] [set2] 返回集合的交集sinterstore [set3] [set1] [set2] 将集合的交集存储到set3集合中sunion [set1] [set2] 返回集合的并集sunionstore [set3] [set1] [set2] 将集合的并集存储到key3集合中sdiff [set1] [set2] 返回集合的差集sdiffstore [key3] [key1] [key2] 将集合的差集存储到key3集合中 有序集合zadd [key] [score1] [member1]... 向有序集合添加成员并设置权值zrem [key] [member] 删除集合元素zincrby [key] [incr] [member] 设置元素的增加值zrank [key] [member] 返回指定元素的下标（从小到大）zrevrank [key] [member] 返回指定元素的下标（从大到小）zrange [key] [start] [end] 返回集合的指定区间元素zrevrange [key] [start] [end] 返回集合的指定区间元素（逆序） zrangebyscore [key][start][end]：返回score在指定范围间的元素。可在最后添加参数withscores返回该元素的score zcount [key][start][end]：返回score在指定范围内的元素个数 zcard [key] 返回集合元素个数zscore [key] [member] 返回元素的权值zremrangebyrank [key] [start] [end] 删除集合中给定排名区间的元素 zremrangebyscore [key][start][end]：删除集合中score在指定范围内的元素 哈希hset [table] [column] [value] 设置字段column的值 hsetnx [table][column][value]：设置字段值，若字段存在则不会修改值，并返回0 hget [table] [column] 获取字段的值hmset [table] [column1] [value1]... 设置多个字段的值hmget [table] [column1] [column2]... 获取多个字段的值hincrby [table] [column] [incr] 字段增加指定值hexists [table] [column] 字段是否存在 hlen [table]：返回指定hash的字段数 hdel [table] [column]... 删除表中字段hdel [table] 删除表hkeys [table] 返回表的所有字段hvals [table] 返回表的所有值hgetall [table] 返回表的所有字段与值 排序Redis支持对list、set、sorted set的排序。sort [key] [BY partten][LIMIT offset count][GET pattern][ASC|DESC][ALPHA][STORE dstkey] sort默认排序为从小到大，若要按照字母顺序排可选择ALPHA选项，ALPHA可以和ASC DESC一起用。 在对有序集合类型排序时会忽略元素的分数，只针对元素自身的值进行排序。 123456789101112131415&gt; lpush list1 1 2 3 4&gt; sort list11) &quot;1&quot;2) &quot;2&quot;3) &quot;3&quot;4) &quot;4&quot;&gt; lpush list2 a b c A B C&gt; sort list2 alpha1) &quot;a&quot;2) &quot;A&quot;3) &quot;b&quot;4) &quot;B&quot;5) &quot;c&quot;6) &quot;C&quot; BY partten 设置条件进行排序 1&gt; sort list1 by a* LIMIT offset count 表示跳过前offset个元素，并获取之后的countge元素 1234&gt; sort list2 alpha limit 2 31) &quot;b&quot;2) &quot;B&quot;3) &quot;c&quot; GET pattern 发布与订阅发布/订阅是一种消息通信模式，主要目的是解除消息发布者与消息订阅者的耦合。 订阅者可以通过subscribe和psubscribe命令向redis server订阅自己感兴趣的消息类型，redis将消息类型称为频道(channel)。当发布者通过publish命令向redis server发送特定类型的消息时，该频道的全部订阅者都会收到此消息。这里消息的传递是多对多的。一个订阅者可以订阅多个频道,也可以向多个频道发送消息。publish [channel] [message]向指定频道发布信息subscribe [channel] 订阅频道实验：开启两个终端123456# 终端2&gt; SUBSCRIBE chan1Reading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;chan1&quot;3) (integer) 1 此时该终端处于订阅状态，该状态下客户端不可使用除subscribe、unsubscribe、psubscribe、punsubscribe以外的命令。在订阅频道后客户端会收到三种类型的回复，每种回复都包含三个值。第一个值为消息类型。有以下三种消息类型 subscribe：表示订阅成功的反馈信息。此时第二个值为订阅的频道名，第三个值为当前客户端订阅的频道数 1234# 终端21) &quot;subscribe&quot;2) &quot;chan1&quot;3) (integer) 1 message：表示接收到的消息。此时第二个值为产生消息的频道，第三个值为消息的内容另一个终端在该频道发布消息 123456# 终端1&gt; PUBLISH chan1 hello# 终端21) &quot;message&quot;2) &quot;chan1&quot;3) &quot;hello&quot; unsubscribe：表示成功取消订阅某个频道。此时第二个值为对应频道名，第三个值为当前频道数量。 12345# 频道2&gt; UNSUBSCRIBE chan11) &quot;unsubscribe&quot;2) &quot;chan1&quot;3) (integer) 0 unsubscribe命令可退订频道，若不指定频道则退订所有频道 按照规则订阅使用psubscribe订阅符合指定规则的频道。规则支持glob风格的通配符。123456789101112131415161718# 频道2&gt; PSUBSCRIBE chan*Reading messages... (press Ctrl-C to quit)1) &quot;psubscribe&quot;2) &quot;chan*&quot;3) (integer) 1# 频道1&gt; PUBLISH chan2 hello&gt; PUBLISH chan100 hello# 频道21) &quot;pmessage&quot;2) &quot;chan*&quot;3) &quot;chan2&quot;4) &quot;hello&quot;1) &quot;pmessage&quot;2) &quot;chan*&quot;3) &quot;chan100&quot;4) &quot;hello&quot; 频道2收到了任意以chan开头的频道的信息第一个值：表示该信息的通过psubscribe命令订阅得到的第二个值：订阅使用的通配符第三个值：收到消息的具体频道名第四个值：收到的消息内容 punsubscribe命令可退订规则，若不指定频道则退订所有规则，且只会退订由规则加入的频道，并不会退订subscribe加入的频道。退订的规则必须严格匹配，与订阅时的一致。 发布订阅存在的问题： 如果订阅者读取消息的速度很慢，会使得消息不断积压在发布者的输出缓存区中，造成内存占用过多； 如果订阅者在执行订阅的过程中网络出现问题，那么就会丢失断线期间发送的所有消息。 事务事务的原理是先将属于一个事务的命令发送给Redis，使Redis依次执行这些命令。 使用multi开启事务，之后的所有操作都属于该事务，直到提交exec，在事务中若有失误，可通过discard回滚，取消事务中所有操作。使用事务可保证一个事务内不会有其他的客户端的命令的插入。123456789101112131415161718&gt; set num1 11OK&gt; set num2 abcOK&gt; set num3 111OK&gt; MULTIOK&gt; incr num1QUEUED&gt; incr num2QUEUED&gt; incr num3QUEUED&gt; exec1) (integer) 122) (error) ERR value is not an integer or out of range3) (integer) 112 可见，事务中若有错误命令，仅会影响该命令，不会影响接下来的命令的执行。 事务的所有操作都是在事务提交时操作并一起返回值的，而有时需要先获得一条命令的返回值，再根据这个值执行下一条命令，即前一条命令的返回值需要作为后一条命令的参数。于是需要另一条命令watch，用于监视一个或多个键，一旦其中一个键被修改了，之后的事务都不会执行，监控一直持续到事务提交1234567891011121314151617181920212223242526&gt; set key 1OK&gt; watch keyOK&gt; set key 2 # 由于这里key被修改，于是之后的事务不会执行OK&gt; multiOK&gt; incr keyQUEUED&gt; exec(nil)&gt; get key&quot;2&quot;# 若在开启监视后，事务开启前，该键未被修改，则事务中对该键的操作仍有效&gt; set key 1OK&gt; watch keyOK&gt; multiOK&gt; incr keyQUEUED&gt; exec1) (integer) 2 在执行exec后会取消对所有键的监视，若不想在执行事务中的命令也可使用unwatch命令取消监控。 过期时间在实际开发中会遇到有时效的数据，过了一定时间就应该清除，在Redis中可使用expire设置一个键的过期时间，到达该时间后Redis会自动删除该键。expire &lt;key&gt; &lt;time&gt; （时间单位：秒，且必须是整数）返回值为1表示设置成功，0表示未成功或键不存在。 若要设置更加精确的时间，可用命令pexpire，单位：毫秒。可使用ttl命令查看指定键的剩余时间。若该键被删除了，则返回值为-2，若未设置该键的过期时间，，则返回-1。可使用persist &lt;key&gt;命令取消设置指定键的过期时间，成功则返回1，否则（键不存在，或键原来就没有过期时间设置）返回0。 注：set或getset命令对键重新赋值也会清除过期时间。 若watch监视一个没有过期时间的键，该键到期自动删除后并不会被watch认为该键被修改。 命令expireat &lt;key&gt; &lt;time&gt; 用Unix时间作为过期时间（1970年1月1日到现在的秒数）命令pexpireat &lt;key&gt; &lt;time&gt;同上，但单位为毫秒 当Redis用作缓存系统时，可以限制Redis能够使用的最大内存，并让Redis按照一定规则淘汰不需要的缓存键。修改配置文件maxmemory参数，限制最大可用内存大小（单位：字节）。当超出限制后，Redis会根据maxmemory-policy参数指定的策略删除键直到Redis占用的内存小于指定内存。 以下为Redis提供的策略规则： 规则名 作用 volatile-lru 使用LRU算法删除一个键（只对设置了过期时间的键起作用） allkeys-lru 使用LRU算法删除一个键（会不断删除） volatile-random 随机删除一个键（只对设置了过期时间的键起作用） allkeys-random 随机删除一个键 volatile-ttl 删除过期时间最近的一个键 noeviction 不开启策略 LRU算法：Least Recently Used 最近最少使用。该算法认为最近最少使用的键在未来一段时间内也不会被用到，即当需要空间时这些键是可以被删除的。 注：实际上，Redis不会准确将整个数据库中最久未使用的键删除，而是每次从数据库中随机取5个键（可修改）并删除其中最久未被使用的键。随机取的键个数可通过配置文件的maxmemory-samples参数设置。默认为5个能产生最优的结果。10个最接近LRU算法的要求，但会消耗更多的CPU资源。3个会更快，但并不准确。 持久化redis为了内部数据安全考虑，会把数据以文件形式保存一份在硬盘中，服务器重启后会自动将数据还原到内存中，将数据保存到硬盘称为持久化。持久化分为以下两种： 快照持久化（snap shotting），也称RDB AOF持久化（append only file） RDB默认开启，一次性将所有数据保存在硬盘中，整个数据库只保存为一个文件，便于数据迁移，也便于数据库毁坏后的恢复。在开始初始化时，唯一要做到的只是fork出子进程，再由子进程完成持久化工作，极大避免了服务进程执行IO操作，而父进程仍然处理客户端的请求，实现性能最大化。相较于AOF，若数据集很大，RDB的启动效率会很高。 若要保证数据的高可用性，最大限度避免数据丢失，则不宜选择RDB。因为依靠子进程完成持久化，所以当数据集较大时，可能会导致整个服务器延时增大。 写时复制策略保证了在fork的时刻虽然生成了两份内存副本，但内存的占用量并不会增加一倍，因此需要确保linux系统允许应用申请超过可用内存的空间。可通过/etc/sysctl.conf中修改vm.overcommit_memory参数为1。 当快照时，若写入操作交到，造成fork前后差异较大，是会使内存使用量显著超过实际数据大小的，因为内存不仅保存了当前数据库数据，还保存了快照时的内存数据。 快照方式 根据配置规则自动进行快照redis目录中的dump.rdb就是快照持久化的数据备份文件。配置文件/etc/redis.conf的RDB参数1234567# 设置备份频率save 900 1 # 900秒中有一个键发生变化就触发RDB备份save 300 10 # 300秒中有10个键发生变化就触发RDB备份save 60 10000 # 60秒中有10000个键发生变化就触发RDB备份dbfilename dump.rdb # 备份数据库文件名dir ./ # 备份数据库文件存放位置 在RDB中可实现精细持续化，将每个修改的键保存，频率可达到秒级。 只有当快照结束时，新的rdb文件才会覆盖旧的文件，而在备份过程中，redis是不会修改原rdb文件的，即任何时刻rdb文件都是完整的。于是可通过定时备份rdb文件实现redis数据库备份。rdb文件是经过压缩的二进制格式，可通过配置文件的rdbcompression yes参数禁用来压缩节省CPU占用。 Redis启动后会读取RDB文件，将数据从硬盘载入内存。通常一个记录1000万个字符串类型键、大小为1GB的快照文件载入到内存中需要花费20-30秒。 使用save或bgsave命令快照save命令：Redis会同步进行快照，快照时会自动阻塞所有来自客户端的请求。若数据量大会导致Redis长时间无法访问，在生产环境中尽量不要用。bgsave命令：推荐使用，可在后台异步快照，快照时Redis仍能响应客户端请求。可通过lastsave命令查看快照是否完成，返回unix时间戳。 执行flushall命令Redis会清空数据库中所有数据。无论清空数据库过程中是否触发了自动快照条件，只要自动快照条件不为空，redis就会执行一次快照。若未指定自动快照条件，则flushall并不会执行快照。 执行复制（replication）时当设置了主从模式时，Redis会在复制初始化时自动执行快照，并生成RDB文件，并不需要定义快照条件或手动执行。 AOF将用户执行的写指令都备份到日志文件中，还原数据就是执行写指令。AOF可带来更高的数据安全性，即持久性。注：开启AOF持久化会清空redis数据库所有数据，所以若要选择AOF持久化，应该在安装完redis服务器后就要立刻开启。 Redis有三种同步策略：每秒同步，每修改同步，不同步。 每秒同步为异步持久化，效率高。若服务器突然宕机，则在这一秒中的数据会丢失。 每修改同步为同步持久化，每次数据发生变化就会立刻记录到磁盘中，效率低。 该机制对日志文件的写入操作采用append模式，即使在写入过程中出现宕机，也不会破坏日志中已写入的数据，在Redis重启后可通过命令redis-check-aof解决数据一致性问题。当日志过大时，Redis会自动启用重写rewrite机制，以append模式不断将修改数据写入老磁盘文件，并会创建一个新文件用于记录期间哪些修改命令被执行，保证了数据持久性。 对于相同数量的数据集，AOF文件通常比RDB文件大。AOF的运行效率通常慢于RDB，但其中每秒同步的效率较高。 配置文件/etc/redis.conf的AOF参数1234567891011# 若要开启AOF，将此项改为yesappendonly no # 还可设置AOF的备份文件位置appendfilename appendonly.aof# 设置同步机制，三种机制always，everysec，no。# always：每修改同步# everysec：每秒同步，默认# no：同步禁用appendfsync everysec AOF是将Redis客户端向Redis发送的所有命令全部记录下来，这就造成了有很多冗余无用的命令，如SELECT等也会记录，随着执行命令的增多，AOF文件的大小也会逐渐增大。因此，Redis提供了优化策略，可在配置文件中修改以下两个参数：auto-aof-rewrite-percentage 100：设置当目前AOF文件的大小超过上一次AOF文件大小的指定百分比时就会再次进行重写，若之前未重写过，则会根据启动时的AOF文件大小作依据。auto-aof-rewrite-min-size 64mb：限制允许重写的最小AOF文件大小。 若不满足重写条件，可通过命令bgrewriteaof手动重写。 Redis优化技术管道客户端使用TCP与服务器建立连接，若执行较多的命令，每个命令的往返时延累加起来对性能有一定的影响。在执行多个命令时每条命令都需要等待上一条命令执行完（即收到Redis的返回结果）才能执行。Redis支持管道（pipelining），可一次性发送多条命令并在执行后一次性返回结果。通过减少客户端与服务器的通信次数来实现降低往返时累计值。注：每一组中的命令都不能依赖之前命令的执行结果。 内部编码优化Redis为每种数据类型都提供了两种内部编码的方式，并且会自动根据实际情况进行编码的转变，对于开发者而言是透明的。其中一种为复杂度是O(1)的编码，而当键的元素个数大时，变会采用复杂度为O(n)的编码。可通过object encoding &lt;key&gt;查看指定键的编码方式。 Redis的每个键值都是使用一个redisObject的结构体保存的。12345678typedef struct redisObject &#123; unsigned type:4; unsigned notused:2; # not used unsigned encoding:4; unsigned lru:22; # lru时间 int refcount; # 存储某个键值被引用的数量 void *ptr;&#125;robj; 每个数据类型的编码 数据类型 内部编码方式 object encoding命令结果 字符串 REDIS_ENCODING_RAW “raw” REDIS_ENCODING_INT “int” REDIS_ENCODING_EMBSTR “embstr” 散列 REDIS_ENCODING_HT “hashtable” REDIS_ENCODING_ZIPLIST “ziplist” 列表 REDIS_ENCODING_LINKEDLIST “linkedlist” REDIS_ENCODING_ZIPLIST “ziplist” 集合 REDIS_ENCODING_HT “hashtable” REDIS_ENCODING_INTSET “intset” 有序集合 REDIS_ENCODING_SKIPLIST “skiplist” REDIS_ENCODING_ZIPLIST “ziplist” EMBSTR字符串编码方式与RAW类似，都是基于sdshdr实现。 字符串类型Redis使用sdshdr类型变量存储一个键值能被多个键引用，Redis会预先建立10000个分别存储从0到9999的redisObject型的变量对象，若设置的键值在10000以内，则该键就会直接引用这个共享对象，并不会再建立一个redisObject对象了。 当配置文件设定了macmemoryRedis可用最大空间后，就不会使用共享对象，因为对于每个键值都需要使用一个redisObject记录LRU信息 集群Redis集群主要用于防止单点故障，以及解决存储、性能瓶颈问题。 复制（主从）Redis提供的复制功能，可实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。因此，将数据库分为主数据库（master）与从数据库（slave）。主数据库可进行读写操作，当数据更新时将更新的数据同步到从数据库。而从数据库一般为只读操作，接收主数据库的同步数据。一个从数据库只能有一个主数据库。从数据库默认只读，若创建键会报错。 在一台主机上模拟主从数据库首先启动主数据库redis-server /etc/redis.conf然后可直接通过命令redis-server --port 6666 --slaveof 127.0.0.1 6379再打开一个数据库，并作为从数据库连接到从数据库redis-cli -p 6666并执行INFO replication，查看从数据库的信息1234567&gt; INFO replication# Replicationrole:slavemaster_host:127.0.0.1master_port:6379master_link_status:up...... 在主数据库上创建键，在从数据库上就能得到该键了。123127.0.0.1:6379&gt; set key1 123127.0.0.1:6666&gt; get key1&quot;123&quot; 也可通过修改数据库的配置文件将该数据库设为从数据库在redis从服务器上修改配置文件参数bind &lt;主服务器IP&gt;slaveof &lt;主服务器IP&gt; &lt;主服务器端口&gt;主数据库上不需要任何配置。 还可在一个已开启的数据库中输入命令slaveof &lt;ip-addr&gt; &lt;port&gt;将本数据库设为指定主数据库的从数据库。若该数据库已是其他数据库的从数据库了，则这条命令会取消与原主数据库的同步，而与新指定的主数据库同步。还可通过命令slaveof no one使当前数据库停止接收主数据库同步，并转变为主数据库。 主从同步流程： 当一个从数据库启动后，会向主数据库发送SYNC命令。 主数据库收到SYNC后，会在后台保存RDB快照，并将快照与缓存的命令都发送给从数据库。 从数据库收到后载入快照，并将执行缓存命令。1到3步称为复制初始化 复制初始化完成后，主数据库每当收到写命令后就会将命令同步到从数据库。 当主从数据库断开连接并重连后，Redis提供有条件的增量数据传输，主数据库只需将断线期间执行的命令传送给从数据库即可。 试验同步：先使用telnet伪装成一个从数据库与主数据库通信123# telnet 127.0.0.1 6379Trying 127.0.0.1...Connected to 127.0.0.1. 然后在从数据库中使用ping确认与主数据库的连接，若正常则主数据库会返回PONG。再输入REPLCONF listening-port 6666说明自己端口号。开始同步SYNC，此时telnet的界面会出现以下信息1234567* Slave 127.0.0.1:6666 asks for synchronization* Starting BGSAVE for SYNC with target: disk* Background saving started by pid 4079* DB saved on disk* RDB: 6 MB of memory used by copy-on-write* Background saving terminated with success* Synchronization with slave 127.0.0.1:6666 succeeded 默认从数据库会使用同步前的数据响应客户端请求，可以在从数据库上修改配置文件参数slave-serve-stale-data为no，使从数据库再同步完成前对所有命令都返回错误（除INFO和SLAVEOF）。复制同步阶段会贯穿整个主从同步始终，直到主从关系终止。 乐观复制：允许一定时间内主从数据库的内容不一致，但最终是会同步的。主从数据库的数据同步是异步的，会产生主从数据库数据不一致的时间窗口（即网络传输的时间加上命令执行的时间），因此，主数据库是不知道命令最终同步给多少个数据库的。Redis提供配置文件参数限制至少同步给的从数据库的数量时，主数据库才是可写的。min-slaves-to-write 3 表示有3个以上的从数据库连接到主数据库时，主数据库才是可写的。min-slaves-max-lag 10 表示允许从数据库失去与主数据库连接的最长时间。若从数据库最后一次与主数据库的联系（即发送replconf ack命令）的时间小于该值，则认为从数据库仍与主数据库连接，否则就断开主从连接。这一特性默认关闭。 图结构：从数据库不仅能从主数据库接收同步数据，还能再以自身作为主数据库，将数据再同步给下属的从数据库。 通过复制可实现读写分离，提高负载能力。往往读的频率大于写的频率，当单机的Redis无法应对大量读请求时，可通过复制建立多个从数据库节点，主数据库只进行写操作，从数据库负责读操作。 从数据库的持久化可通过复制建立一个或多个从数据库，并在从数据库启动持久化，在主数据库禁用持久化。当从数据库崩溃重启后主数据库会自动同步数据。当主数据库崩溃后则需要按照以下步骤进行恢复。121. 在从数据库中使用命令slaveof no one将从数据库提升为主数据库继续对外提供服务2. 启动崩溃的主数据库，再使用slaveof将其设置为新的主数据库的从数据库，再将数据进行同步。 当开启复制且主数据库关闭持久化功能时，不要使用supervisor等进程管理工具使主数据库崩溃后自动重启。同样当主数据库所在服务器因故关闭时，也要避免直接重启。因为主数据库重启后没有开启持久化功能，所以主数据库中所有数据都会被清空，而从数据库又会与从主数据库中同步数据，导致从数据库所有数据也被清空。 无硬盘复制Redis的复制是基于RDB方式持久化实现的，即主数据库端在后台保存RDB快照，从数据库接收并载入快照文件。缺点： 当主数据库禁用RDB快照后，如果执行复制初始化，Redis依然会生成RDB快照，所以下次启动后主数据库会以该快照恢复数据。因为复制发生的时间不能确定，这使得恢复的数据可能是任何时间点的。 因为复制初始化时需要在硬盘中创建RDB快照文件，所以如果硬盘性能很慢（如网络硬盘）时这一过程会对性能产生影响。举例来说，当使用Redis做缓存系统时，因为不需要持久化，所以服务器的硬盘读写速度可能较差。但是当该缓存系统使用一主多从的集群架构时，每次和从数据库同步，Redis都会执行一次快照，同时对硬盘进行读写，导致性能降低。 因此Redis引入了无硬盘复制选项，开启该选项时，Redis在与从数据库进行复制初始化时将不会将快照内容存储到硬盘上，而是直接通过网络发送给从数据库，避免了硬盘的性能瓶颈。 可修改配置文件中repl-diskless-sync参数为yes开启。 增量复制场景：当主从数据库连接断开后，从数据库会发送SYNC命令来重新进行一次完整复制操作。虽然断开期间数据库的变化很小，但也需要将数据库中的所有数据重新快照并传送一次。因此Redis实现了主从断线重连的情况下的增量复制。 增量复制是基于如下3点实现的。 从数据库会存储主数据库的运行ID（run id）。每个Redis运行实例均会拥有一个唯一的运行ID，每当实例重启后，就会自动生成一个新的运行ID。 在复制同步阶段，主数据库每将一个命令传送给从数据库时，都会同时把该命令存放到一个积压队列（backlog）中，并记录下当前积压队列中存放的命令的偏移量范围。 同时，从数据库接收到主数据库传来的命令时，会记录下该命令的偏移量。 当主从连接准备就绪后，从数据库会发送一条PSYNC命令来告诉主数据库可以开始把所有数据同步过夹了，格式为PSYNC 主数据库的运行ID断开前最新的命令偏移量。主数据库收到PSYNC命令后，会执行以下判断来决定此次重连是否可以执行增量复制。 首先主数据库会判断从数据库传送来的运行ID是否和自己的运行ID相同，确保从数据库之前确实是和自己同步的。 然后判断从数据库最后同步成功的备今信移景是否在积压队列中，如果在则可以执行增量复制，并将积压队列中相应的命令发送给从数据库。如果此次重连不满足增量复制的条件，主数据库会进行一次全部同步。 增量复制的过程对开发者来说是完全透明的，唯一需要开发者设置的就是积压队列的大小了。主数据库可以正常地和旧版本的从数据库同步（通过接收SYNC命令），从数据库也可以与旧版本的主数据库同步（通过发送SYNC命令）。积压队列在本质上是一个固定长度的循环队列，默认情况下积压队列的大小为1MB，可以通过配置文件的rep1-backlog-size选项来调整。积压队列越大，其允许的主从数据库断线的时间就越长。根据主从数据库之间的网络状态，设置一个合理的积压队列很重要。因为积压队列存储的内容是命令本身，所以估算积压队列的大小只需估计主数据库可能执行的命令的大小即可。另一个配置参数是rep1-backlog-ttl，当所有从数据库与主数据库断开连接后，经过多久时间可以释放积压队列的内存空间，默认为1小时。 哨兵Redis提供哨兵实现自动化的系统监控和故障恢复功能，哨兵是一个独立的进程。哨兵有以下功能： 监控主数据库和从数据库是否正常运行。 主数据库出现故障时自动将从数据库转换为主数据库。 在一个主从Redis系统中，可使用多个哨兵进行监控任务以保证系统足够稳健。哨兵不仅能监控主从数据库，还能与其他哨兵互相监控。 哨兵实验1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283实验环境：system2 192.168.163.102主服务器：127.0.0.1 6379redis-server /etc/redis.conf 从服务器：127.0.0.1 6380 6381redis-server --port 6380 --slaveof 127.0.0.1 6379redis-server --port 6381 --slaveof 127.0.0.1 6379127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=6380,state=online,offset=266,lag=0slave1:ip=127.0.0.1,port=6381,state=online,offset=266,lag=0设置哨兵创建配置文件/etc/sentinel.conf，并添加以下内容：sentinel monitor MyMaster_1 127.0.0.1 6379 1sentinel monitor master-name ip port quoram# MyMaster_1为要监视的主数据库的名字，可自定义# 后面跟上主数据库的IP地址和端口号# 最后一个数字quoram表示最低通过票数# 配置哨兵时，只需要配置监视的主数据库即可，哨兵会自动发现主数据库下的所有从数据库。然后启动Sentinel进程redis-sentinel /etc/sentinel.conf启动哨兵后会报如下信息Sentinel ID is 33766bbd6ec93b3574240b6a4ac5c8ea498207d4+monitor master MyMaster_1 127.0.0.1 6379 quorum 1* +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ MyMaster_1 127.0.0.1 6379* +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ MyMaster_1 127.0.0.1 6379# +slave表示发现了从数据库然后在另一个终端中关闭主数据库在原终端中会出现一连串的以下信息* Connecting to MASTER 127.0.0.1:6379* MASTER &lt;-&gt; SLAVE sync startedError condition on socket for SYNC: Connection refused在过了一段时间（默认30s，可配置修改）后，会出现以下信息+sdown master MyMaster_1 127.0.0.1 6379+odown master MyMaster_1 127.0.0.1 6379 #quorum 1/1# +sdown 表示哨兵主观认为主数据库停止服务了# +odown 表示哨兵客观认为主数据库停止服务了# 此时哨兵执行故障恢复，挑选一个从数据库提升为主数据库然后会报出许多信息，下面列举出几条重要的信息+try-failover master MyMaster_1 127.0.0.1 6379+vote-for-leader 33766bbd6ec93b3574240b6a4ac5c8ea498207d4 1......+failover-end master MyMaster_1 127.0.0.1 6379+switch-master MyMaster_1 127.0.0.1 6379 127.0.0.1 6380+slave slave 127.0.0.1:6381 127.0.0.1 6381 @ MyMaster_1 127.0.0.1 6380+slave slave 127.0.0.1:6379 127.0.0.1 6379 @ MyMaster_1 127.0.0.1 6380# +try-failover 表示哨兵开始故障恢复# +failover-end 表示哨兵完成故障恢复，故障恢复步骤包括领头哨兵选举、备份从数据库的选择等# +switch-master 表示主数据库从6379端口迁移到6380，即6380端口的从数据库提升为主数据库# 两个+slave，原主数据库变为了现主数据库的从数据库，但此时6379的数据库并未启动，说明哨兵并不会清除已停止服务的实例的信息再次登录上127.0.0.1:6380127.0.0.1:6380&gt; info replication# Replicationrole:masterconnected_slaves:1slave0:ip=127.0.0.1,port=6381,state=online,offset=99027,lag=1# 因为6379端口数据库未启动，所以此时只有一个从数据库然后重启6379端口数据库-sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ MyMaster_1 127.0.0.1 6380+convert-to-slave slave 127.0.0.1:6379 127.0.0.1 6379 @ MyMaster_1 127.0.0.1 6380# -sdown 表示实例6379已恢复服务（与+sdown相反）# +convert-to-slave 表示将6379端口实例设置为6380端口实例的从数据库。在6379端会报以下信息：SLAVE OF 127.0.0.1:6380 enabled再在6380端查看127.0.0.1:6380&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=6381,state=online,offset=541686,lag=0slave1:ip=127.0.0.1,port=6379,state=online,offset=541686,lag=0 一个哨兵节点可同时监控多个Redis主从系统，只要提供多个sentinel monitor配置即可。多个哨兵节点也可监控一个主从系统。 sentinel.conf配置文件的其他配置12# sentinel down-after-milliseconds 主数据库名 值# 这条参数用于设置哨兵发送ping命令检测数据库节点状态的周期时间，单位为毫秒 当超过该参数时间而未收到回复后，则哨兵认为该节点主观下线。若该节点为主数据库，则哨兵会进一步判断是否需要故障恢复。哨兵会向其他节点发送sentinel is-master-down-by-addr命令询问其他节点是否他们也认为主数据库主观下线，当赞同的节点达到指定数目后，哨兵会认为主数据库客观下线，并进行故障恢复。这个指定数目就是sentinel.conf中sentinel monitor最后一项数值quoram。 哨兵启动后，会与要监控的主数据库建立两条连接。一条连接用来订阅该主数据的_sentinel_:he11o频道以获取其他同样监控该数据库的哨兵节点的信息，另外哨兵也需要定期向主数据库发送INFO等命令来获取主数据库本身的信息。 哨兵创建后与立刻做的事情：发送INFO命令获得当前数据库的相关信息（包括运行ID、复制信息等）从而实现新节点的自动发现。哨兵向主数据库发送INFO命令，通过解析返回结果来得知从数据库列表，而后对每个从数据库同样建立两个连接。至此，与主数据库的连接建立成功。 和主数据库的连接建立完成后，哨兵会定时执行下面3个操作。 每10秒哨兵会向主数据库和从数据库发送INFO命令。 每2秒哨兵会向主数据库和从数据库的_sentinel_:hel1o频道发送自己的信息。发送的消息内容为：&lt;哨兵IP&gt;，&lt;哨兵port&gt;，&lt;哨兵运行ID&gt;，&lt;哨兵配置版本&gt;，&lt;主数据库名&gt;，&lt;主数据库IP&gt;，&lt;主数据库port&gt;，&lt;主数据库配置版本&gt; 每1秒哨兵会向主数据库、从数据库和其他哨兵节点发送PING命令。 选举领头哨兵的过程使用了Raft算法，过程如下： 发现主数据库客观下线的哨兵节点向每个哨兵节点发送命令，要求对方选自己为领头哨兵。 如果目标哨兵节点没有选过其他人，则会同意将该节点设为领头哨兵。 如果该节点发现有超过半数且超过该数值的哨兵节点同意选自己为领头哨兵，则此节点会成功成为领头哨兵。 当有多个哨兵节点同时参选领头哨兵，会出现没有一个节点当选的情况。此时参选节点会等待一个随机时间重新发起参选请求，进行下一轮直到选举成功。 故障恢复过程： 领头哨兵会从从数据库中挑选一个作为新的主数据库。 挑选的依据分为三点： 所有在线的从数据库中选择优先级最高的，优先级可通过配置文件slave-priority参数设置 若有多个最高优先级的从数据库，则复制的命令偏移量大的优先 若上述都相同，则运行ID小的优先 选出符合的从数据库后，会向该数据库发送slaveof no one使其提升为主数据库，然后再向其他数据库发送slaveof使其成为新的主数据库的从数据库。最后再更新数据记录，原的主数据库变为从数据库。 哨兵的部署方案： 每个节点部署一个哨兵 每个哨兵与其对应节点网络环境相同或相近 这样可以保证哨兵的视角具有代表性和可靠性。最好将quoram的值设为N/2+1（N为哨兵节点个数）。若每个节点都部署一个哨兵的话，可能会因为Redis不支持连接复用而造成产生大量冗余连接。 集群集群往往用于水平扩容。若要开启集群，只要将配置文件的cluster-enabled参数设为yes即可，默认开启。每个集群至少需要三个主数据库。 集群实验1234实验环境6个数据库，3个主数据库，3个从数据库三个主数据库端口分别为6000，6001，6002三个从数据库端口分别为6003，6004，6005 集群会将当前节点记录的集群状态持久化到指定文件，默认为当前目录下的nodes.conf，这里还是存放在/etc/nodes.conf，每个节点对应的文件必须不同，否则会启动失败，因此启动节点时要注意最后为每个节点使用不同的工作目录，或通过配置文件cluster-config-file 节点文件路径修改。最好给每个节点都创建一个目录，然后每个节点都复制一份配置文件，并修改port参数，cluster-config-file参数。然后通过redis-server 配置文件启动。使用ps查看，每个节点都是显示类似redis-server *:6000 [cluster]。然后进入节点123127.0.0.1:6000&gt; info cluster# Clustercluster_enabled:1 # 1说明集群启动正常 目前仅仅节点运行正常，但并未加入集群。需要使用redis的ruby插件。首先需要安装ruby，最好不要yum安装，应该下最新版本的源码包编译安装。安装完后可以在/usr/local/redis/src/目录下找到redis-trib.rb命令，创软链接。然后使用该命令初始化集群12345678910111213141516171819202122redis-trib.rb create --replicas 1 \ 127.0.0.1:6000 \ 127.0.0.1:6001 \ 127.0.0.1:6002 \ 127.0.0.1:6003 \ 127.0.0.1:6004 \ 127.0.0.1:6005# --replicas 1 表示每个主数据库拥有的从数据库个数为1会出现以下信息：&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:127.0.0.1:6000127.0.0.1:6001127.0.0.1:6002Adding replica 127.0.0.1:6004 to 127.0.0.1:6000Adding replica 127.0.0.1:6005 to 127.0.0.1:6001Adding replica 127.0.0.1:6003 to 127.0.0.1:6002......Can I set the above configuration? (type &apos;yes&apos; to accept):确认输入yes创建集群 通过redis-trib.rb创建集群的过程： 首先该命令会以客户端形式尝试连接所有节点，并发送ping确定节点正常，同时发送info获取节点运行ID、验证是否开启了集群 集群会向每个节点发送cluster meet IP地址 端口告诉当前节点指定的节点也是集群成员。 redis-trib.rb会分配主从数据库节点，分配原则为尽量保证每个主数据库运行在不同IP地址上，同时每个从数据库和主数据库都不运行在同一IP地址。 分配完成后，会为主数据库分配插槽，即分配哪些键归哪些节点复制。对每个要成为子数据库的节点发送cluster replicate 主数据库运行ID将当前节点转换为从数据库并复制指定主数据库。 1234567127.0.0.1:6000&gt; CLUSTER nodes5c15caa067f96e557d73704e961ee08504fe3ac1 127.0.0.1:6004@16004 slave b098c2ddc169cc6e5411e8c42fb5afa96fa91764 0 1531150828178 5 connected6808731e0d12e8ec740509ef060c81306d5cd9bd 127.0.0.1:6000@16000 myself,master - 0 1531150825000 1 connected 0-54608e885e28b530491468b76bb8084cf7c22a8166f4 127.0.0.1:6005@16005 slave 9de0340daaf29f81b32c96d8010e9e443d66be0b 0 1531150827000 6 connectedb098c2ddc169cc6e5411e8c42fb5afa96fa91764 127.0.0.1:6001@16001 master - 0 1531150825153 2 connected 5461-10922e219bc21f1ab59f4cf00ca1b35da84e955424556 127.0.0.1:6003@16003 slave 6808731e0d12e8ec740509ef060c81306d5cd9bd 0 1531150827000 4 connected9de0340daaf29f81b32c96d8010e9e443d66be0b 127.0.0.1:6002@16002 master - 0 1531150827169 3 connected 10923-16383 可通过cluster meet IP地址 端口向新节点发送使新节点加入集群当新节点收到该命令后，会根据命令中的IP地址和端口与目标建立握手连接，然后目标会认为此节点为集群中的一员，并使用Gossip协议（一种分布式系统通信协议）向集群中所有节点发送此节点的信息。 新节点加入集群后可进行以下操作： 使用cluster replicate复制每个主数据库，以从数据库运行 向集群申请分配插槽（slot）以主数据库运行 在一个集群中，所有键会被分配给16384个插槽，每个主数据库会负责处理其中一部分插槽。12345678910111213141516确认创建集群后的报出的信息&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:6000)M: 6808731e...... 127.0.0.1:6000 slots:0-5460 (5461 slots) master 1 additional replica(s)S: 5c15caa0...... 127.0.0.1:6004 slots: (0 slots) slave replicates b098c2d......S: 8e885e28...... 127.0.0.1:6005 slots: (0 slots) slave replicates 9de0340......M: b098c2dd...... 127.0.0.1:6001 slots:5461-10922 (5462 slots) master 1 additional replica(s)......由此也可看出，只有主数据库才会分配插槽，从数据库无插槽。 初始化集群时分配给每个节点的插槽是连续的，但实际上Redis没有限制，可将任意几个插槽分配给任意节点。 键与插槽的关系键名的有效部分通过算法计算出散列值并取16384的余数。使得每个键都可以分配到16384个插槽中，进而分配的指定的一个节点中处理。 有效部分：若键名包含大括号，则有效部分为大括号内的内容，若不包含大括号，则整个键名都是有效部分 12345678910111213141516171819202122232425262728293031323334可使用命令cluster slots查看插槽分配情况127.0.0.1:6000&gt; CLUSTER SLOTS1) 1) (integer) 0 2) (integer) 5460 3) 1) &quot;127.0.0.1&quot; 2) (integer) 6000 3) &quot;6808731e0d12e8ec740509ef060c81306d5cd9bd&quot; 4) 1) &quot;127.0.0.1&quot; 2) (integer) 6003 3) &quot;e219bc21f1ab59f4cf00ca1b35da84e955424556&quot;2) 1) (integer) 5461 2) (integer) 10922 3) 1) &quot;127.0.0.1&quot; 2) (integer) 6001 3) &quot;b098c2ddc169cc6e5411e8c42fb5afa96fa91764&quot; 4) 1) &quot;127.0.0.1&quot; 2) (integer) 6004 3) &quot;5c15caa067f96e557d73704e961ee08504fe3ac1&quot;3) 1) (integer) 10923 2) (integer) 16383 3) 1) &quot;127.0.0.1&quot; 2) (integer) 6002 3) &quot;9de0340daaf29f81b32c96d8010e9e443d66be0b&quot; 4) 1) &quot;127.0.0.1&quot; 2) (integer) 6005 3) &quot;8e885e28b530491468b76bb8084cf7c22a8166f4&quot;因为有3个master，所以有三条记录，每条记录中包含四个值：1) 插槽的开始号2) 插槽的结束号3) 所有负责该插槽的节点（第一个是主数据库，后面都是从数据库）。包含以下内容： 1) 节点的IP地址 2) 节点端口号 3) 节点运行ID 插槽的分配的情况 插槽之前没被分配过，现在想分配给指定节点 插槽之前被分配过，现在想移动到指定节点 将插槽分配给节点的过程 若是上述的第一种情况，即插槽未被分配过。使用cluster addslots [插槽号]....可分配多个插槽。 若被分配过则会报错(error) ERR Slot 100 is already busy 若是第二种情况，即插槽被分配过。redis-trib.rb提供简便迁移方法 redis-trib.rb reshard 目标IP地址:端口 其中reshard表示需要重新分片。1234567891011121314151617181920212223242526272829303132333435363738394041424344目标：将6000端口的插槽分1000个到6001端口redis-trib.rb reshard 127.0.0.1:6000# 然后会询问要迁移的插槽个数How many slots do you want to move (from 1 to 16384)? 1000# 询问要迁移到的节点ID（redis-trib.rb会给出，也可以进入数据库cluster nodes查看）What is the receiving node ID? b098c2ddc169cc6e5411e8c42fb5afa96fa91764# 询问从哪个节点开始移出插槽，输入6000端口节点的ID# 在结束输入后回车，并输入donePlease enter all the source node IDs. Type &apos;all&apos; to use all the nodes as source nodes for the hash slots. Type &apos;done&apos; once you entered all the source nodes IDs.Source node #1:6808731e0d12e8ec740509ef060c81306d5cd9bdSource node #2:done# 然后会要求再次确认，输入yesDo you want to proceed with the proposed reshard plan (yes/no)? yes# 再进redis查看cluster slots127.0.0.1:6000&gt; CLUSTER SLOTS1) 1) (integer) 1000 2) (integer) 5460 3) 1) &quot;127.0.0.1&quot; 2) (integer) 6000 3) &quot;6808731e0d12e8ec740509ef060c81306d5cd9bd&quot; 4) 1) &quot;127.0.0.1&quot; 2) (integer) 6003 3) &quot;e219bc21f1ab59f4cf00ca1b35da84e955424556&quot;2) 1) (integer) 0 2) (integer) 999 3) 1) &quot;127.0.0.1&quot; 2) (integer) 6001 3) &quot;b098c2ddc169cc6e5411e8c42fb5afa96fa91764&quot; 4) 1) &quot;127.0.0.1&quot; 2) (integer) 6004 3) &quot;5c15caa067f96e557d73704e961ee08504fe3ac1&quot;3) 1) (integer) 5461 2) (integer) 10922 3) 1) &quot;127.0.0.1&quot; 2) (integer) 6001 3) &quot;b098c2ddc169cc6e5411e8c42fb5afa96fa91764&quot; 4) 1) &quot;127.0.0.1&quot; 2) (integer) 6004 3) &quot;5c15caa067f96e557d73704e961ee08504fe3ac1&quot; 若不使用redis-trib.rb命令。也可通过cluster setslot命令分片。1234cluster setslot 插槽号 node 新节点运行ID例：若要将上面分好的1000个插槽迁移回到6000管理前提：插槽中没有任何键。因为这样迁移时并不会连同相应键一起迁移，会造成键的丢失。 可通过cluster getkeysinslot 插槽号 要返回的键的数量获取指定插槽中的键，以查看要迁移的插槽中是否存在键。然后把每个键迁移迁移到目标节点：123migrate 目标节点地址 目标节点端口 键名 数据库号 超时时间 [copy] [replace]`其中copy和replace可选，copy表示不会将键从当前数据库删除，只是复制。replace表示目标节点若存在同名键则覆盖。因为集群模式数据库只能使用0号数据库，所以数据库号始终是0 Redis还提供以下命令实现集群不下线的数据迁移：123456789clsuter setslot 插槽号 migrating 新节点运行IDcluster setslot 插槽号 importing 原节点运行ID迁移时若要把N号插槽从A迁移到B，需要如下操作在B执行cluster setslot N importing A在A执行clsuter setslot N migrating B在A执行cluster getkeysinslot N 获取N号插槽的键列表对列表的每个键都执行migrate命令执行cluster setslot 0 B 完成迁移 当客户端向集群中任一节点发送命令后，该节点都会判断相应键是否在当前节点，若在则立刻处理，若不在则返回一个MOVE重定向请求，告诉客户端目前负责该键的节点。返回的错误信息格式为：(error) MOVED 键所在的插槽号 IP地址:端口redis-cli也提供集群模式支持自动重定向，通过-c参数启动客户端。 集群中每个节点都会每隔1秒随机选5个节点，并选择其中最久无响应的节点发送一个ping，若超时无回复，则变为主观下线，进行判断，与哨兵类似。选择主数据库的过程也与哨兵一致，都使用Raft算法。若一个至少负责一个插槽的主数据库下线且无相应从数据库可进行故障恢复，则整个集群默认会进入下线状态无法工作。也可修改配置文件的cluster-require-full-coverage设为no，使集群在这种情况下继续工作。 管理安全可通过配置文件的requirepass参数设置密码，于是客户端每次连接数据库时必须发送密码验证，否则Redis会拒绝执行客户端发来的命令，会报错：(error)NOAUTH Authentication required。使用auth 密码验证。也可在redis中通过命令config set requirepass 密码设置密码。也可通过命令config get requirepass获取密码（已验证后才能看） 攻击者会通过穷举法破解Redis密码（1秒内可尝试十几万个密码）。 配置Redis复制时，若主数据库设置了密码，需要在从数据库的配置文件中通过masterauth参数设置验证密码，在从数据库连接主数据库时会自动auth验证。 Redis支持对命令的重命名，可在配置文件中的rename-command进行设置。格式为rename-command 命令 重命名后的命令。若要禁用某命令可直接将该命令重命名为空字符串即可。 通信协议Redis支持两种通信协议： 统一请求协议：二进制安全 简单协议：便于在telnet中输入（已废弃） 简单协议中提供五种telnet返回值表示形式已被封装到redis-cli中，而就成为了redis的返回形式。 错误回复error reply以-开头，并跟上错误信息，以\r\n结尾 状态回复status reply以+开头，跟上状态信息，以\r\n结尾 整数回复integer reply以:开头，跟上数值，以\r\n结尾 字符串回复bulk reply以$开头，跟上字符串长度，\r\n分隔，再跟上字符串内容，再以\r\n结尾。若返回值为空，会返回$-1 多行字符串回复multi-bulk reply以*开头，跟上字符串个数，\r\n分隔，再跟上字符串内容，再以\r\n结尾。 统一请求协议命令格式类似于多行字符串回复的格式，每个命令都可以包含二进制字符。Redis的AOF文件和主从复制时发送的内容都使用了统一请求协议。若发送命令set foo bar，则在传输中的写法为*3\r\n$3\r\nSET\r\n*3\r\n$3\r\nFOO\r\n*3\r\n$3\r\nBAR\r\n。 一些管理命令 耗时命令日志当一条命令执行时间超时后，Redis会将该命令的执行时间等信息加入耗时命令日志（slow log）。可通过配置文件的slowlog-log-slower-than参数设置该限制时间，单位为微秒（1s=10^6μs），默认为10000μs。耗时命令日志会存储在内存中，也可通过配置文件slowlog-max-len设置记录的最多条数，默认128。 可在rediscli中使用slowlog get获取当前耗时命令日志。每条日志由四个部分组成： 该日志的唯一ID 该命令执行的Unix时间 该命令的耗时时间，单位微秒 命令和参数 命令监控Redis提供monitor命令监控Redis执行的所有命令。在一个终端中输入monitor，便开始监视任何执行操作（该终端被挂起，不能执行命令）。123456789在第一个终端中输入127.0.0.1:6379&gt; MONITOROK在另一个终端中执行一条命令set foo bar于是在第一个终端中就会打印出以下内容1531104811.876088 [0 127.0.0.1:41664] &quot;COMMAND&quot;1531104820.923283 [0 127.0.0.1:41664] &quot;set&quot; &quot;foo&quot; &quot;bar&quot; monitor命令十分影响redis的性能，会降低近一半的负载能力，因此只适合进行排错和调试。 config get &lt;指定配置&gt;：获取服务器配置信息（就是配置文件中的参数）。 Redis配置文件常用参数按照配置文件中的出现顺序 bind &lt;IPaddr&gt;： 指定Redis只接收该地址的请求。默认接收所有IP地址的请求，这样会造成安全隐患，最好填写需要调用redis的服务器的IP地址，或者直接写127.0.0.1仅允许本地用户调用。 daemonize yes|no：是否在后台运行。默认在前台运行 pidfile：PID文件路径。若运行多个Redis，则需要在各自的配置文件中指定不同的PID文件路径和端口 port：Redis监听的端口，默认为6379 timeout：客户端连接超时时间，单位秒。若客户端在超时前没发出任何指令，则会关闭连接。 logfile：日志文件路径 loglevel：日志等级，分为四个：debug、verbose、notice、warning，默认为notice databases：数据库个数，默认设为16个 save &lt;seconds&gt; &lt;changes&gt;：redis进行备份的频率。在多少秒内进行几次更新操作，就会触发备份，将数据同步到RDB文件。详见持久化 rdbcompression yes|no：是否开启rdb备份时压缩，默认开启 dbfilename：rdb备份的文件名，默认为dump.rdb dir：rdb备份文件存放路径。路径和文件名要分开配置，因为Redis备份时会先将当前数据库的状态写入一个临时文件，等备份完成后再把该文件替换为指定文件。 slaveof &lt;masterip&gt; &lt;masteport&gt;：在从数据库上设置，指定主数据库 masterauth &lt;master-password&gt; ：当主数据库连接需要密码验证时，在此指定密码 requirepass：设置客户端连接后进行任何其他操作前需要的密码。 因为Redis速度快，所以外部用户可以每秒进行150000次密码尝试，若密码简单，很容易被破解。 maxmemory &lt;bytes&gt;：设置Redis最大能使用的内存，单位字节。当分配的内存完全被占用后，若再接收到set命令，则Redis会先删除设置了expire的键，无论是否到期。若所有expire的键都被删除了，则redis不再进行set操作，只允许get操作。此参数适合把redis当做类似Memcached缓存来使用 maxclients：限制同时连接的客户数。当连接数超过该值，则不再接收，并返回error。 appendonly yes|no ：默认情况下，redis会在后台异步把数据库镜像备份到此磁盘，但这样备份非常耗时，且不能很频繁，若断电会造成大量数据丢失。若开启appendonly，则redis会将接收到的每一次写操作追加到appendonly.aof中，当redis重启时，会从该文件恢复到之前的状态。但这样容易造成该文件过大。可通过指令BGREWRITEAOF对该文件整理。 appendfsync always|everysec|no：详见持久化 vm-enabled：是否开启虚拟内存支持。当内存不够时，会把value存放到交换区（swap）中。性能基本不受影响。同时要将vm-max-memory设置足够大以存放所有key vm-max-memory：开启虚拟内存后redis可用的最大内存大小，默认为0。在生产环境中，最好不要设为0，根据实际情况调整。 在Docker上搭建RedisFAQ Redis内存用完怎么办？ redis的性能会下降，并可能出错。可通过info查看redis内存使用情况，并写脚本进行监控。可通过配置文件maxmemory调整redis可用内存大小。若redis的内存使用达到上限，即给出错误写入的命令，仅能接受只读命令。 使redis内存使用率降低的方法？ 最好使用redis的哈希、列表、排序集、整数集 如果没有数据集较大的内存，怎么进行高层次的操作？ 使用客户端哈希，并部署redis集群，自动分发，以及redis子集的热备 单线程Redis如何利用多个CPU？ 只需在同一台机器上启动多个redis实例，当做不同服务器即可。 Redis报错问题 Redis被配置为保存数据库快照，但它目前不能持久化到硬盘。用来修改集合数据的命令不能用1报错：(error) MISCONF Redis is configured to save RDB snapshots, but it is currently not able to persist on disk. Commands that may modify the data set are disabled, because this instance is configured to report errors during writes if RDB snapshotting fails (stop-writes-on-bgsave-error option). Please check the Redis logs for details about the RDB error. 原因：强制关闭Redis快照导致不能持久化解决：将配置文件stop-writes-on-bgsave-error设置为no 参考资料 Redis入门指南（第二版）Linux_基于Docker搭建Redis集群Docker Redis的官方镜像简单使用【Redis】基于 Redis3.2.4 集群搭建说明 高性能网站构建实战]]></content>
      <tags>
        <tag>数据库</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维小技巧整理]]></title>
    <url>%2F2018%2F05%2F09%2F%E8%BF%90%E7%BB%B4%E5%B0%8F%E6%8A%80%E5%B7%A7%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[网上、书上的运维技巧整理 删除脚本-1为防止rm -rf失误造成破坏，可将删除写成一个脚本remove.sh 首先在指定目录创建.trash目录，作为回收站 创建脚本，放在一个固定位置/root/shell/ vim /root/shell/remove.sh 1234567#!/bin/bashTRASH_DIR="/root/.trash"for i in $*;do TIME_STAMP=$(date +%F) filename=$i mv $i $TRASH_DIR/$TIME_STAMP.$filename done 设置rm别名vim /root/.bashrc修改alias rm=&quot;sh /root/shell/remove.sh&quot; 设置定时任务echo &quot;0 0 * * * rm -rf /root/.trash/*&quot; &gt;&gt; /etc/crontab这样删除的文件也能尽快恢复]]></content>
      <tags>
        <tag>运维</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx笔记-1]]></title>
    <url>%2F2018%2F05%2F02%2FNginx%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇包含以下知识点： Nginx介绍 Nginx安装 Nginx配置文件解析 访问控制、身份认证与SSL Nginx日志 Nginx缓存 Nginx负载均衡 Nginx反向代理 Nginx邮件服务 重写与重定向 Nginx与PHP 防盗链 Nginx常见模块 Nginx配置简单优化 LNMP分布式集群方案 Docker部署LNMP Nginx介绍Nginx有以下功能： 负载均衡 HTTP web服务器 http协议的反向代理服务器 pop3\smtp\imap4等邮件协议的反向代理 能缓存打开的文件（元数据） ，支持FastCGI、uWSGI协议，作为缓存服务器 模块化（非DSO机制），过滤器zip，SSI，SSL 特性： 模块化设计，较好扩展性 高可靠性：master/worker支持多进程，也支持多线程 支持热备份：不停机更新配置文件，更换日志，更新服务器程序版本 低内存消耗：10000个 keep-alive连接模式下非活动连接仅消耗2.5M内存 热部署（平滑升级）：旧的配置维持现状，新的配置立刻使用，并在使用中逐步自动将旧配置替换为新配置。 Nginx架构：nginx会以daemon方式启动进程，后台进程包含一个master进程和多个worker进程。master进程用于启动管理多个worker进程，若取消master进程，则nginx会以单进程运行一个请求只能在一个worker进程中处理，一个worker进程只能处理一个请求。worker进程个数一般设置为cpu核数 master：加载配置文件、管理worker进程、平滑升级 worker：http服务、http代理、fastcgi代理 事件驱动：epoll 消息通知：select、poll、rt signals 模块类型：核心模块、标准http模块、可选http模块、邮件模块、第三方模块 Master进程完成的工作： 读取并验证配置文件 创建、绑定及关闭套接字 启动、终止及维护worker进程 无需终止服务而重新配置 控制非中断式程序升级（平滑升级），启用新的二进制程序，并且能在需要时回滚到老版本 重新打开日志文件 可编译嵌入式perl脚本 Worker进程完成的工作： 接收、传入并处理来自客户端的请求 提供反向代理及过滤功能 请求过程： 在master进程里面，先建立好需要listen的socket（listenfd）之后，然后再fork出多个worker进程 所有worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。 当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接 IO复用： ​ 单进程模型：阻塞，一次仅处理一个请求，无法应对高并发场景 ​ 多进程模型：每个进程响应一个请求。缺陷：当请求量庞大时，会占用大量CPU及内存资源，因为每个请求访问的页面都会单独缓存，若访问的页面相同，会造成内存使用效率低，且进程间切换会消耗大量CPU资源 ​ Linux原生并不支持线程，Windows和SunOS都支持。Linux将线程当做进程来处理，但称作LWP轻量级进程（Light Weight Process），Linux进行线程管理是通过调用各种线程库实现的。 ​ 多线程单请求模型：每个线程响应一个请求。线程和进程类似，也需要切换，但线程是轻量级的进程，切换消耗的资源很小。且同一进程内的线程共享一片存储空间，若有访问同一资源的请求，也可直接从存储空间调用该资源。线程对内存资源的需求量也比进程要小。而如果CPU数量只有1个，则多线程的优势基本无法体现，只有在多颗CPU的情况下，多线程才能发挥出极高的效率。 ​ 多线程多请求模型：一个线程响应多个请求。 Nginx安装在安装nginx前需要安装以下环境： gcc与gcc-c++等，可直接组安装Development Tools prce-devel(perl的正则表达库) zlib与zlib-devel(资料压缩的函数库) openssl与openssl-devel(安全套接字密码库) 注：带devel的包是一定要安装的。 创建系统用户组groupadd -r nginx创建系统useradd -r nginx -M -g nginx -r创建系统用户（组），-M不创建该用户家目录 创建目录/var/tmp/nginx/client，否则在后面运行时可能报错。 初始化文件模块配置 123456789101112131415./configure --prefix=/usr/local/nginx \ # 设置nginx安装目录 --sbin-path=/usr/sbin/nginx \ # 命令放在/sbin下 --conf-path=/etc/nginx/nginx.conf \ # 配置文件位置 --pid-path=/var/run/nginx/nginx.pid \ # nginx进程号文件 --lock-path=/var/lock/nginx.lock \ # nginx锁文件 --user=nginx \ # 指定用户 --group=nginx \ # 指定用户组 --http-log-path=/var/log/nginx/access.log \ # 运行日志位置 --error-log-path=/var/log/nginx/error.log \ # 报错日志 --http-client-body-temp-path=/var/tmp/nginx/client \ # 指定客户端post上传的$_FILES上传的文件地址，该目录需要自己创 --with-http_ssl_module \ # 加载ssl模块，默认没加载 --with-http_stub_status_module \ # 加载监控模块 --with-http_gzip_static_module \ # 加载gzip压缩模块 --with-debug # 允许debug 之后make &amp;&amp; make install 也可以通过配置的yum源安装，此例是centos7的repo配置。然后直接yum install最新的版本。 12345[nginx]name=nginx.repobaseurl=https://nginx.org/packages/centos/7/x86_64/gpgcheck=0enabled=1 nginx命令 12345678910nginx -t #检查配置文件语法 -c #指定配置文件 -V #查看编译信息 -s #指定对nginx的操作 stop #停止（快速关闭） quit #退出（优雅关闭，所有worker进程会停止接收新连接，然后将所有未处理完的请求处理完后关闭） reopen #重新打开日志文件 reload #重新读取配置文件（平滑重启） -q #在配置测试期间不显示非错误消息 Nginx配置文件解析配置文件/etc/nginx.conf配置文件组织结构： 全局配置：main 模块配置：events，http，server，location 注：配置的每条指令的结尾必须加上分号; 全局配置main块 正常运行配置： 1234user Username [Groupname] # 指定运行worker进程的用户pid PATH # 指定nginx进程的pid文件worker_rlimit_nofile # 指定一个worker进程所能打开的最大文件描述符数量worker_rlimit_sigpending # 指定每个用户能发给worker进程的最大的信号数量 性能优化配置： 12345worker_processes # worker进程个数，通常为物理CPU核心数量-1可填auto，自动使用所有CPU。worker_cpu_affinity CPUMask # 指定使用的cpu，cpumask为cpu掩码。# cpumask：0001,0010,0100,1000work_priority NICE # 指定nice值，即优先级 worker_processes和work_connections决定了最大并发数量。最大并发量即为worker_processes × work_connections 而在反向代理场景，因为nginx既要维持和客户端的连接，又要维持和后端服务器的连接，因此处理一次连接要占用2个连接，所以最大并发数为：worker_processes × worker_connections/2 Nginx可能还会打开其他的连接，这些都会占用文件描述符，影响并发数量 最大并发数量还受”允许打开的最大文件描述符数量”限制，可以使用worker_rlimit_nofile指令修改。或直接通过ulimit -n修改 调试定位配置：123456daemon &#123;on|off&#125; # 是否以守护进程方式启动master_process &#123;on|off&#125; # 是否以master模型运行error_log PATH [level] # 错误日志文件路径及日志等级。#日志等级：debug|info|notice|warn|error|crit|alert|emerg，默认为error# 可设置为debug，但需要在编译时指定--with-debug才能用# 若要禁用error_log 则可设置为error_log /dev/null; 模块配置events块events { }事件驱动，并发响应连接。控制Nginx处理连接的方式包含以下配置： 1234worker_connections # 每个worker进程能响应的最大并发请求数量use &#123;epoll | select | poll &#125; # 选择使用事件类型，最好让nginx自动选择accept_mutex &#123;on|off&#125; # 是否开启负载均衡锁，启用时，表示让多个worker进程轮流响应请求。默认开启lock_file PATH # 锁文件路径 http块http { }处理http响应的配置 注：http块下的文件相对路径是相对于Nginx的配置文件目录 包含以下配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include 用于引入配置文件#设置mime.types文件路径，若是相对地址则是相对于nginx.conf配置文件include mime.types; #default_type用于设置默认文件类型#若在编译时设置了配置文件目录，则此项路径为/usr/share/mime/application/octet-stream.xmldefault_type application/octet-stream;#日志格式#log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;#日志文件路径，由于已设置了/var/log/nginx/access.log，所以不需要改#access_log logs/access.log main;#开启高效传输文件模式，默认为on。#可以让Nginx在传输文件时直接在磁盘和tcp socket之间传输数据，而不用经过任何buffersendfile on;#在sendfile为on时，确定是否启用tcp_nopush(FreeBSD)或tcp_cork(linux)#会将多个http首部打包为单个报文。用于防止网络阻塞，但会额外占用资源#tcp_nopush on;tcp_nodelay &#123;on| off&#125; #tcp 有一个nagle算法，将多个小的数据块打包传输以提高带宽利用率。#有时只需要访问一个较小页面，但由于nagle算法，要等待其他响应以打包为大数据块，所以会等较长时间才会返回页面。对keepalive模式下连接是否使用tcp_nodelay。通常关闭。#设置keepalive长连接的超时时间。默认为65。若为0则保持长连接#keepalive_timeout 0;#设置keepalive连接上最大请求资源数，默认100keepalive_requests 数量 #指明禁止指定浏览器使用keepalive功能keepalive_disable &#123;none|browser&#125;#设置发送响应报文的超时时长，默认60ssend_timeout 时长 #接收客户端报文body的缓冲区大小，默认8k（32位|16k--64位）超出该大小时，会被存储于磁盘client_body_buffer_size 数值 #指定存储客户端报文的路径及子目录的结构数量#就是编译时--http-client-body-temp-path指定的路径client_body_temp_path PATH &#123;level1 | level2 | level3&#125; #例：client_body_temp_path /var/tmp/client_body 2 2 表示该目录下有2层目录，每层有两个子目录#是否开启gzip压缩响应报文#gzip on;#指定错误页面#error_page 404 /404.html;error_page 500 502 503 504 /50x.html;#更改响应状态码，隐藏服务器的真实状态码信息#error_page 404=200 /404.html;#设置由重定向后实际的处理结果来决定状态码#error_page 404=/404.html;server &#123; &#125; # 虚拟主机模块 server块12345678910111213141516171819202122232425262728293031323334353637#虚拟主机监听的本地端口和主机名listen 80;server_name localhost;#设置编码类型，为防止网页出现乱码，需要将charset设置gb2312或utf-8。#charset koi8-r;#Location，URI的根location / &#123; root html; index index.html index.htm;&#125;location /XXX &#123;&#125; #location块#在响应首部中添加字段add_header 字段名 值try_files [页面] [uri | =code] #设置尝试打开的文件，若都找不到再返回最后一个uri#最后一个uri必须存在，且必须由别的location定义，不能在当前的location中，否则会死循环 #例：try_files $uri xxx.html 先找用户需要的uri，若找不到返回xxx.html#显示访问连接信息。#stub_status on; #注：要放入server块# 然后设置location#location /status &#123;# stub_status;#&#125;#便可通过域名/status 查看。Active connections: 164 server accepts handled requests 7595 7595 7601 Reading: 0 Writing: 164 Waiting: 0 # 当前活动连接数已接收的连接个数，已处理的连接个数，已经处理的请求个数正在读取客户端的Header个数（Reading），正在返回给客户端的Header个数（Writing），长连接或等待状态的请求个数（Waiting）（当开启Keepalive时，该值为Active-Reading-Writing）。 location块目录映射。允许根据用户请求的URI匹配定义的location，匹配到就按该location中的配置处理 location的第一个/为root中指定路径的最后的/ alias 设置别名，用于定义路径别名，只用于location配置段。 12345678910location /images &#123; root /data/www/imgs/ ; # 即表示在URL中访问/images即为访问服务器中/data/www/imgs/images/目录 # root为将location接在root指定的路径后&#125;location /images &#123; alias /data/www/imgs/ ; # 即表示在URL中访问/images即为访问服务器的/data/www/imgs/ 目录 # alias为整段替换&#125; 与root和alias指令相关的变量为$document_root、$realpath_root。 $document_root的值即是root指令、alias指令的值 $realpath_root的值是对root、alias指令进行绝对路径换算后的值 location匹配 不带符号URI：匹配该资源目录下的所有资源 = URL精确匹配，只匹配该资源 ~ 正则表达式匹配，区分大小写 ~* 正则表达式匹配，不区分大小写（例如 location ~* \.(gif|jpg)$ 匹配.gif或jpg结尾的文件） ^~ URI左半部分匹配，非正则匹配，不区分大小写 优先级：= &gt; ^~&gt;~或~*&gt; 不带符号的URI 若要将Nginx作为文件存放服务器，在location块中添加autoindex on;即可，并且要确保文件存放的目录中没有首页文件。 访问控制、身份认证与SSLNginx的两个配置访问控制的指令allow和deny，由模块ngx_http_access_module提供。 12allow|deny IP地址[/mask]allow|deny all 若同一个块中同时配置了多条deny或allow，则先出现的访问权限生效。若多个块中都配置了权限指令，则内层的优先级高于外层的。 被访问控制deny的IP地址访问时会返回403状态码。 Nginx的basic身份认证指令auth_basic和auth_basic_user_file由模块ngx_http_auth_basic_module提供。可配置在http、server、location块中 12auth_basic 描述 | off; 是否开启http_basic对用户认证auth_basic_user_file FILE; 指定用户认证的账号文件 可通过Apache的工具htpasswd创建用户认证文件 htpasswd -c -m -b /etc/nginx/secret mike 123456 使用SSL将网站配置为HTTPS 注：如果是编译安装，需要在构建时添加--with_http_ssl_module支持SSL。 首先进入目录/etc/pki/CA/private下创建服务器RSA私钥，叫server.key。 openssl genrsa -out server.key 2048 生成服务器的CSR证书请求文件。CSR证书请求文件是服务器的公钥，用于提交给CA机构进行签名。 openssl req -new -key server.key -out server.csr按要求填写信息即可 12345Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:JiangsuLocality Name (eg, city) [Default City]:Yangzhou....Common Name (eg, your name or your server&apos;s hostname) []:system3.example.com CSR参数含义： 参数 说明 Country Name 符合ISO的两个字母的国家代码，中国CN State or Province Name 省份 Locality Name 城市 Organization Name 公司名 Organizational Unit Name 组织名/部门名 Common Name 使用SSL加密的域名，不能填错 Email Address 邮箱，可省略 A challenge password 有的CA机构需要此密码，通常省略即可 An optional company name 可选的公司名，可省略 CA为服务器认证证书 openssl x509 -req -days 30 -in server.csr -signkey server.key -out server.crt 在CA用私钥签名了证书后，该证书将用于浏览器验证请求的网站是否真实，防止网络通信过程中被篡改。 浏览器保存了受信任的CA机构的公钥，在请求HTTPS网站时，会利用CA公钥验证服务器证书，并检查域名是否吻合、证书是否过期等。 在Nginx配置文件中设置https配置。Nginx配置文件中已默认存在SSL配置，只是注释了，取消注释，并修改crt文件路径即可。 123456789101112131415161718192021 server &#123; listen 443 ssl; server_name system3.example.com; ssl on; # 这条配置文件可能没有，要加上 ssl_certificate /etc/pki/CA/private/server.crt; # SSL认证证书路径 ssl_certificate_key /etc/pki/CA/private/server.key; # SSL认证密钥路径 ssl_session_cache shared:SSL:1m; # 用于存储SSL会话的高速缓存的类型和大小 ssl_session_timeout 5m; # 客户端可以重复使用存储在缓存中的会话参数的时间 ssl_ciphers HIGH:!aNULL:!MD5; # openssl允许的加密类型 ssl_prefer_server_ciphers on; location / &#123; root html; index index.html index.htm; &#125; &#125; location / &#123; proxy_set_header X-FORWARDED-PROTO https; #将http协议头换为https proxy_pass http://upstream; &#125;&#125; 在/etc/hosts中确定配置了system3的条目。在浏览器上输入https://system3.example.com会说明此连接不安全。是因为当前的证书是服务器自己作为CA签名的，所以浏览器无法信任。点添加例外，可查看该证书，与配置的一致。 添加安全例外后，即可访问网页 Nginx日志关于Nginx日志的指令如下： log_format：日志格式。格式：log_format 格式名 格式（由变量组成），默认格式如下： &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39; $remote_addr：客户端的地址。如果Nginx服务器在后端，则该变量只能获取到前端（代理或负载均衡服务器）的IP地址 $remote_user：远程客户端用户名称 $time_local：记录访问时间和时区信息 $request：记录用户访问时的url和http协议信息 $status：记录客户端请求时返回的状态码 $body_bytes_sent：记录服务器响应给客户端的主体大小 $http_referer：记录此次请求是从哪个链接过来的，需要模块ngx_http_referer_module支持，默认已装，可以防止盗链问题 $http_user_agent：记录客户端的浏览器信息。如使用什么浏览器发起的请求，是否是压力测试工具在测试等 $http_x_forward_for：若要在$remote_addr中获取的是真正客户端的IP，则要添加此项，并且在前端的服务器要开启x_forward_for access_log：访问日志的路径和采用的日志格式名。格式：access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];。若不指定格式名，默认为combined。buffer为日志缓冲区的大小，默认64K。flush为日志刷盘时间，即日志保存在缓冲区的最大时间。gzip为日志刷盘前是否压缩以及压缩级别。if指定条件。 open_log_file_cache：设置日志文件缓存。默认关闭，即每一条日志都是打开文件，写入后关闭，这样会消耗一定量的IO。而设置了缓存后，会等日志数量达到一个指标后一下写入日志文件。 格式：open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];。其中max为缓存中的最大文件描述符数量。inactive为存活时间，默认是10s。min_uses为在inactive时间段内，日志文件最少使用多少次后，该日志文件描述符记入缓存中，默认是1次。valid为检查频率，默认60s。 log_subrequest：是否在access.log中记录子请求的访问日志。默认不记录 rewrite_log：是否在error.log中记录notice级别的重写日志。默认关闭 日志切割默认Nginx不会自动切割日志。 手动切割： 12mv access.log access-XXXX.lognginx -s reopen 自动切割： 创建shell脚本 123456#!/bin/bashACCESS_LOG=/var/log/nginx/access.logNEW_ACCESS_LOG=/var/log/nginx/access-$(date -d yesterday +%Y%m%d).log[ -f $ACCESS_LOG ] || exit 1 mv $ACCESS_LOG $NEW_ACCESS_LOG /sbin/nginx -s reopen 添加定时任务 10 0 * * * /bin/sh XXX.sh &amp;&gt; /dev/null #每天晚上12点切割日志 Nginx的其他常见HTTP功能文件查找规则Nginx 为了响应一个请求，它将请求传递给一个内容处理程序，由配置文件中的location指令决定处理。 无条件内容处理程序首先被尝试 ：perl 、proxy_pass、flv、mp4等。如果这些处理程序都不匹配，那么 Nginx 会将该请求按顺序传递给下列操作之一，顺序依次是 ：random index 、 index 、 autoindex 、gzip_static、 static 。 处理以斜线结束请求的是 index 处理程序。如果 gzip 没有被激活，那么 static 模块会处理该请求。 这些模块如何在文件系统上找到适当的文件或者目录则由某些指令组合来决定。root 指令最好定义在一个默认的 server 指令内 ， 或者至少在一个特定的 location 指令之外定义，以便它的有效界限为整个 server。 文件路径指令： 指令 说明 root 设置文档根目录，URI后设置，可在文件系统中找到具体文件 try_files 测试文件的存在性，若前面的文件没找到，则最后的条目作为备用，需要确保最后一个路径或location存在 例： 123location / &#123; try_files $uri $uri/ /40x.html;&#125; 域名解析 指令 说明 resolver 设置一个或多个域名解析服务器。可选valid参数，会覆盖域名记录的TTL resolver_timeout 当解析服务器不可达时的等待时间，尽量设置的小。目前只适用于商业订阅 该指令需要配置在server块中 1234server &#123; resolver 8.8.8.8 valid=300s; resolver_timeout 2s;&#125; 客户端交互Nginx 与客户端交互的方式有多种，这些方式可以从连接本身 （IP 地址、超时、存活时间等）到内容协商头的属性。 指令 说明 default_type 设置响应的默认MIME类型。只有文件的MIME类型不匹配任何types，才会用此项 types 设置MIME类型到文件扩展名的映射，一般不用设置。只需要载入conf/mime.types即可 ignore_invalid_headers 禁止忽略无效名字的头。一个有效的名字由ASCII字母、数字、连字符号组成 recursie_error_pages 启用error_page实现多个重定向 Nginx缓存Nginx的模块ngx_http_proxy_module自带缓存功能，Nginx可实现几种缓存：网页内容缓存，日志缓存，打开文件缓存，fastcgi缓存。Nginx的缓存功能主要由proxy_chache相关的命令集和fastcgi_cache相关命令集构成，前者用于反向代理，后者用于对FastCGI缓存。 需要下载第三方的Nginx模块ngx_cache_purge，用于清除指定的URL缓存，下载地址 下载后解压，然后重新编译Nginx，通过nginx -V查看编译选项，复制过去然后加上解压后的模块目录（不是里面的.c文件） 123./configure ........ --add-module=/root/ngx_cache_purge-2.3 编译后能看到新的模块添加成功的信息 123configuring additional modulesadding module in /root/ngx_cache_purge-2.3 + ngx_http_cache_purge_module was configured 然后只要make就行，不能make install，不然就是重新安装Nginx了 最后还要替换nginx启动文件，在重新编译后，nginx的下载目录中有个objs目录，将里面的nginx启动脚本复制到/usr/sbin/下，替换原来的nginx 12rm -f /usr/sbin/nginx cp /root/nginx-1.14.0/objs/nginx /usr/sbin/ 通过nginx -V查看，--add-module=/root/ngx_cache_purge-2.3已成功编译 Nginx自带的缓存相关指令有三个： proxy_cache_path：配置缓存存放路径。常用格式：proxy_cache_path path [levels=levels] keys_zone=name:size [max_size=size] [inactive=time];。 levels：缓存目录级别以及缓存目录名的字符数，数字间用冒号分隔。最多可有三层目录，目录名最多两个字符。例：levels=1:2:2表示一共三层目录，第一层目录名1字符，第二和第三层目录名为2字符。 keys_zone：缓存标识名和内存中缓存的最大空间。名字必须唯一。可在keys_zone的值后加上:内存缓存空间指定内存中的缓存空间大小 max_size：磁盘中缓存目录的最大空间 inactive：缓存的默认时长，到达指定时间却没被访问的缓存会被自动删除 proxy_cache：指定要使用的缓存方法，使用proxy_cache_path中keys_zone指定的名称。格式：proxy_cache 缓存标识名; proxy_cache_valid：根据状态码指定缓存有效期。格式：proxy_cache_valid 状态码（可指定多个，或直接指定any） 时间（支持m|h等时间单位）; 在配置文件添加缓存配置。首先在http块下（server块外）添加缓存路径，路径可根据需要自定义 12proxy_temp_path /data/ngxcache/proxy_temp_dir;proxy_cache_path /data/ngxcache/proxy_cache_dir levels=1:2 keys_zone=cache_one:1000m max_size=1g; 然后在server块中的location块添加其余的缓存配置 123456location / &#123; proxy_cache cache_one; proxy_cache_valid 200 1h; # 状态码为200的缓存1小时 proxy_cache_valid 404 1m; proxy_cache_valid any 5m; # 剩余的所有状态都缓存5分钟&#125; 当开启缓存后，Nginx会生成进程cache_manager对缓存进行管理。 12nginx 1359 1356 0 11:23 ? 00:00:00 nginx: cache manager processnginx 1360 1356 0 11:23 ? 00:00:00 nginx: cache loader process 可在server块中添加add_header X-Cache $upstream_cache_status;，该参数用于显示缓存状态返回值，一共有七种： 返回值 说明 HIT 缓存 MISS 未命中，请求被传送到后端 EXPIRED 缓存已过期，请求被传到后端 UPDATING 正在更新缓存，将使用旧的应答 STALE 无法从后端服务器更新缓存时，返回了旧的缓存 BYPASS 缓存被绕过了 REVALIDATED 在启用proxy_cache_revalidate后，当缓存内容过期后时，Nginx通过一次If-Modified-Since的请求头去验证缓存内容是否过期，此时会返回该状态 1add_header X-Cache &quot;$upstream_cache_status from $server_addr&quot;; 完整的配置： 12345678910111213141516proxy_temp_path /data/ngxcache/proxy_temp_dir;proxy_cache_path /data/ngxcache/proxy_cache_dir levels=1:2 keys_zone=cache_one:1000m max_size=1g;upstream web &#123; server 172.16.246.134; server 172.16.246.135;&#125;server &#123; listen 80; server_name web; root /usr/share/nginx/html; add_header X-Cache &quot;$upstream_cache_status from $server_addr&quot;; location / &#123; proxy_cache cache_one; proxy_cache_valid 200 1h; proxy_pass http://web;&#125; 通过浏览器访问http://web。如果是第一次访问，会发现状态是MISS 若再次访问，则状态会变为HIT。 并且可以看到缓存目录下已建立缓存 1234567/data/ngxcache/proxy_cache_dir/├── 5│ └── a4│ └── 383e066904ed363cfafab47f9f53fa45└── 6 └── 01 └── abca5f5d9926bd7fbfc52390d3d35016 另外常用的三种缓存： open_log_cache：日志缓存 open_file_cache：文件缓存 fastcgi_cache：fastcgi缓存 Nginx负载均衡Nginx提供负载均衡模块ngx_http_upstream_module，且Nginx有四种典型的负载均衡配置方式。 配置方式 说明 轮询round-robin 默认配置方式，每个请求按照时间顺序逐一分配到不同后端服务器 权重 利用weight指定轮询的权重比率，weight与访问比率成正比。用于后端服务器性能不均的情况 ip_hash 每个请求按访问IP的hash结果分配，使每个访客固定访问一个后端服务器，可解决Session问题 fair（第三方） 按后端服务器响应时间来分配请求，响应时间短的优先 url_hash（第三方） 按访问URL的哈希结果来分配请求，使每个URL固定访问一个后端服务器。适用于后端服务器做缓存的情况 一致性Hash（Tengine） 将每个服务器虚拟成N个节点，均匀分布在哈希环上，每次请求时会根据配置参数计算出一个Hash，在哈希环上查找离这个哈希值最近的虚拟节点，对应服务器作为该次请求的后端服务器。好处：若增加或减少了机器，对整个集群的影响会最小 Nginx作负载均衡的优点： 配置简单 成本低 支持Rewrite重写规则 有内置的健康检查功能 节省带宽：支持Gzip，可添加浏览器本地缓存的Header 稳定性高：高并发的情况下也基本不会宕机 轮询实验环境： 负载均衡器：172.16.246.133 后端服务器1：172.16.246.134 后端服务器2：172.16.246.135 仅需在负载均衡服务器上配置 12345678910111213server&#123; listen 80; server_name sys1.example.com; location / &#123; proxy_pass http://sys1.example.com; &#125;&#125;upstream sys1.example.com &#123; server 172.16.246.134; server 172.16.246.135;&#125;# 实际上，轮询也是有weight的，只是所有的server的weight都为默认的1。 在本机上进行访问 12345678&gt; curl sys1.example.comWEB1&gt; curl sys1.example.comWEB2&gt; curl sys1.example.comWEB1&gt; curl sys1.example.comWEB2 权重仍在负载均衡器上配置，仅修改upstream块 1234upstream sys1.example.com &#123; server 172.16.246.134 weight=1 max_fails=1 fail_timeout=2; server 172.16.246.135 weight=3 max_fails=2 fail_timeout=2;&#125; 参数 说明 weight 权重 max_fails 允许请求失败次数，默认为1。当超过最大次数时，返回proxy_next_upstream指令定义的错误 fail_timeout 在经历max_fails次失败后，暂停服务的时间 backup 预备备份机器，当所有其他主机都down后，就会启用该主机 down 指定的server暂不参与负载均衡 查看现象 12345678&gt; curl sys1.example.com # 一共四次访问，访问web1和web2的比例正好为1:3WEB2&gt; curl sys1.example.comWEB1&gt; curl sys1.example.comWEB2&gt; curl sys1.example.comWEB2 ip_hash12345upstream sys1.example.com &#123; ip_hash; server 172.16.246.134; server 172.16.246.135;&#125; 测试： 12345678&gt; curl sys1.example.comWEB2&gt; curl sys1.example.comWEB2&gt; curl sys1.example.comWEB2&gt; curl sys1.example.comWEB2 每个IP地址绑定一个web服务器，可能会导致某些web服务器负载很大，有的很少，反而无法保证负载均衡。 upstream块补充指令： keepalive：指定每个worker进程缓存到上游服务器的连接数。需要先将proxy_http_version设为1.1，proxy_set_header设为Connection &quot;&quot; 123456789upstream apache &#123; server 127.0.0.1:8080; keepalive 32;&#125;location / &#123; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; proxy_pass http://apache;&#125; least_conn：直接激活最少连接算法，将请求发送至活跃连接数最少的服务器。 Nginx反向代理在模块ngx_http_proxy_module中与Nginx反向代理有关的指令：proxy_pass，用于设置后端服务器的地址，仅用于location块。可以设置代理服务器的协议和地址以及映射位置的可选URI。 实验环境： 代理服务器：172.16.246.133 后端服务器1：172.16.246.134 后端服务器2：172.16.246.135 只需要在代理服务器上配置即可 1234567891011121314server&#123; listen 80; server_name web1; location / &#123; proxy_pass http://172.16.246.134; &#125;&#125;server&#123; listen 80; server_name web2; location / &#123; proxy_pass http://172.16.246.135; &#125;&#125; 然后在本机上配置hosts文件 1172.16.246.133 web1 web2 确保代理服务器和后端服务器的端口都打开。然后在本机测试 1234&gt; curl web1WEB1&gt; curl web2WEB2 如果代理的是动态内容服务器，要使用fastcgi_pass指令进行代理 123location ~* \.php$ &#123; fastcgi_pass http://phpserver;&#125; 补充指令： proxy_set_header：在将客户端请求转交给后端服务器前，更改请求头信息。默认只重新定义了两个字段 1234567891011proxy_set_header Host $proxy_host;# 最好使用$host变量，它的值等于“Host”请求头字段中的服务器名称，如果此字段不存在则等于主服务器名称proxy_set_header Host $host;# 服务器名称可以与代理服务器的端口一起传递proxy_set_header Host $host:$proxy_port;# 请求host为代理主机proxy_set_header Host $proxy_host;# 添加客户端IPproxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_set_header Connection close; 若设置了X-Real-IP，且后端服务器是httpd，则可以修改httpd配置文件中的LogFormat，添加一个%{X-Real-IP}i。而若后端是Nginx，则不用修改了，因为Nginx的log_format中已默认配置了$remote_addr，即客户端IP。 如果启用了缓存，则标题字段为“If-Modified-Since”，“If-Unmodified-Since”，“If-None-Match”，“If-Match”，“Range”和“If-Range”来自原始请求不会传递给代理服务器。 proxy_connect_timeout：配置Nginx与后端代理服务器尝试连接的超时时间，默认60s，且通常不会大于75秒。 1proxy_connect_timeout 30; proxy_read_timeout：配置Nginx向后端服务器组发出read请求后，等待响应的超时时间。仅在两个连续的读操作之间设置超时，而不是整个响应。如果代理服务器在此时间内未传输任何内容，则关闭连接。默认为60秒。 1proxy_read_timeout 15; proxy_send_timeout：配置Nginx向后端服务器组发出write请求后，等待响应的超时时间。仅在两个连续的写操作之间设置超时，而不是整个请求。如果代理服务器在此时间内未收到任何内容，则关闭连接。默认为60秒。 1proxy_send_timeout 15; proxy_redirect：用于修改后端服务器返回的响应头中的Location和Refresh 1proxy_redirect off; proxy_buffer_size：用于读取从代理服务器接收的响应的第一部分的缓冲区的大小，这部分通常包含一个小的响应头。默认情况下，缓冲区大小等于一个内存页面，默认为4K或8K。 1proxy_buffer_size 4k; proxy_buffers：用于从代理服务器读取响应的缓冲区的数量(number)和大小(size)，用于单个连接。默认情况下，缓冲区大小等于一个内存页面。默认为4K或8K。语法：proxy_buffers number size; 12proxy_buffers 32 4k;# 那么最多支持的并发活动连接数 = 分配给nginx的内存量（字节）/ (number×size×1024) proxy_temp_file_write_size：当启用从代理服务器到临时文件的响应缓冲时，限制一次写入临时文件的数据大小。默认情况下，size由proxy_buffer_size和proxy_buffers指令设置的两个缓冲区限制。默认为8k或16k。 1proxy_temp_file_write_size 64k; 可以讲这些代理指令单独存放为一个配置文件，然后在主配置文件的代理块中include应用。 非HTTP型上游服务器Memcached服务器Nginx提供memcached模块并默认开启，用于与memcached守护进程通信，此时Nginx并不是充当反向代理，而是使Nginx使用memcached协议会话，因此key的查询能够在请求传递到应用服务器之前完成。 12345678910upstream memcaches &#123; server xxxx:11211; server xxxx:11211;&#125;server &#123; location / &#123; set $memcached_key &quot;$uri?args&quot;; memcached_pass memcaches; &#125;&#125; memcached_pass将使用$memcached_key变量实现key查找。 FastCGI服务器fastcgi模块也是默认开启。开启后Nginx可使用FastCGI协议与多个上游服务器会话。 1234567upstream fastcgis &#123; server xxxx:9000; server xxxx:9000;&#125;location / &#123; fastcgi_pass fastcgis;&#125; SCGI与uWSGI服务器与FastCGI类似，分别使用scgi_pass与uwsgi_pass指定上游服务器。 Nginx邮件服务Nginx提供邮件代理服务，能代理POP3、IMAP、SMTP。 每一个进入的请求都会基于相应的协议处理，对于每一个协议，Nginx都需要一个用户名密码认证服务，如果认证成功，则连接被代理到邮件服务器。 Nginx邮件服务，若是编译安装，则需要在构建时指定--with-mail。 如果代理pop3服务，在配置文件中添加以下配置 12345678mail &#123; auth_http localhost:9000/auth; # 查询认证服务 server &#123; listen 110; # pop3的TCP端口110，监听POP3服务 protocol pop3; proxy on; &#125;&#125; 如果是代理imap服务，则同理，而可以不用指定protocol imap;，因为imap是默认值。而端口号改为143。 如果代理smtp服务，则修改protocol后，再修改端口号为25。 Nginx还为三种服务提供了可选指令，能做到根据服务器的情况灵活代理。 最好在mail块中，指定server_name，为邮件代理提供统一入口。 重写与重定向Nginx提供模块ngx_http_rewrite_module实现URL重写与重定向。rewrite指令能用于server、location、if块中。Nginx的rewrite需要pcre的支持。 rewrite regex replacement [flag]; 其中regex为正则表达式，replacement为符合正则的替换算法。flag为进一步处理的标识。以下为flag的可选值： 参数值 说明 last 终止rewrite，继续匹配 break 终止rewrite，不再继续匹配 redirect 临时重定向，返回的HTTP状态码为302 permanent 永久重定向，返回的HTTP状态码为301 例： 1234rewrite ^/(.*) http://www1.example.com/$1 permanent;# ^/(.*) 正则表达式，表示匹配全部# 匹配成功就跳转到www1.example.com/$1# $1对应的是前面正则表达式的()部分 rewrite有以下的作用： 使URL更加规范，方便开发 使搜索引擎收录网站内容 网站换域名后，让旧域名的访问跳转到新域名上 根据特殊变量、目录、客户端信息进行URL跳转 应用实验：使www1.example.com和example.com访问同一个地址 12345678910111213server &#123; listen 80; server_name example.com; rewrite ^/(.*) http://www1.example.com/$1 permanent;&#125;server &#123; listen 80; server_name www1.example.com; location / &#123; root html/www; index index.html; &#125;&#125; 重写两种匹配规则： break：本条规则匹配完成后，不再继续匹配后续任何规则 last：本条规则匹配完成后，继续向下匹配新的location URI规则 在server块中添加以下内容： 12345# !-e判断请求指定的资源是否不存在，若不存在就执行if块中的指令。$request_filename表示当前请求的文件路径if (!-e $request_filename) &#123; rewrite &quot;^/.*&quot; /40x.html break; # 重写符合规则的请求地址。&quot;^/.*&quot;表示匹配当前网站下的所有请求&#125; 试验： 12&gt; curl http://web/asdasd400 ERROR 若使用last标记： 12 常用的测试： 双目测试： ~，!~：正则匹配与不匹配（区分大小写） =，!=：精确匹配与不匹配 ~*，!~*：正则匹配与不匹配（不区分大小写） 使用案例： 12if ($request_method=&quot;POST&quot;)&#123;&#125;if ($request_uri ~* &quot;/forum&quot;)&#123;&#125; 单目测试： -f，!-f：文件存在与不存在 -d，!-d：目录存在与不存在 -e，!-e：文件或目录存在与不存在 -x，!-x：判断是否可执行与不可执行 Nginx与PHPNginx自带的FastCGI模块，不仅能接受php-fpm，还能与任何兼容FastCGI的服务器通信，该模块默认启用。 常用指令： FastCGI指令 说明 fastcgi_buffer_size 来自FastCGI服务器响应头的第一部分设置缓冲大小 fastcgi_buffers 设置来自FastCGI服务器响应的缓冲数量和大小，用于单个连接 fastcgi_cache 定义一个共享的内存zone，用于缓存 fastcgi_no_cache 指定一个或多个字符串，Nginx不会将来自FastCGI服务器的响应保存在缓存中 fastcgi_keep_conn 服务器不立即关闭连接以保持到FastCGI服务器的连接 fastcgi_pass 指定FastCGI服务器如何传递请求，格式：address:port fastcgi_cache_path 该指令用于设置存储缓存响应的目录和存储活跃的 key 和响应元数据的共享内存 zone fastcgi_connect_timeout 指定Nignx将等待它接受连接的最长时间 fastcgi_hide_header 指定不应该传递到客户端的头列表 Nginx常见模块gzip压缩gzip模块默认启用。 12345678910http &#123; gzip on; gzip_comp_level 2; # 指定gzip压缩等级（1-9） gzip_types text/plain text/css application/xml application/json; #指定除了text/html，其他需要压缩的MIME类型 gzip_min_length 1024; # 在启用压缩前先确定响应的长度，若高于此处设定的值，则启用压缩 gzip_buffers 40 4k; # 用于压缩响应使用的缓存数量和大小&#125; LNMP分布式集群方案搭建Nginx+PHP环境编译安装PHP，php版本7.2.11。 确保zlib及其库zlib-devel，gd及其库gd-devel，curl及其库libcurl、libcurl-devel，openssl及其库openssl-devel，libxml2和libxml2-devel（php编译必须的依赖包），libjpeg及其库libjpeg-devel，libpng及其库libpng-devel，freetype-devel 123456789101112131415161718./configure --prefix=/usr/local/php7.2 \ --enable-fpm \ # 开启PHP的FPM功能 --with-zlib \ --enable-zip \ --enable-mbstring \ # 用于多字节字符串处理 --with-mysqli \ # 增强版Mysql数据库访问支持 --with-pdo-mysql \ # 基于PDO（php data object）的MySQL数据库访问支持 --with-gd \ # gd库支持，用于php图像处理 --with-jpeg-dir \ # jpeg图像处理库 --with-png-dir \ # png图像处理库 --with-freetype-dir \ # freetype字体图像处理库 --with-curl \ # curl支持 --with-openssl \ --with-mhash \ # mhash加密支持 --enable-bcmath \ # 精确计算功能 --enable-opcache # 开启opcache，一种php代码优化器 make &amp;&amp; make install 安装完成后，php-fpm是无法通过systemctl管理的。需要以下配置 php配置文件目录 12345/usr/local/php7.2/etc/├── pear.conf├── php-fpm.conf.default└── php-fpm.d └── www.conf.default 需要将php-fpm.conf.default改名为php-fpm.conf。然后进入解压包的目录中sapi/fpm目录，里面有一个php-fpm.service，将该文件的权限改为754，然后复制到/usr/lib/systemd/system/中。 如果是CentOS/Redhat 6系列，则将init.d.php-fpm复制到/etc/init.d/中并改名为php-fpm，添加执行权限，然后chkconfig --add php-fpm。 查看php-fpm.service，确保PID文件、配置文件路径正确。 12345678910111213[Unit]Description=The PHP FastCGI Process ManagerAfter=network.target[Service]Type=simplePIDFile=/usr/local/php7.2/var/run/php-fpm.pidExecStart=/usr/local/php7.2/sbin/php-fpm --nodaemonize --fpm-config /usr/local/php7.2/etc/php-fpm.confExecReload=/bin/kill -USR2 $MAINPIDPrivateTmp=true[Install]WantedBy=multi-user.target 其中配置文件的路径为安装目录的etc/php-fpm.conf，所以该配置文件原来的.default文件一定要改名为php-fpm.conf。并且还需要将php-fpm.d/下的www.conf.default改名为www.conf，否则还会报错。 /usr/local/php7.2/sbin/php-fpm -t检查配置文件是否正确。 再启动php-fpm，systemctl start php-fpm.service 1234567ps -ef | grep php-fpmroot 47197 1 0 22:53 ? 00:00:00 php-fpm: master process (/usr/local/php7.2/etc/php-fpm.conf)nobody 47198 47197 0 22:53 ? 00:00:00 php-fpm: pool wwwnobody 47199 47197 0 22:53 ? 00:00:00 php-fpm: pool wwwss -anpt | grep php-fpmLISTEN 0 128 127.0.0.1:9000 *:* users:((&quot;php-fpm&quot;,pid=47199,fd=5),(&quot;php-fpm&quot;,pid=47198,fd=5),(&quot;php-fpm&quot;,pid=47197,fd=7)) 可以看出，php-fpm监听了9000端口，主进程用户为root，子进程用户为nobody。 可以将bin和sbin目录添加到环境变量中，将配置文件软连接到/etc/php/中，方便操作。 php-fpm主配置文件php-fpm.conf，该配置文件采用的是INI的格式 123456789[global] # 全局配置pid = run/php-fpm.pid # pid文件路径error_log = log/php-fpm.log # 日志路径syslog.ident = php-fpm # syslog标识名称log_level = notice # 日志等级。alert, error, warning, notice, debugdaemonize = yes # 是否在后台运行events.mechanism = epoll # 事件机制。include=/usr/local/php7.2/etc/php-fpm.d/*.conf # 进程池配置存放目录; process.max = 128 php-fpm进程池配置文件www.conf，采用的也是INI格式 123456789101112131415[www] # 进程池配置user = nobody # 工作用户group = nobody # 工作组listen = 127.0.0.1:9000 # 监听IP地址与端口;listen.owner = nobody # socket文件所属用户;listen.group = nobody # socket文件所属组;listen.allowed_clients = 127.0.0.1 # 指定允许连接的客户端IP，默认为环回口pm = dynamic # 控制子进程的数量，默认为dynamic（动态控制）pm.max_children = 5 # 最多子进程数pm.start_servers = 2 # 启动进程数，对应了php-fpm:pool www的个数pm.min_spare_servers = 1 # 最少空闲进程数，若少于该数，则会自动创建空闲进程pm.max_spare_servers = 3 # 最多空闲进程数，若多于该数，则会自动删除空闲进程access.log = log/$pool.access.log # 日志文件，默认不记录日志;php_admin_value[memory_limit] = 32M # 以php_admin_value的方式替换php.ini中memory_limit的值;php_flag[display_errors] = off # 以php_flag的方式替换php.ini中display_errors的值 在php的解压包中，有两个关于php.ini的配置文件：php.ini-production和php.ini-development，其中production适用于实际上线环境（安全性高），development适合于开发环境（便于调试）。选择其中一个复制到php安装目录下lib/php/中，并改名为php.ini。 123456789101112131415161718192021222324252627[PHP] # PHP核心配置output_buffering = 4096 # 输出缓冲，单位字节;open_basedir = # 限制php脚本可访问的路径disable_functions = # 禁用的函数列表max_execution_time = 30 # 每个PHP脚本最长时间限制，单位秒memory_limit = 128M # 每个PHP脚本最大内存使用限制display_errors = On # 是否输出错误信息log_errors = On # 是否开启错误日志;error_log = php_errors.log # 错误日志路径post_max_size = 8M # 通过POST提交的最大限制default_mimetype = &quot;text/html&quot; # 默认MIME类型default_charset = &quot;UTF-8&quot; # 默认编码file_uploads = On # 是否开启文件上传;upload_tmp_dir = # 上传文件临时保存目录upload_max_filesize = 2M # 上传文件最大限制allow_url_fopen = On # 是否允许打开远程文件;cgi.fix_pathinfo=1 # 开启在CGI模式下自动识别PATHINFO# PATHINFO用于在某个脚本后添加自定义内容# 开启后，若要访问的资源不存在，则会执行上一级的文件，若上一级的文件仍不存在，则返回“File not found”# 若不开启，要访问的文件不存在，则直接返回错误“No input file specified”[Date] # 时间与日期配置;date.timezone = Asia/Shanghai # 时区 [Session] # 会话配置session.save_handler = files # 将会话以文件形式保存;session.save_path = &quot;/tmp&quot; # 会话保存目录 修改Nginx配置文件，取消以下行的注释： 1234567891011location ~ \.php$ &#123; root html; fastcgi_pass 127.0.0.1:9000; # 将动态请求交给该端口处理 fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # 额外参数文件 include fastcgi.conf; # 包含了当前目录下的fastcgi_params配置 # 一定要设置为fastcgi.conf，不能设为fastcgi_params # 因为.conf文件不_params文件多了一条 # fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; # 这是指定了脚本的路径&#125; 查看/etc/nginx/fasstcgi_params文件 1234567891011121314151617# 请求字符串（/xxx.php?xxx=xxxx&amp;xxx=xxxx）fastcgi_param QUERY_STRING $query_string;# 请求方法（get、post）fastcgi_param REQUEST_METHOD $request_method;# 内容的类型（即MIME类型）fastcgi_param CONTENT_TYPE $content_type;# 内容长度fastcgi_param CONTENT_LENGTH $content_length;# CGI脚本名fastcgi_param SCRIPT_NAME $fastcgi_script_name;# 请求URIfastcgi_param REQUEST_URI $request_uri;# 文件URIfastcgi_param DOCUMENT_URI $document_uri;# 文件根目录fastcgi_param DOCUMENT_ROOT $document_root;...... 在index.php中写入&lt;? phpinfo(); ?&gt;。刷新配置，浏览器访问。 Nginx+Apache动静分离Nginx提供外部访问，静态请求直接由Nginx处理，动态请求转交给Apache处理，实现动静分离。 首先要确保Apache已支持PHP。确保Apache是--enable-so的，会在Apache的bin/下有一个apxs命令，是Apache的一个扩展工具（Apache extension tools），用于编译模块。php的configure可用apxs编译用于Apache访问PHP的模块。 使用php -i | grep configure查看php的编译参数 1Configure Command =&gt; &apos;./configure&apos; &apos;--prefix=/usr/local/php7.2&apos; &apos;--enable-fpm&apos; &apos;--with-zlib&apos; &apos;--enable-zip&apos; &apos;--enable-mbstring&apos; &apos;--with-mcrypt&apos; &apos;--with-mysql&apos; &apos;--with-mysqli&apos; &apos;--with-pdo-mysql&apos; &apos;--with-gd&apos; &apos;--with-jpeg-dir&apos; &apos;--with-png-dir&apos; &apos;--with-freetype-dir&apos; &apos;--with-curl&apos; &apos;--with-openssl&apos; &apos;--with-mhash&apos; &apos;--enable-bcmath&apos; &apos;--enable-opcache&apos; 重新整理并添加--with-apxs2=/usr/local/httpd-2.4/bin/apxs。 注：如果此时直接编译仍然会报错，错误来自于apxs命令。报错信息如下： 12./configure: /usr/local/httpd-2.4/bin/apxs: /replace/with/path/to/perl/interpreter: bad interpreter: No such file or directory 查看apxs命令。第一行是#!/replace/with/path/to/perl/interpreter -w肯定是不存在的，需要替换为#!/usr/bin/perl -w。重试./configure，然后make（不要make install）。 修改httpd的配置文件，以下为要修改的内容 1234567Listen 81 # 防止与Nginx冲突，要修改端口号# 修改httpd虚拟主机&lt;VirtualHost *:81&gt; Servername &quot;system3.example.com&quot; DocumentRoot &quot;htdocs/php&quot;&lt;/VirtualHost&gt; 修改Nginx配置文件，将以下行取消注释并修改 123456location ~ \.php$ &#123; proxy_pass http://127.0.0.1:81; # 代理客户端浏览器请求Apache服务器 proxy_set_header Host $host; # 发送Host消息头 # 因为Nginx在代理时能传递客户端的请求头，但无法传递Host消息头 # $host保存了请求的主机名（system3.example.com）&#125; 参考文章 nginx基础及提供web服务(nginx.conf详解) nginx日志配置 Nginx高性能Web服务器实战教程 高性能网站构建实战 跟老男孩学Linux运维 Web集群实战 精通Nginx（第二版）]]></content>
      <tags>
        <tag>server</tag>
        <tag>集群</tag>
        <tag>代理</tag>
        <tag>负载均衡</tag>
        <tag>缓存</tag>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache-Server笔记]]></title>
    <url>%2F2018%2F05%2F02%2FApache-Server%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本片包含以下内容： Apache-httpd服务器介绍 httpd服务器安装 httpd配置文件 httpd虚拟主机 httpd认证授权 页面重定向 .htaccess文件 CGI 动态httpd httpd与SSL httpd日志 httpd代理 Apache-MPM模式 Apache实用第三方模块 Apache安全措施 LAMP环境搭建 LAMT环境搭建 Apache-httpd服务器介绍Apache服务器全称Apache-HTTP-Server，而httpd就是Apache服务器端运行的软件，提供WWW服务器平台。 Apache特性 简单强大的配置文件 支持虚拟主机 支持多种HTTP认证 集成Perl脚本，代理服务器模块 支持通用网关接口、FastCGI 支持实时监视服务器状态和定制服务器日志 支持SSL、服务器端包含指令SSI 可通过第三方模块支持Java Servlets 提供对用户会话的跟踪 采用模块化设计模型 Apache最重要的特性就是：采用模块化设计模型。模块分为： 静态模块：是Apache最基本的模块，无法随时添加和卸载，在编译安装时设定 动态模块：是可以随时添加和卸载的模块，使得部署有最大的灵活性 Apache的模块会被编译为动态共享对象DSO，这些DSO独立于httpd，可以在编译时就添加，也可以后期通过Apache Extension Tool工具编译添加模块，可使用httpd -M查看模块加载清单。 httpd服务器安装httpd版本2.4.34。可以使用源码安装，可进行更精细的设定。 12345678./configure --enable-so # 开启模块化功能，支持DSO --enable-mods-shared # 指明以DSO方式编译的模块，all表示所有模块，most表示大部分模块 --enable-ssl # 支持ssl加密 --enable-rewrite # 支持地址重写 --with-mpm # 设置httpd工作模式 --with-suexec-bin # suexec库的路径，用于支持SUID、SGID --with-apr # 指定apr程序的绝对路径 apr：Apache Portable Runtime（APR）项目的任务是创建和维护软件库，为底层平台特定的实现提供可预测且一致的接口。主要目标是提供一个API，软件开发人员可以对其进行编码，并确保可预测的行为，如果不是相同的行为，无论他们的软件构建在哪个平台上，都可以减轻他们编写特殊情况条件以解决问题的需要。 源码安装前需要安装apr和apr-util，仍然需要源码安装 下载apr和apr-util的源码包，先安装apr，先要确保安装了gcc ./configure --prefix=/usr/local/apr-1.6然后make &amp;&amp; make install 再安装apr-util，需要--with-apr指定apr的安装路径 ./configure --prefix=/usr/local/apr-util-1.6 --with-apr=/usr/local/apr-1.6然后make &amp;&amp; make install 可能会报一个错xml/apr_xml.c:35:19: 致命错误：expat.h：No such file or directory，需要安装expat-devel，yum install expat expat-devel即可。 安装与Apache相关的依赖库或软件，直接yum|dnf安装即可： 1234567891011pcre-devel # perl正则表达式库libxml2-devel # xml文件库，很重要libpng-devel # png图像库libjpeg-devel # jpeg图像库libmcrypt-devel # mcrypt加密库zlib-devel # zlib压缩库freetype-devel # freetype字体库autoconf # 生成配置脚本的软件，不一定要gd-devel # gd图像库libcurl-devel # curl库openssl-devel # openssl库。注：php5不支持openssl1.1.0版本以上的 然后 --prefix1234./configure --prefix=/usr/local/httpd-2.4 \ --with-apr=/usr/local/apr-1.6 \ --with-apr-util=/usr/local/apr-util-1.6 # 若不指定--prefix，会默认安装在/usr/local/apache2中 并make &amp;&amp; make install即可。源码安装后可能不能直接使用Apache的管理命令，需要添加环境变量，export PATH=/usr/local/httpd-2.4/bin:$PATH，也可以永久添加。 httpd提供两种编译方式：静态编译和动态编译 静态编译：把模块直接编译进httpd核心，httpd启动时所有静态编译的模块都会启动 动态编译：将模块编译好，但不编译进httpd核心，httpd启动动态模块并不会启动，而是需要在配置文件中LoadModule加载才能启动，实现了模块热插拔。 可在编译时指定--enable-模块名=shared|static指定模块是动态或静态编译。 httpd能够实现动态编译的原因在于httpd默认会安装mod_so，此模块提供了配置文件的LoadModule和LoadFile指令，在编译时指定--enable-so即可，而此模块只能使用静态编译，若指定为shared则编译时会出错。 动静态编译的优先级： 不指定模块编译选项，则默认值为--enable-mods-shared=most即动态编译大部分模块 显式指定的优先级高，如果某个模块既指定了静态，又指定了动态，则静态优先。 静态关键字规则优先于动态关键字规则，即若--enable-mods-static=few和--enable-mod-shared=all同时配置，静态优于动态，静态生效。 也可通过各种源安装。yum|dnf install httpd。安装完成后，Apache会提供apachectl脚本命令，可进行httpd的启动、关闭和测试，若没有修改配置文件下使用start启动httpd，会报以下错误信息： 1Could not reliably determine the server&apos;s fully qualified domain name 报错说明httpd无法确定服务器域的名称，可通过修改主配置文件的ServerName解决。修改后再通过apachectl starts启动httpd，再直接打命令apachectl能看到httpd已在运行的消息httpd (pid 2012) already running。也可以通过systemctl start httpd启动httpd。 若开启了firewalld服务，需要放行80/tcp端口，放行http服务。 httpd的主要目录（yum源安装）： /etc/httpd：httpd服务根目录 /etc/httpd/conf和/etc/httpd/conf.d：httpd服务配置文件目录 /var/www/html：网站数据目录 /var/log/httpd：httpd日志目录，里面存放有access_log访问日志和error_log错误日志 若是通过yum源安装的httpd，则在/etc/httpd中的logs，modules和run目录都是软连接。 123/etc/httpd/logs --&gt; /var/log/httpd/etc/httpd/modules --&gt; /usr/lib64/httpd/modules/etc/httpd/run --&gt; /run/httpd apachectl命令： 1234567891011apachectl -V # 查看apache版本信息，以及模块、编译信息 -l # 查看已被编译的模块 start # 启动httpd，如果已在运行就会返回错误 stop # 停止httpd restart # 重启httpd fullstatus # 显示mod_status的完整状态报告。需要在服务器上启用mod_status，并在系统上使用基于文本的浏览器 status # 显示简要状态报告，信息与systemctl status httpd一致 graceful # 优雅地重启Apache httpd守护进程。如果守护程序未运行，则启动它。这与正常重启不同，因为当前打开的连接不会中止。副作用是旧的日志文件不会立即关闭。这意味着，如果在日志轮换脚本中使用，则可能需要大量延迟才能确保在处理旧日志文件之前将其关闭。 graceful-stop # 让已运行的httpd进程不再接受新请求，并给他们足够的时间处理当前正在处理的事情，处理完成后才退出。所以在进程退出前，日志文件暂时不会关闭，正在进行的连接暂时不会断开。 configtest # 配置文件语法测试，相当于apachectl -t httpd命令：与apachectl一致 12345678910111213141516171819202122httpd # 可直接启动httpd -D name # 定义一个在&lt; IfDefine name &gt;中使用的name，以此容器中的指令 -d directory # 指定ServerRoot -f file # 指定配置文件 -C &quot;directive&quot; # 指定在加载配置文件前要处理的指令(directive) -c &quot;directive&quot; # 指定在加载配置文件后要处理的指令 -e level # 显示httpd启动时的日志调试级别 -E file # 将启动信息记录到指定文件中 -v # 显示版本号 -V # 显示编译配置选项 -h # 显示帮助信息 -l # 显示已编译但非动态编译的模块，即静态编译的模块 -L # 显示静态模块可用的指令列表 -t -D DUMP_VHOSTS # 显示虚拟主机的设置信息 -t -D DUMP_RUN_CFG # 显示运行参数 -S # 等价于-t -D DUMP_VHOSTS -D DUMP_RUN_CFG。在调试如何解析配置文件时非常有用 -t -D DUMP_MODULES # 显示所有已被加载的模块，包括静态和动态编译的模块 -M # 等价于-t -D DUMP_MODULES -t # 检查配置文件语法 -T # 不检查DocumentRoot，直接启动 -X # 调试模式，此模式下httpd进程依赖于终端 -k # 管理httpd进程，接受start|restart|graceful|graceful-stop|stop httpd配置文件httpd主配置文件主要由指令和容器构成，容器使用&lt;容器名&gt;&lt;/容器名&gt;作为开始和结束，容器的指令一般只在容器内生效，每个指令都是某个模块提供的，指令生效方式是从上往下读取，所以不要变更指令位置。 主配置文件重点指令： ServerRoot：设置Apache的安装主目录，若采用源码安装，默认路径为/usr/local/apache2 Listen：设置服务器监听端口IP及端口号，默认监听服务器本机所有IP地址的80端口。格式：Listen [IP地址:]端口 [协议]，默认监听所有IP，使用TCP协议。可多次使用Listen以开启多个端口 LoadModule：加载模块。格式 LoadModule 模块名 模块文件名，模块文件一般存放在ServerRoot的module目录中 ServerAdmin：主服务器返回给客户端的错误消息中的管理员邮箱地址 ServerName：设置服务器本机的主机名和端口，用于URL重定向 User：apache在本地系统上运行的用户名 Group：apache在本地系统上运行的组名 DocumentRoot：网络路径相对路径的根，是文档的根目录，使用rpm包安装则默认值为/var/www，使用源码安装则默认为$ServerRoot/htdocs ErrorLog：服务器错误日志存放位置，默认使用相对路径logs/error_log ErrorLogFormat：错误日志格式 CustomLog：客户端访问日志文件路径及日志格式，格式：CustomLog 文件名 格式，默认相对路径为logs/access_log LogFormat：用户日志文件格式，一般用这里指定的格式创建别名，然后通过CustomLog调用该格式 LogLevel：日志消息等级，分为debug/info/notice/warm/error/crit/alert/emerg AllowOverride：支持从.htaccess文件中重写前面的指令，若值为None，表示不支持 Require：给所有用户或特定用户/组授予或拒绝对目录的访问 Include：允许Apache在主配置目录加载其他配置文件，默认为conf.d/*.conf Options：为特殊目录设置选项，语法格式为Options [+|-]选项。 All：开启除MultiViews之外的所有选项 None：不启用额外功能 FollowSymlinks：允许Options指定目录下的文件链接到目录外的文件或目录 Indexes：若与URL对应的Options目录下找不到DirectoryIndex指定的首页文件，则会将当前目录的所有文件索引出来 Order：控制默认访问状态以及Allow和Deny的顺序 若为Order deny,allow则先检查拒绝，当拒绝与允许冲突时，allow优先，默认规则allow，即只要是deny排在前面，就只要写拒绝的IP地址即可，使用Deny from [IP地址]|all 若为Order allow,deny则先检查允许，当拒绝与允许冲突时，deny优先，默认规则deny，即只要是allow排在前面，就只要写拒绝的IP地址即可，使用Allow from [IP地址]|all Alias：用于将URL路径映射到本地文件系统的路径，且本地路径不受DocumentRoot的限制，该目录中的脚本不允许执行。格式：Alias URL路径 &quot;本地资源的文件系统路径&quot;。Alias不支持正则，而AliasMatch支持，格式一致。 ScriptAlias：类似于Alias，并且能将Web路径映射到DocumentRoot之外的文件系统位置，还告诉Apache指定的目录存在CGI脚本，可以执行脚本 DirectoryIndex：作为索引的文件名，默认找index.html。若url中未指定网页文件，则会返回该目录下DirectoryIndex定义的文件，可指定多个文件，若都不存在，会生成所有文件列表，此时Option Indexes必须打开。 UserDir：定义和本地用户的主目录相对的目录，可将公共的html文件放入该目录，即每个用户的个人站点。默认设置为public_html，每个用户都可在自己的主目录下创建名为public_html的目录，该目录下的html文件可通过域名/~用户名访问。若值为disabled表示禁止使用个人站点。 Timeout：客户端与服务器连接的超时间隔 KeepAlive：开启长连接。HTTP/1.1中支持一次连接多次传输，可在一次连接中传递多个HTTP请求 KeepAliveTimeout：一次连接中多次请求间的超时间隔 MaxKeepAliveRequests：一个HTTP连接中最多可请求的次数，若为0，表示无限制 指令文档 常用容器： IfDefine：使管理员能采用多种配置方式启动Apache，当启动httpd时使用命令httpd -D 自定义名便会匹配，若测试条件为真，就会加载该容器中定义的参数。格式：&lt;IfDefine [!]自定义名&gt; IfModule：可以封装仅在条件满足时才会处理的命令，根据模块是否加载决定条件是否满足。语法：&lt;IfModule [!] 模块&gt;指令&lt;/IfModule&gt; Directory：仅用于特定的文件系统目录、子目录及目录下内容，通常用绝对路径，即使是相对路径，也是相对于文件系统的根目录。语法：&lt;Directory 路径&gt;指令&lt;/Directory&gt;，路径可使用~匹配正则表达式。 DirectoryMatch：类似Directory，可直接用正则表达式匹配 Files：类似Directory，但Files内指令仅能应用与特定文件，匹配的范围是它所在的上下文。语法：&lt;Files 文件名&gt;指令&lt;/Files&gt;，可使用~匹配正则表达式 FilesMatch：与Files类似，可直接用正则表达式匹配 Location：该容器内的指令仅对特定URL有效。格式&lt;Location URL&gt;指令&lt;/Location&gt;，可使用~匹配正则表达式。Location支持三种匹配模式： 精确匹配：精确到资源的URL路径 加尾随斜线：匹配目录内容，如&lt;Location &quot;/myapp/&quot;&gt; 无尾随斜线：匹配目录和目录内容，如&lt;Location &quot;/myapp&quot;&gt; LocationMatch：类似Location，可直接用正则表达式匹配 在DirectoryMatch，Files，FilesMatch，Location，LocationMatch中，若出现包含关系，如一个目录同时匹配到了两个相同类型容器，则会选择匹配先定义的容器 VirtualHost：虚拟主机，可直接用正则表达式匹配。语法：VirtualHost IP地址:[端口号]，IP地址为监听的本地网卡IP，若为*则表示监听本地所有网卡 EnableSendfile：使用sendfile系统调用，把静态文件发送给客户端，获得更好的性能 httpd虚拟主机基于IP的虚拟主机可根据不同IP地址及端口号定位不同的网站请求，但需要独立的公网IP地址。基于域名的虚拟主机能实现在一台公网服务器上部署多个网站，服务器根据客户端访问HTTP头部信息实现网站的分离解析。 客户端请求到达后，服务器根据&lt;VirtualHost IP地址:[端口号]&gt;匹配主机，若IP地址 为*，表示匹配本地所有IP地址 匹配顺序： 匹配虚拟主机。匹配虚拟主机的规则为最佳匹配法，IP地址越精确，匹配就越优先。 如果基于名称的虚拟主机无法匹配上，则采用虚拟主机列表中的第一个虚拟主机作为响应主机。 如果所有虚拟主机都无法匹配上，则采用从主配置段落中的主机。 首先配置虚拟主机配置文件，将/usr/share/doc/httpd/httpd-vhosts.conf复制到/etc/httpd/conf.d/目录下，可改名，以此为模板，创建一台虚拟主机。配置完成后重启httpd。 1234567891011&lt;VirtualHost *:80&gt; DocumentRoot &quot;/var/www/virhost1&quot; ServerName virhost1.example.com ErrorLog &quot;/var/log/httpd/virhost1-error_log&quot; CustomLog &quot;/var/log/httpd/virhost1-access_log&quot; common&lt;/VirtualHost&gt;&lt;Directory &quot;/var/www/virhost1&quot;&gt; Require all granted Options Indexes AllowOverride None&lt;/Directory&gt; 注：在实验机上，需要将该地址解析出来，所以要修改/etc/hosts，在环回口后添加virhost1.example.com，再访问即可。 注：物理站点与虚拟站点不能同时存在，如果启动虚拟站点，物理站点立刻失效。若要让之前的物理站点恢复访问，就将该站点按虚拟站点的格式重新搭建 httpd认证授权httpd提供各种认证模块，名称以mod_auth开头。基础的http认证模块为mod_auth_basic。 可以通过命令htpasswd生成用于网页认证的用户信息文件，该命令在httpd-tools包中，支持3种加密算法：MD5、SHA和系统上的crypt()函数，默认为md5。 1234567891011121314htpasswd [-cimBdpsDv] [-C cost] passwordfile usernamehtpasswd -b[cmBdpsDv] [-C cost] passwordfile username password -c 创建一个新密码文件 -n 不会更新密码文件，仅仅在输出显示，因此不用指定密码文件。而若不指定此项就必须指定密码文件，不能与-c一起用 -b 在命令行中读取密码，若不指定，系统会提示输入 -i 从输入读取密码（类似echo XXX | htpasswd -i），常用于脚本 -m 使用md5加密（默认） -B 使用bcrypt函数加密，很安全 -C 使用bcrypt函数加密的次数，默认为5，范围是4到31，次数越多越安全，但会更慢 -d 使用crypt函数加密，不安全 -s 使用SHA加密密码，不安全 -p 不加密密码，不安全 -D 删除指定认证用户 主配置文件的认证指令： 12345678AuthType 指定web身份认证的类型，有四种类型： none 不认证 basic 文件认证（默认），需要mod_auth_basic模块 digest md5摘要认证，需要mod_auth_digest模块 form 表单认证，需要mod_auth_form模块AuthName 设置身份认证时的提示信息AuthUserFile 指定web用户认证列表，即htpasswd命令生成的密码文件AuthGroupFile 指定组认证文件，文件中分组格式为&quot;组名: 组成员....&quot; Require指令：只能放在Directory容器中，用于控制对目录的访问权限，功能由mod_authz_core模块提供。有以下配置： Require all granted | denied：允许|拒绝所有人访问该目录 Require method http方法 ...：只有指定的http方法（如get,post）才能访问该目录 Require expr 正则表达式：只要满足指定正则表达式才能访问 Require user 用户...：只有指定用户能访问 Require valid-user 用户...：认证列表中所有用户都可访问 关于用户的认证需要mod_authz_user模块 Require group 组...：指定组内的用户才能访问 Require file-owner：web用户名必须与请求文件的UID对应用户名一致才能访问 Require file-group：web用户名必须为请求文件的gid组中的一员才能访问 组认证需要mod_authz_groupfile模块 Require ip IP地址[/Mask]...：指定IP能访问该目录 Require host 域名...：指定域名能访问该目录 关于ip和host的认证需要mod_authz_host模块 若Require后加上not则是取反。 认证实验： 首先创建密码认证文件：htpasswd -cb /etc/httpd/secret mike 123456，认证用户并不需要在系统中存在。 配置文件中的认证配置： 123456789&lt;Directory &quot;/var/www/virhost1&quot;&gt; Options Indexes AllowOverride None #若通过.htaccess文件配置了以下认证信息，则需要将AllowOverride的值设为AuthConig AuthType Basic AuthName &quot;Enter Auth Username and Password:&quot; AuthUserFile /etc/httpd/secret Require user mike&lt;/Directory&gt; 重启httpd，通过浏览器访问，会提示输入用户名密码。 创建组认证文件echo &quot;group1: mike&quot; &gt; /etc/httpd/auth_group，修改配置文件： 12345678910&lt;Directory &quot;/var/www/virhost1&quot;&gt; Options Indexes AllowOverride None AuthType Basic AuthName &quot;Enter Auth Username and Password:&quot; AuthUserFile /etc/httpd/secret AuthGroupFile /etc/httpd/auth_group Require user mike Require group group1&lt;/Directory&gt; .htaccess文件.htaccess文件提供了一种基于每个目录进行配置更改的方法，该文件包含一个或多个配置，而该文件存放在某个Directory下，则该文件中的配置都应用于这个Directory。 如果有权限访问httpd主服务器配置文件，则应该完全避免使用.htaccess文件，使用.htaccess文件会降低Apache http服务器的速度。 如果想给.htaccess文件改名，则需要在配置文件中用指令AccessFileName &quot;文件名&quot;说明。 是否启用.htaccess文件取决于AllowOverride指令，该指令决定是否启用文件中定义的指令。 通常，只有在无法访问主服务器配置文件时才应使用.htaccess文件。.htaccess文件主要面向于没有root访问权限而无法改动主配置文件的用户，允许他们通过配置各自网站的.htaccess文件自行进行配置修改。 应该避免使用.htaccess文件的两点原因： 当AllowOverride设置为允许使用.htaccess文件时，httpd将在每个目录中查找.htaccess文件。因此，允许.htaccess文件会导致性能下降，且每次请求文档时都会加载.htaccess文件。 httpd必须在所有更高级别的目录中查找.htaccess文件，以便拥有必须应用的完整指令。 例如，如果从目录/www/htdocs/example中请求文件，httpd必须查找以下文件 1234/.htaccess/www/.htaccess/www/htdocs/.htaccess/www/htdocs/example/.htaccess 这样会查找四个文件，即使不存在。 若指定重定向的指令，则在.htaccess上下文中，必须重新编译每个对目录的请求的正则表达式 允许用户修改服务器配置可能导致无法控制的更改，必须对用户的权限进行精细的控制，准确地设置AllowOverride的内容。 由于会从最上级目录迭代向下查找.htaccess文件，所以，若不同的.htaccess文件中有相同指令，则最下层的.htaccess文件中的该指令生效，下层的文件中的指令会覆盖上层文件中相同的指令。 .htaccess文件的常用示例认证（Authentication）：需要在&lt;Directory&gt;中配置AllowOverride AuthConfig 12345AuthType BasicAuthName &quot;Password Required&quot;AuthUserFile &quot;/www/passwords/password.file&quot;AuthGroupFile &quot;/www/passwords/group.file&quot;Require group admins 服务器端包括（Server Side Includes，SSI）：提供了向现有HTML文档添加动态内容的方法，而无需通过CGI程序或其他动态技术。 SSI适用于在大部分内容都是静态的网页中添加小块动态信息，例如当前时间。若网页大部分内容都是动态生成的，则并不适用。 若要使能SSI，则需要在配置文件中或.htaccess文件中添加Options +Includes，表示允许为SSI指令解析文件。 还需要告诉Apache需要解析的文件，例如： 12AddType text/html .shtmlAddOutputFilter INCLUDES .shtml 缺点：如果想将SSI指令添加到现有页面，则必须更改该页面的名称以及该页面的所有链接。 重写规则（Rewrite Rules）：在.htaccess文件中使用RewriteRule时，每个目录的上下文会稍微改变一下，规则被认为是相对于当前目录，而不是原始请求的URI。 12345在根目录中的.htaccess文件RewriteRule &quot;^images/(.+)\.jpg&quot; &quot;images/$1.png&quot;在images中的.htaccess文件RewriteRule &quot;^(.+)\.jpg&quot; &quot;$1.png&quot; CGI配置：允许指定目录中的CGI程序运行 1234Options +ExecCGIAddHandler cgi-script cgi pl若要将目录中的所有文件都看做CGI程序，则将AddHandler替换为SetHandler cgi-script 页面重定向CGICGI（common gateway interface，通用网关接口）是Web 服务器运行时外部程序的规范，按CGI 编写的程序可以扩展服务器功能，处理动态内容。CGI 应用程序能与浏览器进行交互，还可通过数据库API与数据库服务器等外部数据源进行通信,从数据库服务器中获取数据。对于HTTP，只有get和post方法允许执行cgi脚本。 常见的CGI术语： fastcgi：是cgi协议的优化版本 php-cgi：php-cgi实现了fastcgi，但性能不佳，单进程处理请求。 php-fpm：全称：php-fastcgi process manager，是php-cgi的改进版，管理多个php-cgi的进程及线程 cgi进程或线程：用于接收web服务器的动态请求，调用并初始化zend虚拟机 zend虚拟机：对php文件的语法分析、编译并执行，执行完成后关闭 CGI的三种交互模式： cgi模式：httpd每收到一个动态请求就fork一个cgi进程，该进程返回结果后就自动销毁 动态模块模式：将php-cgi模块编译进httpd php-fpm模式：使用php-fpm管理php-cgi，httpd不再控制php-cgi进程的启动，可将php-fpm独立运行在其他非web服务器上，实现动静分离 动态httpd安装Apache后，会在存放网页的目录中生成一个目录cgi-bin，关于CGI的配置在主配置文件中。 指令ScriptAlias：使Apache允许执行一个特定目录中的CGI程序，当客户端请求此特定目录中的资源时，Apache假定其中所有的文件都是CGI程序并试图运行它。格式：ScriptAlias /cgi-bin/ &quot;CGI存放目录&quot; 12345678&lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/var/www/cgi-bin/&quot;&lt;/IfModule&gt;&lt;Directory &quot;/var/www/cgi-bin&quot;&gt; AllowOverride None Options None Require all granted&lt;/Directory&gt; 关于CGI模块加载的配置在conf.modules.d/01-cgi.conf中。 12345678910&lt;IfModule mpm_worker_module&gt; LoadModule cgid_module modules/mod_cgid.so&lt;/IfModule&gt;&lt;IfModule mpm_event_module&gt; LoadModule cgid_module modules/mod_cgid.so&lt;/IfModule&gt;# worker和event使用mod_cgid，而prefork使用mod_cgi&lt;IfModule mpm_prefork_module&gt; LoadModule cgi_module modules/mod_cgi.so&lt;/IfModule&gt; 若开启了Selinux，则还需要修改cgi-bin的上下文chcon -R -t httpd_sys_script_exec_t /var/www/cgi-bin httpd与SSLSSL对Apache能提供的功能： 认证用户与服务器 提供数据保密性和完整性 SSL协议的工作流程包括服务器认证阶段和用户认证阶段 客户端向服务器发送一个hello开始消息，发起一个会话连接 服务器根据客户端信息确定是否生成新的主密钥，如果需要就会在响应hello信息中添加生成主密钥需要的信息 客户端收到响应信息，根据信息生成一个主密钥，用服务器的公钥加密发给服务器 服务器收到后返回客户一个用主密钥认证的信息，让客户端认证服务器 服务器通过客户端认证后，进入用户认证阶段，由服务器开始对客户端的认证 服务器向客户端发起提问（封装在数字签名中） 客户端返回答案和公钥，提供认证信息 HTTPS安全超文本传输协议，内置在浏览器中，对数据压缩和解密。HTTPS就是用SSL作为HTTP应用层的子层，使用TCP443端口。 Apache通过mod_ssl模块实现对TLS/SSL的支持，该模块存放在/usr/lib64/httpd/modules/mod_ssl.so，并有配置文件/etc/httpd/conf.modules.d/00-ssl.conf。还有相关模块mod_socache_shmcb，是一个共享对象缓存提供程序，提供对共享内存段内高性能循环缓冲区支持的缓存的创建和访问，已默认加载。 httpd服务器配置自签名证书： 123456789openssl genrsa -out /etc/pki/tls/private/server.key 2048 #生成私钥openssl req -new -x509 -key /etc/pki/tls/private/server.key -out /etc/pki/tls/certs/server.crt #根据私钥生成根证书 Country Name (2 letter code) [XX]:CN #国家名 State or Province Name (full name) []:jiangsu #省名 Locality Name (eg, city) [Default City]:Yangzhou #地名 Organization Name (eg, company) [Default Company Ltd]:NJUPT #公司名 Organizational Unit Name (eg, section) []:Tech #部门名 Common Name (eg, your name or your server&apos;s hostname) []:system1 #主机名 Email Address []:system1@example.com #邮箱 也可以通过进入/etc/pki/tls/certs并使用命令make server.key创建私钥。 配置SSL虚拟主机，需要引用/etc/httpd/conf.d/ssl.conf中的配置，并做修改。 12345678910111213&lt;VirtualHost *:443&gt; SSLEngine on SSLProtocol all -SSLv2 -SSLv3 SSLCipherSuite HIGH:3DES:!aNULL:!MD5:!SEED:!IDEA SSLHonorCipherOrder on SSLCertificateFile /etc/pki/tls/certs/server.crt SSLCertificateKeyFile /etc/pki/tls/private/server.key DocumentRoot &quot;/var/www/html&quot; ServerName system1.example.com ErrorLog &quot;/var/log/httpd/error_log&quot; CustomLog &quot;/var/log/httpd/access_log&quot; common&lt;/VirtualHost&gt; 由于是对已存在的虚拟主机进行SSL封装，所以，需要在原虚拟主机中添加两条指令进行重定向，使任何访问原http地址的客户端都跳转到https地址。 12345678&lt;VirtualHost *:80&gt; DocumentRoot &quot;/var/www/html&quot; ServerName system1.example.com ErrorLog &quot;/var/log/httpd/error_log&quot; CustomLog &quot;/var/log/httpd/access_log&quot; common RewriteEngine on RewriteRule ^(/.*)$ https://%&#123;HTTP_HOST&#125;$1 [redirect=301]&lt;/VirtualHost&gt; 通过浏览器访问http://system1.example.com，会出现不安全提示 确认添加例外后，就能自动跳转到https://system1.example.com。 httpd日志当Apache开始运行后，会生成4种标准日志文件： 错误日志error_log 访问日志access_log 传输日志 cookie日志 若使用SSL加密，还会生成ssl_access_log、ssl_error_log、ssl_request_log。当日志文件过大时，Apache会自动生成新的日志文件，文件的名称以配置文件中指定。 LogFormat指定的日志记录格式变量： 变量 含义 %b 发送字节（不含HTTP标题） %f 文件名 %h 远程主机 %a 远程IP地址 %{HEADER}i HEADER内容：发送给服务器的请求 %p 服务器的服务端口 %r 请求的第一行，类似GET / HTTP/1.0 %s 状态（起始请求），最后请求状态为%&gt;s %t 时间，格式是common日志格式中的时间格式 %{format}t 时间，格式由format给出 %T 服务器请求花费的时间（单位秒） %u 来自auth的远程用户，若返回码为401则可能是假的 %U 请求的URL路径 %v 服务器的提供服务ServerName 错误日志记录的等级： 等级 解释 Emerg 紧急，系统不可用 Alert 需要立刻注意 Crit 危险警告 Error 除上述三种外的其他情况 Warm 警告 Notice 需要引起注意 Info 一般消息 Debug Debug模式产生的消息 访问日志的种类： 普通日志：在LogFormat定义的名字为common 参考日志：记录客户访问站点的用户身份，名字为referer 代理日志：记录请求的用户代理，名字为agent 综合日志：结合了上面三种，名字为combined 日志切割Apache提供了命令rotatelogs，对日志进行切割，将庞大的日志文件切割为相对小的文件。 12345678910111213141516以轮替时间做切割：rotatelogs [options] 日志文件 [轮替时间（单位秒）][偏移量]以日志大小做切割：rotatelogs [options] 日志文件 [日志文件大小]偏移量为相对于UTC的分钟数，若省略，默认为0，即使用UTC时间。东八区即为8x60=480可以把以下配置添加到主配置文件：TransferLog &quot;|rotatelogs 日志文件 86400&quot;TransferLog &quot;|rotatelogs 日志文件 5M&quot;默认生成的日志名为&quot;日志名.日志开始记录的时间&quot;，如果使用轮替时间，则该值就是轮替时间的倍数，可通过cron服务设置。如果日志文件包含了strftime转换格式，则使用该格式。当轮替时间结束或日志文件大小达到指定值，就会生成一个新日志文件 -v 详细的操作信息会被错误输出(strerr) -l 使用本地时间。不要在改变了GMT偏移量的环境中使用该选项，若设置了此选项，也就不用设置偏移量了 -f 在程序启动时强制开启日志 -t 截断日志 -e 输出日志到标准输出 -c 创建日志，无论是否为空 若要按时间轮替日志文件： ErrorLog &quot;|rotatelogs 日志存放目录/%Y%m%d_error.log 86400 480&quot; CustomLog &quot;|rotatelogs 日志存放目录/%Y%m%d_access.log 86400 480&quot; common 若要按日志大小轮替日志文件： ErrorLog &quot;|rotatelogs -l 目录/%Y%m%d_error.log 5M&quot; CustomLog &quot;|rotatelogs -l 目录/%Y%m%d_access.log 5M&quot; common Webalizer分析统计日志Webalizer是一个高效的web服务器日志分析程序。webalizer基本支持所有的日志文件格式，包括common，combined。目前还支持ftp日志、squid日志分析。 直接yum install webalizer即可。webalizer的配置主要通过配置文件webalizer.conf实现。 12345678910111213LogFile /var/log/httpd/access_log #日志文件的路径，也可通过命令行选项指定OutputDir /var/www/usage #统计报表的输出位置HistoryName /var/lib/webalizer/webalizer.hist #webalizer生成的历史文件名Incremental yes #设置是否增量IncrementalName /var/lib/webalizer/webalizer.current #保存当前数据的文件名PageType htm* #定义哪些类型的URL属于页面访问UseHTTPS no #若在一台安全服务器上运行，需要开启DNSCache /var/lib/webalizer/dns_cache.db #反向DNS解析的缓存文件DNSChildren 10 #设置用于DNS解析的子进程，值要在5到20间Quiet yes #不显示输出信息FoldSeqErr yes #强制忽略次序错误，因为Apache HTTP服务器可能会生成无序日志条目HideURL *.gif #设置需要隐藏的内容SearchEngine yahoo.com p= #设置搜索引擎和URL查询格式 一般只要配置LogFile和OutputDir即可。 123456789101112131415161718webalizer [options] [log file] -v 显示日志详细信息 -d 显示额外的debug信息 -F type 设置日志类型（clf | ftp | squid | w3c） -f 忽略次序错误 -i 忽略历史文件 -p 保留状态（递增） -b 忽视状态（递增） -q 忽略消息信息 -Q 忽略所有信息 -T 显示时间信息 -c file 指定配置文件 -n name 指定服务器主机名 -o dir 指定存放结果的文件 -t name 指定报告题目的主机名 --ip 查看指定IP地址的访问情况 --start 指定开始时间 --end 指定结束时间 在/var/www/usage下生成了几张图片和两个html文件，其中index.html是简要信息，usage_日期.html是详细的分析文件 index.html usage_日期.html httpd代理httpd通过ProxyRequests指令配置正向代理的功能 123456ProxyRequests onProxyVia on&lt;Proxy &quot;*&quot;&gt; #访问任意外网URL Require host 允许通过代理访问外网的内网服务器 #也可以是Require all granted&lt;/Proxy&gt; Apache-MPM模式MPM(Multi-Processing Modules)，Apache的多路处理模块，有三种模式：prefork、worker、event。 编译时可通过--with-mpm指定模式，也可以通过--enable-mpms-shared=all支持全部三种。httpd2.4以上默认采用event模式。并可通过apachectl -l看到编译了event.c模块。 httpd2.4通过rpm安装会发现仍采用prefork模式，而源码安装则已使用event模式 可以修改httpd.conf中添加以下模块（源码安装）或/etc/httpd/conf.modules.d/00-mpm.conf（rpm安装）改变模式 123LoadModule mpm_prefork_module modules/mod_mpm_prefork.so 或LoadModule mpm_worker_module modules/mod_mpm_worker.so 或LoadModule mpm_event_module modules/mod_mpm_event.so prefork：实现了一个非线程、预派生的工作模式。在Apache启动之初，就会预派生一些子进程，然后等待连接。可以减少频繁创建和销毁进程的开销，每个子进程只有一个线程。成熟稳定，可以兼容新老模块，也不需要担心线程安全问题。效率比worker略高 缺点：一个进程相对地占用更多的资源，消耗大量内存，不擅长处理高并发的场景。 worker：使用了多进程和多线程的混合模式，也同样会预派生一些子进程，然后每个子进程创建一些线程，同时包括一个监听线程，每个请求过来会被分配到一个线程来服务。占用内存少，适合高并发环境 使用线程的原因：线程比进程更加轻量级，因为线程通常会共享父进程的内存地址的，因此内存占用会减少一些。如果一个线程异常挂了，会导致父进程和它的其他正常子线程都挂了，只会影响Apache的一部分，而不是整个服务。 缺点：必须考虑线程安全问题，因为多个子进程时共享父进程的内存地址的。若使用keepalive的长连接方式，某个线程一直占据，若过多的线程被占用，会导致高并发时无服务线程可用。 event：从Apache2.2才被加入MPM，Apache2.4开始成为默认MPM。类似worker模式，但解决了keepalive问题。有一个专门的线程来管理这些keep-alive线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放，这样增强了在高并发场景下的请求处理能力。 各MPM模式的简单优化：若是rpm安装，就在httpd.conf中添加，若为源码安装，就在/usr/local/httpd-2.4/conf/extra/httpd-mpm.conf中找到对应模块修改。以下参数基本采用配置文件默认值。 worker模式 1234567891011121314151617181920212223242526&lt;IfModule mpm_worker_module&gt; ServerLimit 25 #服务器允许配置的上限进程数 # 与ThreadLimit结合使用，可设置MaxClients允许配置的最大数值 # 在重启期间对ServerLimit的修改都会被忽略，但对MaxClients的修改可生效 ThreadLimit 200 #每个子进程可配置的线程数的上限 # 也设置了ThreadPerChild的上限，默认为64 StartServers 3 #服务器启动时建立的子进程数，默认为3 MinSpareThreads 75 #最小空闲线程数，默认75。 #若服务器中空闲进程太少，子进程会自动产生空闲进程等待 MaxSpareThreads 250 #最大空闲线程数，默认250。 #若服务器中空闲进程太多，子进程会杀死多余的空闲进程。 #取值范围：&gt;= MinSpareThreads+ThreadsPerChild MaxClients 2500 #允许同时运行的最大进程数，任何超过限制的请求进入等待队列 #默认值为ServerLimit*ThreadsPerChild。若要增加此项，则同时也要增加ServerLimit ThreadsPerChild 25 #每个子进程建立的常驻执行线程数，默认25。 #子进程创建这些线程后就不创建新线程了 MaxConnectionsPerChild 0 #处理多少个请求后子进程自动销毁，默认值0意味着永不销毁。 # 在Apache2.4版本以前，叫做MaxRequestsPerChild #当负载较高时，为了使每个进程处理更多的请求，避免销毁、创建进程的开销，一般建议设置为0或较大的数字。&lt;/IfModule&gt; prefork模式 12345678&lt;IfModule mpm_prefork_module&gt; StartServers 5 MinSpareServers 5 #最小空闲进程数，与MinSpareThreads同理 MaxSpareServers 10 #最大空闲进程数，与MaxSpareThreads同理 ServerLimit 2000 MaxClients 1000 #默认MaxClients最多有256个线程 MaxConnectionsPerChild 0 &lt;/IfModule&gt; 修改模式重启httpd，查看进程，能看到五个子进程 1234567ps -ef | grep httpdroot 2241 1 1 22:05 ? 00:00:00 /usr/sbin/httpd -DFOREGROUNDapache 2242 2241 0 22:05 ? 00:00:00 /usr/sbin/httpd -DFOREGROUNDapache 2243 2241 0 22:05 ? 00:00:00 /usr/sbin/httpd -DFOREGROUNDapache 2244 2241 0 22:05 ? 00:00:00 /usr/sbin/httpd -DFOREGROUNDapache 2245 2241 0 22:05 ? 00:00:00 /usr/sbin/httpd -DFOREGROUNDapache 2248 2241 0 22:05 ? 00:00:00 /usr/sbin/httpd -DFOREGROUND event模式 12345678&lt;IfModule mpm_event_module&gt; StartServers 3 MinSpareThreads 75 MaxSpareThreads 250 ThreadsPerChild 25 MaxRequestWorkers 400 MaxConnectionsPerChild 0&lt;/IfModule&gt; Apache实用第三方模块若要在httpd上添加新的模块，可以通过修改模块配置文件增加LoalModule指令添加，也可以使用httpd-devel提供的工具apxs直接添加，需要httpd开启了DSO。 123456apxs -n 模块名 指定模块名，可与-i和-g组合 -i 安装模块，可指定多个 -a 自动在主配置文件加上LoadModule -A 自动在主配置文件加上#LoadModule，即安装了但先不启用 -c C文件 将.c文件编译为.so文件 模块间可能存在依赖，可根据报错信息解决。 Gzip压缩Gzip将Apache网页内容压缩后传输给客户端，加快网页加载速度，建议开启。Gzip有两个模块：mod_gzip和mod_deflate， 防DDOS攻击应对DDOS攻击的模块为mod_evasive，可通过yum install mod_evasive获取。安装完成后会生成/usr/lib64/httpd/modules/mod_evasive24.so，以及/etc/httpd/conf.d/mod_evasive.conf LAMP环境搭建直接用yum|dnf安装php，php版本为7.1。php的核心包： php：在/etc/httpd/conf.d/创建了php.conf，在/usr/lib64/httpd/modules/创建了libphp7.so php-common：创建了大量模块存放在/usr/lib64/php/modules/，帮助文档，配置文件/etc/php.ini以及/etc/php.d/中各个配置文件。 php-fpm：创建了配置文件/etc/php-fpm.conf及/etc/php-fpm.d/ php-cli：创建了命令php、php-cgi、phar、phpize存放在/usr/bin/中 使用systemctl start php-fpm启动。 参考文章 高性能网站构建实战 Linux系统管理与网络管理 Linux就该这么学 Linux运维之道（第二版） Linux服务器架设指南（第二版） 防线-企业Linux安全运维理念和实战 RHCSA/RHCE红帽Linux认证学习指南（第7版） Apache性能优化之MPM选择和配置 Apache的三种MPM模式比较：prefork，worker，event apache的三种mpm模式 浅谈.htaccess文件—避免滥用.htaccess文件 Apache HTTP Server Tutorial: .htaccess files Apache httpd Tutorial: Introduction to Server Side Includes 简单说明CGI和动态请求是什么]]></content>
      <tags>
        <tag>server</tag>
        <tag>Apache</tag>
        <tag>http</tag>
        <tag>LAMP</tag>
        <tag>LAMT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS基础笔记]]></title>
    <url>%2F2018%2F05%2F02%2FNFS%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇笔记包含以下内容： NFS原理 NFS基础配置 服务器端 客户端 NFS原理NFS（Network Files Network）网络文件系统，允许网络中主机通过通过TCP/IP进行资源共享。采用C/S工作模式，NFS服务器相当于文件服务器，将某个目录设置为输出目录，客户端可将服务器端的输出目录挂载在本地进行访问。NFSv4基于TCP，端口号2049。RPC（Remote Procedure Call）远程过程调用，是一种通过网络从远程计算机程序上请求服务，跨越了传输层和应用层的协议。 NFS基础配置环境： 两台虚拟机 192.168.163.103/24 192.168.163.104/24 系统：CentOS7 Selinux：关闭 防火墙：关闭 服务器端NFS服务依赖于RPC服务与外界通信，所以需要安装rpcbind程序而NFS 安装NFS主程序和RPC程序yum install nfs-utils rpcbindsystemctl enable nfs-serversystemctl start nfs-server rpcbind.service 配置文件/etc/exports12# 格式为：共享目录 分享给的主机1(参数) 主机2(参数) .../var/nfsshare 192.168.163.*(rw,sync) *.example.com(rw) 参数列表 参数 含义 ro 客户端只读 rw 客户端可读写 sync 数据同步写入内存与磁盘，保证数据一致性，效率低 async 异步IO，数据先暂时存与内存，待需要时写入硬盘，效率高，但数据丢失风险高 noaccess 阻止访问该目录及其子目录 all_squash 无论NFS客户端使用什么用户访问，都映射为NFS服务器端的匿名用户，即nfsnobody root_squash 当NFS客户端使用root访问时，映射为NFS服务器端的匿名用户，即nfsnobody no_root_squash 当NFS客户端使用root访问时，仍映射为NFS服务器端的root，并不安全 wdelay 为合并多次更新而延迟写入磁盘 no_wdelay 尽可能快地写入磁盘 secure 限制nfs服务只能使用小于1024的TCP/IP端口传输数据 insecure 可使用大于1024的端口 anounuid 指定NFS服务器中的用户为匿名用户 anoungid 指定NFS服务器中的用户组为匿名用户组 默认情况下，nfs服务会禁止客户端的root用户对共享目录进行写操作，目的是为了保证当nfs以共享目录工作时，共享目录的数据不会被客户端随意修改，但是当nfs以远程存储工作时，这个功能就不合理，所以当nfs以远程存储来工作时，需要在服务端设置no_root_squash选项关闭该功能。 配置完后重启nfs-server服务，或者使用exportfs命令12345exportfs -a 导出所有列在/etc/exports的目录 -v 显示所有被导出或取消导出的目录 -r 重新导出所有列在/etc/exports的目录 -u [目录] 取消指定目录的导出，与-a同时用时，会取消配置文件中所有目录的导出 nfsstat命令可查看当前NFS信息12345nfsstat -s 显示NFS服务器信息 -c 显示NFS客户端信息 -m 显示每个NFS文件系统的统计信息（在客户端上查看） -r 显示RPC信息 若开启了firewalld，则需要放行nfs和rpcbind还有mountd服务，放行端口20491234firewall-cmd --permanent --add-service=nfsfirewall-cmd --permanent --add-service=rpc-bindfirewall-cmd --permanent --add-service=mountdfirewall-cmd --permanent --add-port=2049/tcp 2049/udp mountd提供挂载服务，与nfs无关，只是为了方便客户端挂载 若开启了Selinux，需要添加上下文123chcon -R -t public_content_t /var/nfssharesetsebool -P nfs_export_all_rw onsetsebool -P nfs_export_all_ro on NFS客户端 需要安装nfs-utils rpcbindyum install nfs-utils rpcbind 通过showmount查看NFS服务器的共享信息123showmount [options] [NFS服务器] -e 显示NFS服务器的共享列表 -a 显示本机挂载NFS资源情况 123# showmount -e 192.168.163.102Export list for 192.168.163.102:/var/nfsshare 192.168.163.* 挂载到本机123456# mkdir /nfsshare #创建挂载目录# mount -t nfs 192.168.163.102:/var/nfsshare /nfsshare# df -hFilesystem Size Used Avail Use% Mounted on......192.168.163.102:/var/nfsshare 17G 8.1G 9.0G 48% /nfsshare 在mount时也可使用-o指定文件系统的选项12345678910rsize= 从NFS服务器读文件时每次使用的字节数，默认1024字节wsize= 向NFS服务器写文件时每次使用的字节数，默认1024字节timeo= RPC调用超时后，确定重试算法的参数soft 软挂载方式，当客户端请求得不到回应时，提示IO错误并退出hard 硬挂载方式，当客户端请求得不到回应时，提示服务器无响应，但继续请求。默认硬挂载intr NFS文件操作超时并时硬挂载时，允许中断文件操作并向调用它的程序返回EINTRro 只读方式挂载NFS文件系统rw 读写方式挂载NFS文件系统fg 在前台重试挂载bg 在后台重试挂载 也可通过配置文件/etc/fstab开机自动挂载123# vim /etc/fstab......192.168.163.102:/var/nfsshare /nfsshare nfs defaults 0 0 使用mount或配置文件/etc/fstab挂载的不足：NFS服务器与客户端的连接不是永久的，任何一方的掉线都会导致另一方等待超时。并且即使很多用户都挂载了共享目录，也会有大部分的用户在大部分时间是不会使用的，这样造成了NFS服务器资源的大量消耗。可通过autofs服务按需动态挂载解决该问题。 使用autofs自动挂载autofs是一个提供按需挂载的服务，只有在用户访问该挂载点时才会动态挂载该共享目录。安装autofs程序，并开机自启yum install autofssystemctl enable autofs.servicesystemctl start autofs.service创建autofs关于nfs主配置文件，也可以直接在autofs的主配置文件/etc/auto.master中添加内容。12345# vim /etc/auto.master.d/nfs.autofs主配置文件的配置格式：挂载点顶层目录 映射文件/nfs /etc/nfs.misc由于挂载点为/nfs/share，所以顶层目录为/nfs 创建nfs配置的映射文件/etc/nfs.misc12345# vim /etc/nfs.misc映射文件格式：挂载点 [-挂载选项] NFS服务器名或IP:共享目录挂载点是对于挂载点顶层目录的相对路径share -fstype=nfs,rw 192.168.163.102:/var/nfsshare 配置完成后重启autofs服务即可。进入/nfs目录中，查看并无内容。然后进入share便可查看到挂载目录的内容。再通过df查看，已成功挂载。 注：由于在客户端挂载时也会指定选项，若与服务器端选项不同，在执行操作时可能会报错，即：选项以服务器端配置为准。]]></content>
      <tags>
        <tag>server</tag>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Samba基础学习笔记]]></title>
    <url>%2F2018%2F05%2F02%2Fsamba%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇笔记包含以下内容： Samba原理 Samba基础配置 服务器端 客户端 Samba原理Samba最初的目的是为了Windows和Linux之间的沟通，实现不同操作系统的资源共享，如今成为了十分安全，高效的文件服务。Samba有以下主要功能： 共享文件与打印机 提供身份认证，给不同身份的用户不同的访问权限和文件 可进行域名解析，将计算机的NetBIOS名解析为IP地址 samba能收集局域网上用户广播的主机信息，提供检索服务，也称为浏览服务，能显示共享目录，打印机等资源 支持SSL Samba整合了SMB协议和NetBIOS协议，基于TCP/IP。NetBIOS协议NetBIOS（Network Basic Input/Output System），网络基本输入输出系统协议，属于会话层协议。能通过该协议获取计算机主机名，并解析为IP地址。SMB协议SMB（Send Messsage Block），运行于NBT协议（NetBIOS over TCP/IP），属于表示层与应用层协议。端口号：139/TCP，137、138/UDP。 SMB协议工作流程 协议协商客户端向Samba服务器发送Negport请求报文，列出所有支持的SMB版本。服务器收到后回应Negport报文，列出希望客户端使用的SMB版本。 建立连接确定了SMB版本，客户端会发送Session Setup请求报文，包含用户名与密码，建立连接。服务器收到后进行验证并回应报文，若验证通过，就返回为该用户分配的唯一UID，若失败则返回失败信息。 访问共享资源客户端向服务器发送Tree Connect请求报文，包含要访问的共享资源名。服务器收到后，根据配置文件确定是否该用户能访问，返回一个响应报文，若允许访问，就给该用户与共享资源连接分配一个TID，用户即可访问该资源。 断开连接客户端向服务器发送Tree Disconnect报文，请求服务器断开连接，服务器也回应一个响应，并断开连接。 Samba守护进程 用户若要访问Windows上的公共资源，必须加入该Windows主机的群组Workgroup，并该用户主机必须设置一个主机名（不是hostname），该主机名是建立在NetBIOS协议上的，可称为NetBIOS Name，在同一个群组中，该NetBIOS Name必须唯一。 用户是否能访问并对该文件进行操作不仅需要通过服务器身份认证，还需要对该文件具有权限。 Samba服务有两个守护进程 smbd：用于管理samba主机共享目录、文件、打印机等，利用TCP传输文件，开放端口为139/TCP和445/TCP nmbd：用于管理群组、NetBIOS Name的解析，基于UDP，开启端口137/UDP，138/UDP进行解析 Samba安装包： samba：包含samba的守护进程文件，samba文档，logrotate配置文件，开机默认选项配置文件 samba-common：包含samba主要配置文件smb.conf，配置文件检查程序testparm等 samba-client：samba客户端程序，提供客户端操作指令集 Samba基础配置实验环境： 两台虚拟机： samba服务器：192.168.163.103/24 samba客户端：192.168.163.104/24 系统：CentOS7 Selinux：未开启 firewalld：未开启 服务器端安装samba客户端123yum install samba-common sambasystemctl enable smb nmbsystemctl start smb nmb 创建共享目录，可随意创mkdir /var/smbshare修改配置文件/etc/samba/smb.conf配置文件中可在选项前加;使其不生效，相当于#注释配置文件存在以下配置块：[global] 全局选项，对所有资源生效基础配置则不需要修改123456789101112131415161718[global] workgroup = SAMBA #设置群组 server string = Samba Server #设置服务器描述 netbios name = MYSERVER #设置NetBIOS Name interfaces = lo eth0 192.168.163.0/24 # 设置监听接口、IP地址 hosts allow = 192.168.163. #白名单，设置允许的主机网段 hosts deny = #黑名单，黑白名单设置一个即可 security = user #samba的安全模式，有三种模式：user、share、server #user模式为每次访问服务器都会登录验证，share模式为不需登录。官方仅推荐user模式。 passdb backend = tdbsam #存放用户信息，有两种选择tdbsam和lsapsam，tdbsam不需要额外配置 log file = /var/log/samba/log.%m #设置日志文件路径，%m会替换为请求连接的NetBIOS名 username map = /etc/samba/smbusers #设置用户映射，记录samba账号和虚拟账号的对应关系 #---打印配置--- printing = cups #打印配置，使用cups服务 printcap name = cups #通常设置为printcap文件 load printers = yes #自动加载打印机列表 cups options = raw #设置cups的选项，raw为允许在windows客户端上加载驱动 [homes]为特殊共享目录，表示用户主目录[printers]为特殊共享目录，表示打印机配置共享资源：12345678910111213[smbshare] comment = smbshare #资源描述 path = /var/smbshare #共享目录 public = no #是否允许匿名访问 guest ok = no #是否允许不输入密码访问 printable = Yes #是否可读 writable = yes #是否可写，只有该目录有写权限且此项为yes，才能写入 browseable = yes #是否可见 write list = mike #设定特定用户写权限 #若writable为no，此项仍能生效 create mask = 0600 #创建文件默认权限 directory mask = 0775 #创建目录默认权限链路 hosts allow =192.168.163. #白名单 可通过testparm检查配置文件是否正确可通过man smb.conf查看详细配置文件选项创建用户并添加到samba由于该用户是提供给客户端用于登录samba的，所以在服务器端应设置为不能登陆，并且为了安全性，不要设密码。useradd mike -s /sbin/nologin注：samba并不是将系统中的用户变为samba用户的，samba的用户是独立于linux系统的，但必须在linux系统中存在，才能映射，所以linux系统中需要创建同名用户。将用户添加到smb服务器的用户列表中，并设置smb登录密码smbpasswd -a mike，然后输入登录密码12345smbpasswd [options] [username] -a add添加 -d disable禁止用户访问 -n no password不设置密码，需要smb.conf中global设置nullpasswords=true开启 -x delete删除用户 或者使用另一条命令pdbedit，用于管理SMB服务的账号信息数据库pdbedit -a -u mike12345pdbedit [options] [username] -a 添加 -x 删除 -L 列出用户列表 -v 详细信息 注： 若安装并开启了firewalld，需要开启端口TCP139端口，UDP137、138端口，并放行服务samba。 若安装并开启了Selinux，需要添加上下文12345678chcon -R -t samba_share_t /var/smbshare或semanage fcontext -a -t samba_share_t /var/smbshare然后setsebool -P samba_export_all_rw onsetsebool -P samba_export_all_ro on若分享的是/homesetsebool -P samba_enable_home_dirs on配置完后restorecon -Rv /var/smbshare 客户端安装samba客户端yum install samba-client cifs-utilscifs-utils是让Windows系统能使用公共文件系统的工具。CIFS是微软开发的公共Internet文件系统协议，能够支持网上邻居。查看服务器给指定用户提供的共享目录的信息123456789101112131415161718# smbclient -L //192.168.163.103/smbshare -U mikeEnter SAMBA\mike&apos;s password: Sharename Type Comment --------- ---- ------- print$ Disk Printer Drivers share Disk SHARE smbshare Disk smbshare IPC$ IPC IPC Service (Samba 4.7.1) mike Disk Home DirectoriesReconnecting with SMB1 for workgroup listing. Server Comment --------- ------- Workgroup Master --------- ------- SAMBA SYSTEM3 从返回信息可得知共享资源以及群组和服务器名登录smb服务器，进入指定资源1234# smbclient //192.168.163.103/smbshare -U mikeEnter SAMBA\mike&apos;s password:Try &quot;help&quot; to get a list of possible commands.smb: \&gt; 已进入该共享目录，并进入samba客户端命令行模式，可通过help查看能进行的操作常用命令如下：put [本机文件路径] [资源中相对路径] 上传文件get [资源路径] 下载文件 客户端挂载 创建认证文件1234# vim /root/secure/auth.smbusername=mikepassword=redhatdomain=SAMBA 设置该文件的权限，这个文件的机密性很重要chmod 700 /root/securechmod 600 /root/secure/auth.smb 挂载共享目录mount -t cifs -o rw,credentials=/root/secure/auth.smb //192.168.163.103/smbshare /shares/smbshare Windows端登录及挂载在Windows端，可在文件资源管理器的地址栏输入\\192.168.163.103\smbshare登录进入smb服务器的该资源。若要挂载，在“此电脑”中右击，选择“添加一个网络位置”，按“下一步”，进入以下界面，填入要挂载的共享目录 然后不断“下一步”，即可设置完成。在“此电脑”查看，已成功挂载。]]></content>
      <tags>
        <tag>server</tag>
        <tag>Samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL完全笔记]]></title>
    <url>%2F2018%2F04%2F30%2FMySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于MySQL5.7 本篇包含以下知识点： MySQL体系结构 存储引擎 数据类型 运算符 函数 表操作 数据操作 索引 视图 触发器 存储过程与函数 事务 安全 日志 维护 MySQL体系MySQL采用C/S体系，因此在使用时，是运行两个程序： mysqld：MySQL服务器程序，运行在数据库服务器上，负责监听并处理请求 mysql-client：运行在客户端上，负责连接到数据库服务器并发出指令。 存储引擎MySQL具有可替换存储引擎构架的特征。MySQL功能分为两部分： 外层部分：完成与客户端的连接，调查SQL语句的内容 内层部分：即存储引擎部分，负责接收外层的数据操作指令，完成实际的数据输入输出及文件操作。MySQL支持多种存储引擎，可通过show engines;查看mysql支持的存储引擎，MySQL共支持9种存储引擎，其中最主要的两个引擎为MyISAM和InnoDB，默认引擎为InnoDB。 MyISAM与InnoDB的区别： 特性 MyISAM InnoDB 存储限制 有 64TB 事务安全 不支持 支持 锁机制 表锁 行锁 B树索引 支持 支持 哈希索引 不支持 不支持 全文索引 支持 不支持 集群索引 不支持 支持 数据缓存 支持 索引缓存 支持 支持 数据可压缩 支持 不支持 空间使用 低 高 内存使用 低 高 批量插入速度 高 低 外键 不支持 支持 InnoDB只有表结构，数据全部存储在ibdata1文件中，算法复杂。 MyISAM将表，数据，索引全部单独存储。 MyISAM适合对事务完整型无要求并以访问为主的应用，访问速度快。 InnoDB适合频繁更新、删除操作，对事务要求高，需要实现并发控制的应用。 可通过show create table 表名查询表中使用的存储引擎。也可通过alter table 表名 engine=引擎更改表的存储引擎。 数据类型 整数 tinyint：1字节 smallint：2字节 mediumint：3字节 int：4字节 bigint：8字节 整数类型都分为有符号与无符号。默认有符号，可在类型前加上unsigned创建无符号类型。插入数据只能插入整数，若字段设置了是整数类型，就算插入浮点数也会转换为整数。零填充：zerofill，若数据位数不满设置位数值，则前面补充0，且若设置零填充，数据类型自动变为无符号类型。零填充意义：保持数据格式 12345678910111213141516171819mysql&gt; desc my_int;+-------------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------------+--------------+------+-----+---------+-------+| tinyint_1 | tinyint(4) | YES | | NULL | || smallint_1 | smallint(6) | YES | | NULL | || mediumint_1 | mediumint(9) | YES | | NULL | || int_1 | int(11) | YES | | NULL | || bigint_1 | bigint(20) | YES | | NULL | |+-------------+--------------+------+-----+---------+-------+# 括号中的数值为显示位数（宽度），可修改，不会影响数据。mysql&gt; alter table my_int modify int_1 int zerofill;# zerofill 会在显示宽度不满时用0填满mysql&gt; select int_1 from my_int;+------------+| int_1 |+------------+| 0000000004 |+------------+ 浮点数 float：4字节，也可设置为float(M,D) double：8字节 decimal(M,D)：定点数，M+2字节，取值范围与double一致，但有效范围由M与D决定，M为一共的位数，D为小数部分的位数。小数部分超出没问题，会自动四舍五入，但整数部分不能超出。12345678910111213create table my_float( float_1 float(5,2), double_1 double(5,2), decimal_1 decimal(5,2));mysql&gt; insert into my_float values(1.115,1.115,1.115);# 整数部分不能超出规定长度，但小数部分可以，小数的超出部分会四舍五入。mysql&gt; select * from my_float;+---------+----------+-----------+| float_1 | double_1 | decimal_1 |+---------+----------+-----------+| 1.12 | 1.12 | 1.12 |+---------+----------+-----------+ 字符串 char(length)：定长字符串，定义时指定长度，最大255字节。 varchar(length)：变长字符串，最大长度65536个字节，一般会自动多加一个字节。实际存储从第二个字节开始，接着要用1到2个字节表示实际长度（长度超过255时需要2个字节），因此最大长度不能超过65535。varchar 会保留字符串末尾的空格，而 char 会删除。 text：存储文字的文本字符串 blob：存储二进制的文本字符串若数据量非常大（超过255字节），可选用文本字符串。 枚举字符串：enum()，用于规定数据格式，节省空间（枚举实际存储的是数值）。 集合字符串：set()，集合存储的也是数值，且可以多选 存储数据 char(4) varchar(4) char占用字节 varchar占用字节 abcd abcd abcd 4x3 4x3+1 abcde 错误 错误 超出长度 超出长度 如何选择定长或变长字符串？ * 定长字符串：磁盘空间浪费，但效率高，若数据确定长度一样，就选定长（如身份证，电话号） * 变长字符串：磁盘空间节省，但效率低，若数据长度不确定，就选变长（如住址，姓名） 枚举字符串举例123456mysql&gt; create table my_enum(sex enum(&apos;m&apos;,&apos;f&apos;));mysql&gt; insert into my_enum values(&apos;m&apos;);Query OK, 1 row affected (0.01 sec)# 字段赋值必须填枚举中的字符串mysql&gt; insert into my_enum values(&apos;a&apos;);ERROR 1265 (01000): Data truncated for column &apos;sex&apos; at row 1 在MySQL中，系统会自动转换数据类型。枚举中字符串是数值的证明如下：1234567891011mysql&gt; select sex+0,sex from my_enum \G*************************** 1. row ***************************sex+0: 1 sex: m*************************** 2. row ***************************sex+0: 2 sex: f# 由此可知，枚举中字符串的数值是按照枚举顺序从1开始。# 于是也可以通过数值插入mysql&gt; insert into my_enum values(1),(2);Query OK, 2 rows affected (0.00 sec) 枚举原理：枚举在进行数据规范（定义）的时候，系统会自动建立一个数字与枚举元素的对应关系（存放在日志），然后在进行数据插入时，系统自动将字符转换成对应的数字存储，在进行数据提取时，系统自动将数值转换成对应字符串显示。 集合字符串举例：12mysql&gt; create table my_set(lang set(&apos;c&apos;,&apos;c++&apos;,&apos;python&apos;,&apos;java&apos;));# 与枚举类似，集合也可通过数值进行赋值 日期和时间 date：4字节，1001年到9999年的日期 datetime：8字节，1001年到9999年的日期，并能保存时间 timestamp：4字节，1970年1月1日到现在的秒数，最大到2038年 time：3字节 year：1字节，最小值1901，最大值2155MySQL提供函数from_unixtime()将unix时间戳转换为时间，unix_timestamp()将日期转换为unix时间戳。默认情况下，如果插入时没有指定 TIMESTAMP 列的值，会将这个值设置为当前时间。应该尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高。datetime与时区无关，timestamp与时区有关。 记录长度：任何一条记录的长度最长不能超过65535个字节，一条记录的最长字节数为65534，但可以人为填满。MySQL中text文本字符串不占用记录长度：额外存储，但text字符串也属于记录的一部分，所以一定要占据记录中的部分长度（10字节，保存数据的地址与长度） 运算符算数运算符：加、减、乘、除、模12345678910111213mysql&gt; select 6+4 加, 6-2 减, 6*4 乘, 6/4 除, 6 DIV 4 除, 6%4 模, 6 MOD 4 模;+----+----+----+--------+------+------+------+| 加 | 减 | 乘 | 除 | 除 | 模 | 模 |+----+----+----+--------+------+------+------+| 10 | 4 | 24 | 1.5000 | 1 | 2 | 2 |+----+----+----+--------+------+------+------+当除数为0时，结果为NULL 比较运算符：大于、小于、等于、不等于、IS NULL、BETWEEN AND、IN、LIKE、REGEXP 比较运算符 说明 &gt;或&gt;= 大于或大于等于 &lt;或&lt;= 小于或小于等于 =或&lt;=&gt; 等于 !=或&lt;&gt; 不等于 BETWEEN AND 在指定范围 IS NULL 为空 IN 在指定集合 LIKE 通配符匹配 REGEXP 正则表达式匹配 常用正则表达式 模式字符 说明 案例 ^ 匹配字符串开始 ‘^a’ $ 匹配字符串结束 ‘g$’ . 匹配字符串中任意一个字符 ‘a.c’ [字符集合] 匹配字符集合内的任意一个字符 ‘[abc]’ [\^字符集合] 匹配字符集合外的任意一个字符 ‘^abc’ str1｜str2 匹配符合的字符串 ‘abc｜cde’ * 匹配字符，包含0个和1个 ‘a*‘ + 匹配字符，包含1个 ‘a+‘ 字符串{N} 字符串出现N次 ‘abc{2}’ 字符串(M,N) 字符串至少出现M次，最多N次 ‘abc(2,3)’ 逻辑运算符AND(&amp;&amp;)：与，OR(||)：或，NOT(!)：非，XOR：异或 位运算符&amp;：按位与，|：按位或，~：按位取反，^：按位异或，&lt;&lt;：按位左移，&gt;&gt;：按位右移可使用BIN()函数显示二进制。 函数SQL语句的移植性较强，而函数的移植性不强，因为各种数据库软件都有自己特有的函数。Mysql函数分为： 字符串函数 数值函数 日期函数 系统信息函数 字符串函数 函数 功能 concat(str1,str2…) 连接字符串 insert(str,x,y,instr) 用字符串str的x位置开始y个字符长的子串替换字符串instr lower(str) 将str的所有字符换为小写 upper(str) 将str的所有字符换为大写 left(str,x) 返回str的最左边的x个字符 right(str,x) 返回str的最右边的x个字符 lpad(str,n,pad) 使用pad字符串对str最左边进行填充直到长度为n rpad(str,n,pad) 使用pad字符串对str最右边进行填充直到长度为n ltrim(str) 去掉str左边的空格 rtrim(str) 去掉str右边的空格 trim(str) 去除str行头和行尾的空格 repeat(str,x) 返回str重复x次的结果 replace(str,a,b) 使用字符串b替换str中所有字符串a strcmp(str1,str2) 比较字符串 substring(str,x,y) 返回str中从x位置起y个长度的字符串 数值函数 函数 功能 abs(x) 返回x的绝对值 ceil(x) 返回大于x的最小整数值 floor(x) 返回小于x的最大整数值 mod(x) 返回x%y rand() 返回0-1的随机数 rand(x) 返回0-1的随机数，x对应的随机数是固定的 round(x,y) 返回x的四舍五入后y位小数的值（y可选） truncate(x,y) 返回x截断为y位小数的值 日期和时间函数 函数 功能 curdate() 获取当前日期 curtime() 获取当前时间 now() 获取当前日期和时间 unix_timestamp(date) 获取date的unix时间戳 from_unixtime(timestamp) 获取unix时间戳 week(date) 返回date为一年中的第几周 year(date) 返回date的年份 monthname(date) 返回date的月份 hour(time) 返回time的小时值 minute(time) 返回time的分钟值 系统信息函数 函数 功能 version() 返回版本号 database() 返回当前数据库名 user() 返回当前用户 last_insert_id() 返回最近生成的Auto_Increment值 特殊功能函数|password(str)|对str加密||format(x,n)|对x格式化，保留n位小数||inet_aton(ip)|将IP地址转换为数字||inet_ntoa(x)|将数字转换为IP地址||get_loct(name,time)|创建一个持续时间time的名为name的锁||release_loct(name)|对名字为name的锁解锁||benchmark(count,expr)|将表达式expr执行count次||convert(s USING cs)|将字符串s的字符集变为cs||convert(x,type)|将x转为type类型| 表操作创建表123456create table 表名( 字段1 数据类型, 字段2 数据类型, ......);也可直接create table 数据库名.表名(); # 这样不需要先进入库，直接建表。 表创建后，数据库文件下会生成对应表的结构文件.frm（与存储引擎有关）。 查看创建语句show create table 表名;查看表结构desc/show 表名; 12345678mysql&gt; desc user;# field：字段名# type：字段类型# null：（列属性）是否允许为空，null不是数据类型# key：索引：pri主键，uni唯一键# defalut：（列属性）默认值# extra：（列属性）扩充属性 更改表名rename table 表名 to 新表名;更改表属性12345678alter table 表名 表选项 参数表选项:add column 字段名 数据类型 [位置]; # 新增字段modify 字段名 数据类型 [属性] [位置]; # 修改字段change 旧字段 新字段 数据类型 [属性] [位置]; # 重命名字段drop 字段名; # 删除字段位置：first：第一个，after 字段：在字段后 删除表drop table 表名; 若要删除多张表，用,分隔表名 表约束：保证数据的合法性 空属性：NULL（默认），NOT NULL（不为空） 要做到数据不为空，空就没有意义，空数据无法参与运算，所以定义字段时就要设置not null，若字段未指定该选项，当字段为空时，MySQL会用NULL填充，而NULL会占用一个字节，当指定了not null后，该字段必须有值，确保数据准确性。 列描述comment：无实际含义，描述字段 默认值default：可在字段设置时添加default ，在插入字段时不赋初值就会使用默认值 主键primary key：一张表只有一个字段可以使用对应键，用来唯一的约束该字段里的数据，不能重复，一张表最多只有一个主键，主键默认不为空（not null）。 增加主键： 12345678910111213141516171819202122法一：在创建字段时就添加primary key 关键字create table user( id int primary key, name varchar(20));法二：在创建表时，在所有字段后使用primary key(字段名) 创建主键，如有多个字段作为主键，可以是复合主键create table user( id int, name varchar(20), primary key(id,name));mysql&gt; desc user1;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(20) | NO | PRI | NULL | |+-------+-------------+------+-----+---------+-------+法三：追加主键alter table 表名 add primary key(字段); 或alter table 表名 modify 字段名 类型 primary key;# 前提：字段对应数据是独立的（不重复） 主键约束：主键字段数据不允许相同，若相同则数据操作失败 主键删除：无法更新主键，只有删除了以后才能再添加 alter table 表名 drop primary key; 分类 逻辑主键：字段无业务含义（如id），一般以此类字段做主键 业务主键：字段存放业务数据 自增长auto-increment：若该字段未赋值或仅有默认值，会自动触发，会给字段值不断+1（当前字段中最大值），形成新字段，常与主键搭配。 注： 字段做自增长的前提：本身是一个索引（key属性有值），字段值必须是整型数字。一张表最多只有一个字段自增长。 修改自增长：修改的值必须比该字段当前最大值大(小的话不生效) alter table 表 auto_increment = x; 查看自增长变量 show variables like &#39;auto_increment%&#39;; 123456789101112mysql&gt; show variables like &apos;auto_increment%&apos;;+--------------------------+-------+| Variable_name | Value |+--------------------------+-------+| auto_increment_increment | 1 || auto_increment_offset | 1 |+--------------------------+-------+increment为自增长步数offset为自增长起始值修改：set auto_increment_increment = x;# 修改是对整个数据库，且仅是会话级alter table 表 modify即可修改 唯一键unique key：数据不能重复，允许为空，也可多个为空，空字段不参与唯一键比较。 数据操作数据插入1234insert into 表名 values(字段1,字段2,...),(字段1,字段2,...),...; # 插入数据（直接插数据，字段要一一对应）insert into 表名 (字段1名,字段2名,...) values(字段1,字段2,字段3),...; # 可指定插入字段，就不用对齐了 若主键冲突，即主键对应的值已存在，插入就会失败。有以下两种解决方法。法一：更新insert into 表名(字段(要包含主键)) values() on duplicate key update 字段 = 值;法二：替换replace into 表名(字段(包含主键)) values(); 蠕虫复制：将已有的数据进行新增，数据成倍增加 用法1：从已有表创建新表（仅仅复制表结构） create table 表名 like 库名.表名; 例：mysql&gt; create table user_worm like user; 用法2：将查出的数据复制到一张表 insert into 表名(字段) select 字段 from 表名; 例：mysql&gt; insert into user_worm (id,name,sex,age) select id,name,sex,age from user;蠕虫复制的意义： 可以快速让表中数据膨胀到一定数量级以测试表的压力与效率 数据更新update 表名 set 字段 = 值 [where] [limit 限制更新数量（前几行）]; 数据删除delete from 表名 [where];数据删除不会改变表的结构，如自增长不会归零，只能删除表后再重建truncate 表名; # 先删除该表后再创建该表 数据查询123456select [选项] 字段[别名] from 表名 [where][group by][having][order by][limit];选项： all/* ：保留所有结果，默认（尽量不要打印所有） distinct：去重 别名： 字段名 as 别名 常用关键字： where：where子句用于过滤满足条件的数据。子句返回结果为0或1。where是唯一一个直接从磁盘读取数据时就开始判断的条件（从读取到第一条数据时就进行判断，成立就保存在内存）。where后的参数 参数 说明 between…and… 介于某个范围之内（闭区间） not between…and… 不在某个范围之内 in(项1,项2…) 在指定项内 not in(项1,项2…) 不在指定项内 like 搜索匹配，常与模式匹配符配合使用 not like like的反义 is null 空值判断符 is not null 非空判断符 not/and/or 逻辑运算符，分别表示否、并且、或，用于多个逻辑连接 % 模式匹配符，表示任意字串 优先级：NOT &gt; AND &gt; OR group by：根据某字段分组，用于按组统计数据常用统计函数：12345count()：统计分组后的记录数max()：每组中最大值min()：每组中最小值avg()：求平均值sum()：求和 可在group by后加上asc或desc，分别表示升序或降序。若只是分类，并不会显示所有数据，仅仅是分组，列出有哪些组。 可以设置多个字段进行排序，会按照字段的书写顺序进行先后排序。例如，group by age,score会先对age进行排序，然后对结果再进行score的排序。函数group_concat(字段名)可对分组结果中的某个字段进行字符串的连接。 with rollup：回溯统计，根据当前分组字段向上级分组汇报多字段回溯：考虑第一层分组会有回溯，第二层要看第一层分组的组数，组数是多少就回溯几次 having：进行条件判断在where判断后，由于数据已进入内存，所以不能再用where判断了，要对where判断的结果再次判断，就要用having。having能做where做到几乎所有事情，而where不能做having能做的很多事情。 分组统计的结果只能having使用123456789101112mysql&gt; select id,score,count(*),group_concat(name) from user group by score having count(*)&gt;=1;+-------+-------+----------+--------------------+| id | score | count(*) | group_concat(name) |+-------+-------+----------+--------------------+| 10002 | 68 | 2 | mike,jessie || 10001 | 78 | 3 | jack,kate,lisi || 10006 | 86 | 2 | zhangsan,wangwu || 10005 | 97 | 1 | jason |+-------+-------+----------+--------------------+ order by：排序，依赖校对集，显示所有记录，认升序排序。多字段排序：根据某个字段排序，然后对排序好的结果再按某字段排序 limit：限制数量 1234567891011121314151617181920用法1：limit 长度 限制记录数（排名前N个）mysql&gt; select * from user order by score desc limit 3;+-------+----------+------+------+-------+| id | name | sex | age | score |+-------+----------+------+------+-------+| 10005 | jason | m | 22 | 97 || 10008 | wangwu | m | 20 | 86 || 10006 | zhangsan | m | 21 | 86 |+-------+----------+------+------+-------+用法2：limit 起始,长度 从某起始位置（最小为0）开始限制（实现分页）mysql&gt; select * from user order by score desc limit 4,8;+-------+--------+------+------+-------+| id | name | sex | age | score |+-------+--------+------+------+-------+| 10003 | kate | f | 19 | 78 || 10007 | lisi | f | 19 | 78 || 10002 | mike | m | 21 | 68 || 10004 | jessie | f | 20 | 68 |+-------+--------+------+------+-------+ 多表查询关系分为： 一对一：一张表的一条记录最多只能与另一张表的一条数据对应 一对多：一张表的一条记录可与另一张表的多条数据对应 多对多：两张表互相存在一对多关系 联合查询也称“并”（UNOIN），多次查询（多条select），在记录上进行拼接。每一条select获取的字段数必须一致，字段名可以不一致，但字段数一定一致。会自动删除重复的记录（所有字段和值全部一致的记录）。1234select 语句1 union select 语句2union选项： all # 保留所有 distinct # 去重 联合查询的意义： 查询同一张表，但需求不同 多表查询：多张表结构完全一样，保存数据类型也一致 在联合查询中，order by不能直接使用，必须搭配limit限定最大数 例：12345678910111213141516171819202122232425262728mysql&gt; (select id,name,score from user order by score) union (select id,name,score from stu order by score);+-------+------------+-------+| id | name | score |+-------+------------+-------+| 10001 | jack | 78 || 10002 | mike | 68 || 10003 | kate | 78 || 10004 | jessie | 68 || 10005 | jason | 97 || 10006 | zhangsan | 86 |并没有排序，当加上limit 后即可实现排序mysql&gt; (select id,name,score from user order by score desc limit 999) union (select id,name,score from stu order by score desc limit 999);是两张表分别进行排序，然后合并 连接查询将多张表进行数据的拼接。分类：内连接（Inner Join），外连接（Outer Join），交叉连接（Cross Join）。连接查询的速度很慢，通常使用子查询。 内连接从左表中读取每一条记录与右表中所有记录匹配，只保留匹配的数据12345语法：select 字段 from 左表 inner join 右表 on 左表.字段 = 右表.字段; 若这两张表要查询的字段唯一，就不需要加表名。字段别名及表别名的使用：查询数据时，不同表有同名字段，可使用别名。 若内连接不指定on ，效果会和交叉连接一样。可用where代替on（但where没on效率高） 内连接根据不同的实现作用又分为： 自然连接：natural join，仅进行匹配以及去重。不能指定执行过程中的匹配条件。 等值连接：用=匹配字段值相等的记录 不等连接：用!=匹配字段值不相等的记录 注：内连接和外连接都可以模拟自然连接，只要在连接后面加using(字段名)，就可使用同名字段作为连接条件，自动合并1select * from stu join user using(id,name,score); 外连接从主表中读取每一条记录与另一张表中所有记录匹配，会保留所有记录以一张表为主，称为主表，根据主表的位置，外连接又分为左连接和右连接。 左连接left join：以左表为主表 右连接right join：以右表为主表 全外连接full outer join：除了匹配的记录，还包括不匹配的记录结果记录数至少为主表的总记录数，副表的为匹配的记录会显示为null显示仍为左连接在表的靠左部分，右连接在表的靠右部分12345语法：左连接select 字段 from 左表 left|right join 右表 on 左表.字段 = 右表.字段; 子查询虽然可通过连接查询实现多表查询，但性能很慢，因此推荐使用子查询进行多表查询。 子查询分类： 按位置分类：子查询在外部查询中出现的位置 from子查询：子查询在from之后 where子查询：在where中 exist子查询：在exists中 按结果分类：根据子查询得到的结果查询 标量子查询：子查询得到的结果是一行一列 列子查询：结果是一列多行 行子查询：结果是多列一行（也可以多行多列） 表子查询：子查询得到的结果是多行多列（出现在from后） 标量子查询123456mysql&gt; select * from stu_info where id = (select id from stu where id = 20001);+-------+------------+------------+| id | birthday | birthplace |+-------+------------+------------+| 20001 | 1998-07-03 | 河南 |+-------+------------+------------+ 列子查询123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657关键字IN的子查询mysql&gt; select * from stu_info where birthplace in (select birthplace from stu_info where birthplace = &apos;江苏&apos;);+-------+------------+------------+| id | birthday | birthplace |+-------+------------+------------+| 20003 | 1998-10-03 | 江苏 || 20005 | 1998-10-02 | 江苏 || 20007 | 1997-11-24 | 江苏 |+-------+------------+------------+关键字ANY（或SOME）的子查询 三种匹配规则： 1. = ANY ，与关键字IN作用相同 2. &gt; ANY（或&gt;=） ，比子查询中记录的最小值大的即可 3. &lt; ANY（或&lt;=） ，比子查询中记录的最大值小的即可mysql&gt; select * from stu where score &gt;= ANY ( select score from stu where age = 19);+-------+----------+------+------+-------+| id | name | sex | age | score |+-------+----------+------+------+-------+| 20001 | chenning | f | 20 | 98 || 20004 | yunlu | f | 19 | 93 || 20007 | chenliu | m | 20 | 94 |+-------+----------+------+------+-------+关键字ALL的子查询 两种匹配规则： 1. &gt; ALL ，比子查询中记录的最大值还要大 2. &lt; ALL ，比子查询中记录的最小值还要小mysql&gt; select * from stu where score &gt; ALL ( select score from stu where age = 19); +-------+----------+------+------+-------+| id | name | sex | age | score |+-------+----------+------+------+-------+| 20001 | chenning | f | 20 | 98 || 20007 | chenliu | m | 20 | 94 |+-------+----------+------+------+-------+关键字EXISTS的子查询用于判断是否满足（跨表），接在where后，exists返回值只有0和1 两种匹配： 1. EXISTS，存在 2. NOT EXISTS，不存在mysql&gt; select * from stu where not exists(select * from stu_info where birthplace = &apos;河南&apos;);解释：只要不存在河南的学生，就将所有学生信息打印出。EXISTS语句仅仅是判断where中的条件，并不会进行select的输出控制。 行子查询123456789mysql&gt; select * from stu where (age,score) = ( select age,score from stu where id = 20001);+-------+----------+------+------+-------+| id | name | sex | age | score |+-------+----------+------+------+-------+| 20001 | chenning | f | 20 | 98 |+-------+----------+------+------+-------+ 索引系统通过算法将已有的数据单独建立一个文件，文件能实现快速查找匹配数据作用：1.提高查询数据效率 2.约束数据的有效性增加索引的前提条件：因为索引本身会产生文件（较大），所以若某个数据经常使用时就可使用索引。 根据存储类型，可将索引分为：B树索引（默认索引）和哈希索引。InnoDB和MyISAM引擎都支持B树索引，Memory引擎支持哈希索引 Mysql支持六种索引： 普通索引 index 唯一索引 unique 全文索引 fulltext index 单列索引 多列索引 空间索引 以下情况时适合创建索引： 经常被查询的字段，即where子句出现的字段 在分组的字段，即group by子句出现的字段 存在依赖关系的子表和父表间的联合查询，即主键和外键字段 设置唯一完整性约束的字段 不适合创建索引的情况： 查询中很少被使用的字段 拥有许多重复值的字段 普通索引在创建索引时，不附加任何限制条件，可创建在任何数据类型上 1234567891011121. 创建表时创建普通索引create table 表名( 字段 类型, index|key 索引名(字段1(长度) &#123;ASC|DESC&#125;));2. 在已存在的表上创建普通索引create index 索引名 on 表名 (字段(长度) &#123;ASC|DESC&#125;);3. 修改表创建索引alter table 表名 add index|key 索引名(字段(长度) &#123;ASC|DESC&#125;); 用INDEX或KEY参数都可创建索引。索引名与字段关联，可设置索引长度（因为不同存储引擎定义了表的最大索引数和最大索引长度），还可设置升降序。 Mysql支持的存储引擎对每个表支持至少16个索引，总索引长度至少为256字节。 唯一索引创建索引时，限制索引的值必须唯一。根据创建索引的方式分为：自动索引和手动索引。自动索引：在数据库表中设置完整性约束时，该表会被系统自动创建索引。当设置表中的某个字段设置主键或唯一键完整性约束时，系统会自动关联该字段的唯一索引。1234567891011121. 在创建表时创建唯一索引create table 表名( 字段 类型, unique index|key 索引名(字段(长度) &#123;ASC|DESC&#125;);2. 在已存在的表上创建唯一索引create unique index 索引名 on 表名(字段(长度) &#123;ASC|DESC&#125;);3. 修改表创建索引alter table 表名 add unique index|key 索引名(字段(长度) &#123;ASC|DESC&#125;); 全文索引针对文章内部的关键字进行索引，表引擎必须为MyISAM。主要用于关联数据类型为char、varchar、text的字段，以便能够更加快速地查询数据量较大的字符串类型的字段。默认情况全文索引搜索不区分大小写，若全文索引所关联的字段为二进制类型，则以区分大小写搜索。 注：不要在导入数据时使用fulltext，应该在导入后使用1234567891011121. 创建表时创建全文索引create table 表名( 字段 属性, fulltext index|key 索引名(字段(长度) &#123;ASC|DESC&#125;))engine=MYISAM;2. 在已存在的表上创建全文索引create fulltext index 索引名 on 表名(字段(长度) &#123;ASC|DESC&#125;);3. 修改表创建索引alter table 表名 add fulltext index|key 索引名(字段(长度) &#123;ASC|DESC&#125;); 全文索引操作符： 操作符 说明 + 包含 - 排除 &lt; 包含且增加等级 &gt; 包含且减少等级 ( ) 表达式 * 词尾通配符 “ “ 字符串 多列索引在创建索引时所关联的字段不是一个字段，而是多个字段。只有查询条件使用了关联字段的第一个字段，多列字段才会被使用。1234567891011121314151617181920211. 创建表时创建多列索引create table 表名( 字段 类型, index|key 索引名( 字段1(长度) &#123;ASC|DESC&#125;, ... 字段n(长度) &#123;ASC|DESC&#125;);2. 在已存在的表上创建多列索引create index 索引名 on 表名 ( 字段1(长度) &#123;ASC|DESC&#125;, ... 字段n(长度) &#123;ASC|DESC&#125;);3. 修改表创建索引alter table 表名 add index|key 索引名( 字段1(长度) &#123;ASC|DESC&#125;, ... 字段n(长度) &#123;ASC|DESC&#125;); 视图本质是一种虚拟表，内容与真实表相似，但并不在数据库中以存储的数据值形式存在，数据来自自定义视图的查询所引用基本表，并在具体引用视图时动态生成。 创建视图：create view 视图名 as select语句;注：有多张基表时，要保证字段名不同，可用别名区分修改视图：123456781. 使用ALTER语句修改视图alter view 视图名 as select语句;2. 使用CREATE OR REPLACE语句修改视图create or replace view 视图名 as select 语句;这个方式修改视图会在视图存在的情况下直接修改，而若不存在就创建视图。 删除视图：drop view 视图名; 可以向单表中插数据，但不能向多表插数据，且插入数据只能插视图中有的字段 1234567891011查看视图show tables;查看视图详细信息show table status (from 数据库);查看视图定义信息show create view 视图名;查看视图设计信息desc 视图名; 触发器触发器的执行是由事件来触发、激活从而实现执行。为某张表绑定一段代码，当对表操作时，就会触发代码执行。触发器由三部分组成： 事件类型：增删改—insert、delete、update 触发时间：before、after 触发对象：表中记录123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172创建触发器：create trigger 触发器名 before|after 触发事件 on 表名 for each row 触发后动作;# for each row 表示任何一条记录上的操作满足触发事件# 后面跟上的是激活触发器后执行的语句创建包含多条执行语句的触发器：create trigger 触发器名 before|after 触发事件 on 表名 for each row begin 触发后动作 end# 在BEGIN和END间因为有多条语句需要使用分号隔开# 而在mysql中默认分号为结束，因此需要在创建触发器前将结束符重新设置，并在创建完成后再将触发器设置回分号。delimiter 结束符删除触发器drop trigger 触发器名;查看触发器show triggers;mysql&gt; show triggers\G*************************** 1. row *************************** Trigger: my_trigger1 # 触发器名 Event: INSERT # 触发事件 Table: stu # 操作表 Statement: begin # 激活触发器后的动作insert into stu_journal values(&apos;insert&apos;,now());end Timing: AFTER # 触发器执行的时间 Created: 2018-07-08 14:10:54.01 sql_mode: STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION Definer: root@localhostcharacter_set_client: gbkcollation_connection: gbk_chinese_ci Database Collation: utf8_general_ci查看系统表triggers中所有记录select * from information_schema.triggers\Gmysql&gt; select * from information_schema.triggers where trigger_name=&apos;my_trigger1&apos;\G*************************** 1. row *************************** TRIGGER_CATALOG: def TRIGGER_SCHEMA: test TRIGGER_NAME: my_trigger1 EVENT_MANIPULATION: INSERT EVENT_OBJECT_CATALOG: def EVENT_OBJECT_SCHEMA: test EVENT_OBJECT_TABLE: stu ACTION_ORDER: 1 ACTION_CONDITION: NULL ACTION_STATEMENT: begininsert into stu_journal values(&apos;insert&apos;,now());end ACTION_ORIENTATION: ROW ACTION_TIMING: AFTERACTION_REFERENCE_OLD_TABLE: NULLACTION_REFERENCE_NEW_TABLE: NULL ACTION_REFERENCE_OLD_ROW: OLD ACTION_REFERENCE_NEW_ROW: NEW CREATED: 2018-07-08 14:10:54.01 SQL_MODE: STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION DEFINER: root@localhost CHARACTER_SET_CLIENT: gbk COLLATION_CONNECTION: gbk_chinese_ci DATABASE_COLLATION: utf8_general_ci 存储过程与函数一个完整的操作会包含 多条SQL语句，在执行过程中需要根据前面的SQL语句的执行结果有选择的执行后面的SQL语句。存储过程与函数可理解为一条或多条SQL语句的集合，且也是事先经过编译并存储在数据库中的一段SQL语句集合，是一种没有返回值的函数。 存储过程与函数的优点： 允许表春组件式编程，提高了SQL语句的重用性、共享性、可移植性 实现较快执行速度，减少网络流量 可被作为一种安全机制 缺点： 编写复杂 需要创建数据库对象的权限 存储过程和函数的区别： 函数必须有返回值，存储过程没有 存储过程创建存储过程12345678delimiter 结束符create procedure 过程名(procedure_parameter参数) characteristic特性 begin 过程体 end 结束符delimiter ;与触发器类似，同样需要先用delimiter修改结束符 其中procedure_parameter参数的格式如下输入/输出类型 参数名 参数类型 输入输出类型有三种 IN：输入类型，数据只从外部传入内部，可是数值也可是变量。存储过程可能会修改这个值，但是对于调用者来说，在存储过程返回结果时，所做的修改是不可见的。 OUT：输出类型，只允许过程使用内部数据，外部传入内部只能是变量。其初始值为NULL，当存储过程返回时，这个值对调用者来说是可见的。 INOUT：输入输出类型，外部可在内部使用，内部修改也可在外部使用，只能传变量，存储过程可能会修改这个值，当存储过程返回的时候，所做的修改对调用者来说是可见的。 参数类型可为Mysql支持的任何类型 characteristic特性的可选参数12345678910111213141516[NOT] DETERMINSTIC：存储过程的执行结果是否确定# DETERMINSTIC表示确认，加NOT则为不确认&#123;CONTAINS SQL|NO SQL|READS SQL DATA|MODIFIES SQL DATA&#125;：表示使用SQL语句的限制# CONTAINS SQL：表示可包含SQL，但不包含读或写数据的语句# NO SQL：表示不包含SQL语句# READS SQL DATA：表示包含读数据语句# MODIFIES SQL DATA：表示包含写数据语句# 默认为CONTAINS SQLSQL SECURITY &#123;DEFINER|INVOKER&#125;：表示谁有权限执行# DEFINER：表示只有定义者自己能执行# INVOKER：表示调用者都可执行# 默认为DEFINERCOMMENT 注释 示例：1234567delimiter $create procedure proce_sel_stu(in stuid int)comment &apos;显示stu表指定学号的学生姓名和成绩&apos;bgein select name,score from stu where id=stuid;end$$delimiter ; 使用call 存储过程名(参数);对存储过程的调用。 查看存储过程查看存储过程创建语句show create procedure 存储过程名\G查看存储过程状态信息show procedure status like &#39;过程名&#39;\G 在information_schema库中存在一张存储所有存储过程和函数的表routines，因此此表也可查看存储过程和函数。 修改存储过程12alter procedure 过程名 特性 存储过程不能修改过程体，只能删除后重新创。删除存储过程drop procedure 存储过程名; 函数123456789101112创建函数delimiter 结束符create function 函数名(参数) returns 返回数据类型 特性 begin 函数体 end结束符delimiter ;# 特性与存储过程一致# 参数不用指定输入输出 注：函数不存在“重写”，即函数名不能相同。并且推荐函数名的格式为func_XXX或function_XXX示例：1234567delimiter $$create function func_sel_stu(stuid int) returns int begin return (select score from stu where id=stuid); end $$delimiter ; 使用select 函数(参数);调用函数。 查看函数查看函数创建函数show create function 函数名\G查看函数状态信息show function status like &#39;函数名&#39;\G修改函数12alter function 函数名 特性 存储过程不能修改函数体，只能删除后重新创。删除函数drop function 函数名; 存储过程和函数表达式 变量使用declare 变量名（可多个，逗号分隔） 类型 [默认值]声明变量使用set 变量名=XX（可以是值，也可以是赋值表达式，可多个，逗号分隔）;赋值变量也可以通过select 字段 into 变量（可多个） from ...;将查询结果赋给变量。注：将查询结果赋值给变量时，该查询语句的返回结果只能是单行 条件条件用于提高安全性。条件用于定义在处理过程中遇到问题时相应的处理步骤。12345678910111213141516171819202122232425262728定义条件declare 条件名 condition for condition_value状态值状态值：mysql_error_code mysql错误值SQLSTATE[VALUE] sqlstate_value 指定sql状态不要使用mysql error code 0或以‘00’开头的code或一个SQLSTATE，因为这些指示成功而不是一个错误条件。定义处理delimiter 结束符declare 处理类型 handler for 状态值（可多个） begin 处理 end 结束符delimiter ;处理类型，即当handler被触发后需要执行什么动作1. CONTINUE：继续执行2. EXIT：终止程序3. UNDO状态值，handler触发的条件：1. mysql error code或SQLSTATE value2. 定义条件时的条件名3. SQLWARNING：代表所有以01开头的SQLSTATE4. NOT FOUND：代表所有以02开头的SQLSTATE5. SQLEXCEPTION：代表除01和02开头的SQLSTATE 详细SQLSTATE表 示例：12345DECLARE no_such_table CONDITION FOR 1051;DECLARE CONTINUE HANDLER FOR no_such_table BEGIN -- body of handler END; 游标指定由select语句返回的行集合结果集，并遍历该结果集，可看做一种数据类型，类似指针或数组下标。使用declare 游标名 cursor for select语句;声明游标使用open 游标名打开游标。打开时，游标指向的是第一条数据的前一位。使用fetch 游标名 into 变量名（可多个，逗号分隔）使用游标，遍历赋值给变量。使用close 游标名关闭游标 流程控制条件控制1234567891011121314if条件分支if 条件 then 执行语句elseif 执行语句else 执行语句end if;case条件分支case 条件判断的变量 when 条件 then 执行语句 when 条件 then 执行语句end case 注：创建条件控制需要修改语句结束符循环控制1234567891011121314151617181920212223[标签:]where 条件 do 执行语句end where[标签];循环控制：循环内部进行循环判断和控制interate：迭代，类似continueleave：离开，类似break[标签:]where 条件 do 执行语句 leave | interate 循环名;end where[标签];[标签:]loop 执行语句end loop[标签][标签:]repeat 条件 do 执行语句end repeat[标签]可使用标签，两个标签分别代表循环的开始和结束，但必须一致，也可省略若要退出循环，使用leave 标签 事务为保证数据库记录的更新从一个一致性状态变更为另一个一致性状态。事务的四个特性： 原子性：事务中所有操作视为一个原子单元，对事务所进行的数据修改等操作只能是完全提交或完全回滚。 一致性：事务完成时，所有变更必须应用于事务的修改 隔离性：一个事务中的操作必须与其他事务所做的修改隔离，当前事务不会查看由另一个并发事务正在修改的数据（通过锁机制实现） 持久性：事务完成后，所做的所有修改对数据的影响是永久的 InnoDB支持事务，而MyISAM不支持事务事务安全：保护连续操作同时满足。意义：保证数据操作的完整性事务操作分为：自动事务（默认），手动事务 手动事务： 开启事务：告诉系统以下所有操作不直接写入数据表，先放到事务日志中。start transaction;或begin;此后的操作会保存在事务日志中，并不是真的对操作了数据表，所以若再通过另一个命令行用户登录查看时，该数据是未被操作的。 关闭事务：选择性的将日志文件中操作的结果同步到数据表包含两个操作： 提交事务commit：同步数据表，操作成功 回滚事务rollback：直接清空日志表，操作失败 自动事务：通过autocommit变量控制查看自动事务状态show variables like &#39;autocommit&#39;;默认开启set autocommit = off;关闭事务自动提交。关闭自动后，需要手动选择处理提交或回滚 事务原理：事务开启后，所有操作临时保存在事务日志，只有在commit时才会同步到数据表，其他情况都会导致清空。其中日志文件分为两个： REDO日志：记录事务日志。每条SQL进行数据库更新操作时，首先将REDO日志写入到日志缓存区中。当客户端执行COMMIT命令提交时，日志缓冲区的内容被刷新到磁盘。REDO日志对应ib_logfile文件，默认大小5MB，建议设置为512MB以便容纳较大的事务。在Mysql崩溃恢复时，会重新执行REDO日志记录。 UNDO日志：也称为回滚段。用于事务异常时的回滚处理，复制事务前得到数据库内容到UNDO缓冲区，然后在合适的时间将内容刷新到磁盘。磁盘上不存在单独的UNDO日志文件，而是存放在表空间对应的.ibd数据文件中。 回滚点：在某个成功的操作完成后，后续的操作可能成功可能失败，可以自当前成功的位置设置一个点，可以供后续失败操作返回到该位置，而不是返回所有操作。savepoint 回滚点名;rollback 回滚点名;12345# 使用start transaction 或 begin开启事务mysql&gt; start transaction;mysql&gt; update stu set age=22 where id=20007;mysql&gt; commit; 或mysql&gt; rollback; 事务隔离级别SQL定义了4种隔离级别，指定了事务中哪些数据改变其他事务可见，哪些数据改变其他事务不可见。低隔离级别可支持更高并发处理，同时占用的系统资源更少。可通过show variables like &#39;tx_isolation&#39;查看当前事务隔离级别。 READ-UNCOMMITTED：读取未提交内容，所有事务都可以看到其他未提交事务的执行结果。读取未提交的数据称为脏读。开启A与B事务，A更新，B不操作，但A在提交前，B能读到更新后的数据，而此时A回滚了，也就是B还是读到了错误的数据。 READ-COMMITTED：读取提交内容，一个事务从开始到提交前所做的任何改变都是不可见的，事务只能看见已经提交的变化。同一事务的其他实例在该实例处理时可能会有新的数据提交导致数据改变，所以同一查询可能返回不同结果。 REPEATABLE-READ：可重读，Mysql默认事务隔离级别。确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。存在问题：A的操作对表中所有行，B的操作是添加一行，于是A会发现有一行没有被修改。这个问题称为幻读。解决：InnoDB的多版本并发控制MVCC机制。InnoDB通过为每个数据行增加两个隐含值的方式实现，两个隐含值记录行的创建时间和过期时间。每行记录事件发生时的系统版本号。每一次开始一个新事务时版本号会自动加1，每个事务保存开始时的版本号，每个查询根据事务的版本号查询结果。 SERIALIZABLE：可串行化。最高的隔离级别。通过强制事务排序，使各事务不可能冲突。通过在每个读的数据行上加上共享锁实现。不推荐使用。 InnoDB锁机制锁机制：为解决数据库并发控制问题，保证数据一致性，需要对并发操作控制，并实现Mysql各个隔离级别。有以下类型： 共享锁：S（Share），锁粒度是单行或多行。一个事务获取了共享锁后，可对锁定范围内的数据执行读操作。事务A与B，若A获取了共享锁，B仍可获得共享锁，但不能获得排他锁。若A获得了排他锁，B不能获得共享锁和排他锁。 排他锁：X（eXclusive），排他锁的粒度与共享锁相同。事务获取排他锁后，可对锁定范围的数据执行写操作。 意向锁：一种表锁，粒度为整张表。分为意向共享锁IS和意向排他锁IX。表示一个事务有意对数据上共享锁或排他锁。锁与锁之间的关系，要么相容，要么互斥。相容：事务A获得了锁a，事务B还可获得锁b互斥：事务A获得了锁a，事务B在A释放a之前不能获得锁b 锁粒度锁粒度分为表锁和行锁。innodb默认是行锁，但如果在事务操作的过程中，没有使用索引，那么系统会自动全表检索数据，自动升级为表锁。行锁：只有当前行被锁住，别的用户不能操作。行锁支持最大并发。InnoDB使用行锁。支持并发读写。表锁：整张表被锁住，别的用户不能操作。开销最小，允许的并发量也最小。MyISAM使用表锁。当行或表被锁住时，若另一用户也要更改就只能等待锁被解除（commit或rollback），否则无法操作成功。 安全权限机制三张关于权限的表，存放在mysql库中。 user db host mysql.user表一共有45个字段，可分为4类：用户字段、权限字段、安全字段、资源控制字段 用户字段三个字段：host主机名，user用户名，password密码 权限字段一系列以_priv结尾的字段，这些字段决定了权限。两个返回值，Y和N，默认为N。 字段 权限名 权限范围 Select_priv select 查询表 Insert_priv insert 插入表 Update_priv update 更新表 Delete_priv delete 删除表 Create_priv create 库、表、索引 Drop_priv drop 库、表 Reload_priv reload 库、表 Shutdown_priv shutdown 关闭服务器 Process_priv process 服务器管理 File_priv file 加载服务器主机的文件 Grant_priv grant 库、表、存储过程、函数 References_priv references 库、表 Index_priv index 用索引查表 Alter_priv alter 修改表 Show_db_priv show databases 服务器 Super_priv super 超级权限 Create_tmp_table_priv create temporary tables 临时表 Lock_tables_priv lock tables 锁定表 Execute_priv execute 执行存储过程或函数 Repl_slave_priv replication slave 服务器管理 Repl_client_priv replication client 服务器管理 Create_view_priv create view 创建视图 Show_view_priv show view 查看视图 Create_routine_priv create routine 创建存储过程或函数 Alter_routine_priv alter routine 修改存储过程或函数 Create_user_priv create user 创建用户 Event_priv event 计时器 Trigger_priv create trigger 触发器 Create_tablespace_priv create tablespace 创建表空间 安全字段用于判断用户是否能够登录成功 字段 说明 ssl_type 支持ssl加密的安全字段 ssl_cipher 支持ssl加密的安全字段 x509_issuer 支持x509的字段 x509_subject 支持x509的字段 可通过以下方式查看是否字段支持ssl加密123456mysql&gt; show variables like &apos;have_openssl&apos;;+---------------+----------+| Variable_name | Value |+---------------+----------+| have_openssl | DISABLED |+---------------+----------+ 资源控制字段 字段 说明 max_questions 每小时允许执行多少次查询 max_updates 每小时允许执行多少次更新 max_connections 每小时允许建立多少次连接 max_user_connections 单个用户可同时具有的连接数 所有资源控制字段的默认值为0，表示是没有限制。 用户机制包括：登录和退出Mysql，创建用户，删除用户，修改用户密码，修改用户权限等。 连接Mysql服务器的命令：1234567mysql -h Mysql服务器的地址，可用域名，也可用IP地址 -p 指定所连接Mysql服务器的端口，默认3306 -u 登录Mysql使用的用户 -p 将提示输入密码 DBname 指定登录到的库 -e 指定执行的SQL语句 对用户的操作： 创建用户： 12345671. create user 用户名[@主机] [identified by &quot;密码&quot;];2. insert into mysql.user(Host,User,Password) values(主机名,用户名,PASSWORD(&quot;密码&quot;));# 要使用PASSWORD()对密码加密3. grant 权限 on 库.表 to 用户名[@主机] [identified by &quot;密码&quot;];在赋予权限后，要flush privileges;刷新权限 修改用户账户密码： 12345671. mysqladmin -u 用户名 -p 原密码 &quot;新密码&quot;# 新密码必须用双引号括起来2. set password=PASSWORD(&quot;新密码&quot;);# 修改当前登录用户的密码（即只修改自己的密码）3. update mysql.user set password=PASSWORD(&quot;新密码&quot;) where user=&quot;用户名&quot; and host=&quot;localhost&quot;; 修改普通用户账户密码： 123456781. grant 权限 on 库.表 to 用户名 [identified by &quot;密码&quot;];2. set password for 用户名[@主机]=PASSWORD(&quot;新密码&quot;);3. update mysql.user set password=PASSWORD(&quot;新密码&quot;) where user=&quot;用户名&quot; and host=&quot;主机名&quot;;4. set password=PASSWORD(&quot;新密码&quot;);# 修改当前登录用户的密码（即只修改自己的密码） 删除普通用户账号： 1231. drop user 用户名1,用户名2....2. delete from mysql.user where user=&quot;用户名&quot; and host=&quot;主机&quot;; 对用户的权限管理 对用户授权： 1234567grant 权限 on 库.表 to 用户 [identified by &quot;密码&quot;] with 选项;# with后有以下选项：GRANT OPTION：被授权用户可将权限授权给其他用户MAX_QUERIES_PER_HOUR count：设置每小时可执行count次查询MAX_UPDATES_PER_HOUR count：设置每小时可执行count次更新MAX_CONNECTIONS_PER_HOUR count：设置每小时可建立count次查询MAX_USER_CONNECTIONS count：设置单个用户可同时具有count个连接 查看用户拥有权限：show grant for 用户名[@主机]; 收回用户拥有权限：1234revoke 权限 on 库.表 from 用户名 [identified by &quot;密码&quot;];若要直接回收全部权限，可使用以下语句revoke all privileges,grant option from 用户名 [identified by &quot;密码&quot;]; 日志Mysql日志分为： 二进制日志：以二进制形式记录数据库的各种操作，但不记录查询语句 错误日志：记录Mysql服务器启动、关闭、运行时的错误信息 通用查询日志：记录Mysql启动和关闭信息、客户端连接信息、更新数据SQL语句、查询SQL语句 慢查询日志：记录执行时间超过指定时间的各种操作，可用于定位Mysql性能瓶颈 二进制日志二进制日志默认关闭。可通过mysql配置文件my.ini的log-bin参数，将注释去掉即可开启二进制日志。log-bin = 二进制日志路径路径是可选。若没指定路径，会使用默认名主机名-bin.number，number格式为000001开始的计数，并保存到默认目录：数据库的数据文件目录，即C:\ProgramData\MySQL\MySQL Server 5.7\Data。 每次重启Mysql服务器都会生成一个新的二进制日志文件，number会递增 可通过mysqlbinlog 二进制日志查看。不能直接打开，否则是乱码。 若要停止二进制日志，只要将my.ini中的log-bin恢复注释或删除即可。或者在数据库中通过对变量的设置实现开启或关闭二进制日志。set SQL_LOG_BIN=若为1表示开启，若为0表示关闭 只有有super权限的用户才能执行set语句 删除二进制日志reset master;可删除所有二进制日志文件purge master logs to 日志文件可删除number所有小于该日志的日志purge master logs before &#39;yyyy-mm-dd hh:MM:ss&#39;删除指定日期前创建的二进制日志 错误日志Mysql默认开启错误日志，也无法被禁止。同样该日志默认也存放在C:\ProgramData\MySQL\MySQL Server 5.7\Data中，文件名称格式为Mysql主机名.err。可修改my.ini的error-bin修改日志的路径。 错误日志以文本文件形式存储信息，可直接打开。命令mysqladmin -u root -p flush-logs会先创建一个新的错误日志，然后将旧的错误日志改名为原文件名-old。 通用查询日志由于该日志记录了客户端Mysql的所有请求，若实例的访问量较大，则此日志会急剧增大，影响Mysql性能，一般建议关闭。 若要开启通用查询日志，设置my.ini的general-log=1，默认未开启。general_log_file设置通用查询日志的路径，格式为文件名.log，默认为主机名.log。 也可通过设置环境变量开启或关闭，set global general_log = on;开启通用查询日志。若要关闭，设为off即可。通过show variables like &#39;%general_log%&#39;;查看相关变量（只有是否开启和文件路径）。 同样可以使用mysqladmin -u root -p flush-logs删除日志，但Mysql会创建一个新日志覆盖旧日志。 慢查询日志默认慢查询日志是关闭的。可通过my.ini的slow-query-log=1开启。可通过slow_query_log_file设置慢查询日志的路径，文件格式为文件名-slow.log，默认为主机名-slow.log。默认存放在C:\ProgramData\MySQL\MySQL Server 5.7\Data。可通过long_query_time设置超时时间，默认为10s。修改配置后需要重启Mysql才能生效。所以最好通过修改环境变量动态开启关闭。set global slow_query_log=on;开启慢查询日志set global long_query_time=3;设置超时时间，对设置后的新连接有效，可重新连接Mysql。 Mysql提供工具mysqldumpslow.pl对慢查询日志文件进行分析，该工具在C:\Program Files\MySQL\MySQL Server 5.7\bin中。该工具由perl语言编写，因此需要perl环境123456mysqldumpslow.pl -s 分析慢查询日志时指定排序参数，有以下可选参数 al 平均锁定时间 ar 平均返回记录数 at 平均查询时间 -t 只显示指定的行数 若要停止慢查询日志，可将my.ini的slow-query-log与long_query_time注释即可。或通过修改环境变量slow-query-log=off关闭。若要删除慢查询日志，可通过命令mysqladmin -u root -p flush-logs创建新的日志，会覆盖旧日志。 维护数据库备份与还原使用mysqldump命令进行数据备份mysqldump -u [username] -p [dbname] [table1]... &gt; [path]/[filename].sql备份单个数据库，可指定表（可多张），若不指定，就备份整个库。导出的sql文件路径与名称都可自定义。mysqldump -u [username] -p --databases [dbname]... &gt; [path]/[filename].sql备份多个数据库mysqldump -u [username] -p --all -databases &gt; [path]/[filename].sql备份所有数据库 还原数据需要先在mysql中创建对应库，然后在数据库外执行命令。mysql -u [username] -p [dbname] &lt; [path]/[filename].sql可指定数据库，指定就还原该数据库下的表，不指定就还原所有库。 若要通过复制对数据恢复，则需要保证两个Mysql的版本号一致，且只能对存储引擎为MYISAM的表有效。 将数据库表与文本文件互相导入导出导出有三种方法： select ...into outfile...;命令 mysqldump命令 mysql命令 1234567891011121314151617181920212223242526272829301. select 字段名 from 表名 过滤条件 # 第一部分是普通的查询语句 into outfile 文件名 选项; # 设置要导出到的文件以及文件的参数选项有六种选项： fields terminated by 字符串：用于设置字段的分隔符，默认为&apos;\t&apos; fields enclosed by 字符：用于设置括上字段值的字符符号，默认不使用任何符号 fields optionally enclosed by 字符：用于设置括上char、varchar、text等字段值的字符符号，默认不使用任何符号 fields escaped by 字符：用于设置转义字符的字符符号，默认为&apos;\&apos; lines starting by 字符：用于设置每行开头的字符符号，默认不使用任何符号 lines terminated by 字符串：用于设置每行结束时的字符串符号，默认为&apos;\n&apos;例：select * from user into outfile &apos;.\user.txt&apos; fields terminated by &apos;\,&apos; optionally enclosed by &apos;\&quot;&apos; lines terminated by &apos;\r\n&apos;;2. mysqldump -u 用户名 -p -T 文件目录 数据库 表名 选项有四种选项： --fields-terminated-by=字符串 ：设置字段的分隔符，默认为&apos;\t&apos; --fields-enclosed-by=字符 ：设置括上字段值的字符符号，默认不使用任何符号 --fields-optionally-enclosed-by=字符 ：设置括上char、varchar、text等字段值的字符符号，默认不使用任何符号 --lines-terminated-by=字符串 ：设置每行结束时的字符串符号，默认为&apos;\n&apos;例：mysqldump -u 用户名 -p -T &apos;.\&apos; test user &quot;--fields-terminated-by=,&quot; &quot;--lines-terminated-by=\r\n&quot;使用mysqldump命令不仅会在指定目录中生成[表名].txt文件，还会生成[表名].sql文件。3. mysql -u 用户名 -p -e &quot;select 字段 from 表名&quot; 数据库名 &gt; 文件名 -e选项用于执行查询语句例：mysql -u root -p -e &quot;select * from user&quot; test &gt; .\user.txt 导入有两种方法： load data infile命令 mysqlimport命令 1234567891011121314151617181. load data infile 文件名 into table 表名 选项;有九种选项。前六种与导出的select六种一致，后三种为： ignore N lines ：忽视文件的前N行数据 字段列表：实现根据字段列表中的字段和顺序加载记录 set column=EXPR ：设置列的转换条件EXPR，即所指定的列经过相应转换后才会被加载例：load data infile &apos;.\uesr.txt&apos; into table user into outfile &apos;.\user.txt&apos; fields terminated by &apos;\,&apos; optionally enclosed by &apos;\&quot;&apos; lines terminated by &apos;\r\n&apos;;2. mysqlimport -u 用户名 -p 数据库名 文件名 选项有六种选项。其中四种与导出的mysqldump选项一致，其余两种为： --fields-escaped-by=字符 ：设置转移字符 --ignore-lines=N ：忽略文件的前N行记录例：mysqlimport -u root -p test &quot;.\user.txt&quot; &quot;--fields-terminated-by=,&quot; &quot;--lines-terminated-by=\r\n&quot; 数据库迁移分为三种情况： 相同版本间迁移：使用mysqldump和mysql进行备份与恢复 12345案例：mysqldump -h 主机A -u root -p=密码 -all-databases | mysql -h 主机B -u root -p=密码# 其中 | 即为管道符 不同版本间迁移：又分为高版本向低版本迁移和低版本向高版本迁移 123456高版本向低版本迁移：高版本会兼容低版本若表的存储引擎为MYISAM，可直接复制或使用命令mysqlhotcopy。若表的存储引擎为InnoDB，可使用mysqldump与mysql的组合进行备份与恢复而低版本并不兼容高版本，所以迁移会较困难 不同数据库间迁移若从MYSQL迁移到SQL SERVER，可通过MyODBC实现。若从MYSQL迁移到ORACLE，可先导出sql文件，然后手动修改create语句。 简单的性能优化思路 可通过show variables和show status查看修改配置和变量参数进行调优 若多个任务中一个执行缓慢，会影响其他任务。可通过show processlist显示所有活动进程，或执行kill终结消耗资源过多的进程 最好多次试验连接或子查询，找到效率最高的搜索方法。在select时可通过explain语句查看select的执行情况 使用存储过程的速度会提高 若不必要，不要直接执行select *语句 使用UNION连接select语句，比一系列OR条件的select语句效率高 对象索引可改善数据检索的性能，但会损失插入、更新、删除的性能。对于不常查询的表最好不要创建索引 关键字like的执行效率很低，一般会通过full text代替like 常见查看命令显示解析SHOW TABLE STATUSshow table status (from 数据库名) (like 表达式);会直接显示该数据库中所有表的状态信息。123456789101112131415161718 Name: stu # 表名或视图名 Engine: InnoDB # 存储引擎 Version: 10 # .frm文件版本 Row_format: Dynamic # 行存储格式 Rows: 7 # 行数目 Avg_row_length: 2340 # 行平均长度 Data_length: 16384 # 文件长度Max_data_length: 0 # 文件最大长度 Index_length: 0 # 索引文件长度 Data_free: 0 # 表被整序后，但未使用的字节数目 Auto_increment: NULL # 下一个Auto_increment值 Create_time: 2018-07-07 08:58:34 # 表的创建时间 Update_time: 2018-07-07 09:01:00 # 最后一次更新时间 Check_time: NULL # 最后一次检查时间 Collation: utf8_general_ci # 字符集 Checksum: NULL # 表的活性校验 Create_options: # 表的额外选项 Comment: # 表的注释 参考资料 MYSQL数据库应用从入门到精通（第二版）Mysql 异常处理—condition和handlerMysql系列—骏马金龙]]></content>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YAML学习笔记]]></title>
    <url>%2F2018%2F04%2F29%2FYAML%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[YAML语言学习]]></content>
      <tags>
        <tag>Lang</tag>
        <tag>YAML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[I/O学习笔记]]></title>
    <url>%2F2018%2F04%2F29%2FI-O%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[I/O本篇包含以下知识点： 同、异步概念 五种Unix I/O模型 同步模型 异步模型 同、异步同步： 指的是在两个或多个数据库、文件、模块、线程之间用来保持数据内容一致性的机制。同步处理过程：提交请求-&gt;等待服务器处理（期间客户端浏览器不能干任何事）-&gt;处理完毕返回异步： 异步处理不用阻塞当前线程来等待处理完成，而是允许后续操作，直至其它线程将处理完成，并回调通知此线程。异步处理过程：请求通过事件触发-&gt;服务器处理（这是浏览器仍然可以作其他事情）-&gt;处理完毕 同步、异步关注的是消息通知机制，针对的是客户端。 阻塞与非阻塞阻塞：调用结果返回之前，调用者会被挂起（不可中断），调用者只有在得到返回结果后才能继续。非阻塞：调用结果返回前，不会被挂起，调用不会阻塞调用者。在内核的数据还未准备好时，会立即返回，进程可以去干其他事情。 阻塞、非阻塞关注的是调用者等待被调用者返回结果时的状态，针对的是服务器端。 阻塞、非阻塞与同步、异步的区别同步是在I/O中的一系列操作都是调用者（用户进程）自己完成（自己去问内核）。而异步是调用者在发起调用后，自己不管了，等内核数据准备好了以后，内核自己告诉进程，即让内核去通知进程，实现回调。 至于阻塞与非阻塞，是决定是否让调用者挂起。 网络I/O的本质是socket的读取，socket在linux系统被抽象为流，I/O可以理解为对流的操作。这个操作又分为两个阶段： 1.等待流数据准备，即等待网络上的数据分组到达，然后被复制到内核的某个缓冲区 2.从内核向进程复制数据，把数据从内核缓冲区复制到应用进程缓冲区 五种Unix I/O模型I/O模型：进程是无法直接操作I/O设备的，其必须通过系统调用请求内核来协助完成I/O动作，而内核会为每个I/O设备维护一个buffer。 用户进程发起请求，内核接受到请求后，从I/O设备中获取数据到buffer中，再将buffer中的数据copy到用户进程的地址空间，该用户进程获取到数据后再响应客户端。如下图中，真正称为I/O的就是内核内存与与进程内存间的过程 同步I/O模型阻塞I/O（Blocking I/O）： 当用户进程进行系统调用read()时，进程发起recvform系统调用，内核就开始了I/O的第一个阶段，准备数据到缓冲区中，当数据都准备完成后，则将数据从内核缓冲区中拷贝到用户进程的内存中，这时用户进程才解除block的状态重新运行。整个过程中用户进程都是阻塞的。不会消耗CPU时间，执行效率高。 非阻塞I/O（Non-Blocking I/O）： 用户进程只有在第二个阶段被阻塞了，而第一个阶段没有阻塞。在第一个阶段中，recvform系统调用调用之后，内核马上返回给进程，如果数据还没准备好，此时会返回一个error，进程在返回之后，可以干点别的事情，然后再发起recvform系统调用，用户进程需要盲等，不停的去轮询内核，看数据是否准备好了。在拷贝数据整个过程，进程仍然是属于阻塞的状态。由于用户进程轮询内核，所以该模型是比较消耗CPU的，效率较低。 I/O复用（I/O Multiplexing）： I/O执行的两个阶段都是用户进程都是阻塞的，但是两个阶段是独立的，在一次完整的I/O操作中，该用户进程是发起了两次系统调用。使用select()、poll()或epoll()（poll的改进版）进行调用，可支持两路调用。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。 select调用是内核级别的，select轮询可以等待多个socket，当其中任何一个socket的数据准备好了（通过内核监视），就能返回进行可读，然后进程再进行recvform系统调用。select在此模式下最多只支持1024个并发。 I/O复用应用场景： 服务器需要同时处理多个处于监听状态或多个连接状态的套接字。 服务器需要同时处理多种网络协议的套接字。 信号驱动I/O（Signal Driven I/O）： 也称基于事件的I/O。只有在I/O执行的第二阶段阻塞了用户进程，而在第一阶段是没有阻塞的。在I/O执行的第一阶段，当数据准备完成之后，内核会主动的通知用户进程数据已经准备完成（通过返回一个SIGIO信号），即对用户进程做一个回调。该通知分为两种，一为水平触发，即如果用户进程不响应则会一直发送通知，二为边缘触发，即只通知一次。 注：需要先开启套接字的信号驱动I/O功能，并使系统调用sigaction安装一个信号处理函数 异步I/O模型异步I/O（Asynchrnous I/O）： 当用户进程发起系统调用后，立刻就可以开始去做其它的事情，然后直到I/O执行的两个阶段都完成之后，内核会给用户进程发送通知，告诉用户进程操作已经完成了。由于在调用后进程会立刻返回，所以在整个输入操作的等待和复制期间，进程都不会阻塞。 异步I/O不需要select或poll 主动询问，也没有询问描述符的数量限制。 参考文章：简明网络I/O模型—-同步异步阻塞非阻塞之惑 https://www.jianshu.com/p/55eb83d60ab1浅谈Linux下的五种I/O模型 https://www.cnblogs.com/chy2055/p/5220793.htmlLinux 网络 I/O 模型简介（图文） https://blog.csdn.net/anxpp/article/details/51503329socket 和 网络I/O模型 https://www.jianshu.com/p/7ac69db65a0e]]></content>
      <tags>
        <tag>网络</tag>
        <tag>I/O</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker网络学习笔记-1]]></title>
    <url>%2F2018%2F04%2F27%2FDocker%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[主要是对docker文档(v18.03)的翻译以及自己的学习笔记 本篇涉及知识点： Docker网络模式 跨主机网络 Overlay Macvlan 补充知识点 支持IPv6 配置iptables Docker网络模式目前Docker容器共有5种网络模式： 桥接模式（bridge） 主机模式（host） 容器模式（container） 无网络模式（none） 用户自定义模式（user-defined） 当安装完docker后，会默认创建三个网络，可通过docker network ls查看12345# docker network lsNETWORK ID NAME DRIVER SCOPE01ec14a3a84c bridge bridge local56d5a7a9b06c host host local9cbd2d449df7 none null local 用户可在运行容器时通过--network=指定网络。 桥接模式bridgebridge是docker默认选择的网络，而网桥就是docker0通过ifconfig即可看到。 1234# ifconfigdocker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt; mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 0.0.0.0 ...... 创建容器时若未指定network或网桥，就会默认挂到docker0网桥上。docker0的网段为172.17.0.0/16，网关地址为172.17.0.1，可通过docker inspect bridge查看。12345678910111213# docker inspect bridge[ &#123; &quot;Name&quot;: &quot;bridge&quot;, ...... &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot; &#125; ] &#125;, ...... docker daemon会创建一对对等接口：虚拟网桥上的vethxxx和容器的eth0。veth放置在宿主机的命名空间中，将宿主机上的所有网络为bridge的容器都连接到这个内部网络中，同时daemon会从网桥的私有地址空间中分配一个IP地址和子网给该容器。 123456789101112# ifconfig......veth7576df5: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::9023:faff:fe28:14b3 prefixlen 64 scopeid 0x20&lt;link&gt; ether 92:23:fa:28:14:b3 txqueuelen 0 (Ethernet) ......vethab244c0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::d047:b2ff:fee4:89c8 prefixlen 64 scopeid 0x20&lt;link&gt; ether d2:47:b2:e4:89:c8 txqueuelen 0 (Ethernet) ............ 连接同一个bridge网络的容器间能够通过IP地址互相通信。由于运行容器默认使用bridge网络，所以若要运行对外提供访问的服务，如web服务，就必须暴露端口，通过-p（指定容器暴露端口）或-P（发布容器所有端口）发布容器暴露的端口。 默认情况下，创建容器时不会将任何端口发布到外部。若通过-p或--publish发布端口，会创建一个防火墙规则，将容器端口映射到宿主机上的端口。 Docker在bridge网络上不支持服务自动发现。如果需要通过容器名实现容器间的互相通信，就要设置连接属性--link=容器名:别名（官方并不推荐，已快被淘汰，官方推荐用user-definded网络实现互通）。容器内所有的环境变量都可供连接到它的容器使用，可能会造成安全隐患。 主机模式host在此模式下，容器网络与宿主机网络间的隔离将被禁止，容器共享宿主机的网络命名空间，使容器直接暴露在公共网络中。因此，需要通过端口映射（Port Mapping）进行协调。 1234567891011121314# docker run -it --network=host alpine/ # ifconfigbr-7673688a6ae1 Link encap:Ethernet HWaddr 02:42:DC:D4:64:FA inet addr:172.22.0.1 Bcast:172.22.255.255 Mask:255.255.0.0 ......docker0 Link encap:Ethernet HWaddr 02:42:81:58:18:0C inet addr:172.17.0.1 Bcast:172.17.255.255 Mask:255.255.0.0 ......ens33 Link encap:Ethernet HWaddr 00:0C:29:58:0C:12 inet addr:192.168.163.101 Bcast:192.168.163.255 Mask:255.255.255.0 ............ 由此可知，当使用host模式网络时，容器实际上继承了宿主机的IP地址，并且在容器中可以看到宿主机的所有网卡。 因为没有路由开销，因此主机模式会比bridge模式更快。但是由于容器直接被暴露在公共网络中，会有安全隐患。 容器网络container在该模式，新创建的容器和已经存在的一个容器共享一个网络命名空间。两个容器除了网络的命名空间，其他的如文件系统、进程列表等仍然是隔离的。两个容器可以通过环回口进行设备通信。该模式也是Kubernetes使用的网络模式。 该模式通过--network=container:另一个已存在的容器实现。1234567891011# docker run -it --name container_A alpine/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:05 inet addr:172.17.0.5 Bcast:172.17.255.255 Mask:255.255.0.0 ......# docker run -it --name container_B --network=container:container_A alpine/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:05 inet addr:172.17.0.5 Bcast:172.17.255.255 Mask:255.255.0.0 ...... 无网络模式none该模式关闭了容器的网络功能，容器处于自己独立的网络命名空间中，且不进行任何配置。 使用场景：1.容器并不需要网络（例如只需要写磁盘卷的批处理任务，或生成随机密钥）2.自定义网络 用户自定义模式user-defined本模式使用户可自定义网络中的参数，以满足特定需求，例如DNS服务器。同一个自定义网络中，可以使用对方容器的容器名、服务名、网络别名来找到对方。这个时候帮助进行服务发现的是Docker内置的DNS。所以，无论容器是否重启、更换IP，内置的DNS都能正确指定到对方的位置。 docker内嵌DNS Server，但只有在用户自定义模式才能使用。 docker提供的网络驱动：User-defined bridge，overlay，macvlan，host，Third-party network plugins。 可通过docker network create --driver=[driver] [network-name] [--subnet] [--gateway]指定网络驱动创建网络，并指定网段和网关。 bridge用于在同一主机内的通信。macvlan和overlay用于跨主机通信。 macvlan：当从VM设置迁移或需要容器看起来像网络上的物理主机时使用，可以使每个容器都具有唯一的MAC地址。 overlay：当需要在不同Docker主机上运行的容器进行通信，或者当多个应用程序使用swarm服务一起工作时使用。 host和网络模式对应的作用相同，host驱动仅可用于v17.06版本以上的docker swarm集群。network plugins是第三方为docker制作的网络插件。 bridge驱动: 用于创建类似bridge网络模式的网络，加入该网络的容器必须在同一台宿主机，仅适合一台主机上的小型网络。 123456789101112131415161718192021222324# docker network create --driver=bridge mybridge --subnet=10.1.1.0/24 --gateway=10.1.1.1# docker inspect mybridge[ &#123; &quot;Name&quot;: &quot;mybridge&quot;, ...... &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;10.1.1.0/24&quot;, &quot;Gateway&quot;: &quot;10.1.1.1&quot; &#125; ]......# docker run -it --network=mybridge alpine/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:0A:01:01:02 inet addr:10.1.1.2 Bcast:10.1.1.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 ...... 同主机容器间通信，分为：IP通信，DNS Server，Joined容器。 IP通信： 容器处于两个不同网络中，通过docker network connect [对端容器所处网络名][本端容器]连接容器。 12345--alias 设置对端网络别名--ip 指定对端网络上该IP地址的容器--ip6 同上，为IPv6地址--link 指定连接的容器名--link-local-ip 为容器添加一个连接本地的地址 12345678910111213141516171819202122# docker run -it --name container_A alpine# docker network connect mybridge container_A# docker run -it --network=mybridge --name=container_B alpine# docker inspect container_B -f &apos;&#123;&#123;.NetworkSettings.Networks.mybridge.IPAddress&#125;&#125;&apos;10.1.1.4# docker inspect container_A -f &apos;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&apos;172.17.0.3# docker attach container_A/ # ping 10.1.1.4PING 10.1.1.4 (10.1.1.4): 56 data bytes64 bytes from 10.1.1.4: seq=0 ttl=64 time=0.294 ms/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:03 inet addr:172.17.0.3 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 ......eth1 Link encap:Ethernet HWaddr 02:42:0A:01:01:03 inet addr:10.1.1.3 Bcast:10.1.1.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 ...... 原理如图（图为docker文档的，ip地址有偏差），docker会在本容器上创建一个新的网卡，由指定的网络分配IP地址，实现与指定的网桥中容器的连接（如上面ifconfig中eth1）。 DNS： 使用对方容器的容器名、服务名、网络别名来找到对方，无论容器是否重启、更换IP，内置的DNS都能正确指定到对方的位置。 Joined容器： 即container网络模式，使两个及以上的容器共享一个网络栈，共享网卡和配置。 容器访问外网容器默认就能访问外网，这里外网指容器外的网络，不只是互联网。 处理流程：1.容器发数据包，docker0收到数据包后查看IP头，发现是发往外网的，交给NAT处理。2.NAT将源地址转为宿主机IP地址，并从主机网卡发出。 外网访问容器外网通过端口映射访问容器，每个映射的端口，宿主机都会启动一个docker-proxy进程处理访问容器的流量，可在宿主机通过ps -ef | grep docker-proxy查看端口映射情况下图为内外网的完整访问流程图 跨主机网络docker容器有多种访问外网的方案，其中docker提供两个原生方案：overlay和macvlan。还可选择第三方方案：flannel，weave，calico。 众多的docker网络方案通过libnetwork与容器网络模型（Container Network Model）集成在一起，其中libnetwork为docker容器网络库，而其核心即为容器网络模型，对容器网络进行了抽象，由以下三个组件组成： Sandbox：容器的网络栈，包含容器接口、路由表和DNS设置。Sandbox的实现标准为Linux Network Namespace，可以包含来自不同Network的Endpoint。 Endpoint：将Sandbox接入Network，典型实现为Veth Pair。一个Endpoint只属于一个网络，也只属于一个Sandbox。 Network：包含一组Endpoint，同一Network的Endpoint可以直接通信。 OverlayOverlay网络驱动创建了多docker主机间的分布式网络，允许与其连接的容器互相安全地通信，服务和容器能同时连接多个网络，但也仅能在连接的网络间通信。虽然可以将集群服务和单独的容器都连入一个overlay网络，但overlay对于集群与单独容器的默认配置是不同的，对于不同对象有不同的选项。 在创建overlay网络之前，需要使用docker swarm初始化作为swarm manager，或者使用docker swarm join将其加入到现有swarm中。这两者都创建缺省的swarm服务使用的默认overlay网络ingress。 实验环境：swarm manager：192.168.163.102swarm worker：192.168.163.103 在manager上初始化docker swarmdocker swarm initworker上加入docker swarm（将manager上生成的命令复制粘贴到worker上运行） 12# docker swarm join --token SWMTKN-1-077i43tqnp5df8y29nrrh8apm9y2a4khzggg8nydd2yy8nzzjw-0i1qu8z1xl2s7ngy8y1gcnfnb 192.168.163.102:2377This node joined a swarm as a worker. 创建overlay网络my_overlay：123456789# docker network create -d overlay my_overlay# docker network lsNETWORK ID NAME DRIVER SCOPE8cc4b6f2ddfa bridge bridge local5db2b494b1af docker_gwbridge bridge local5a1cfdddfd60 host host localy6l4bambmqoj ingress overlay swarmbdv2xdmkujbu my_overlay overlay swarm7ec96e1718f1 none null local 若要创建一个overlay网络供群集服务或独立容器与其他Docker守护程序上运行的其他独立容器进行通信，要添加--attachable参数。ingress网络创建时没有--attachable选项，说明只有swarm服务可以使用它，而不是独立的容器。通过在创建网络时添加--attachable选项使得运行在不同Docker守护进程上的独立容器能够进行通信，而无需在各个Docker守护进程主机上设置路由。 容器发现对于大多数情况，应该连接到服务名，而不是单独容器，因为服务是负载均衡的且是由所有服务后的容器（即任务task）处理的。要获取支持该服务的所有任务（task）的列表，可以执行DNS查找tasks.&lt;service-name&gt; overlay网络加密默认docker对swarm服务在GCM模式下使用AES算法加密，集群中的manager节点每12小时就轮换用于加密gossip（反熵算法）数据的密钥。 要加密应用程序数据，需要在创建overlay网络时添加--opt encrypted。这使得vxlan级别的IPSEC加密成为可能。这种加密会带来不可忽视的性能损失，所以应该在生产中使用它之前对其进行测试。 当启用overlay加密时，Docker会在所有节点之间创建IPSEC隧道，在这些节点上调度连接到overlay网络服务的任务。这些通道在GCM模式下也使用AES算法，manager节点每12小时自动轮换一次密钥。 不要将Windows节点添加到加密的overlay网络。Windows上不支持overlay网络加密。如果Windows节点尝试连接到加密的overlay网络，虽不会报告错误，但节点无法通信。 默认ingress网络默认overlay网络ingress的作用：当自动选择的子网与网络中已存在的子网冲突或需要自定义某项低层的网络配置（例如MTU）时，默认的ingress网络会很有用。通常在Swarm中创建服务前对ingress网络进行删除或重建操作。如果已有发布端口的服务，在删除ingress网络前必须先删除这些服务。若没有ingress网络且不发布端口的服务在运行却没有进行负载均衡，那么那些发布端口的服务会受到影响。 可在创建网络时加上--ingress选项创建ingress网络并自定义网络参数。只能创建一个ingress网络。 默认docker_gwbridge网络docker_gwbridge是一个虚拟网桥，它将overlay网络（包括ingress网络）连接到单独的Docker守护进程的物理网络。初始化群集或将Docker主机加入群集时，Docker会自动创建它，但它不是Docker设备。它存在于Docker主机的内核中。如果需要自定义其设置，则必须在将Docker主机加入集群之前或临时从集群中暂时删除主机之后执行该自定义操作。 若要删除docker_gwbridge网络，需要先停止docker，再删除docker_gwbridge网络，由于停止了docker，所以要通过ip link删除该网络。12# ip link set docker_gwbridge down# ip link del docker_gwbridge 再启动docker，但不要加入或初始化swarm。重建一个docker_gwbridge网络，然后再加入或初始化swarm。 在overlay网络发布端口连接在同一个overlay网络的集群服务可以有效地互相发布所有端口。若要使一个端口能在服务外能访问，必须在docker service create或docker service update后加上-p选项发布指定端口。支持冒号分隔的旧语法-p 8080:80/tcp和逗号分隔的新语法-p published=8080,target=80,protocol=tcp。 绕过集群服务的路由网格（routing mesh）默认情况下，发布端口的群集服务使用路由网格来完成。当连接到任何swarm节点上的已发布端口（无论是否运行给定服务）时，都会透明地重定向到正在运行该服务的worker。实际上，Docker充当群集服务的负载平衡器。使用路由网格的服务以虚拟IP（VIP）模式运行。即使在每个节点上运行的服务（通过--global标志）也使用路由网格。使用路由网格时，不能保证哪个Docker节点服务客户端会请求。 要绕过路由网格，可以通过设置选项--endpoint-mode dnsrr来使用DNS Round Robin（DNSRR）模式启动服务且必须在服务前运行自定义的负载均衡器。对Docker主机上服务名的DNS查询会返回运行该服务的节点的IP地址列表，可以通过配置负载均衡器使用此列表并且平衡各节点间的流量。 单独控制和数据默认情况下，尽管群集控制流量是加密的，但群集管理和应用程序之间的控制流量运行在同一个网络上，可以配置Docker使用单独的网络接口来处理两种不同类型的流量。初始化或加入群集时，分别指定--advertise-addr和--datapath-addr，加入集群的每个节点都要执行此操作。 实验（根据官方文档的实验）Manager（system2）:192.168.163.102Worker-1（system3）：192.192.168.163.103Worker-2（system4）：192.192.168.163.104 在manager上初始化swarm，worker节点加入swarm。在manager上查看节点。12345# docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONohfkwg8uu4zkjtyk1l1nbze4p * system2.example.com Ready Active Leader 18.03.1-ce6dbboj25t5tws0ohd1pdhsahl system3.example.com Ready Active 18.03.1-ceaug4gnqnm0na4pwu835dku51x system4.example.com Ready Active 18.03.1-ce 可通过--filter role=worker|manager过滤节点信息 在manager上创建overlay网络。不需要在其他节点上创建overlay网络，当其中一个节点开始运行需要overlay网络的服务时，它将自动创建。docker network create -d overlay nginx-net在manager上创建一个nginx服务（只能在manager上创建服务）12345678910# docker service create \--name my-nginx \-p 80:80 \--replicas=5 \ #设置创建的任务个数--network nginx-net \nginx# docker service lsID NAME MODE REPLICAS IMAGE PORTSnvxzb5kzihl6 my-nginx replicated 5/5 nginx:latest *:80-&gt;80/tcp 在manager和worker上查看nginx-net网络情况，以及容器情况docker inspect nginx-net 新建overlay网络，将服务更新到新的网络上docker network create -d overlay nginx-net-21234# docker service update \--network-add nginx-net-2 \ # 将my-nginx添加进nginx-net-2网络中--network-rm nginx-net \ # 将my-nginx从nginx-net网络中删除my-nginx 注：overlay网络会因为需要自动创建，但不会自动删除（当服务不需要该网络后）。需要手动删除服务和网络。docker service rm my-nginxdocker network rm nginx-net nginx-net-2 Macvlan一些应用类似传统应用或监视网络流量的应用，希望直接连接到物理网络，可以使用macvlan网络驱动为每个容器的虚拟网络接口分配MAC地址，需要指定宿主机上的物理接口用于Macvlan，以及Macvlan的子网和网关。可以使用不同的物理网络接口来隔离Macvlan网络。网络设备需要能够处理“混杂模式”，其中一个物理接口可以分配多个MAC地址。网络模式最好是bridge或overlay。可以在bridge模式或vlan的trunk模式中创建macvlan网络。 在bridge网络模式中创建macvlan网络在docker network create后添加-d macvlan，也可再指定流量通过的实际网卡-o parent=ens33。若要排除在macvlan中使用的IP地址，可添加选项--aux-addresses=&quot;aux-addr=&quot;，参数值为一组键值对。一张网卡仅能被一个macvlan网络设为parent。 在vlan trunk模式中创建macvlan网络通过在网卡名后加.[数字]创建网卡子接口，例如-o parent=ens33.10。 使用IPvlan可以使用三层IPvlan取代二层Macvlan。通过指定-o ipvlan_mode=l2 补充知识点支持IPv6只有Linux主机的docker支持IPv6。修改/etc/docker/daemon.json，添加{&quot;ipv6&quot;: true}开启IPv6。然后重新加载配置文件systemctl daemon-reload或systemctl reload docker。在创建网络的时候可以加上--ipv6选项，在创建容器时加上--ip6选项 配置iptablesDocker通过iptables规则来提供网络隔离，不应修改Docker已设置的iptables规则。所有Docker的iptables规则都被添加到DOCKER链中，不要手动操作此表。如果需要添加能在加载Docker规则之前加载的规则，应该将它们添加到DOCKER-USER链中，这些规则在Docker自动创建任何规则之前加载。 默认情况下，所有外部源IP都被允许连接到Docker守护进程。若要只允许特定的IP或网络访问容器，可在DOCKER过滤器链的顶部插入否定规则。 例：iptables -I DOCKER-USER -i ens33 ! --source 192.168.163.0/24 -j DROP为防止Docker修改iptables策略，在/etc/docker/daemon.json中设置{&quot;iptables&quot;: false}，官方不推荐这样设置，因为这样所有关于docker的iptables配置都要手动管理。 DNS选项1234--dns 指定一个或多个DNS服务器--dns-search 设置dns搜索域--dns-opt 键值对，可参考/etc/resolv.conf--hostname 设置容器的主机名，默认就是容器名 docker代理在Docker客户端上编辑启动容器的用户主目录~/.docker/config.json文件。添加字段，可用httpsProxy或ftpProxy指定代理服务器的类型，并指定代理服务器的地址和端口，可以同时配置多个代理服务器。 通过将noProxy键设置为一个或多个逗号分隔的IP地址或主机，指定排除的代理服务器，支持*字符作为通配符。12345678910&#123; &quot;proxies&quot;: &#123; &quot;default&quot;: &#123; &quot;httpProxy&quot;: &quot;http://127.0.0.1:3001&quot;, &quot;noProxy&quot;: &quot;*.test.example.com,.example.com&quot; &#125; &#125;&#125; 在创建容器时可通过--env设置环境变量，通过环境变量指定代理服务器。1234--env HTTP_PROXY=&quot;&quot;--env HTTPS_PROXY=&quot;&quot;--env FTP_PROXY=&quot;&quot;--env NO_PROXY=&quot;&quot; 参考文档Cloudman 《每天五分钟玩转docker容器技术》docker官方文档-网络板块docker网络模式]]></content>
      <tags>
        <tag>网络</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrony/NTP学习笔记]]></title>
    <url>%2F2018%2F01%2F31%2FChrony%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Chrony/NTP学习笔记本篇包含以下内容 chrony介绍 chrony配置 ntpd配置 NTP协议介绍NTP全称Network Time Protocol网络时间协议，用于同步计算机时间。保证局域网服务器与时间服务器的时间保持一致，并支持使用加密确认的方式防止恶意协议攻击。 自CentOS7.2后，chronyd服务代替原来的ntpd服务，性能提高且配置简单。 根据红帽文档，chronyd与ntpd的区别在于： chronyd使用更好的算法，同步精度、速度与对系统的影响都比ntpd更好。 chronyd可以在更大的范围内调整系统时间速率，且能在时钟损坏或不稳定的计算机上正常工作。 当网络故障时，chronyd仍能很好地工作，而ntpd必须定时轮询时间参考才能正常工作。 chronyd可以快速适应时钟速率的突然变化，ntpd则需要一段时间才能稳定。 chronyd提供对孤立网络的支持，手动输入校准时间，并通过算法计算实时时间，估计计算机增减时间的速率，从而调整时间。 实验环境 CentOS7.4 Chrony基础搭建步骤 安装chrony服务（默认已安装） yum install chrony 安装完后会有两个程序，一个chronyd服务，一个chronyc监控配置程序。 启动服务，设置开机自启 systemctl start chronyd systemctl enable chronyd chrony的配置文件/etc/chrony.conf 123456789101112131415161718192021222324server ntp.sjtu.edu.cn iburstserver s1a.time.edu.cn iburstserver s1b.time.edu.cn iburstserver s1d.time.edu.cn iburst//server 添加时间服务器，能添加很多driftfile /var/lib/chrony/drift//chronyd中的校准文件，根据实际时间计算出计算机增减时间的比率，能在重启后做出补偿makestep 1.0 3//当系统时钟漂移过快后，会通过很长的调整期纠正，该命令指定在调整期大于某阈值时才调整//此处是当偏移大于1秒，系统时钟调整3次。rtcsync//启用内核模式，系统时间每11分钟拷贝到实时时钟#allow 192.168.0.0/16//允许指定网段或主机使用服务#keyfile /etc/chrony.keys //设置密钥文件，可做NTP加密logdir /var/log/chrony//设置日志文件 防火墙放行并重启服务firewall-cmd --permanent --add-service=ntpfirewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 port port=123 protocol=udp accept&#39;firewall-cmd --reloadsystemctl restart chronyd 查看同步源信息 1234567891011chronyc sourcestats//查看同步源状态210 Number of sources = 4Name/IP Address NP NR Span Frequency Freq Skew Offset Std Dev==============================================================================202.120.2.100.dns.sjtu.e&gt; 0 0 0 +0.000 2000.000 +0ns 4000ms10.112.202.in-addr.arpa.&gt; 0 0 0 +0.000 2000.000 +0ns 4000msntpa.nic.edu.cn 0 0 0 +0.000 2000.000 +0ns 4000mstime.njnet.edu.cn 4 3 10 +810.140 43784.844 +7121us 14mschronyc sources //查看同步源，结果与上一条类似 自动同步时间chronyc sources -v 若要局域网内同步时间，只要客户端都安装chrony，且配置文件的server设置为此服务器ip即可。 ntpd基础搭建 安装ntpd服务yum install ntp 修改配置文件/etc/ntp.conf在restrict段添加允许的主机网段restrict 192.168.163.0 mask 255.255.255.0允许指定网段或主机使用服务（类似chrony的allow）server字段与chrony类似，指定上游ntp服务器。 重启ntpdsystemctl restart ntpd.service 在ntpd服务未开启时，可用命令ntpdate 0.centos.pool.ntp.org手动同步。这条命令只能在ntpd未开启时才有效。 命令ntpq -p列出NTP服务器与上游服务器的连接状态12345678910111213# ntpq -p remote refid st t when poll reach delay offset jitter==============================================================================*static-5-103-13 .GPS. 1 u 19 64 1 777.937 -99.910 133.624+mx.comglobalit. 128.227.205.3 2 u 19 64 1 413.258 84.278 15.570-ntp6.flashdance 192.36.143.130 2 u 18 64 1 438.957 196.165 32.565+119.79-161-57.c 129.242.4.241 2 u 50 64 1 670.566 58.678 51.049remote：上层ntp的IP地址或主机名，&apos;+&apos;表示优先，&apos;*&apos;表示次优先refid：参考的上一层NTP主机的地址st：stratum阶层poll：下次更新在几秒后offset：时间补偿的结果 扩展内容123456系统时间与BIOS时间不一定相同。查看硬件BIOS时间：# hwclock -rWed 02 May 2018 05:00:32 PM CST -0.854732 seconds将当前系统时间写入BIOS中# hwclock -w]]></content>
      <tags>
        <tag>server</tag>
        <tag>Chrony</tag>
        <tag>NTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iSCSI学习笔记]]></title>
    <url>%2F2018%2F01%2F29%2FiSCSI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[iSCSI学习笔记-1第一篇iSCSI笔记主要是基础配置，包含以下内容 iSCSI介绍 iSCSI基础搭建 常见存储方式 DAS 直接附加存储：外接存储设备直接连在服务器内部总线上，数据存储设备是整个服务器结构的一部分。 NAS 网络接入存储：存储设备独立于服务器，作为文件服务器独立存在与网络中。存储设备通过标准的网络拓扑（如以太网）添加到一群计算机。 SAN 存储区域网络：创造了存储的网络化。包含两种部署方式 FCSAN：使用光纤通道 IPSAN：使用IP通道（如以太网线与iSCSI技术） SCSI与iSCSI SCSI 小型计算机系统接口：一种通用接口标准，多用于服务器系统级接口。SCSI 结构基于C/S模式，其通常应用环境是：设备互相靠近，并且这些设备由 SCSI 总线连接。 iSCSI Internet小型计算机系统接口：一种基于TCP/IP的协议，用于建立管理IP存储设备、主机与客户机之间的连接，并创建SAN。SAN 使得 SCSI 协议应用于高速数据传输网络成为可能，这种传输以数据块级别（block-level）在多个数据存储网络间进行。 iSCSI 的主要功能是在 TCP/IP 网络上的主机系统（启动器 initiator）和存储设备（目标器 target）之间进行大量数据的封装和可靠传输。此外，iSCSI 提供了在 IP 网络封装 SCSI 命令，且运行在 TCP 上。 服务器：target 客户端：initiator 实验环境 CentOS7，内核3.10 两台虚拟机，system1与system2，system1为服务器，system2为客户端 虚拟机网段192.168.163.0/24 system1 IP：192.168.163.100/24 system2 IP：192.168.163.102/24 首先搭建服务器 安装target与targetcli并开机启动服务器端要安装的服务为targetd，还需安装targetcli程序进行配置 123yum install targetd targetclisystemctl enable targetd targetsystemctl start targetd target 确保系统有空闲可用的裸磁盘本处选择/dev/sdc1，大小5G 进入targetcli程序配置123456789目录结构o- / o- backstores | o- block | o- fileio | o- pscsi | o- ramdisk o- iscsi o- loopback 进入block，创建设备disk1create dev=/dev/sdc1 name=disk1另一种写法create disk1 /dev/sdc1然后进入iscsi目录，设置服务器端识别号 识别号规范：iqn.年-月.域名反置:服务器主机名 create wwn=iqn.2018-01.com.example:system1该标识符可以自己设定如上配置，也可让系统自动生成直接在iscsi目录中create设置后iscsi目录结构如下1234567o- iscsi o- iqn.2018-01.com.example:system1 o- tpg1 o- acls o- luns o- portals o- 0.0.0.0:3260 进入acls/ 添加客户端身份标识create wwn=iqn.2018-01.com.example:system2进入luns/ 给该组设置可用的存储设备create /backstores/block/disk1disk1就是block中创建的设备名此时iscsi目录结构12345678910o- iscsi o- iqn.2018-01.com.example:system1 o- tpg1 o- acls | o- iqn.2018-01.com.example:system2 | o- mapped_lun0 o- luns | o- lun0 o- portals o- 0.0.0.0:3260 进入portals/ 修改服务端端口号有可能里面没有默认配置，直接创建。若有默认配置就先删除再创建delete 0.0.0.0 ip_port=3260create 192.168.163.100 3260此处ip地址为服务器端IP，端口号为3260全部配置完exit退出配置程序 防火墙放行对应端口号，重启服务端口号3260，且tcp端口放行123firewall-cmd --permanent --add-port=3260/tcpfirewall-cmd --reloadsystemctl restart targetd target 然后是客户端搭建 安装客户端软件yum install iscsi-initiator-utils 设置客户端识别号该文件需要自己输入配置，输入客户端的识别码vim /etc/iscsi/initiatorname.iscsiinitiatorname=iqn.2018-01.com.example:system2 启动服务systemctl enable iscsi iscsidsystemctl start iscsi iscsid 获取硬盘iscsiadm -m discovery -t st -p 192.168.163.100 -l iscsiadm 用于管理iSCSI数据库配置文件的命令行工具-m discovery 表示发现查找-t senbtargets 表示发布的target，简写st-p IP 指定服务器地址-l 表示login，可不加 123连接成功信息:Logging in to [iface: default, target: iqn.2018-01.com.example:system1, portal: 192.168.163.100,3260] (multiple)Login to [iface: default, target: iqn.2018-01.com.example:system1, portal: 192.168.163.100,3260] successful. 通过命令lsblk查看是否拿到123456789[root@system2 ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot└─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP]sdb 8:16 0 5G 0 disk sr0 11:0 1 1024M 0 rom 发现出现了sdb，大小为5G，已成功获取]]></content>
      <tags>
        <tag>server</tag>
        <tag>iSCSI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS学习笔记（1）]]></title>
    <url>%2F2018%2F01%2F28%2FDNS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇DNS笔记包含以下内容 DNS简介 DNS解析原理 DNS深入理解 基本配置 DNS简介DNS全称Domain Name System域名解析服务，用于解析域名与IP地址对应关系。 DNS基于UDP，UDP端口号53，也会使用TCP的53端口，先会用UDP查找，若UDP查不到或请求大于512字节时才用TCP查找。同时，UDP进行名称解析，TCP进行区域解析。 DNS组成： 域名服务器：提供域名解析服务的软件。DNS域名解析服务中最高效的是Bind。Bind的程序名叫named。 解析器：访问域名服务器的客户端，负责解析从域名服务器获取的响应。如nslookup。 目前互联网的命名方式为层次树状结构，任何互联网上的主机或路由器都有唯一层次结构的名字，即域名。 功能 正向解析：根据域名查找对应IP 反向解析：根据IP查找对应域名 DNS解析原理DNS域名解析原理（迭代） 客户端将域名解析请求发给本地域名服务器或/etc/resolv.conf中列出的服务器 本地域名服务器收到后，查询本地缓存，若有就返回 若没有就把请求发给根域名服务器，迭代查询 本地域名服务器会将最终的结果存入缓存，同时将结果返回给主机。 /etc/resolv.conf用于定义dns查询指向的服务器以及解析顺序文件结构 1234domain domain_name # 声明本地域名，即解析时自动隐式补齐的域名search domain_name_list # 指定域名搜索顺序(最多6个)，和domain不能共存，若共存了，则后面的行生效nameserver IP-Address # 设置DNS指向，最多3个options timeout:n attempts:n # 指定解析超时时间(默认5秒)和解析次数(默认2次) 域名解析方法 递归：服务器收到请求时，若不能解析，则把请求转发到下一台服务器直到有一台解析成功。注：是收到请求的服务器去问，一个问下一个，最后解析完成后原路返回。 迭代：服务器收到请求时，若不能解析，则按根域-&gt;一级域名-&gt;二级域名-&gt;三级域名依次询问，直到解析成功。注：是本地服务器去不断问。 禁止递归查询的原因：对于授权域名服务器，若打开了递归查询，相当于配置为开放DNS服务器，会造成大量数据流量。所以在授权域名服务器上，应该禁用递归查询。recursion no; 反向解析：根据IP查找对应域名。将创建一个in-addr.arpa的专门的域处理。 高速缓存：DNS会将解析的信息保存在高速缓存中。每条记录都对应一个TTL，设置在缓存中保存的时间。 DNS深入理解DNS报文解析 分类 主域名服务器master server：在特定区域内具有唯一性的域名解析服务器 辅域名服务器slave server：从主服务器获取域名解析信息并维护，以防主服务器宕机。会通过TCP与主域名服务器通信，获取zone数据。 缓存服务器Caching-Only Server：向其他服务器查询域名解析信息，每获取一个就放在高速缓存中，提高重复查询效率。 域名服务器类型 根域名服务器：最高层次的域名服务器，存放所有顶级域名服务器的IP地址与域名。当一个本地域名服务器对一个域名无法解析时，就会直接找根域名服务器，根域名服务器会告知应该去哪个顶级域名服务器查询。全球共13个根域名服务器。可通过dig查看。 顶级域名服务器：负责管理在该服务器上注册的二级域名服务器的IP地址和域名。 授权域名服务器：DNS采用分区方式设置域名服务器。一个服务器所管理的范围为区。区的范围小于等于域的范围，每个区都设有一台权限域名服务器，负责将其分区的主机域名解析。由专业域名服务公司维护，若授权域名服务器出现故障，域名将不能被解析。 本地域名服务器：也称默认域名服务器，当主机发出DNS查询报文时，会最先询问本地域名服务器。 域名结构每一级域名都由英文字母与数字组成，不超过63字符，且不区分大小写，完整域名不超过255字符。目前顶级域名TLD（Top Level Domain）三大类：国家顶级域名、国际顶级域名、通用顶级域名。互联网的命名空间是按照机构的组织划分的，与物理网络无关，与IP子网无关。 . 根域，管理一级域名 com、or、gov、cn等一级域名，管理二级域名 baidu、google等二级域名，管理三级域名，当国家为一级域名时，com等一级域名便会下降一级别，依次类推 依次会有三级，四级 www、ftp、mail等主机域名，为提供服务的主机名 DNS系统采用阶层式管理，上一级的服务器只记录下一层的主机名（服务器名） 资源记录语法{name} {TTL} class record-type record-specfic-data name：域记录名。通常只有第一个DNS资源记录会配置，其他资源记录的name可能为空，那么其他资源记录会接受先前资源记录的名字。 TTL：生存时间。指定该数据在数据库中保存的时间，此栏若为空，表示默认生存时间在授权资源记录中指定。 class：记录的类。大范围用于Internet地址和其他信息地址类为IN（基本都是IN）。 record-type：记录类型。常为A、NS、MX、CNAME record-specfic-data：记录指定数据。 记录类型： A：IPv4地址记录，将主机映射到IPv4地址 1234# host -v -t A baidu.com;; ANSWER SECTION:baidu.com. 5 IN A 123.125.115.110baidu.com. 5 IN A 220.181.57.216 AAAA：IPv6地址记录，将主机名映射到IPv6地址 CNAME：规范名称记录，将一个记录别名化为另一个记录，其中应具有A或AAAA记录。就是实际主机名当DNS解析器收到CNAME记录为查询响应时，DNS解析器会使用规范名称重新发出查询。CNAME记录数据可指向DNS中任何位置的名称，无论在区域内还是区域外。应避免将CNAME记录指向其他CNAME记录以避免CNAME循环。CNAME记录链必须以A或AAAA记录结束。当使用CDN时，也可使用CNAME链。NS和MX记录不可指向CNAME记录。 123# host -v -t CNAME baidu.com;; ANSWER SECTION:www.baidu.com. 5 IN CNAME www.a.shifen.com. PTR：指针记录，将IPv4或IPv6地址映射到主机名，用于反向DNS解析。对行为类似于主机名的IP进行编码。 123# host -v -t PTR 202.108.22.220;; ANSWER SECTION:220.22.108.202.in-addr.arpa. 5 IN PTR xd-22-220-a8.bta.net.cn. NS：名称服务器记录，将域名映射到DNS名称服务器。区域的每个公开授权名称服务器必须具有NS记录。 123# host -v -t ns baidu.com;; ANSWER SECTION:baidu.com. 5 IN NS ns7.baidu.com. SOA：授权起始记录，提供有关DNS区域工作方式的信息。每个区域正好有一个SOA记录，指定主服务器，以及辅（从）服务器更新副本的方式。 12345678910111213141516# host -v -t SOA baidu.com;; AUTHORITY SECTION:baidu.com. 5 IN SOA dns.baidu.com. sa.baidu.com. 2012138777 300 300 2592000 7200# dns.baidu.com. 主名称服务器（Master） # sa.baidu.com. DNS区域负责人的邮箱地址，因为@在zone文件中有意义，所以改为了.# 2012138777 区域版本号（序列号）# 300 检查区域更新频率（单位s）（refresh）# 300 在重试失败的刷新前应等待的时间（单位s）（retry）# 2592000 刷新失败，在停止使用其旧区域副本前等待的时间（单位s）（expire）# 7200 若解析器查询某个名称并该名称不存在，解析器将“记录不存在”信息进行缓存的时间（单位s）值的设置范围：刷新频率（refresh）&gt;= 2 × 重试刷新时间（retry）refresh+retry &lt; 超时时间（expire）expire &gt;= retry × 10expire &gt;= 7天 MX：邮件交换记录，将域名映射到邮件交换。邮件交换将接收该名称的电子邮件。数据为优先级，用于在多个MX记录间确定顺序，以及用于该名称的邮件交换的主机名。 123456789# dig -t mx google.com;; ANSWER SECTION:google.com. 5 IN MX 40 alt3.aspmx.l.google.com.google.com. 5 IN MX 50 alt4.aspmx.l.google.com.google.com. 5 IN MX 20 alt1.aspmx.l.google.com.google.com. 5 IN MX 30 alt2.aspmx.l.google.com.google.com. 5 IN MX 10 aspmx.l.google.com.#邮件域名前的数字，为优先级，值越低越优先，具有优先的邮件处理权 TXT：文本记录，将名称映射到文本。通常用于提供发送方策略框架SPF、域密钥识别邮件DKIM、基于域的消息身份验证报告一致性DMARC等数据。 12345678910# dig -t txt google.com;; ANSWER SECTION:google.com. 5 IN TXT &quot;v=spf1 include:_spf.google.com ~all&quot;google.com. 5 IN TXT &quot;facebook-domain-verification=22rm551cu4k0ab0bxsw536tlds4h95&quot;google.com. 5 IN TXT &quot;docusign=05958488-4752-4ef2-95eb-aa7ba8a3bd0e&quot;# txt记录是按一定格式编写的，最常用的是SPF（sender policy framework），登记某个域名拥有的用来外发邮件的所有IP# SPF就是用于反垃圾邮件，阻止发件人发送假冒域中发件人地址的电子邮件# v=spf1 include:_spf.google.com ~all# 其中v标识spf版本，include指定spf标识，~all表示其余都不认可 SPF防止伪造邮件的过程： 邮件服务器收到邮件后，先检查哪个域声明发送了该邮件，并检查该域名的SPF记录的DNS 确定发送服务器的IP地址是否与SPF记录中已发布的IP地址匹配 对该邮件打分，若匹配，则通过验证并打一个正分，否则不通过并打一个负分 SRV：服务记录，用于查找支持域的特定服务的主机。使用格式设置为包含服务和协议名称的域名。如_service._protocol.domainname，SRV记录可记录为域提供服务的主机名和服务端口号，还包括优先级和权重值。 名称服务器Name Server：存储域名资源信息的程序，会响应解析器的请求。利用该服务器，整个网络可划分为一个域的分层结构。整个域名空间可划分为多个区域zone，zone通常表示管理界限的划分，也就是DNS树状结构上的一点。每个zone都有一个主域名服务器，还可有多个辅域名服务器。 反向解析：IP是倒过来写的。 123# dig -x 8.8.4.4;; ANSWER SECTION:4.4.8.8.in-addr.arpa. 5 IN PTR google-public-dns-b.google.com. 基础配置环境 CentOS7，内核3.10 虚拟机网段：192.168.163.0/24 DNS服务器IP地址：192.168.163.102/24 DNS服务器主机名：system2.example.com 网关：192.168.163.254 客户端主机名：system3.example.com DNS服务相关配置文件 /etc/named.conf：主配置文件 /etc/named.rfc1912.zones：区域配置文件 /etc/reslov.conf：本地的DNS服务器 /etc/nsswitch.conf：优先级配置文件 /var/named/目录：存放区域（zone）文件 步骤 安装bind服务yum groupinstall DNS\ Server 开启named服务防火墙放行dns，rich rules放行UDP和TCP的53端口systemctl enable named.servicefirewall-cmd --add-service=dns --permanentfirewall-cmd --permanent --add-rich-rule=&#39;rule family=ipv4 port port=53 protocol=udp protocol=tcp accept&#39;firewall-cmd --reload 修改配置文件修改配置文件最好先做备份 cp -a XX XX.bak首先修改/etc/named.conf 注：注释需要用; 1234567891011121314151617181920212223只摘取部分options &#123; //指定bind服务参数 //listen-on 指定bind侦听的本机IP及端口 listen-on port 53 &#123; any; &#125;; //要将&#123;&#125;中改为any，本机的任意IP都监听（一台服务器可能有多个IP） listen-on-v6 port 53 &#123; ::1; &#125;; //directory 指定区域配置文件的路径 //若使用chroot则该路径是相对路径，对应/var/named/chroot/var/named/ directory &quot;/var/named&quot;; //改为any，接受任意IP的DNS查询请求 //也可指定网段，只给该网段做DNS allow-query &#123; any; &#125;; ;forward only; #只做转发 forwarders &#123;114.114.114.114; 8.8.8.8;&#125;; #上层的DNS服务器&#125;;zone &quot;.&quot; IN &#123; //指定当前bind可管辖的区域 type hint; //指定区域类型 file &quot;named.ca&quot;;//指定区域配置文件&#125;;//以下是区域配置文件和密钥文件include &quot;/etc/named.rfc1912.zones&quot;;include &quot;/etc/named.root.key&quot;; 修改后直接重新加载配置文件rndc reload，之后测试是否生效 1234567891011# dig www.google.com @127.0.0.1#@127.0.0.1是用于指定本地解析.......;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;www.google.com. IN A;; ANSWER SECTION:www.google.com. 113 IN A 208.101.60.87# 域名（FQDN） TTL值 关键词INTERNET RR类型 IPv4地址 正向解析修改/etc/named.rfc1912.zones配置正向解析区域文件named.conf中也能写区域配置，但为了安全和管理，将主配置和区域配置分开为两个文件 12345678zone &quot;example.com&quot; IN &#123; type master; //指定区域类型master file &quot;example.com.zone&quot;; //指定区域配置文件路径（相对路径，相对于named.conf中directory指定路径） //表示若要解析example.com的域名就要去该文件找 allow-update &#123; none; &#125;; //不允许客户机动态更新解析信息&#125; DNS区域类型 master：主要区域，拥有该区域数据文件，并对此区域提供管理数据 slave：辅助区域，拥有主要区域数据的只读副本，从主区域同步所有区域数据 hint：dns启动时，使用hint区域的信息查找最近的根域名服务器，没有就使用默认根服务器 然后配置解析数据信息文件/var/named/example.com.zone配置文件有模板，可复制/var/named/named.localhost并改名最好将文件名改为域名.zone 123456789101112131415161718192021222324$TTL 1D@ IN SOA example.com. root.example.com. ( 0 ; serial //更新序列号 1D ; refresh //更新时间 1H ; retry //重试延时 1W ; expire //失效时间 3H ) ; minimum //无效解析记录的缓存时间 NS ns.example.com.ns IN A 192.168.163.102 IN MX 10 mail.example.com.mail IN A 192.168.163.102www IN A 192.168.163.102// TTL 指定资源记录存放在缓存中的时间，单位秒，一般直接调用$TTL的值// @为当前域，根据主配置文件的zone区域决定// IN是网络类型，表示自身// SOA记录：起始授权记录，在一个区域一定是唯一的，定义区域的全局参数// example.com. DNS区域地址（完整的，要加.根域）// root.example.com. 服务器邮箱地址（完整）//NS记录：名称服务器记录，在一个区域至少一条，记录区域的授权服务器，一般就指定为主机名ns//该记录下一行就指定该服务器的ip地址//ns 为主机名 A为地址记录，写域名对应IP//MX邮件交换记录：指定邮件服务器，用于根据收件人地址后缀定位邮件服务器，为管理员自己接收邮件的域名//其他主机名也是一样 主和辅服务器都应该列在上级域的NS记录中，才能形成一个正式的授权。也应该列在自己主机的域文件中，任何列在NS记录中的服务器必须配置为那个域的授权域名服务器。 反向解析修改/etc/named.rfc1912.zones，添加 1234zone &quot;163.168.192.in-addr.arpa&quot; IN &#123; type master; # 服务类型master file &quot;192.168.163.arpa&quot;;&#125; 反向解析的参考配置文件为/var/named/named.loopback 可通过named-checkconf或named-checkzone检查配置文件语法是否正确。至此基础配置完成，重启服务 使用命令nslookup输入域名测试 常用命令rndc：bind的管理配置工具 123456789rndc COMMANDS reload 重载主配置文件和区域解析库文件 reload zone 重载区域解析库文件 retransfer zone 手动启动区域传输过程 notify zone 重新对区域传送通知 reconfig 重载主配置文件和区域解析库文件 querylog 开启或关闭查询日志 trace 递增debug级别rndc-confgen 生成rndc配置文件 host：查询某个域名或主机名所对应的所有IP地址 123# host baidu.combaidu.com has address 123.125.115.110baidu.com has address 220.181.57.216 nslookup：查询一台主机IP及对应的域名 12345678910两种模式：交互式：不加参数 非交互式：加参数# nslookup baidu.comServer: 192.168.163.254Address: 192.168.163.254#53# nslookup&gt; baidu.comServer: 192.168.163.254Address: 192.168.163.254#53 dig：查询DNS服务器 123dig -t 指定查询类型 例：dig -t mx|soa|nsdig -x 反向解析 参考书籍：骏马金龙 DNS &amp; bind从基础到深入http://www.cnblogs.com/f-ck-need-u/p/7367503.html骏马金龙 Linux的网络管理http://www.cnblogs.com/f-ck-need-u/p/7074594.htmlLinux就该这么学Linux运维最佳实践Linux系统管理与网络管理Linux服务器架设指南Linux服务器架设、性能调优、集群管理教程]]></content>
      <tags>
        <tag>server</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
</search>
